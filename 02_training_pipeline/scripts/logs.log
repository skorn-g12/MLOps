2023-05-21 15:21:12,884:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:21:12,884:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:21:12,884:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:21:12,884:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:21:16,506:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-21 15:25:42,304:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:25:42,304:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:25:42,304:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:25:42,305:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:25:43,219:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-21 15:26:02,243:INFO:PyCaret ClassificationExperiment
2023-05-21 15:26:02,243:INFO:Logging name: baseline_allFeatures
2023-05-21 15:26:02,244:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-21 15:26:02,244:INFO:version 3.0.0
2023-05-21 15:26:02,244:INFO:Initializing setup()
2023-05-21 15:26:02,244:INFO:self.USI: 2f3b
2023-05-21 15:26:02,245:INFO:self._variable_keys: {'fix_imbalance', 'pipeline', 'gpu_n_jobs_param', 'logging_param', 'X', 'html_param', 'y_train', 'fold_generator', 'X_test', 'n_jobs_param', 'y_test', 'seed', 'y', 'fold_shuffle_param', 'is_multiclass', 'fold_groups_param', '_ml_usecase', 'USI', '_available_plots', 'log_plots_param', 'X_train', 'exp_id', 'exp_name_log', 'data', 'target_param', 'idx', 'gpu_param', 'memory'}
2023-05-21 15:26:02,245:INFO:Checking environment
2023-05-21 15:26:02,245:INFO:python_version: 3.10.10
2023-05-21 15:26:02,246:INFO:python_build: ('main', 'Mar  5 2023 22:26:53')
2023-05-21 15:26:02,246:INFO:machine: x86_64
2023-05-21 15:26:02,248:INFO:platform: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 15:26:02,249:INFO:Memory: svmem(total=16717086720, available=5188038656, percent=69.0, used=10984357888, free=3529998336, active=6746091520, inactive=2833252352, buffers=75845632, cached=2126884864, shared=201261056, slab=455487488)
2023-05-21 15:26:02,255:INFO:Physical Core: 6
2023-05-21 15:26:02,255:INFO:Logical Core: 12
2023-05-21 15:26:02,255:INFO:Checking libraries
2023-05-21 15:26:02,255:INFO:System:
2023-05-21 15:26:02,256:INFO:    python: 3.10.10 (main, Mar  5 2023, 22:26:53) [GCC 12.2.1 20230201]
2023-05-21 15:26:02,256:INFO:executable: /usr/bin/python3.10
2023-05-21 15:26:02,256:INFO:   machine: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 15:26:02,257:INFO:PyCaret required dependencies:
2023-05-21 15:26:02,258:INFO:                 pip: 23.0.1
2023-05-21 15:26:02,258:INFO:          setuptools: 67.6.1
2023-05-21 15:26:02,258:INFO:             pycaret: 3.0.0
2023-05-21 15:26:02,258:INFO:             IPython: 8.12.0
2023-05-21 15:26:02,259:INFO:          ipywidgets: 7.7.5
2023-05-21 15:26:02,259:INFO:                tqdm: 4.64.1
2023-05-21 15:26:02,259:INFO:               numpy: 1.23.0
2023-05-21 15:26:02,260:INFO:              pandas: 1.5.3
2023-05-21 15:26:02,260:INFO:              jinja2: 3.1.2
2023-05-21 15:26:02,260:INFO:               scipy: 1.9.3
2023-05-21 15:26:02,260:INFO:              joblib: 1.2.0
2023-05-21 15:26:02,261:INFO:             sklearn: 1.2.2
2023-05-21 15:26:02,261:INFO:                pyod: 1.0.9
2023-05-21 15:26:02,261:INFO:            imblearn: 0.10.1
2023-05-21 15:26:02,262:INFO:   category_encoders: 2.6.0
2023-05-21 15:26:02,262:INFO:            lightgbm: 3.3.5
2023-05-21 15:26:02,262:INFO:               numba: 0.57.0
2023-05-21 15:26:02,262:INFO:            requests: 2.28.2
2023-05-21 15:26:02,263:INFO:          matplotlib: 3.6.3
2023-05-21 15:26:02,263:INFO:          scikitplot: 0.3.7
2023-05-21 15:26:02,263:INFO:         yellowbrick: 1.5
2023-05-21 15:26:02,263:INFO:              plotly: 5.14.1
2023-05-21 15:26:02,264:INFO:             kaleido: 0.2.1
2023-05-21 15:26:02,264:INFO:         statsmodels: 0.13.5
2023-05-21 15:26:02,264:INFO:              sktime: 0.18.0
2023-05-21 15:26:02,265:INFO:               tbats: 1.1.3
2023-05-21 15:26:02,265:INFO:            pmdarima: 2.0.3
2023-05-21 15:26:02,265:INFO:              psutil: 5.9.4
2023-05-21 15:26:02,265:INFO:PyCaret optional dependencies:
2023-05-21 15:26:02,320:INFO:                shap: 0.41.0
2023-05-21 15:26:02,320:INFO:           interpret: 0.3.2
2023-05-21 15:26:02,321:INFO:                umap: 0.5.3
2023-05-21 15:26:02,321:INFO:    pandas_profiling: 3.6.6
2023-05-21 15:26:02,321:INFO:  explainerdashboard: 0.4.2.2
2023-05-21 15:26:02,322:INFO:             autoviz: 0.1.603
2023-05-21 15:26:02,322:INFO:           fairlearn: 0.7.0
2023-05-21 15:26:02,322:INFO:             xgboost: 1.7.5
2023-05-21 15:26:02,322:INFO:            catboost: Not installed
2023-05-21 15:26:02,323:INFO:              kmodes: Not installed
2023-05-21 15:26:02,323:INFO:             mlxtend: Not installed
2023-05-21 15:26:02,323:INFO:       statsforecast: Not installed
2023-05-21 15:26:02,324:INFO:        tune_sklearn: Not installed
2023-05-21 15:26:02,324:INFO:                 ray: Not installed
2023-05-21 15:26:02,324:INFO:            hyperopt: Not installed
2023-05-21 15:26:02,324:INFO:              optuna: 3.1.1
2023-05-21 15:26:02,325:INFO:               skopt: Not installed
2023-05-21 15:26:02,325:INFO:              mlflow: 2.3.1
2023-05-21 15:26:02,325:INFO:              gradio: Not installed
2023-05-21 15:26:02,325:INFO:             fastapi: Not installed
2023-05-21 15:26:02,326:INFO:             uvicorn: Not installed
2023-05-21 15:26:02,326:INFO:              m2cgen: Not installed
2023-05-21 15:26:02,326:INFO:           evidently: Not installed
2023-05-21 15:26:02,327:INFO:               fugue: Not installed
2023-05-21 15:26:02,327:INFO:           streamlit: Not installed
2023-05-21 15:26:02,327:INFO:             prophet: Not installed
2023-05-21 15:26:02,327:INFO:None
2023-05-21 15:26:02,328:INFO:Set up data.
2023-05-21 15:26:02,488:INFO:Set up train/test split.
2023-05-21 15:26:02,608:INFO:Set up index.
2023-05-21 15:26:02,609:INFO:Set up folding strategy.
2023-05-21 15:26:02,610:INFO:Assigning column types.
2023-05-21 15:26:02,628:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-21 15:26:02,679:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 15:26:02,757:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:26:02,880:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:26:03,454:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:26:03,506:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 15:26:03,508:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:26:03,543:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:26:03,547:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:26:03,548:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-21 15:26:03,601:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:26:03,634:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:26:03,637:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:26:03,690:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:26:03,723:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:26:03,726:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:26:03,727:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-21 15:26:03,822:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:26:03,827:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:26:03,950:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:26:03,956:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:26:03,965:INFO:Preparing preprocessing pipeline...
2023-05-21 15:26:03,980:INFO:Set up simple imputation.
2023-05-21 15:26:04,019:INFO:Set up encoding of categorical features.
2023-05-21 15:26:05,384:INFO:Finished creating preprocessing pipeline.
2023-05-21 15:26:05,427:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 15:26:05,427:INFO:Creating final display dataframe.
2023-05-21 15:26:08,549:INFO:Setup _display_container:                     Description                 Value
0                    Session id                    42
1                        Target     app_complete_flag
2                   Target type                Binary
3           Original data shape           (238964, 7)
4        Transformed data shape          (238964, 39)
5   Transformed train set shape          (167274, 39)
6    Transformed test set shape           (71690, 39)
7              Numeric features                     3
8          Categorical features                     3
9                    Preprocess                  True
10              Imputation type                simple
11           Numeric imputation                  mean
12       Categorical imputation                  mode
13     Maximum one-hot encoding                    25
14              Encoding method                  None
15               Fold Generator       StratifiedKFold
16                  Fold Number                    10
17                     CPU Jobs                    -1
18                      Use GPU                 False
19               Log Experiment          MlflowLogger
20              Experiment Name  baseline_allFeatures
21                          USI                  2f3b
2023-05-21 15:26:08,660:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:26:08,663:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:26:08,748:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:26:08,751:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:26:08,753:INFO:Logging experiment in loggers
2023-05-21 15:26:10,306:INFO:SubProcess save_model() called ==================================
2023-05-21 15:26:10,421:INFO:Initializing save_model()
2023-05-21 15:26:10,421:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/tmp/tmp8_wus1n7/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-21 15:26:10,421:INFO:Adding model into prep_pipe
2023-05-21 15:26:10,428:WARNING:Only Model saved as it was a pipeline.
2023-05-21 15:26:10,469:INFO:/tmp/tmp8_wus1n7/Transformation Pipeline.pkl saved in current working directory
2023-05-21 15:26:10,510:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 15:26:10,510:INFO:save_model() successfully completed......................................
2023-05-21 15:26:10,627:INFO:SubProcess save_model() end ==================================
2023-05-21 15:26:11,346:INFO:setup() successfully completed in 6.51s...............
2023-05-21 15:31:07,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:31:07,027:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:31:07,027:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:31:07,027:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:31:10,095:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-21 15:33:07,384:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:33:07,384:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:33:07,385:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:33:07,385:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:33:08,281:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-21 15:33:23,372:INFO:PyCaret ClassificationExperiment
2023-05-21 15:33:23,372:INFO:Logging name: clf-default-name
2023-05-21 15:33:23,372:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-21 15:33:23,372:INFO:version 3.0.0
2023-05-21 15:33:23,373:INFO:Initializing setup()
2023-05-21 15:33:23,373:INFO:self.USI: ecb6
2023-05-21 15:33:23,373:INFO:self._variable_keys: {'USI', '_ml_usecase', 'seed', 'pipeline', 'memory', 'gpu_n_jobs_param', 'X', 'X_train', 'y_train', 'y', 'data', 'log_plots_param', 'logging_param', 'exp_id', 'is_multiclass', '_available_plots', 'fold_groups_param', 'fold_shuffle_param', 'y_test', 'exp_name_log', 'fold_generator', 'n_jobs_param', 'X_test', 'gpu_param', 'fix_imbalance', 'html_param', 'idx', 'target_param'}
2023-05-21 15:33:23,374:INFO:Checking environment
2023-05-21 15:33:23,374:INFO:python_version: 3.10.10
2023-05-21 15:33:23,374:INFO:python_build: ('main', 'Mar  5 2023 22:26:53')
2023-05-21 15:33:23,374:INFO:machine: x86_64
2023-05-21 15:33:23,377:INFO:platform: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 15:33:23,378:INFO:Memory: svmem(total=16717086720, available=5682036736, percent=66.0, used=10351669248, free=4112691200, active=5316448256, inactive=3685445632, buffers=30412800, cached=2222313472, shared=339951616, slab=452874240)
2023-05-21 15:33:23,383:INFO:Physical Core: 6
2023-05-21 15:33:23,383:INFO:Logical Core: 12
2023-05-21 15:33:23,384:INFO:Checking libraries
2023-05-21 15:33:23,384:INFO:System:
2023-05-21 15:33:23,384:INFO:    python: 3.10.10 (main, Mar  5 2023, 22:26:53) [GCC 12.2.1 20230201]
2023-05-21 15:33:23,385:INFO:executable: /usr/bin/python3.10
2023-05-21 15:33:23,385:INFO:   machine: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 15:33:23,385:INFO:PyCaret required dependencies:
2023-05-21 15:33:23,387:INFO:                 pip: 23.0.1
2023-05-21 15:33:23,387:INFO:          setuptools: 67.6.1
2023-05-21 15:33:23,387:INFO:             pycaret: 3.0.0
2023-05-21 15:33:23,388:INFO:             IPython: 8.12.0
2023-05-21 15:33:23,388:INFO:          ipywidgets: 7.7.5
2023-05-21 15:33:23,388:INFO:                tqdm: 4.64.1
2023-05-21 15:33:23,389:INFO:               numpy: 1.23.0
2023-05-21 15:33:23,389:INFO:              pandas: 1.5.3
2023-05-21 15:33:23,389:INFO:              jinja2: 3.1.2
2023-05-21 15:33:23,390:INFO:               scipy: 1.9.3
2023-05-21 15:33:23,390:INFO:              joblib: 1.2.0
2023-05-21 15:33:23,390:INFO:             sklearn: 1.2.2
2023-05-21 15:33:23,390:INFO:                pyod: 1.0.9
2023-05-21 15:33:23,391:INFO:            imblearn: 0.10.1
2023-05-21 15:33:23,391:INFO:   category_encoders: 2.6.0
2023-05-21 15:33:23,391:INFO:            lightgbm: 3.3.5
2023-05-21 15:33:23,392:INFO:               numba: 0.57.0
2023-05-21 15:33:23,392:INFO:            requests: 2.28.2
2023-05-21 15:33:23,392:INFO:          matplotlib: 3.6.3
2023-05-21 15:33:23,393:INFO:          scikitplot: 0.3.7
2023-05-21 15:33:23,393:INFO:         yellowbrick: 1.5
2023-05-21 15:33:23,393:INFO:              plotly: 5.14.1
2023-05-21 15:33:23,394:INFO:             kaleido: 0.2.1
2023-05-21 15:33:23,394:INFO:         statsmodels: 0.13.5
2023-05-21 15:33:23,394:INFO:              sktime: 0.18.0
2023-05-21 15:33:23,394:INFO:               tbats: 1.1.3
2023-05-21 15:33:23,395:INFO:            pmdarima: 2.0.3
2023-05-21 15:33:23,395:INFO:              psutil: 5.9.4
2023-05-21 15:33:23,395:INFO:PyCaret optional dependencies:
2023-05-21 15:33:23,455:INFO:                shap: 0.41.0
2023-05-21 15:33:23,455:INFO:           interpret: 0.3.2
2023-05-21 15:33:23,456:INFO:                umap: 0.5.3
2023-05-21 15:33:23,456:INFO:    pandas_profiling: 3.6.6
2023-05-21 15:33:23,456:INFO:  explainerdashboard: 0.4.2.2
2023-05-21 15:33:23,457:INFO:             autoviz: 0.1.603
2023-05-21 15:33:23,457:INFO:           fairlearn: 0.7.0
2023-05-21 15:33:23,457:INFO:             xgboost: 1.7.5
2023-05-21 15:33:23,458:INFO:            catboost: Not installed
2023-05-21 15:33:23,458:INFO:              kmodes: Not installed
2023-05-21 15:33:23,458:INFO:             mlxtend: Not installed
2023-05-21 15:33:23,459:INFO:       statsforecast: Not installed
2023-05-21 15:33:23,459:INFO:        tune_sklearn: Not installed
2023-05-21 15:33:23,460:INFO:                 ray: Not installed
2023-05-21 15:33:23,460:INFO:            hyperopt: Not installed
2023-05-21 15:33:23,460:INFO:              optuna: 3.1.1
2023-05-21 15:33:23,461:INFO:               skopt: Not installed
2023-05-21 15:33:23,461:INFO:              mlflow: 2.3.1
2023-05-21 15:33:23,461:INFO:              gradio: Not installed
2023-05-21 15:33:23,462:INFO:             fastapi: Not installed
2023-05-21 15:33:23,462:INFO:             uvicorn: Not installed
2023-05-21 15:33:23,462:INFO:              m2cgen: Not installed
2023-05-21 15:33:23,463:INFO:           evidently: Not installed
2023-05-21 15:33:23,463:INFO:               fugue: Not installed
2023-05-21 15:33:23,463:INFO:           streamlit: Not installed
2023-05-21 15:33:23,464:INFO:             prophet: Not installed
2023-05-21 15:33:23,464:INFO:None
2023-05-21 15:33:23,464:INFO:Set up data.
2023-05-21 15:33:23,624:INFO:Set up train/test split.
2023-05-21 15:33:23,707:INFO:Set up index.
2023-05-21 15:33:23,708:INFO:Set up folding strategy.
2023-05-21 15:33:23,708:INFO:Assigning column types.
2023-05-21 15:33:23,729:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-21 15:33:23,784:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 15:33:23,799:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:33:23,881:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:33:24,042:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:33:24,100:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 15:33:24,101:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:33:24,136:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:33:24,140:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:33:24,141:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-21 15:33:24,195:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:33:24,230:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:33:24,234:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:33:24,291:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:33:24,326:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:33:24,330:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:33:24,330:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-21 15:33:24,419:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:33:24,423:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:33:24,514:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:33:24,518:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:33:24,524:INFO:Preparing preprocessing pipeline...
2023-05-21 15:33:24,530:INFO:Set up simple imputation.
2023-05-21 15:33:24,558:INFO:Set up encoding of categorical features.
2023-05-21 15:33:24,962:INFO:Finished creating preprocessing pipeline.
2023-05-21 15:33:25,012:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 15:33:25,012:INFO:Creating final display dataframe.
2023-05-21 15:33:27,185:INFO:Setup _display_container:                     Description              Value
0                    Session id                 42
1                        Target  app_complete_flag
2                   Target type             Binary
3           Original data shape        (238964, 7)
4        Transformed data shape       (238964, 39)
5   Transformed train set shape       (167274, 39)
6    Transformed test set shape        (71690, 39)
7              Numeric features                  3
8          Categorical features                  3
9                    Preprocess               True
10              Imputation type             simple
11           Numeric imputation               mean
12       Categorical imputation               mode
13     Maximum one-hot encoding                 25
14              Encoding method               None
15               Fold Generator    StratifiedKFold
16                  Fold Number                 10
17                     CPU Jobs                 -1
18                      Use GPU              False
19               Log Experiment       MlflowLogger
20              Experiment Name   clf-default-name
21                          USI               ecb6
2023-05-21 15:33:27,300:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:33:27,303:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:33:27,393:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:33:27,397:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:33:27,399:INFO:Logging experiment in loggers
2023-05-21 15:33:28,023:INFO:SubProcess save_model() called ==================================
2023-05-21 15:33:28,115:INFO:Initializing save_model()
2023-05-21 15:33:28,115:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/tmp/tmp4p3ycyd4/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-21 15:33:28,116:INFO:Adding model into prep_pipe
2023-05-21 15:33:28,123:WARNING:Only Model saved as it was a pipeline.
2023-05-21 15:33:28,171:INFO:/tmp/tmp4p3ycyd4/Transformation Pipeline.pkl saved in current working directory
2023-05-21 15:33:28,217:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 15:33:28,217:INFO:save_model() successfully completed......................................
2023-05-21 15:33:28,335:INFO:SubProcess save_model() end ==================================
2023-05-21 15:33:28,955:INFO:setup() successfully completed in 4.03s...............
2023-05-21 15:33:30,502:INFO:Initializing compare_models()
2023-05-21 15:33:30,503:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde0ea3fdc0>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fde0ea3fdc0>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'])
2023-05-21 15:33:30,503:INFO:Checking exceptions
2023-05-21 15:33:30,570:INFO:Preparing display monitor
2023-05-21 15:33:30,591:INFO:Initializing Logistic Regression
2023-05-21 15:33:30,592:INFO:Total runtime is 8.408228556315104e-06 minutes
2023-05-21 15:33:30,593:INFO:SubProcess create_model() called ==================================
2023-05-21 15:33:30,594:INFO:Initializing create_model()
2023-05-21 15:33:30,594:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde0ea3fdc0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fddd3cfa8f0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:33:30,594:INFO:Checking exceptions
2023-05-21 15:33:30,595:INFO:Importing libraries
2023-05-21 15:33:30,595:INFO:Copying training dataset
2023-05-21 15:33:30,646:INFO:Defining folds
2023-05-21 15:33:30,647:INFO:Declaring metric variables
2023-05-21 15:33:30,647:INFO:Importing untrained model
2023-05-21 15:33:30,650:INFO:Logistic Regression Imported successfully
2023-05-21 15:33:30,651:INFO:Starting cross validation
2023-05-21 15:33:30,662:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:34:00,230:INFO:Calculating mean and std
2023-05-21 15:34:00,247:INFO:Creating metrics dataframe
2023-05-21 15:34:00,303:INFO:Uploading results into container
2023-05-21 15:34:00,308:INFO:Uploading model into container now
2023-05-21 15:34:00,311:INFO:_master_model_container: 1
2023-05-21 15:34:00,311:INFO:_display_container: 2
2023-05-21 15:34:00,316:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-21 15:34:00,317:INFO:create_model() successfully completed......................................
2023-05-21 15:34:00,446:INFO:SubProcess create_model() end ==================================
2023-05-21 15:34:00,446:INFO:Creating metrics dataframe
2023-05-21 15:34:00,469:INFO:Initializing Naive Bayes
2023-05-21 15:34:00,470:INFO:Total runtime is 0.4979757269223531 minutes
2023-05-21 15:34:00,470:INFO:SubProcess create_model() called ==================================
2023-05-21 15:34:00,471:INFO:Initializing create_model()
2023-05-21 15:34:00,471:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde0ea3fdc0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fddd3cfa8f0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:34:00,471:INFO:Checking exceptions
2023-05-21 15:34:00,471:INFO:Importing libraries
2023-05-21 15:34:00,471:INFO:Copying training dataset
2023-05-21 15:34:00,516:INFO:Defining folds
2023-05-21 15:34:00,517:INFO:Declaring metric variables
2023-05-21 15:34:00,518:INFO:Importing untrained model
2023-05-21 15:34:00,519:INFO:Naive Bayes Imported successfully
2023-05-21 15:34:00,520:INFO:Starting cross validation
2023-05-21 15:34:00,530:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:34:13,331:INFO:Calculating mean and std
2023-05-21 15:34:13,333:INFO:Creating metrics dataframe
2023-05-21 15:34:13,397:INFO:Uploading results into container
2023-05-21 15:34:13,400:INFO:Uploading model into container now
2023-05-21 15:34:13,403:INFO:_master_model_container: 2
2023-05-21 15:34:13,404:INFO:_display_container: 2
2023-05-21 15:34:13,405:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-21 15:34:13,405:INFO:create_model() successfully completed......................................
2023-05-21 15:34:13,518:INFO:SubProcess create_model() end ==================================
2023-05-21 15:34:13,519:INFO:Creating metrics dataframe
2023-05-21 15:34:13,542:INFO:Initializing Decision Tree Classifier
2023-05-21 15:34:13,542:INFO:Total runtime is 0.7158559362093607 minutes
2023-05-21 15:34:13,543:INFO:SubProcess create_model() called ==================================
2023-05-21 15:34:13,544:INFO:Initializing create_model()
2023-05-21 15:34:13,544:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde0ea3fdc0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fddd3cfa8f0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:34:13,544:INFO:Checking exceptions
2023-05-21 15:34:13,544:INFO:Importing libraries
2023-05-21 15:34:13,544:INFO:Copying training dataset
2023-05-21 15:34:13,582:INFO:Defining folds
2023-05-21 15:34:13,582:INFO:Declaring metric variables
2023-05-21 15:34:13,583:INFO:Importing untrained model
2023-05-21 15:34:13,585:INFO:Decision Tree Classifier Imported successfully
2023-05-21 15:34:13,586:INFO:Starting cross validation
2023-05-21 15:34:13,594:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:34:16,404:INFO:Calculating mean and std
2023-05-21 15:34:16,407:INFO:Creating metrics dataframe
2023-05-21 15:34:16,452:INFO:Uploading results into container
2023-05-21 15:34:16,454:INFO:Uploading model into container now
2023-05-21 15:34:16,456:INFO:_master_model_container: 3
2023-05-21 15:34:16,456:INFO:_display_container: 2
2023-05-21 15:34:16,458:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-05-21 15:34:16,458:INFO:create_model() successfully completed......................................
2023-05-21 15:34:16,579:INFO:SubProcess create_model() end ==================================
2023-05-21 15:34:16,579:INFO:Creating metrics dataframe
2023-05-21 15:34:16,602:INFO:Initializing Ridge Classifier
2023-05-21 15:34:16,603:INFO:Total runtime is 0.7668588717778524 minutes
2023-05-21 15:34:16,603:INFO:SubProcess create_model() called ==================================
2023-05-21 15:34:16,604:INFO:Initializing create_model()
2023-05-21 15:34:16,604:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde0ea3fdc0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fddd3cfa8f0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:34:16,604:INFO:Checking exceptions
2023-05-21 15:34:16,604:INFO:Importing libraries
2023-05-21 15:34:16,604:INFO:Copying training dataset
2023-05-21 15:34:16,642:INFO:Defining folds
2023-05-21 15:34:16,642:INFO:Declaring metric variables
2023-05-21 15:34:16,643:INFO:Importing untrained model
2023-05-21 15:34:16,644:INFO:Ridge Classifier Imported successfully
2023-05-21 15:34:16,645:INFO:Starting cross validation
2023-05-21 15:34:16,653:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:34:18,420:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:34:18,420:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:34:18,434:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:34:18,447:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:34:18,481:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:34:18,591:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:34:18,599:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:34:18,640:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:34:18,718:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:34:18,749:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:34:18,885:INFO:Calculating mean and std
2023-05-21 15:34:18,886:INFO:Creating metrics dataframe
2023-05-21 15:34:18,927:INFO:Uploading results into container
2023-05-21 15:34:18,929:INFO:Uploading model into container now
2023-05-21 15:34:18,931:INFO:_master_model_container: 4
2023-05-21 15:34:18,931:INFO:_display_container: 2
2023-05-21 15:34:18,933:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-05-21 15:34:18,933:INFO:create_model() successfully completed......................................
2023-05-21 15:34:19,048:INFO:SubProcess create_model() end ==================================
2023-05-21 15:34:19,048:INFO:Creating metrics dataframe
2023-05-21 15:34:19,074:INFO:Initializing Random Forest Classifier
2023-05-21 15:34:19,074:INFO:Total runtime is 0.8080472151438395 minutes
2023-05-21 15:34:19,074:INFO:SubProcess create_model() called ==================================
2023-05-21 15:34:19,075:INFO:Initializing create_model()
2023-05-21 15:34:19,075:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde0ea3fdc0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fddd3cfa8f0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:34:19,075:INFO:Checking exceptions
2023-05-21 15:34:19,076:INFO:Importing libraries
2023-05-21 15:34:19,076:INFO:Copying training dataset
2023-05-21 15:34:19,116:INFO:Defining folds
2023-05-21 15:34:19,116:INFO:Declaring metric variables
2023-05-21 15:34:19,117:INFO:Importing untrained model
2023-05-21 15:34:19,119:INFO:Random Forest Classifier Imported successfully
2023-05-21 15:34:19,121:INFO:Starting cross validation
2023-05-21 15:34:19,128:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:34:50,309:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 15:34:50,329:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 15:34:50,415:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 15:34:50,524:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 15:34:50,579:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 15:34:50,633:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 15:34:50,639:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 15:34:50,639:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 15:34:51,535:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 15:34:51,677:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 15:34:51,702:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 15:34:51,798:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 15:34:51,854:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 15:34:51,855:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 15:34:51,896:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 15:34:52,915:INFO:Calculating mean and std
2023-05-21 15:34:52,917:INFO:Creating metrics dataframe
2023-05-21 15:34:53,001:INFO:Uploading results into container
2023-05-21 15:34:53,003:INFO:Uploading model into container now
2023-05-21 15:34:53,005:INFO:_master_model_container: 5
2023-05-21 15:34:53,005:INFO:_display_container: 2
2023-05-21 15:34:53,008:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-05-21 15:34:53,008:INFO:create_model() successfully completed......................................
2023-05-21 15:34:53,127:INFO:SubProcess create_model() end ==================================
2023-05-21 15:34:53,127:INFO:Creating metrics dataframe
2023-05-21 15:34:53,150:INFO:Initializing Linear Discriminant Analysis
2023-05-21 15:34:53,150:INFO:Total runtime is 1.3759906053543092 minutes
2023-05-21 15:34:53,151:INFO:SubProcess create_model() called ==================================
2023-05-21 15:34:53,152:INFO:Initializing create_model()
2023-05-21 15:34:53,152:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde0ea3fdc0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fddd3cfa8f0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:34:53,152:INFO:Checking exceptions
2023-05-21 15:34:53,152:INFO:Importing libraries
2023-05-21 15:34:53,152:INFO:Copying training dataset
2023-05-21 15:34:53,188:INFO:Defining folds
2023-05-21 15:34:53,188:INFO:Declaring metric variables
2023-05-21 15:34:53,189:INFO:Importing untrained model
2023-05-21 15:34:53,190:INFO:Linear Discriminant Analysis Imported successfully
2023-05-21 15:34:53,191:INFO:Starting cross validation
2023-05-21 15:34:53,199:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:35:00,818:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 15:35:00,908:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 15:35:01,054:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 15:35:02,171:INFO:Calculating mean and std
2023-05-21 15:35:02,187:INFO:Creating metrics dataframe
2023-05-21 15:35:02,276:INFO:Uploading results into container
2023-05-21 15:35:02,278:INFO:Uploading model into container now
2023-05-21 15:35:02,279:INFO:_master_model_container: 6
2023-05-21 15:35:02,279:INFO:_display_container: 2
2023-05-21 15:35:02,281:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-21 15:35:02,281:INFO:create_model() successfully completed......................................
2023-05-21 15:35:02,401:INFO:SubProcess create_model() end ==================================
2023-05-21 15:35:02,401:INFO:Creating metrics dataframe
2023-05-21 15:35:02,424:INFO:Initializing Extra Trees Classifier
2023-05-21 15:35:02,425:INFO:Total runtime is 1.5305620789527894 minutes
2023-05-21 15:35:02,425:INFO:SubProcess create_model() called ==================================
2023-05-21 15:35:02,426:INFO:Initializing create_model()
2023-05-21 15:35:02,426:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde0ea3fdc0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fddd3cfa8f0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:35:02,426:INFO:Checking exceptions
2023-05-21 15:35:02,426:INFO:Importing libraries
2023-05-21 15:35:02,427:INFO:Copying training dataset
2023-05-21 15:35:02,464:INFO:Defining folds
2023-05-21 15:35:02,465:INFO:Declaring metric variables
2023-05-21 15:35:02,465:INFO:Importing untrained model
2023-05-21 15:35:02,468:INFO:Extra Trees Classifier Imported successfully
2023-05-21 15:35:02,469:INFO:Starting cross validation
2023-05-21 15:35:02,477:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:35:39,132:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 15:35:39,567:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 15:35:39,609:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 15:35:39,678:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 15:35:39,680:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 15:35:39,737:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 15:35:39,782:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 15:35:39,804:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 15:35:39,888:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 15:35:40,456:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 15:35:40,854:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 15:35:40,980:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 15:35:40,993:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 15:35:41,022:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 15:35:41,120:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 15:35:41,156:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 15:35:41,561:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 15:35:42,203:INFO:Calculating mean and std
2023-05-21 15:35:42,205:INFO:Creating metrics dataframe
2023-05-21 15:35:42,297:INFO:Uploading results into container
2023-05-21 15:35:42,299:INFO:Uploading model into container now
2023-05-21 15:35:42,300:INFO:_master_model_container: 7
2023-05-21 15:35:42,300:INFO:_display_container: 2
2023-05-21 15:35:42,303:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-05-21 15:35:42,303:INFO:create_model() successfully completed......................................
2023-05-21 15:35:42,415:INFO:SubProcess create_model() end ==================================
2023-05-21 15:35:42,416:INFO:Creating metrics dataframe
2023-05-21 15:35:42,439:INFO:Initializing Extreme Gradient Boosting
2023-05-21 15:35:42,439:INFO:Total runtime is 2.1974733591079714 minutes
2023-05-21 15:35:42,440:INFO:SubProcess create_model() called ==================================
2023-05-21 15:35:42,441:INFO:Initializing create_model()
2023-05-21 15:35:42,441:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde0ea3fdc0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fddd3cfa8f0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:35:42,441:INFO:Checking exceptions
2023-05-21 15:35:42,441:INFO:Importing libraries
2023-05-21 15:35:42,441:INFO:Copying training dataset
2023-05-21 15:35:42,477:INFO:Defining folds
2023-05-21 15:35:42,478:INFO:Declaring metric variables
2023-05-21 15:35:42,478:INFO:Importing untrained model
2023-05-21 15:35:42,483:INFO:Extreme Gradient Boosting Imported successfully
2023-05-21 15:35:42,484:INFO:Starting cross validation
2023-05-21 15:35:42,492:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:36:26,314:INFO:Calculating mean and std
2023-05-21 15:36:26,328:INFO:Creating metrics dataframe
2023-05-21 15:36:26,428:INFO:Uploading results into container
2023-05-21 15:36:26,431:INFO:Uploading model into container now
2023-05-21 15:36:26,433:INFO:_master_model_container: 8
2023-05-21 15:36:26,433:INFO:_display_container: 2
2023-05-21 15:36:26,439:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-05-21 15:36:26,439:INFO:create_model() successfully completed......................................
2023-05-21 15:36:26,555:INFO:SubProcess create_model() end ==================================
2023-05-21 15:36:26,556:INFO:Creating metrics dataframe
2023-05-21 15:36:26,579:INFO:Initializing Light Gradient Boosting Machine
2023-05-21 15:36:26,580:INFO:Total runtime is 2.933143266042074 minutes
2023-05-21 15:36:26,580:INFO:SubProcess create_model() called ==================================
2023-05-21 15:36:26,581:INFO:Initializing create_model()
2023-05-21 15:36:26,581:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde0ea3fdc0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fddd3cfa8f0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:36:26,581:INFO:Checking exceptions
2023-05-21 15:36:26,581:INFO:Importing libraries
2023-05-21 15:36:26,582:INFO:Copying training dataset
2023-05-21 15:36:26,618:INFO:Defining folds
2023-05-21 15:36:26,618:INFO:Declaring metric variables
2023-05-21 15:36:26,619:INFO:Importing untrained model
2023-05-21 15:36:26,621:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 15:36:26,622:INFO:Starting cross validation
2023-05-21 15:36:26,630:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:36:31,489:INFO:Calculating mean and std
2023-05-21 15:36:31,492:INFO:Creating metrics dataframe
2023-05-21 15:36:31,594:INFO:Uploading results into container
2023-05-21 15:36:31,596:INFO:Uploading model into container now
2023-05-21 15:36:31,597:INFO:_master_model_container: 9
2023-05-21 15:36:31,597:INFO:_display_container: 2
2023-05-21 15:36:31,600:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 15:36:31,601:INFO:create_model() successfully completed......................................
2023-05-21 15:36:31,713:INFO:SubProcess create_model() end ==================================
2023-05-21 15:36:31,713:INFO:Creating metrics dataframe
2023-05-21 15:36:31,756:INFO:Initializing create_model()
2023-05-21 15:36:31,756:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde0ea3fdc0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:36:31,756:INFO:Checking exceptions
2023-05-21 15:36:31,759:INFO:Importing libraries
2023-05-21 15:36:31,759:INFO:Copying training dataset
2023-05-21 15:36:31,805:INFO:Defining folds
2023-05-21 15:36:31,805:INFO:Declaring metric variables
2023-05-21 15:36:31,806:INFO:Importing untrained model
2023-05-21 15:36:31,806:INFO:Declaring custom model
2023-05-21 15:36:31,816:INFO:Extreme Gradient Boosting Imported successfully
2023-05-21 15:36:31,829:INFO:Cross validation set to False
2023-05-21 15:36:31,829:INFO:Fitting Model
2023-05-21 15:36:37,402:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-05-21 15:36:37,402:INFO:create_model() successfully completed......................................
2023-05-21 15:36:37,524:INFO:Creating Dashboard logs
2023-05-21 15:36:37,527:INFO:Model: Extreme Gradient Boosting
2023-05-21 15:36:37,693:INFO:Logged params: {'objective': 'binary:logistic', 'use_label_encoder': None, 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': -1, 'num_parallel_tree': None, 'predictor': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2023-05-21 15:36:38,882:INFO:Initializing predict_model()
2023-05-21 15:36:38,882:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde0ea3fdc0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fddd4be8af0>)
2023-05-21 15:36:38,883:INFO:Checking exceptions
2023-05-21 15:36:38,883:INFO:Preloading libraries
2023-05-21 15:36:39,657:INFO:SubProcess plot_model() called ==================================
2023-05-21 15:36:39,663:INFO:Initializing plot_model()
2023-05-21 15:36:39,664:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpwdg7dh38, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde0ea3fdc0>, system=False)
2023-05-21 15:36:39,664:INFO:Checking exceptions
2023-05-21 15:36:39,680:INFO:Preloading libraries
2023-05-21 15:36:39,684:INFO:Copying training dataset
2023-05-21 15:36:39,684:INFO:Plot type: auc
2023-05-21 15:36:42,460:INFO:Fitting Model
2023-05-21 15:36:42,472:INFO:Scoring test/hold-out set
2023-05-21 15:36:42,833:INFO:Saving '/tmp/tmpwdg7dh38/AUC.png'
2023-05-21 15:36:44,409:INFO:Visual Rendered Successfully
2023-05-21 15:36:44,541:INFO:plot_model() successfully completed......................................
2023-05-21 15:36:44,548:INFO:Initializing plot_model()
2023-05-21 15:36:44,548:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpwdg7dh38, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde0ea3fdc0>, system=False)
2023-05-21 15:36:44,548:INFO:Checking exceptions
2023-05-21 15:36:44,566:INFO:Preloading libraries
2023-05-21 15:36:44,573:INFO:Copying training dataset
2023-05-21 15:36:44,573:INFO:Plot type: confusion_matrix
2023-05-21 15:36:45,118:INFO:Fitting Model
2023-05-21 15:36:45,124:INFO:Scoring test/hold-out set
2023-05-21 15:36:45,345:INFO:Saving '/tmp/tmpwdg7dh38/Confusion Matrix.png'
2023-05-21 15:36:45,821:INFO:Visual Rendered Successfully
2023-05-21 15:36:45,955:INFO:plot_model() successfully completed......................................
2023-05-21 15:36:45,962:INFO:Initializing plot_model()
2023-05-21 15:36:45,963:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpwdg7dh38, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde0ea3fdc0>, system=False)
2023-05-21 15:36:45,963:INFO:Checking exceptions
2023-05-21 15:36:45,979:INFO:Preloading libraries
2023-05-21 15:36:45,985:INFO:Copying training dataset
2023-05-21 15:36:45,986:INFO:Plot type: feature
2023-05-21 15:36:45,992:WARNING:No coef_ found. Trying feature_importances_
2023-05-21 15:36:46,301:INFO:Saving '/tmp/tmpwdg7dh38/Feature Importance.png'
2023-05-21 15:36:46,982:INFO:Visual Rendered Successfully
2023-05-21 15:36:47,125:INFO:plot_model() successfully completed......................................
2023-05-21 15:36:47,126:INFO:SubProcess plot_model() end ==================================
2023-05-21 15:36:47,175:WARNING:/home/feuer/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-05-21 15:36:47,751:INFO:Creating Dashboard logs
2023-05-21 15:36:47,753:INFO:Model: Light Gradient Boosting Machine
2023-05-21 15:36:47,864:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-21 15:36:49,056:INFO:Creating Dashboard logs
2023-05-21 15:36:49,058:INFO:Model: Random Forest Classifier
2023-05-21 15:36:49,328:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 15:36:50,448:INFO:Creating Dashboard logs
2023-05-21 15:36:50,450:INFO:Model: Extra Trees Classifier
2023-05-21 15:36:50,599:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 15:36:51,703:INFO:Creating Dashboard logs
2023-05-21 15:36:51,704:INFO:Model: Decision Tree Classifier
2023-05-21 15:36:51,813:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2023-05-21 15:36:52,950:INFO:Creating Dashboard logs
2023-05-21 15:36:52,952:INFO:Model: Logistic Regression
2023-05-21 15:36:53,074:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-05-21 15:36:54,060:INFO:Creating Dashboard logs
2023-05-21 15:36:54,062:INFO:Model: Linear Discriminant Analysis
2023-05-21 15:36:54,184:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-05-21 15:36:55,153:INFO:Creating Dashboard logs
2023-05-21 15:36:55,154:INFO:Model: Naive Bayes
2023-05-21 15:36:55,270:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-05-21 15:36:56,243:INFO:Creating Dashboard logs
2023-05-21 15:36:56,244:INFO:Model: Ridge Classifier
2023-05-21 15:36:56,347:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2023-05-21 15:36:57,370:INFO:_master_model_container: 9
2023-05-21 15:36:57,370:INFO:_display_container: 2
2023-05-21 15:36:57,376:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-05-21 15:36:57,376:INFO:compare_models() successfully completed......................................
2023-05-21 15:37:32,990:INFO:PyCaret ClassificationExperiment
2023-05-21 15:37:32,990:INFO:Logging name: OnlyImportantFeatures
2023-05-21 15:37:32,990:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-21 15:37:32,990:INFO:version 3.0.0
2023-05-21 15:37:32,991:INFO:Initializing setup()
2023-05-21 15:37:32,991:INFO:self.USI: c3bc
2023-05-21 15:37:32,991:INFO:self._variable_keys: {'USI', '_ml_usecase', 'seed', 'pipeline', 'memory', 'gpu_n_jobs_param', 'X', 'X_train', 'y_train', 'y', 'data', 'log_plots_param', 'logging_param', 'exp_id', 'is_multiclass', '_available_plots', 'fold_groups_param', 'fold_shuffle_param', 'y_test', 'exp_name_log', 'fold_generator', 'n_jobs_param', 'X_test', 'gpu_param', 'fix_imbalance', 'html_param', 'idx', 'target_param'}
2023-05-21 15:37:32,991:INFO:Checking environment
2023-05-21 15:37:32,991:INFO:python_version: 3.10.10
2023-05-21 15:37:32,992:INFO:python_build: ('main', 'Mar  5 2023 22:26:53')
2023-05-21 15:37:32,992:INFO:machine: x86_64
2023-05-21 15:37:32,992:INFO:platform: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 15:37:32,992:INFO:Memory: svmem(total=16717086720, available=875560960, percent=94.8, used=13524271104, free=558534656, active=6857412608, inactive=4747030528, buffers=24625152, cached=2609655808, shared=1845792768, slab=515887104)
2023-05-21 15:37:32,994:INFO:Physical Core: 6
2023-05-21 15:37:32,995:INFO:Logical Core: 12
2023-05-21 15:37:32,995:INFO:Checking libraries
2023-05-21 15:37:32,995:INFO:System:
2023-05-21 15:37:32,995:INFO:    python: 3.10.10 (main, Mar  5 2023, 22:26:53) [GCC 12.2.1 20230201]
2023-05-21 15:37:32,995:INFO:executable: /usr/bin/python3.10
2023-05-21 15:37:32,996:INFO:   machine: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 15:37:32,996:INFO:PyCaret required dependencies:
2023-05-21 15:37:32,996:INFO:                 pip: 23.0.1
2023-05-21 15:37:32,997:INFO:          setuptools: 67.6.1
2023-05-21 15:37:32,997:INFO:             pycaret: 3.0.0
2023-05-21 15:37:32,997:INFO:             IPython: 8.12.0
2023-05-21 15:37:32,997:INFO:          ipywidgets: 7.7.5
2023-05-21 15:37:32,997:INFO:                tqdm: 4.64.1
2023-05-21 15:37:32,997:INFO:               numpy: 1.23.0
2023-05-21 15:37:32,998:INFO:              pandas: 1.5.3
2023-05-21 15:37:32,998:INFO:              jinja2: 3.1.2
2023-05-21 15:37:32,998:INFO:               scipy: 1.9.3
2023-05-21 15:37:32,998:INFO:              joblib: 1.2.0
2023-05-21 15:37:32,998:INFO:             sklearn: 1.2.2
2023-05-21 15:37:32,998:INFO:                pyod: 1.0.9
2023-05-21 15:37:32,999:INFO:            imblearn: 0.10.1
2023-05-21 15:37:32,999:INFO:   category_encoders: 2.6.0
2023-05-21 15:37:32,999:INFO:            lightgbm: 3.3.5
2023-05-21 15:37:32,999:INFO:               numba: 0.57.0
2023-05-21 15:37:32,999:INFO:            requests: 2.28.2
2023-05-21 15:37:32,999:INFO:          matplotlib: 3.6.3
2023-05-21 15:37:33,000:INFO:          scikitplot: 0.3.7
2023-05-21 15:37:33,000:INFO:         yellowbrick: 1.5
2023-05-21 15:37:33,000:INFO:              plotly: 5.14.1
2023-05-21 15:37:33,000:INFO:             kaleido: 0.2.1
2023-05-21 15:37:33,000:INFO:         statsmodels: 0.13.5
2023-05-21 15:37:33,000:INFO:              sktime: 0.18.0
2023-05-21 15:37:33,001:INFO:               tbats: 1.1.3
2023-05-21 15:37:33,001:INFO:            pmdarima: 2.0.3
2023-05-21 15:37:33,001:INFO:              psutil: 5.9.4
2023-05-21 15:37:33,001:INFO:PyCaret optional dependencies:
2023-05-21 15:37:33,002:INFO:                shap: 0.41.0
2023-05-21 15:37:33,002:INFO:           interpret: 0.3.2
2023-05-21 15:37:33,002:INFO:                umap: 0.5.3
2023-05-21 15:37:33,002:INFO:    pandas_profiling: 3.6.6
2023-05-21 15:37:33,002:INFO:  explainerdashboard: 0.4.2.2
2023-05-21 15:37:33,002:INFO:             autoviz: 0.1.603
2023-05-21 15:37:33,003:INFO:           fairlearn: 0.7.0
2023-05-21 15:37:33,003:INFO:             xgboost: 1.7.5
2023-05-21 15:37:33,003:INFO:            catboost: Not installed
2023-05-21 15:37:33,003:INFO:              kmodes: Not installed
2023-05-21 15:37:33,003:INFO:             mlxtend: Not installed
2023-05-21 15:37:33,003:INFO:       statsforecast: Not installed
2023-05-21 15:37:33,004:INFO:        tune_sklearn: Not installed
2023-05-21 15:37:33,004:INFO:                 ray: Not installed
2023-05-21 15:37:33,004:INFO:            hyperopt: Not installed
2023-05-21 15:37:33,004:INFO:              optuna: 3.1.1
2023-05-21 15:37:33,004:INFO:               skopt: Not installed
2023-05-21 15:37:33,004:INFO:              mlflow: 2.3.1
2023-05-21 15:37:33,004:INFO:              gradio: Not installed
2023-05-21 15:37:33,005:INFO:             fastapi: Not installed
2023-05-21 15:37:33,005:INFO:             uvicorn: Not installed
2023-05-21 15:37:33,005:INFO:              m2cgen: Not installed
2023-05-21 15:37:33,005:INFO:           evidently: Not installed
2023-05-21 15:37:33,005:INFO:               fugue: Not installed
2023-05-21 15:37:33,006:INFO:           streamlit: Not installed
2023-05-21 15:37:33,006:INFO:             prophet: Not installed
2023-05-21 15:37:33,006:INFO:None
2023-05-21 15:37:33,006:INFO:Set up data.
2023-05-21 15:37:33,199:INFO:Set up train/test split.
2023-05-21 15:37:33,302:INFO:Set up index.
2023-05-21 15:37:33,303:INFO:Set up folding strategy.
2023-05-21 15:37:33,303:INFO:Assigning column types.
2023-05-21 15:37:33,328:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-21 15:37:33,397:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 15:37:33,398:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:37:33,434:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:37:33,438:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:37:33,514:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 15:37:33,516:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:37:33,563:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:37:33,567:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:37:33,568:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-21 15:37:33,621:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:37:33,654:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:37:33,658:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:37:33,714:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:37:33,748:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:37:33,751:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:37:33,752:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-21 15:37:33,837:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:37:33,841:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:37:33,926:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:37:33,929:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:37:33,932:INFO:Preparing preprocessing pipeline...
2023-05-21 15:37:33,953:INFO:Set up simple imputation.
2023-05-21 15:37:33,973:INFO:Set up encoding of categorical features.
2023-05-21 15:37:34,297:INFO:Finished creating preprocessing pipeline.
2023-05-21 15:37:34,338:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 15:37:34,338:INFO:Creating final display dataframe.
2023-05-21 15:37:34,881:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     42
1                        Target      app_complete_flag
2                   Target type                 Binary
3           Original data shape            (238964, 7)
4        Transformed data shape           (238964, 39)
5   Transformed train set shape           (167274, 39)
6    Transformed test set shape            (71690, 39)
7              Numeric features                      3
8          Categorical features                      3
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13     Maximum one-hot encoding                     25
14              Encoding method                   None
15               Fold Generator        StratifiedKFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                  False
19               Log Experiment           MlflowLogger
20              Experiment Name  OnlyImportantFeatures
21                          USI                   c3bc
2023-05-21 15:37:34,997:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:37:35,000:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:37:35,087:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:37:35,091:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:37:35,092:INFO:Logging experiment in loggers
2023-05-21 15:37:35,961:INFO:SubProcess save_model() called ==================================
2023-05-21 15:37:36,088:INFO:Initializing save_model()
2023-05-21 15:37:36,089:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/tmp/tmp7xmtx3sv/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-21 15:37:36,089:INFO:Adding model into prep_pipe
2023-05-21 15:37:36,096:WARNING:Only Model saved as it was a pipeline.
2023-05-21 15:37:36,142:INFO:/tmp/tmp7xmtx3sv/Transformation Pipeline.pkl saved in current working directory
2023-05-21 15:37:36,194:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 15:37:36,194:INFO:save_model() successfully completed......................................
2023-05-21 15:37:36,380:INFO:SubProcess save_model() end ==================================
2023-05-21 15:37:37,106:INFO:setup() successfully completed in 2.17s...............
2023-05-21 15:37:40,797:INFO:Initializing compare_models()
2023-05-21 15:37:40,798:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fddd590a950>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fddd590a950>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'])
2023-05-21 15:37:40,798:INFO:Checking exceptions
2023-05-21 15:37:40,864:INFO:Preparing display monitor
2023-05-21 15:37:40,882:INFO:Initializing Logistic Regression
2023-05-21 15:37:40,883:INFO:Total runtime is 9.270509084065755e-06 minutes
2023-05-21 15:37:40,884:INFO:SubProcess create_model() called ==================================
2023-05-21 15:37:40,885:INFO:Initializing create_model()
2023-05-21 15:37:40,885:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fddd590a950>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdde6960e50>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:37:40,885:INFO:Checking exceptions
2023-05-21 15:37:40,886:INFO:Importing libraries
2023-05-21 15:37:40,886:INFO:Copying training dataset
2023-05-21 15:37:40,938:INFO:Defining folds
2023-05-21 15:37:40,938:INFO:Declaring metric variables
2023-05-21 15:37:40,947:INFO:Importing untrained model
2023-05-21 15:37:40,950:INFO:Logistic Regression Imported successfully
2023-05-21 15:37:40,952:INFO:Starting cross validation
2023-05-21 15:37:40,963:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:37:42,860:INFO:Calculating mean and std
2023-05-21 15:37:42,864:INFO:Creating metrics dataframe
2023-05-21 15:37:42,977:INFO:Uploading results into container
2023-05-21 15:37:42,980:INFO:Uploading model into container now
2023-05-21 15:37:42,981:INFO:_master_model_container: 1
2023-05-21 15:37:42,981:INFO:_display_container: 2
2023-05-21 15:37:42,984:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-21 15:37:42,984:INFO:create_model() successfully completed......................................
2023-05-21 15:37:43,119:INFO:SubProcess create_model() end ==================================
2023-05-21 15:37:43,120:INFO:Creating metrics dataframe
2023-05-21 15:37:43,145:INFO:Initializing Naive Bayes
2023-05-21 15:37:43,145:INFO:Total runtime is 0.037713114420572916 minutes
2023-05-21 15:37:43,146:INFO:SubProcess create_model() called ==================================
2023-05-21 15:37:43,146:INFO:Initializing create_model()
2023-05-21 15:37:43,146:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fddd590a950>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdde6960e50>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:37:43,147:INFO:Checking exceptions
2023-05-21 15:37:43,147:INFO:Importing libraries
2023-05-21 15:37:43,147:INFO:Copying training dataset
2023-05-21 15:37:43,196:INFO:Defining folds
2023-05-21 15:37:43,197:INFO:Declaring metric variables
2023-05-21 15:37:43,197:INFO:Importing untrained model
2023-05-21 15:37:43,199:INFO:Naive Bayes Imported successfully
2023-05-21 15:37:43,200:INFO:Starting cross validation
2023-05-21 15:37:43,209:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:37:44,897:INFO:Calculating mean and std
2023-05-21 15:37:44,900:INFO:Creating metrics dataframe
2023-05-21 15:37:45,004:INFO:Uploading results into container
2023-05-21 15:37:45,006:INFO:Uploading model into container now
2023-05-21 15:37:45,008:INFO:_master_model_container: 2
2023-05-21 15:37:45,008:INFO:_display_container: 2
2023-05-21 15:37:45,009:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-21 15:37:45,009:INFO:create_model() successfully completed......................................
2023-05-21 15:37:45,141:INFO:SubProcess create_model() end ==================================
2023-05-21 15:37:45,142:INFO:Creating metrics dataframe
2023-05-21 15:37:45,167:INFO:Initializing Decision Tree Classifier
2023-05-21 15:37:45,168:INFO:Total runtime is 0.07142534653345745 minutes
2023-05-21 15:37:45,168:INFO:SubProcess create_model() called ==================================
2023-05-21 15:37:45,169:INFO:Initializing create_model()
2023-05-21 15:37:45,169:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fddd590a950>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdde6960e50>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:37:45,169:INFO:Checking exceptions
2023-05-21 15:37:45,169:INFO:Importing libraries
2023-05-21 15:37:45,169:INFO:Copying training dataset
2023-05-21 15:37:45,209:INFO:Defining folds
2023-05-21 15:37:45,209:INFO:Declaring metric variables
2023-05-21 15:37:45,210:INFO:Importing untrained model
2023-05-21 15:37:45,212:INFO:Decision Tree Classifier Imported successfully
2023-05-21 15:37:45,213:INFO:Starting cross validation
2023-05-21 15:37:45,221:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:37:46,965:INFO:Calculating mean and std
2023-05-21 15:37:46,967:INFO:Creating metrics dataframe
2023-05-21 15:37:47,069:INFO:Uploading results into container
2023-05-21 15:37:47,071:INFO:Uploading model into container now
2023-05-21 15:37:47,072:INFO:_master_model_container: 3
2023-05-21 15:37:47,072:INFO:_display_container: 2
2023-05-21 15:37:47,074:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-05-21 15:37:47,075:INFO:create_model() successfully completed......................................
2023-05-21 15:37:47,204:INFO:SubProcess create_model() end ==================================
2023-05-21 15:37:47,204:INFO:Creating metrics dataframe
2023-05-21 15:37:47,228:INFO:Initializing Ridge Classifier
2023-05-21 15:37:47,228:INFO:Total runtime is 0.10576387643814088 minutes
2023-05-21 15:37:47,229:INFO:SubProcess create_model() called ==================================
2023-05-21 15:37:47,229:INFO:Initializing create_model()
2023-05-21 15:37:47,229:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fddd590a950>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdde6960e50>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:37:47,229:INFO:Checking exceptions
2023-05-21 15:37:47,230:INFO:Importing libraries
2023-05-21 15:37:47,230:INFO:Copying training dataset
2023-05-21 15:37:47,267:INFO:Defining folds
2023-05-21 15:37:47,267:INFO:Declaring metric variables
2023-05-21 15:37:47,268:INFO:Importing untrained model
2023-05-21 15:37:47,269:INFO:Ridge Classifier Imported successfully
2023-05-21 15:37:47,270:INFO:Starting cross validation
2023-05-21 15:37:47,278:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:37:47,912:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:37:47,947:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:37:47,955:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:37:47,971:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:37:48,029:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:37:48,060:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:37:48,109:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:37:48,113:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:37:48,131:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:37:48,287:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:37:48,595:INFO:Calculating mean and std
2023-05-21 15:37:48,597:INFO:Creating metrics dataframe
2023-05-21 15:37:48,699:INFO:Uploading results into container
2023-05-21 15:37:48,701:INFO:Uploading model into container now
2023-05-21 15:37:48,702:INFO:_master_model_container: 4
2023-05-21 15:37:48,702:INFO:_display_container: 2
2023-05-21 15:37:48,704:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-05-21 15:37:48,704:INFO:create_model() successfully completed......................................
2023-05-21 15:37:48,825:INFO:SubProcess create_model() end ==================================
2023-05-21 15:37:48,825:INFO:Creating metrics dataframe
2023-05-21 15:37:48,852:INFO:Initializing Random Forest Classifier
2023-05-21 15:37:48,852:INFO:Total runtime is 0.1328363617261251 minutes
2023-05-21 15:37:48,853:INFO:SubProcess create_model() called ==================================
2023-05-21 15:37:48,854:INFO:Initializing create_model()
2023-05-21 15:37:48,854:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fddd590a950>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdde6960e50>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:37:48,854:INFO:Checking exceptions
2023-05-21 15:37:48,854:INFO:Importing libraries
2023-05-21 15:37:48,854:INFO:Copying training dataset
2023-05-21 15:37:48,897:INFO:Defining folds
2023-05-21 15:37:48,897:INFO:Declaring metric variables
2023-05-21 15:37:48,898:INFO:Importing untrained model
2023-05-21 15:37:48,900:INFO:Random Forest Classifier Imported successfully
2023-05-21 15:37:48,901:INFO:Starting cross validation
2023-05-21 15:37:48,909:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:37:51,913:INFO:Calculating mean and std
2023-05-21 15:37:51,915:INFO:Creating metrics dataframe
2023-05-21 15:37:52,025:INFO:Uploading results into container
2023-05-21 15:37:52,027:INFO:Uploading model into container now
2023-05-21 15:37:52,029:INFO:_master_model_container: 5
2023-05-21 15:37:52,029:INFO:_display_container: 2
2023-05-21 15:37:52,032:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-05-21 15:37:52,032:INFO:create_model() successfully completed......................................
2023-05-21 15:37:52,158:INFO:SubProcess create_model() end ==================================
2023-05-21 15:37:52,159:INFO:Creating metrics dataframe
2023-05-21 15:37:52,182:INFO:Initializing Linear Discriminant Analysis
2023-05-21 15:37:52,182:INFO:Total runtime is 0.18833562135696413 minutes
2023-05-21 15:37:52,183:INFO:SubProcess create_model() called ==================================
2023-05-21 15:37:52,183:INFO:Initializing create_model()
2023-05-21 15:37:52,184:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fddd590a950>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdde6960e50>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:37:52,184:INFO:Checking exceptions
2023-05-21 15:37:52,184:INFO:Importing libraries
2023-05-21 15:37:52,184:INFO:Copying training dataset
2023-05-21 15:37:52,225:INFO:Defining folds
2023-05-21 15:37:52,225:INFO:Declaring metric variables
2023-05-21 15:37:52,226:INFO:Importing untrained model
2023-05-21 15:37:52,227:INFO:Linear Discriminant Analysis Imported successfully
2023-05-21 15:37:52,229:INFO:Starting cross validation
2023-05-21 15:37:52,237:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:37:53,761:INFO:Calculating mean and std
2023-05-21 15:37:53,764:INFO:Creating metrics dataframe
2023-05-21 15:37:53,870:INFO:Uploading results into container
2023-05-21 15:37:53,872:INFO:Uploading model into container now
2023-05-21 15:37:53,874:INFO:_master_model_container: 6
2023-05-21 15:37:53,874:INFO:_display_container: 2
2023-05-21 15:37:53,875:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-21 15:37:53,876:INFO:create_model() successfully completed......................................
2023-05-21 15:37:54,005:INFO:SubProcess create_model() end ==================================
2023-05-21 15:37:54,006:INFO:Creating metrics dataframe
2023-05-21 15:37:54,032:INFO:Initializing Extra Trees Classifier
2023-05-21 15:37:54,032:INFO:Total runtime is 0.219168492158254 minutes
2023-05-21 15:37:54,033:INFO:SubProcess create_model() called ==================================
2023-05-21 15:37:54,034:INFO:Initializing create_model()
2023-05-21 15:37:54,034:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fddd590a950>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdde6960e50>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:37:54,035:INFO:Checking exceptions
2023-05-21 15:37:54,035:INFO:Importing libraries
2023-05-21 15:37:54,035:INFO:Copying training dataset
2023-05-21 15:37:54,075:INFO:Defining folds
2023-05-21 15:37:54,075:INFO:Declaring metric variables
2023-05-21 15:37:54,076:INFO:Importing untrained model
2023-05-21 15:37:54,078:INFO:Extra Trees Classifier Imported successfully
2023-05-21 15:37:54,080:INFO:Starting cross validation
2023-05-21 15:37:54,087:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:37:57,201:INFO:Calculating mean and std
2023-05-21 15:37:57,204:INFO:Creating metrics dataframe
2023-05-21 15:37:57,310:INFO:Uploading results into container
2023-05-21 15:37:57,312:INFO:Uploading model into container now
2023-05-21 15:37:57,314:INFO:_master_model_container: 7
2023-05-21 15:37:57,314:INFO:_display_container: 2
2023-05-21 15:37:57,317:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-05-21 15:37:57,317:INFO:create_model() successfully completed......................................
2023-05-21 15:37:57,434:INFO:SubProcess create_model() end ==================================
2023-05-21 15:37:57,434:INFO:Creating metrics dataframe
2023-05-21 15:37:57,457:INFO:Initializing Extreme Gradient Boosting
2023-05-21 15:37:57,458:INFO:Total runtime is 0.2762582302093506 minutes
2023-05-21 15:37:57,458:INFO:SubProcess create_model() called ==================================
2023-05-21 15:37:57,459:INFO:Initializing create_model()
2023-05-21 15:37:57,459:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fddd590a950>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdde6960e50>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:37:57,459:INFO:Checking exceptions
2023-05-21 15:37:57,459:INFO:Importing libraries
2023-05-21 15:37:57,459:INFO:Copying training dataset
2023-05-21 15:37:57,495:INFO:Defining folds
2023-05-21 15:37:57,496:INFO:Declaring metric variables
2023-05-21 15:37:57,496:INFO:Importing untrained model
2023-05-21 15:37:57,501:INFO:Extreme Gradient Boosting Imported successfully
2023-05-21 15:37:57,502:INFO:Starting cross validation
2023-05-21 15:37:57,510:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:37:58,980:INFO:Calculating mean and std
2023-05-21 15:37:58,983:INFO:Creating metrics dataframe
2023-05-21 15:37:59,057:INFO:Uploading results into container
2023-05-21 15:37:59,059:INFO:Uploading model into container now
2023-05-21 15:37:59,060:INFO:_master_model_container: 8
2023-05-21 15:37:59,060:INFO:_display_container: 2
2023-05-21 15:37:59,067:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-05-21 15:37:59,067:INFO:create_model() successfully completed......................................
2023-05-21 15:37:59,198:INFO:SubProcess create_model() end ==================================
2023-05-21 15:37:59,198:INFO:Creating metrics dataframe
2023-05-21 15:37:59,221:INFO:Initializing Light Gradient Boosting Machine
2023-05-21 15:37:59,222:INFO:Total runtime is 0.3056594530741374 minutes
2023-05-21 15:37:59,222:INFO:SubProcess create_model() called ==================================
2023-05-21 15:37:59,223:INFO:Initializing create_model()
2023-05-21 15:37:59,223:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fddd590a950>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdde6960e50>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:37:59,223:INFO:Checking exceptions
2023-05-21 15:37:59,223:INFO:Importing libraries
2023-05-21 15:37:59,223:INFO:Copying training dataset
2023-05-21 15:37:59,259:INFO:Defining folds
2023-05-21 15:37:59,260:INFO:Declaring metric variables
2023-05-21 15:37:59,260:INFO:Importing untrained model
2023-05-21 15:37:59,263:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 15:37:59,264:INFO:Starting cross validation
2023-05-21 15:37:59,272:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:38:00,839:INFO:Calculating mean and std
2023-05-21 15:38:00,840:INFO:Creating metrics dataframe
2023-05-21 15:38:00,923:INFO:Uploading results into container
2023-05-21 15:38:00,925:INFO:Uploading model into container now
2023-05-21 15:38:00,927:INFO:_master_model_container: 9
2023-05-21 15:38:00,927:INFO:_display_container: 2
2023-05-21 15:38:00,931:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 15:38:00,931:INFO:create_model() successfully completed......................................
2023-05-21 15:38:01,070:INFO:SubProcess create_model() end ==================================
2023-05-21 15:38:01,070:INFO:Creating metrics dataframe
2023-05-21 15:38:01,114:INFO:Initializing create_model()
2023-05-21 15:38:01,114:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fddd590a950>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:38:01,115:INFO:Checking exceptions
2023-05-21 15:38:01,118:INFO:Importing libraries
2023-05-21 15:38:01,118:INFO:Copying training dataset
2023-05-21 15:38:01,155:INFO:Defining folds
2023-05-21 15:38:01,155:INFO:Declaring metric variables
2023-05-21 15:38:01,156:INFO:Importing untrained model
2023-05-21 15:38:01,156:INFO:Declaring custom model
2023-05-21 15:38:01,166:INFO:Extreme Gradient Boosting Imported successfully
2023-05-21 15:38:01,173:INFO:Cross validation set to False
2023-05-21 15:38:01,174:INFO:Fitting Model
2023-05-21 15:38:01,810:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-05-21 15:38:01,811:INFO:create_model() successfully completed......................................
2023-05-21 15:38:01,938:INFO:Creating Dashboard logs
2023-05-21 15:38:01,941:INFO:Model: Extreme Gradient Boosting
2023-05-21 15:38:02,080:INFO:Logged params: {'objective': 'binary:logistic', 'use_label_encoder': None, 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': -1, 'num_parallel_tree': None, 'predictor': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2023-05-21 15:38:02,901:INFO:Initializing predict_model()
2023-05-21 15:38:02,901:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fddd590a950>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fddd2969bd0>)
2023-05-21 15:38:02,901:INFO:Checking exceptions
2023-05-21 15:38:02,901:INFO:Preloading libraries
2023-05-21 15:38:03,680:INFO:SubProcess plot_model() called ==================================
2023-05-21 15:38:03,690:INFO:Initializing plot_model()
2023-05-21 15:38:03,691:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp4lypfd05, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fddd590a950>, system=False)
2023-05-21 15:38:03,691:INFO:Checking exceptions
2023-05-21 15:38:03,718:INFO:Preloading libraries
2023-05-21 15:38:03,724:INFO:Copying training dataset
2023-05-21 15:38:03,724:INFO:Plot type: auc
2023-05-21 15:38:04,720:INFO:Fitting Model
2023-05-21 15:38:04,730:INFO:Scoring test/hold-out set
2023-05-21 15:38:05,084:INFO:Saving '/tmp/tmp4lypfd05/AUC.png'
2023-05-21 15:38:06,095:INFO:Visual Rendered Successfully
2023-05-21 15:38:06,229:INFO:plot_model() successfully completed......................................
2023-05-21 15:38:06,236:INFO:Initializing plot_model()
2023-05-21 15:38:06,236:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp4lypfd05, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fddd590a950>, system=False)
2023-05-21 15:38:06,236:INFO:Checking exceptions
2023-05-21 15:38:06,252:INFO:Preloading libraries
2023-05-21 15:38:06,259:INFO:Copying training dataset
2023-05-21 15:38:06,259:INFO:Plot type: confusion_matrix
2023-05-21 15:38:06,816:INFO:Fitting Model
2023-05-21 15:38:06,823:INFO:Scoring test/hold-out set
2023-05-21 15:38:07,056:INFO:Saving '/tmp/tmp4lypfd05/Confusion Matrix.png'
2023-05-21 15:38:07,454:INFO:Visual Rendered Successfully
2023-05-21 15:38:07,590:INFO:plot_model() successfully completed......................................
2023-05-21 15:38:07,598:INFO:Initializing plot_model()
2023-05-21 15:38:07,599:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp4lypfd05, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fddd590a950>, system=False)
2023-05-21 15:38:07,599:INFO:Checking exceptions
2023-05-21 15:38:07,621:INFO:Preloading libraries
2023-05-21 15:38:07,628:INFO:Copying training dataset
2023-05-21 15:38:07,629:INFO:Plot type: feature
2023-05-21 15:38:07,634:WARNING:No coef_ found. Trying feature_importances_
2023-05-21 15:38:07,982:INFO:Saving '/tmp/tmp4lypfd05/Feature Importance.png'
2023-05-21 15:38:08,682:INFO:Visual Rendered Successfully
2023-05-21 15:38:08,809:INFO:plot_model() successfully completed......................................
2023-05-21 15:38:08,810:INFO:SubProcess plot_model() end ==================================
2023-05-21 15:38:09,234:INFO:Creating Dashboard logs
2023-05-21 15:38:09,236:INFO:Model: Light Gradient Boosting Machine
2023-05-21 15:38:09,351:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-21 15:38:10,784:INFO:Creating Dashboard logs
2023-05-21 15:38:10,785:INFO:Model: Random Forest Classifier
2023-05-21 15:38:10,917:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 15:38:12,296:INFO:Creating Dashboard logs
2023-05-21 15:38:12,298:INFO:Model: Extra Trees Classifier
2023-05-21 15:38:12,410:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 15:38:13,874:INFO:Creating Dashboard logs
2023-05-21 15:38:13,875:INFO:Model: Decision Tree Classifier
2023-05-21 15:38:14,010:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2023-05-21 15:38:15,125:INFO:Creating Dashboard logs
2023-05-21 15:38:15,127:INFO:Model: Logistic Regression
2023-05-21 15:38:15,266:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-05-21 15:38:16,321:INFO:Creating Dashboard logs
2023-05-21 15:38:16,322:INFO:Model: Linear Discriminant Analysis
2023-05-21 15:38:16,586:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-05-21 15:38:17,791:INFO:Creating Dashboard logs
2023-05-21 15:38:17,792:INFO:Model: Naive Bayes
2023-05-21 15:38:17,919:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-05-21 15:38:19,100:INFO:Creating Dashboard logs
2023-05-21 15:38:19,102:INFO:Model: Ridge Classifier
2023-05-21 15:38:19,212:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2023-05-21 15:38:20,298:INFO:_master_model_container: 9
2023-05-21 15:38:20,298:INFO:_display_container: 2
2023-05-21 15:38:20,304:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-05-21 15:38:20,304:INFO:compare_models() successfully completed......................................
2023-05-21 15:46:34,379:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:46:34,379:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:46:34,379:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:46:34,380:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:46:38,690:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-21 15:46:41,685:INFO:PyCaret ClassificationExperiment
2023-05-21 15:46:41,685:INFO:Logging name: Lead_Scoring_Training_Pipeline
2023-05-21 15:46:41,685:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-21 15:46:41,685:INFO:version 3.0.0
2023-05-21 15:46:41,685:INFO:Initializing setup()
2023-05-21 15:46:41,685:INFO:self.USI: 5227
2023-05-21 15:46:41,685:INFO:self._variable_keys: {'html_param', '_ml_usecase', 'exp_id', 'exp_name_log', 'idx', 'memory', 'data', 'X', 'y_train', 'gpu_param', 'fold_groups_param', 'n_jobs_param', 'fold_shuffle_param', 'seed', 'logging_param', 'X_test', 'fix_imbalance', 'X_train', 'pipeline', 'target_param', 'log_plots_param', 'fold_generator', 'gpu_n_jobs_param', '_available_plots', 'y', 'is_multiclass', 'y_test', 'USI'}
2023-05-21 15:46:41,685:INFO:Checking environment
2023-05-21 15:46:41,685:INFO:python_version: 3.10.10
2023-05-21 15:46:41,685:INFO:python_build: ('main', 'Mar  5 2023 22:26:53')
2023-05-21 15:46:41,685:INFO:machine: x86_64
2023-05-21 15:46:41,686:INFO:platform: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 15:46:41,687:INFO:Memory: svmem(total=16717086720, available=4721754112, percent=71.8, used=9706160128, free=3785678848, active=5912502272, inactive=2462416896, buffers=55676928, cached=3169570816, shared=1941540864, slab=515469312)
2023-05-21 15:46:41,688:INFO:Physical Core: 6
2023-05-21 15:46:41,688:INFO:Logical Core: 12
2023-05-21 15:46:41,688:INFO:Checking libraries
2023-05-21 15:46:41,688:INFO:System:
2023-05-21 15:46:41,688:INFO:    python: 3.10.10 (main, Mar  5 2023, 22:26:53) [GCC 12.2.1 20230201]
2023-05-21 15:46:41,688:INFO:executable: /usr/bin/python3.10
2023-05-21 15:46:41,688:INFO:   machine: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 15:46:41,688:INFO:PyCaret required dependencies:
2023-05-21 15:46:41,688:INFO:                 pip: 23.0.1
2023-05-21 15:46:41,688:INFO:          setuptools: 67.6.1
2023-05-21 15:46:41,689:INFO:             pycaret: 3.0.0
2023-05-21 15:46:41,689:INFO:             IPython: 8.12.0
2023-05-21 15:46:41,689:INFO:          ipywidgets: 7.7.5
2023-05-21 15:46:41,689:INFO:                tqdm: 4.64.1
2023-05-21 15:46:41,689:INFO:               numpy: 1.23.0
2023-05-21 15:46:41,689:INFO:              pandas: 1.5.3
2023-05-21 15:46:41,689:INFO:              jinja2: 3.1.2
2023-05-21 15:46:41,689:INFO:               scipy: 1.9.3
2023-05-21 15:46:41,689:INFO:              joblib: 1.2.0
2023-05-21 15:46:41,689:INFO:             sklearn: 1.2.2
2023-05-21 15:46:41,689:INFO:                pyod: 1.0.9
2023-05-21 15:46:41,689:INFO:            imblearn: 0.10.1
2023-05-21 15:46:41,689:INFO:   category_encoders: 2.6.0
2023-05-21 15:46:41,689:INFO:            lightgbm: 3.3.5
2023-05-21 15:46:41,689:INFO:               numba: 0.57.0
2023-05-21 15:46:41,689:INFO:            requests: 2.28.2
2023-05-21 15:46:41,689:INFO:          matplotlib: 3.6.3
2023-05-21 15:46:41,689:INFO:          scikitplot: 0.3.7
2023-05-21 15:46:41,690:INFO:         yellowbrick: 1.5
2023-05-21 15:46:41,690:INFO:              plotly: 5.14.1
2023-05-21 15:46:41,690:INFO:             kaleido: 0.2.1
2023-05-21 15:46:41,690:INFO:         statsmodels: 0.13.5
2023-05-21 15:46:41,690:INFO:              sktime: 0.18.0
2023-05-21 15:46:41,690:INFO:               tbats: 1.1.3
2023-05-21 15:46:41,690:INFO:            pmdarima: 2.0.3
2023-05-21 15:46:41,690:INFO:              psutil: 5.9.4
2023-05-21 15:46:41,690:INFO:PyCaret optional dependencies:
2023-05-21 15:46:41,701:INFO:                shap: 0.41.0
2023-05-21 15:46:41,701:INFO:           interpret: 0.3.2
2023-05-21 15:46:41,701:INFO:                umap: 0.5.3
2023-05-21 15:46:41,701:INFO:    pandas_profiling: 3.6.6
2023-05-21 15:46:41,701:INFO:  explainerdashboard: 0.4.2.2
2023-05-21 15:46:41,701:INFO:             autoviz: 0.1.603
2023-05-21 15:46:41,701:INFO:           fairlearn: 0.7.0
2023-05-21 15:46:41,701:INFO:             xgboost: 1.7.5
2023-05-21 15:46:41,701:INFO:            catboost: Not installed
2023-05-21 15:46:41,701:INFO:              kmodes: Not installed
2023-05-21 15:46:41,702:INFO:             mlxtend: Not installed
2023-05-21 15:46:41,702:INFO:       statsforecast: Not installed
2023-05-21 15:46:41,702:INFO:        tune_sklearn: Not installed
2023-05-21 15:46:41,702:INFO:                 ray: Not installed
2023-05-21 15:46:41,702:INFO:            hyperopt: Not installed
2023-05-21 15:46:41,702:INFO:              optuna: 3.1.1
2023-05-21 15:46:41,702:INFO:               skopt: Not installed
2023-05-21 15:46:41,702:INFO:              mlflow: 2.3.1
2023-05-21 15:46:41,702:INFO:              gradio: Not installed
2023-05-21 15:46:41,702:INFO:             fastapi: Not installed
2023-05-21 15:46:41,702:INFO:             uvicorn: Not installed
2023-05-21 15:46:41,702:INFO:              m2cgen: Not installed
2023-05-21 15:46:41,702:INFO:           evidently: Not installed
2023-05-21 15:46:41,702:INFO:               fugue: Not installed
2023-05-21 15:46:41,702:INFO:           streamlit: Not installed
2023-05-21 15:46:41,702:INFO:             prophet: Not installed
2023-05-21 15:46:41,702:INFO:None
2023-05-21 15:46:41,702:INFO:Set up data.
2023-05-21 15:46:41,885:INFO:Set up train/test split.
2023-05-21 15:46:41,948:INFO:Set up index.
2023-05-21 15:46:41,948:INFO:Set up folding strategy.
2023-05-21 15:46:41,948:INFO:Assigning column types.
2023-05-21 15:46:41,955:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-21 15:46:41,999:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 15:46:42,014:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:46:42,104:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:46:42,189:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:46:42,235:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 15:46:42,236:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:46:42,263:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:46:42,266:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:46:42,266:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-21 15:46:42,311:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:46:42,339:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:46:42,342:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:46:42,393:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:46:42,421:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:46:42,423:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:46:42,426:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-21 15:46:42,499:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:46:42,502:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:46:42,581:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:46:42,585:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:46:42,586:INFO:Preparing preprocessing pipeline...
2023-05-21 15:46:42,589:INFO:Set up simple imputation.
2023-05-21 15:46:42,611:INFO:Set up encoding of categorical features.
2023-05-21 15:46:42,828:INFO:Finished creating preprocessing pipeline.
2023-05-21 15:46:42,851:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 15:46:42,851:INFO:Creating final display dataframe.
2023-05-21 15:46:43,080:INFO:Setup _display_container:                     Description                           Value
0                    Session id                              42
1                        Target               app_complete_flag
2                   Target type                          Binary
3           Original data shape                     (238964, 7)
4        Transformed data shape                    (238964, 39)
5   Transformed train set shape                    (167274, 39)
6    Transformed test set shape                     (71690, 39)
7              Numeric features                               3
8          Categorical features                               3
9                    Preprocess                            True
10              Imputation type                          simple
11           Numeric imputation                            mean
12       Categorical imputation                            mode
13     Maximum one-hot encoding                              25
14              Encoding method                            None
15               Fold Generator                 StratifiedKFold
16                  Fold Number                              10
17                     CPU Jobs                              -1
18                      Use GPU                           False
19               Log Experiment                    MlflowLogger
20              Experiment Name  Lead_Scoring_Training_Pipeline
21                          USI                            5227
2023-05-21 15:46:43,156:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:46:43,159:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:46:43,232:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:46:43,235:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:46:43,235:INFO:Logging experiment in loggers
2023-05-21 15:46:43,748:INFO:SubProcess save_model() called ==================================
2023-05-21 15:46:43,764:INFO:Initializing save_model()
2023-05-21 15:46:43,764:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/tmp/tmppys28rl7/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-21 15:46:43,764:INFO:Adding model into prep_pipe
2023-05-21 15:46:43,766:WARNING:Only Model saved as it was a pipeline.
2023-05-21 15:46:43,776:INFO:/tmp/tmppys28rl7/Transformation Pipeline.pkl saved in current working directory
2023-05-21 15:46:43,785:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 15:46:43,785:INFO:save_model() successfully completed......................................
2023-05-21 15:46:43,897:INFO:SubProcess save_model() end ==================================
2023-05-21 15:46:44,505:INFO:setup() successfully completed in 1.57s...............
2023-05-21 15:46:44,506:INFO:Initializing compare_models()
2023-05-21 15:46:44,506:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa96a2ec790>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fa96a2ec790>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'])
2023-05-21 15:46:44,506:INFO:Checking exceptions
2023-05-21 15:46:44,518:INFO:Preparing display monitor
2023-05-21 15:46:44,521:INFO:Initializing Logistic Regression
2023-05-21 15:46:44,521:INFO:Total runtime is 1.223882039388021e-06 minutes
2023-05-21 15:46:44,521:INFO:SubProcess create_model() called ==================================
2023-05-21 15:46:44,521:INFO:Initializing create_model()
2023-05-21 15:46:44,521:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa96a2ec790>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa952ee8f70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:46:44,521:INFO:Checking exceptions
2023-05-21 15:46:44,521:INFO:Importing libraries
2023-05-21 15:46:44,522:INFO:Copying training dataset
2023-05-21 15:46:44,547:INFO:Defining folds
2023-05-21 15:46:44,547:INFO:Declaring metric variables
2023-05-21 15:46:44,548:INFO:Importing untrained model
2023-05-21 15:46:44,548:INFO:Logistic Regression Imported successfully
2023-05-21 15:46:44,548:INFO:Starting cross validation
2023-05-21 15:46:44,549:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:46:47,509:INFO:Calculating mean and std
2023-05-21 15:46:47,510:INFO:Creating metrics dataframe
2023-05-21 15:46:47,538:INFO:Uploading results into container
2023-05-21 15:46:47,539:INFO:Uploading model into container now
2023-05-21 15:46:47,540:INFO:_master_model_container: 1
2023-05-21 15:46:47,540:INFO:_display_container: 2
2023-05-21 15:46:47,541:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-21 15:46:47,541:INFO:create_model() successfully completed......................................
2023-05-21 15:46:47,674:INFO:SubProcess create_model() end ==================================
2023-05-21 15:46:47,674:INFO:Creating metrics dataframe
2023-05-21 15:46:47,679:INFO:Initializing Naive Bayes
2023-05-21 15:46:47,679:INFO:Total runtime is 0.0526391863822937 minutes
2023-05-21 15:46:47,680:INFO:SubProcess create_model() called ==================================
2023-05-21 15:46:47,680:INFO:Initializing create_model()
2023-05-21 15:46:47,680:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa96a2ec790>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa952ee8f70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:46:47,680:INFO:Checking exceptions
2023-05-21 15:46:47,680:INFO:Importing libraries
2023-05-21 15:46:47,680:INFO:Copying training dataset
2023-05-21 15:46:47,722:INFO:Defining folds
2023-05-21 15:46:47,722:INFO:Declaring metric variables
2023-05-21 15:46:47,722:INFO:Importing untrained model
2023-05-21 15:46:47,723:INFO:Naive Bayes Imported successfully
2023-05-21 15:46:47,723:INFO:Starting cross validation
2023-05-21 15:46:47,724:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:46:49,385:INFO:Calculating mean and std
2023-05-21 15:46:49,386:INFO:Creating metrics dataframe
2023-05-21 15:46:49,398:INFO:Uploading results into container
2023-05-21 15:46:49,399:INFO:Uploading model into container now
2023-05-21 15:46:49,399:INFO:_master_model_container: 2
2023-05-21 15:46:49,399:INFO:_display_container: 2
2023-05-21 15:46:49,399:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-21 15:46:49,399:INFO:create_model() successfully completed......................................
2023-05-21 15:46:49,500:INFO:SubProcess create_model() end ==================================
2023-05-21 15:46:49,500:INFO:Creating metrics dataframe
2023-05-21 15:46:49,507:INFO:Initializing Decision Tree Classifier
2023-05-21 15:46:49,507:INFO:Total runtime is 0.08309665123621623 minutes
2023-05-21 15:46:49,507:INFO:SubProcess create_model() called ==================================
2023-05-21 15:46:49,507:INFO:Initializing create_model()
2023-05-21 15:46:49,507:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa96a2ec790>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa952ee8f70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:46:49,507:INFO:Checking exceptions
2023-05-21 15:46:49,507:INFO:Importing libraries
2023-05-21 15:46:49,507:INFO:Copying training dataset
2023-05-21 15:46:49,536:INFO:Defining folds
2023-05-21 15:46:49,536:INFO:Declaring metric variables
2023-05-21 15:46:49,537:INFO:Importing untrained model
2023-05-21 15:46:49,537:INFO:Decision Tree Classifier Imported successfully
2023-05-21 15:46:49,537:INFO:Starting cross validation
2023-05-21 15:46:49,538:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:46:50,225:INFO:Calculating mean and std
2023-05-21 15:46:50,225:INFO:Creating metrics dataframe
2023-05-21 15:46:50,237:INFO:Uploading results into container
2023-05-21 15:46:50,238:INFO:Uploading model into container now
2023-05-21 15:46:50,238:INFO:_master_model_container: 3
2023-05-21 15:46:50,238:INFO:_display_container: 2
2023-05-21 15:46:50,239:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-05-21 15:46:50,239:INFO:create_model() successfully completed......................................
2023-05-21 15:46:50,333:INFO:SubProcess create_model() end ==================================
2023-05-21 15:46:50,333:INFO:Creating metrics dataframe
2023-05-21 15:46:50,338:INFO:Initializing Ridge Classifier
2023-05-21 15:46:50,338:INFO:Total runtime is 0.09694278637568157 minutes
2023-05-21 15:46:50,338:INFO:SubProcess create_model() called ==================================
2023-05-21 15:46:50,338:INFO:Initializing create_model()
2023-05-21 15:46:50,338:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa96a2ec790>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa952ee8f70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:46:50,338:INFO:Checking exceptions
2023-05-21 15:46:50,338:INFO:Importing libraries
2023-05-21 15:46:50,338:INFO:Copying training dataset
2023-05-21 15:46:50,369:INFO:Defining folds
2023-05-21 15:46:50,370:INFO:Declaring metric variables
2023-05-21 15:46:50,370:INFO:Importing untrained model
2023-05-21 15:46:50,370:INFO:Ridge Classifier Imported successfully
2023-05-21 15:46:50,370:INFO:Starting cross validation
2023-05-21 15:46:50,371:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:46:50,773:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:46:50,776:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:46:50,797:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:46:50,816:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:46:50,820:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:46:50,831:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:46:50,832:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:46:50,838:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:46:50,853:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:46:50,883:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:46:51,029:INFO:Calculating mean and std
2023-05-21 15:46:51,030:INFO:Creating metrics dataframe
2023-05-21 15:46:51,046:INFO:Uploading results into container
2023-05-21 15:46:51,047:INFO:Uploading model into container now
2023-05-21 15:46:51,047:INFO:_master_model_container: 4
2023-05-21 15:46:51,047:INFO:_display_container: 2
2023-05-21 15:46:51,047:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-05-21 15:46:51,047:INFO:create_model() successfully completed......................................
2023-05-21 15:46:51,146:INFO:SubProcess create_model() end ==================================
2023-05-21 15:46:51,146:INFO:Creating metrics dataframe
2023-05-21 15:46:51,151:INFO:Initializing Random Forest Classifier
2023-05-21 15:46:51,151:INFO:Total runtime is 0.11049424409866335 minutes
2023-05-21 15:46:51,151:INFO:SubProcess create_model() called ==================================
2023-05-21 15:46:51,151:INFO:Initializing create_model()
2023-05-21 15:46:51,151:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa96a2ec790>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa952ee8f70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:46:51,151:INFO:Checking exceptions
2023-05-21 15:46:51,151:INFO:Importing libraries
2023-05-21 15:46:51,151:INFO:Copying training dataset
2023-05-21 15:46:51,184:INFO:Defining folds
2023-05-21 15:46:51,184:INFO:Declaring metric variables
2023-05-21 15:46:51,185:INFO:Importing untrained model
2023-05-21 15:46:51,185:INFO:Random Forest Classifier Imported successfully
2023-05-21 15:46:51,185:INFO:Starting cross validation
2023-05-21 15:46:51,186:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:46:52,799:INFO:Calculating mean and std
2023-05-21 15:46:52,800:INFO:Creating metrics dataframe
2023-05-21 15:46:52,824:INFO:Uploading results into container
2023-05-21 15:46:52,825:INFO:Uploading model into container now
2023-05-21 15:46:52,826:INFO:_master_model_container: 5
2023-05-21 15:46:52,826:INFO:_display_container: 2
2023-05-21 15:46:52,826:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-05-21 15:46:52,826:INFO:create_model() successfully completed......................................
2023-05-21 15:46:52,946:INFO:SubProcess create_model() end ==================================
2023-05-21 15:46:52,946:INFO:Creating metrics dataframe
2023-05-21 15:46:52,952:INFO:Initializing Linear Discriminant Analysis
2023-05-21 15:46:52,952:INFO:Total runtime is 0.14051056305567425 minutes
2023-05-21 15:46:52,952:INFO:SubProcess create_model() called ==================================
2023-05-21 15:46:52,952:INFO:Initializing create_model()
2023-05-21 15:46:52,952:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa96a2ec790>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa952ee8f70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:46:52,952:INFO:Checking exceptions
2023-05-21 15:46:52,952:INFO:Importing libraries
2023-05-21 15:46:52,952:INFO:Copying training dataset
2023-05-21 15:46:52,989:INFO:Defining folds
2023-05-21 15:46:52,989:INFO:Declaring metric variables
2023-05-21 15:46:52,989:INFO:Importing untrained model
2023-05-21 15:46:52,989:INFO:Linear Discriminant Analysis Imported successfully
2023-05-21 15:46:52,990:INFO:Starting cross validation
2023-05-21 15:46:52,990:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:46:53,632:INFO:Calculating mean and std
2023-05-21 15:46:53,633:INFO:Creating metrics dataframe
2023-05-21 15:46:53,657:INFO:Uploading results into container
2023-05-21 15:46:53,658:INFO:Uploading model into container now
2023-05-21 15:46:53,658:INFO:_master_model_container: 6
2023-05-21 15:46:53,658:INFO:_display_container: 2
2023-05-21 15:46:53,659:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-21 15:46:53,659:INFO:create_model() successfully completed......................................
2023-05-21 15:46:53,761:INFO:SubProcess create_model() end ==================================
2023-05-21 15:46:53,761:INFO:Creating metrics dataframe
2023-05-21 15:46:53,765:INFO:Initializing Extra Trees Classifier
2023-05-21 15:46:53,765:INFO:Total runtime is 0.15407252709070843 minutes
2023-05-21 15:46:53,766:INFO:SubProcess create_model() called ==================================
2023-05-21 15:46:53,766:INFO:Initializing create_model()
2023-05-21 15:46:53,766:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa96a2ec790>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa952ee8f70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:46:53,766:INFO:Checking exceptions
2023-05-21 15:46:53,766:INFO:Importing libraries
2023-05-21 15:46:53,766:INFO:Copying training dataset
2023-05-21 15:46:53,791:INFO:Defining folds
2023-05-21 15:46:53,791:INFO:Declaring metric variables
2023-05-21 15:46:53,792:INFO:Importing untrained model
2023-05-21 15:46:53,792:INFO:Extra Trees Classifier Imported successfully
2023-05-21 15:46:53,792:INFO:Starting cross validation
2023-05-21 15:46:53,793:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:46:55,318:INFO:Calculating mean and std
2023-05-21 15:46:55,319:INFO:Creating metrics dataframe
2023-05-21 15:46:55,341:INFO:Uploading results into container
2023-05-21 15:46:55,342:INFO:Uploading model into container now
2023-05-21 15:46:55,343:INFO:_master_model_container: 7
2023-05-21 15:46:55,343:INFO:_display_container: 2
2023-05-21 15:46:55,343:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-05-21 15:46:55,343:INFO:create_model() successfully completed......................................
2023-05-21 15:46:55,448:INFO:SubProcess create_model() end ==================================
2023-05-21 15:46:55,449:INFO:Creating metrics dataframe
2023-05-21 15:46:55,455:INFO:Initializing Extreme Gradient Boosting
2023-05-21 15:46:55,455:INFO:Total runtime is 0.18223591645558676 minutes
2023-05-21 15:46:55,455:INFO:SubProcess create_model() called ==================================
2023-05-21 15:46:55,456:INFO:Initializing create_model()
2023-05-21 15:46:55,456:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa96a2ec790>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa952ee8f70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:46:55,456:INFO:Checking exceptions
2023-05-21 15:46:55,456:INFO:Importing libraries
2023-05-21 15:46:55,456:INFO:Copying training dataset
2023-05-21 15:46:55,493:INFO:Defining folds
2023-05-21 15:46:55,493:INFO:Declaring metric variables
2023-05-21 15:46:55,493:INFO:Importing untrained model
2023-05-21 15:46:55,494:INFO:Extreme Gradient Boosting Imported successfully
2023-05-21 15:46:55,494:INFO:Starting cross validation
2023-05-21 15:46:55,495:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:46:56,301:INFO:Calculating mean and std
2023-05-21 15:46:56,302:INFO:Creating metrics dataframe
2023-05-21 15:46:56,324:INFO:Uploading results into container
2023-05-21 15:46:56,325:INFO:Uploading model into container now
2023-05-21 15:46:56,326:INFO:_master_model_container: 8
2023-05-21 15:46:56,326:INFO:_display_container: 2
2023-05-21 15:46:56,327:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-05-21 15:46:56,327:INFO:create_model() successfully completed......................................
2023-05-21 15:46:56,435:INFO:SubProcess create_model() end ==================================
2023-05-21 15:46:56,435:INFO:Creating metrics dataframe
2023-05-21 15:46:56,440:INFO:Initializing Light Gradient Boosting Machine
2023-05-21 15:46:56,440:INFO:Total runtime is 0.1986507256825765 minutes
2023-05-21 15:46:56,440:INFO:SubProcess create_model() called ==================================
2023-05-21 15:46:56,440:INFO:Initializing create_model()
2023-05-21 15:46:56,440:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa96a2ec790>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa952ee8f70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:46:56,440:INFO:Checking exceptions
2023-05-21 15:46:56,440:INFO:Importing libraries
2023-05-21 15:46:56,441:INFO:Copying training dataset
2023-05-21 15:46:56,475:INFO:Defining folds
2023-05-21 15:46:56,475:INFO:Declaring metric variables
2023-05-21 15:46:56,475:INFO:Importing untrained model
2023-05-21 15:46:56,476:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 15:46:56,476:INFO:Starting cross validation
2023-05-21 15:46:56,477:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:46:57,372:INFO:Calculating mean and std
2023-05-21 15:46:57,373:INFO:Creating metrics dataframe
2023-05-21 15:46:57,393:INFO:Uploading results into container
2023-05-21 15:46:57,393:INFO:Uploading model into container now
2023-05-21 15:46:57,393:INFO:_master_model_container: 9
2023-05-21 15:46:57,394:INFO:_display_container: 2
2023-05-21 15:46:57,394:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 15:46:57,394:INFO:create_model() successfully completed......................................
2023-05-21 15:46:57,510:INFO:SubProcess create_model() end ==================================
2023-05-21 15:46:57,510:INFO:Creating metrics dataframe
2023-05-21 15:46:57,516:INFO:Initializing create_model()
2023-05-21 15:46:57,516:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa96a2ec790>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:46:57,516:INFO:Checking exceptions
2023-05-21 15:46:57,517:INFO:Importing libraries
2023-05-21 15:46:57,517:INFO:Copying training dataset
2023-05-21 15:46:57,550:INFO:Defining folds
2023-05-21 15:46:57,550:INFO:Declaring metric variables
2023-05-21 15:46:57,551:INFO:Importing untrained model
2023-05-21 15:46:57,551:INFO:Declaring custom model
2023-05-21 15:46:57,552:INFO:Extreme Gradient Boosting Imported successfully
2023-05-21 15:46:57,553:INFO:Cross validation set to False
2023-05-21 15:46:57,553:INFO:Fitting Model
2023-05-21 15:46:57,745:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-05-21 15:46:57,745:INFO:create_model() successfully completed......................................
2023-05-21 15:46:57,853:INFO:Creating Dashboard logs
2023-05-21 15:46:57,853:INFO:Model: Extreme Gradient Boosting
2023-05-21 15:46:57,948:INFO:Logged params: {'objective': 'binary:logistic', 'use_label_encoder': None, 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': -1, 'num_parallel_tree': None, 'predictor': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2023-05-21 15:46:58,745:INFO:Initializing predict_model()
2023-05-21 15:46:58,746:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa96a2ec790>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fa950f4bd90>)
2023-05-21 15:46:58,746:INFO:Checking exceptions
2023-05-21 15:46:58,746:INFO:Preloading libraries
2023-05-21 15:46:59,196:INFO:SubProcess plot_model() called ==================================
2023-05-21 15:46:59,197:INFO:Initializing plot_model()
2023-05-21 15:46:59,197:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpmx1skqfh, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa96a2ec790>, system=False)
2023-05-21 15:46:59,197:INFO:Checking exceptions
2023-05-21 15:46:59,206:INFO:Preloading libraries
2023-05-21 15:46:59,210:INFO:Copying training dataset
2023-05-21 15:46:59,210:INFO:Plot type: auc
2023-05-21 15:46:59,749:INFO:Fitting Model
2023-05-21 15:46:59,758:INFO:Scoring test/hold-out set
2023-05-21 15:46:59,942:INFO:Saving '/tmp/tmpmx1skqfh/AUC.png'
2023-05-21 15:47:00,253:INFO:Visual Rendered Successfully
2023-05-21 15:47:00,350:INFO:plot_model() successfully completed......................................
2023-05-21 15:47:00,351:INFO:Initializing plot_model()
2023-05-21 15:47:00,352:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpmx1skqfh, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa96a2ec790>, system=False)
2023-05-21 15:47:00,352:INFO:Checking exceptions
2023-05-21 15:47:00,363:INFO:Preloading libraries
2023-05-21 15:47:00,367:INFO:Copying training dataset
2023-05-21 15:47:00,367:INFO:Plot type: confusion_matrix
2023-05-21 15:47:00,631:INFO:Fitting Model
2023-05-21 15:47:00,634:INFO:Scoring test/hold-out set
2023-05-21 15:47:00,757:INFO:Saving '/tmp/tmpmx1skqfh/Confusion Matrix.png'
2023-05-21 15:47:00,865:INFO:Visual Rendered Successfully
2023-05-21 15:47:00,990:INFO:plot_model() successfully completed......................................
2023-05-21 15:47:00,991:INFO:Initializing plot_model()
2023-05-21 15:47:00,992:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpmx1skqfh, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa96a2ec790>, system=False)
2023-05-21 15:47:00,992:INFO:Checking exceptions
2023-05-21 15:47:01,010:INFO:Preloading libraries
2023-05-21 15:47:01,017:INFO:Copying training dataset
2023-05-21 15:47:01,018:INFO:Plot type: feature
2023-05-21 15:47:01,019:WARNING:No coef_ found. Trying feature_importances_
2023-05-21 15:47:01,174:INFO:Saving '/tmp/tmpmx1skqfh/Feature Importance.png'
2023-05-21 15:47:01,348:INFO:Visual Rendered Successfully
2023-05-21 15:47:01,461:INFO:plot_model() successfully completed......................................
2023-05-21 15:47:01,461:INFO:SubProcess plot_model() end ==================================
2023-05-21 15:47:01,508:WARNING:/home/feuer/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-05-21 15:47:01,964:INFO:Creating Dashboard logs
2023-05-21 15:47:01,965:INFO:Model: Light Gradient Boosting Machine
2023-05-21 15:47:02,053:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-21 15:47:02,901:INFO:Creating Dashboard logs
2023-05-21 15:47:02,902:INFO:Model: Random Forest Classifier
2023-05-21 15:47:02,995:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 15:47:03,777:INFO:Creating Dashboard logs
2023-05-21 15:47:03,777:INFO:Model: Extra Trees Classifier
2023-05-21 15:47:03,871:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 15:47:04,731:INFO:Creating Dashboard logs
2023-05-21 15:47:04,731:INFO:Model: Decision Tree Classifier
2023-05-21 15:47:04,812:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2023-05-21 15:47:05,655:INFO:Creating Dashboard logs
2023-05-21 15:47:05,655:INFO:Model: Logistic Regression
2023-05-21 15:47:05,779:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-05-21 15:47:06,797:INFO:Creating Dashboard logs
2023-05-21 15:47:06,797:INFO:Model: Linear Discriminant Analysis
2023-05-21 15:47:06,953:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-05-21 15:47:08,108:INFO:Creating Dashboard logs
2023-05-21 15:47:08,108:INFO:Model: Naive Bayes
2023-05-21 15:47:08,195:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-05-21 15:47:09,199:INFO:Creating Dashboard logs
2023-05-21 15:47:09,200:INFO:Model: Ridge Classifier
2023-05-21 15:47:09,310:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2023-05-21 15:47:10,425:INFO:_master_model_container: 9
2023-05-21 15:47:10,425:INFO:_display_container: 2
2023-05-21 15:47:10,426:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-05-21 15:47:10,426:INFO:compare_models() successfully completed......................................
2023-05-21 15:47:10,437:INFO:PyCaret ClassificationExperiment
2023-05-21 15:47:10,437:INFO:Logging name: OnlyImportantFeatures
2023-05-21 15:47:10,437:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-21 15:47:10,437:INFO:version 3.0.0
2023-05-21 15:47:10,437:INFO:Initializing setup()
2023-05-21 15:47:10,437:INFO:self.USI: d074
2023-05-21 15:47:10,437:INFO:self._variable_keys: {'html_param', '_ml_usecase', 'exp_id', 'exp_name_log', 'idx', 'memory', 'data', 'X', 'y_train', 'gpu_param', 'fold_groups_param', 'n_jobs_param', 'fold_shuffle_param', 'seed', 'logging_param', 'X_test', 'fix_imbalance', 'X_train', 'pipeline', 'target_param', 'log_plots_param', 'fold_generator', 'gpu_n_jobs_param', '_available_plots', 'y', 'is_multiclass', 'y_test', 'USI'}
2023-05-21 15:47:10,437:INFO:Checking environment
2023-05-21 15:47:10,437:INFO:python_version: 3.10.10
2023-05-21 15:47:10,437:INFO:python_build: ('main', 'Mar  5 2023 22:26:53')
2023-05-21 15:47:10,437:INFO:machine: x86_64
2023-05-21 15:47:10,437:INFO:platform: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 15:47:10,437:INFO:Memory: svmem(total=16717086720, available=2297790464, percent=86.3, used=12120604672, free=1677000704, active=8500506624, inactive=1956478976, buffers=17690624, cached=2901790720, shared=1951068160, slab=517386240)
2023-05-21 15:47:10,438:INFO:Physical Core: 6
2023-05-21 15:47:10,438:INFO:Logical Core: 12
2023-05-21 15:47:10,438:INFO:Checking libraries
2023-05-21 15:47:10,438:INFO:System:
2023-05-21 15:47:10,438:INFO:    python: 3.10.10 (main, Mar  5 2023, 22:26:53) [GCC 12.2.1 20230201]
2023-05-21 15:47:10,438:INFO:executable: /usr/bin/python3.10
2023-05-21 15:47:10,438:INFO:   machine: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 15:47:10,438:INFO:PyCaret required dependencies:
2023-05-21 15:47:10,438:INFO:                 pip: 23.0.1
2023-05-21 15:47:10,438:INFO:          setuptools: 67.6.1
2023-05-21 15:47:10,438:INFO:             pycaret: 3.0.0
2023-05-21 15:47:10,438:INFO:             IPython: 8.12.0
2023-05-21 15:47:10,438:INFO:          ipywidgets: 7.7.5
2023-05-21 15:47:10,438:INFO:                tqdm: 4.64.1
2023-05-21 15:47:10,438:INFO:               numpy: 1.23.0
2023-05-21 15:47:10,438:INFO:              pandas: 1.5.3
2023-05-21 15:47:10,438:INFO:              jinja2: 3.1.2
2023-05-21 15:47:10,438:INFO:               scipy: 1.9.3
2023-05-21 15:47:10,438:INFO:              joblib: 1.2.0
2023-05-21 15:47:10,438:INFO:             sklearn: 1.2.2
2023-05-21 15:47:10,438:INFO:                pyod: 1.0.9
2023-05-21 15:47:10,438:INFO:            imblearn: 0.10.1
2023-05-21 15:47:10,439:INFO:   category_encoders: 2.6.0
2023-05-21 15:47:10,439:INFO:            lightgbm: 3.3.5
2023-05-21 15:47:10,439:INFO:               numba: 0.57.0
2023-05-21 15:47:10,439:INFO:            requests: 2.28.2
2023-05-21 15:47:10,439:INFO:          matplotlib: 3.6.3
2023-05-21 15:47:10,439:INFO:          scikitplot: 0.3.7
2023-05-21 15:47:10,439:INFO:         yellowbrick: 1.5
2023-05-21 15:47:10,439:INFO:              plotly: 5.14.1
2023-05-21 15:47:10,439:INFO:             kaleido: 0.2.1
2023-05-21 15:47:10,439:INFO:         statsmodels: 0.13.5
2023-05-21 15:47:10,439:INFO:              sktime: 0.18.0
2023-05-21 15:47:10,439:INFO:               tbats: 1.1.3
2023-05-21 15:47:10,439:INFO:            pmdarima: 2.0.3
2023-05-21 15:47:10,439:INFO:              psutil: 5.9.4
2023-05-21 15:47:10,439:INFO:PyCaret optional dependencies:
2023-05-21 15:47:10,439:INFO:                shap: 0.41.0
2023-05-21 15:47:10,439:INFO:           interpret: 0.3.2
2023-05-21 15:47:10,439:INFO:                umap: 0.5.3
2023-05-21 15:47:10,439:INFO:    pandas_profiling: 3.6.6
2023-05-21 15:47:10,439:INFO:  explainerdashboard: 0.4.2.2
2023-05-21 15:47:10,439:INFO:             autoviz: 0.1.603
2023-05-21 15:47:10,439:INFO:           fairlearn: 0.7.0
2023-05-21 15:47:10,439:INFO:             xgboost: 1.7.5
2023-05-21 15:47:10,439:INFO:            catboost: Not installed
2023-05-21 15:47:10,439:INFO:              kmodes: Not installed
2023-05-21 15:47:10,439:INFO:             mlxtend: Not installed
2023-05-21 15:47:10,439:INFO:       statsforecast: Not installed
2023-05-21 15:47:10,439:INFO:        tune_sklearn: Not installed
2023-05-21 15:47:10,439:INFO:                 ray: Not installed
2023-05-21 15:47:10,439:INFO:            hyperopt: Not installed
2023-05-21 15:47:10,439:INFO:              optuna: 3.1.1
2023-05-21 15:47:10,439:INFO:               skopt: Not installed
2023-05-21 15:47:10,439:INFO:              mlflow: 2.3.1
2023-05-21 15:47:10,439:INFO:              gradio: Not installed
2023-05-21 15:47:10,439:INFO:             fastapi: Not installed
2023-05-21 15:47:10,439:INFO:             uvicorn: Not installed
2023-05-21 15:47:10,439:INFO:              m2cgen: Not installed
2023-05-21 15:47:10,440:INFO:           evidently: Not installed
2023-05-21 15:47:10,440:INFO:               fugue: Not installed
2023-05-21 15:47:10,440:INFO:           streamlit: Not installed
2023-05-21 15:47:10,440:INFO:             prophet: Not installed
2023-05-21 15:47:10,440:INFO:None
2023-05-21 15:47:10,440:INFO:Set up data.
2023-05-21 15:47:10,575:INFO:Set up train/test split.
2023-05-21 15:47:10,642:INFO:Set up index.
2023-05-21 15:47:10,642:INFO:Set up folding strategy.
2023-05-21 15:47:10,642:INFO:Assigning column types.
2023-05-21 15:47:10,649:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-21 15:47:10,704:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 15:47:10,705:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:47:10,736:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:47:10,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:47:10,787:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 15:47:10,788:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:47:10,816:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:47:10,818:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:47:10,819:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-21 15:47:10,864:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:47:10,892:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:47:10,894:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:47:10,939:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:47:10,967:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:47:10,969:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:47:10,970:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-21 15:47:11,042:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:47:11,045:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:47:11,118:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:47:11,121:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:47:11,121:INFO:Preparing preprocessing pipeline...
2023-05-21 15:47:11,124:INFO:Set up simple imputation.
2023-05-21 15:47:11,135:INFO:Set up encoding of categorical features.
2023-05-21 15:47:11,289:INFO:Finished creating preprocessing pipeline.
2023-05-21 15:47:11,294:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 15:47:11,294:INFO:Creating final display dataframe.
2023-05-21 15:47:11,478:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     42
1                        Target      app_complete_flag
2                   Target type                 Binary
3           Original data shape            (238964, 7)
4        Transformed data shape           (238964, 39)
5   Transformed train set shape           (167274, 39)
6    Transformed test set shape            (71690, 39)
7              Numeric features                      3
8          Categorical features                      3
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13     Maximum one-hot encoding                     25
14              Encoding method                   None
15               Fold Generator        StratifiedKFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                  False
19               Log Experiment           MlflowLogger
20              Experiment Name  OnlyImportantFeatures
21                          USI                   d074
2023-05-21 15:47:11,553:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:47:11,555:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:47:11,629:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:47:11,631:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:47:11,632:INFO:Logging experiment in loggers
2023-05-21 15:47:12,110:INFO:SubProcess save_model() called ==================================
2023-05-21 15:47:12,127:INFO:Initializing save_model()
2023-05-21 15:47:12,127:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/tmp/tmpg08mshm4/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-21 15:47:12,127:INFO:Adding model into prep_pipe
2023-05-21 15:47:12,129:WARNING:Only Model saved as it was a pipeline.
2023-05-21 15:47:12,138:INFO:/tmp/tmpg08mshm4/Transformation Pipeline.pkl saved in current working directory
2023-05-21 15:47:12,147:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 15:47:12,147:INFO:save_model() successfully completed......................................
2023-05-21 15:47:12,263:INFO:SubProcess save_model() end ==================================
2023-05-21 15:47:12,867:INFO:setup() successfully completed in 1.21s...............
2023-05-21 15:47:12,868:INFO:Initializing compare_models()
2023-05-21 15:47:12,868:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa966e63fd0>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fa966e63fd0>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'])
2023-05-21 15:47:12,868:INFO:Checking exceptions
2023-05-21 15:47:12,882:INFO:Preparing display monitor
2023-05-21 15:47:12,884:INFO:Initializing Logistic Regression
2023-05-21 15:47:12,884:INFO:Total runtime is 1.2000401814778646e-06 minutes
2023-05-21 15:47:12,884:INFO:SubProcess create_model() called ==================================
2023-05-21 15:47:12,884:INFO:Initializing create_model()
2023-05-21 15:47:12,884:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa966e63fd0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa966e94070>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:47:12,884:INFO:Checking exceptions
2023-05-21 15:47:12,884:INFO:Importing libraries
2023-05-21 15:47:12,884:INFO:Copying training dataset
2023-05-21 15:47:12,907:INFO:Defining folds
2023-05-21 15:47:12,907:INFO:Declaring metric variables
2023-05-21 15:47:12,908:INFO:Importing untrained model
2023-05-21 15:47:12,908:INFO:Logistic Regression Imported successfully
2023-05-21 15:47:12,908:INFO:Starting cross validation
2023-05-21 15:47:12,910:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:47:13,584:INFO:Calculating mean and std
2023-05-21 15:47:13,585:INFO:Creating metrics dataframe
2023-05-21 15:47:13,608:INFO:Uploading results into container
2023-05-21 15:47:13,609:INFO:Uploading model into container now
2023-05-21 15:47:13,609:INFO:_master_model_container: 1
2023-05-21 15:47:13,609:INFO:_display_container: 2
2023-05-21 15:47:13,610:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-21 15:47:13,610:INFO:create_model() successfully completed......................................
2023-05-21 15:47:13,717:INFO:SubProcess create_model() end ==================================
2023-05-21 15:47:13,717:INFO:Creating metrics dataframe
2023-05-21 15:47:13,721:INFO:Initializing Naive Bayes
2023-05-21 15:47:13,721:INFO:Total runtime is 0.013953038056691488 minutes
2023-05-21 15:47:13,721:INFO:SubProcess create_model() called ==================================
2023-05-21 15:47:13,721:INFO:Initializing create_model()
2023-05-21 15:47:13,721:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa966e63fd0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa966e94070>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:47:13,721:INFO:Checking exceptions
2023-05-21 15:47:13,721:INFO:Importing libraries
2023-05-21 15:47:13,721:INFO:Copying training dataset
2023-05-21 15:47:13,743:INFO:Defining folds
2023-05-21 15:47:13,744:INFO:Declaring metric variables
2023-05-21 15:47:13,744:INFO:Importing untrained model
2023-05-21 15:47:13,744:INFO:Naive Bayes Imported successfully
2023-05-21 15:47:13,744:INFO:Starting cross validation
2023-05-21 15:47:13,745:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:47:14,442:INFO:Calculating mean and std
2023-05-21 15:47:14,443:INFO:Creating metrics dataframe
2023-05-21 15:47:14,466:INFO:Uploading results into container
2023-05-21 15:47:14,467:INFO:Uploading model into container now
2023-05-21 15:47:14,467:INFO:_master_model_container: 2
2023-05-21 15:47:14,467:INFO:_display_container: 2
2023-05-21 15:47:14,467:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-21 15:47:14,467:INFO:create_model() successfully completed......................................
2023-05-21 15:47:14,573:INFO:SubProcess create_model() end ==================================
2023-05-21 15:47:14,573:INFO:Creating metrics dataframe
2023-05-21 15:47:14,577:INFO:Initializing Decision Tree Classifier
2023-05-21 15:47:14,577:INFO:Total runtime is 0.028231390317281085 minutes
2023-05-21 15:47:14,578:INFO:SubProcess create_model() called ==================================
2023-05-21 15:47:14,578:INFO:Initializing create_model()
2023-05-21 15:47:14,578:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa966e63fd0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa966e94070>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:47:14,578:INFO:Checking exceptions
2023-05-21 15:47:14,578:INFO:Importing libraries
2023-05-21 15:47:14,578:INFO:Copying training dataset
2023-05-21 15:47:14,600:INFO:Defining folds
2023-05-21 15:47:14,600:INFO:Declaring metric variables
2023-05-21 15:47:14,600:INFO:Importing untrained model
2023-05-21 15:47:14,601:INFO:Decision Tree Classifier Imported successfully
2023-05-21 15:47:14,601:INFO:Starting cross validation
2023-05-21 15:47:14,602:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:47:15,268:INFO:Calculating mean and std
2023-05-21 15:47:15,269:INFO:Creating metrics dataframe
2023-05-21 15:47:15,294:INFO:Uploading results into container
2023-05-21 15:47:15,295:INFO:Uploading model into container now
2023-05-21 15:47:15,295:INFO:_master_model_container: 3
2023-05-21 15:47:15,295:INFO:_display_container: 2
2023-05-21 15:47:15,296:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-05-21 15:47:15,296:INFO:create_model() successfully completed......................................
2023-05-21 15:47:15,413:INFO:SubProcess create_model() end ==================================
2023-05-21 15:47:15,413:INFO:Creating metrics dataframe
2023-05-21 15:47:15,417:INFO:Initializing Ridge Classifier
2023-05-21 15:47:15,417:INFO:Total runtime is 0.04222235282262166 minutes
2023-05-21 15:47:15,417:INFO:SubProcess create_model() called ==================================
2023-05-21 15:47:15,417:INFO:Initializing create_model()
2023-05-21 15:47:15,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa966e63fd0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa966e94070>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:47:15,417:INFO:Checking exceptions
2023-05-21 15:47:15,417:INFO:Importing libraries
2023-05-21 15:47:15,417:INFO:Copying training dataset
2023-05-21 15:47:15,441:INFO:Defining folds
2023-05-21 15:47:15,442:INFO:Declaring metric variables
2023-05-21 15:47:15,442:INFO:Importing untrained model
2023-05-21 15:47:15,442:INFO:Ridge Classifier Imported successfully
2023-05-21 15:47:15,442:INFO:Starting cross validation
2023-05-21 15:47:15,443:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:47:15,786:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:47:15,810:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:47:15,810:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:47:15,817:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:47:15,842:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:47:15,870:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:47:15,884:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:47:15,891:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:47:15,898:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:47:15,907:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:47:16,055:INFO:Calculating mean and std
2023-05-21 15:47:16,056:INFO:Creating metrics dataframe
2023-05-21 15:47:16,079:INFO:Uploading results into container
2023-05-21 15:47:16,080:INFO:Uploading model into container now
2023-05-21 15:47:16,080:INFO:_master_model_container: 4
2023-05-21 15:47:16,080:INFO:_display_container: 2
2023-05-21 15:47:16,081:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-05-21 15:47:16,081:INFO:create_model() successfully completed......................................
2023-05-21 15:47:16,184:INFO:SubProcess create_model() end ==================================
2023-05-21 15:47:16,184:INFO:Creating metrics dataframe
2023-05-21 15:47:16,188:INFO:Initializing Random Forest Classifier
2023-05-21 15:47:16,188:INFO:Total runtime is 0.05507753690083822 minutes
2023-05-21 15:47:16,188:INFO:SubProcess create_model() called ==================================
2023-05-21 15:47:16,189:INFO:Initializing create_model()
2023-05-21 15:47:16,189:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa966e63fd0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa966e94070>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:47:16,189:INFO:Checking exceptions
2023-05-21 15:47:16,189:INFO:Importing libraries
2023-05-21 15:47:16,189:INFO:Copying training dataset
2023-05-21 15:47:16,211:INFO:Defining folds
2023-05-21 15:47:16,211:INFO:Declaring metric variables
2023-05-21 15:47:16,211:INFO:Importing untrained model
2023-05-21 15:47:16,211:INFO:Random Forest Classifier Imported successfully
2023-05-21 15:47:16,212:INFO:Starting cross validation
2023-05-21 15:47:16,212:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:47:17,655:INFO:Calculating mean and std
2023-05-21 15:47:17,656:INFO:Creating metrics dataframe
2023-05-21 15:47:17,679:INFO:Uploading results into container
2023-05-21 15:47:17,680:INFO:Uploading model into container now
2023-05-21 15:47:17,680:INFO:_master_model_container: 5
2023-05-21 15:47:17,681:INFO:_display_container: 2
2023-05-21 15:47:17,681:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-05-21 15:47:17,681:INFO:create_model() successfully completed......................................
2023-05-21 15:47:17,788:INFO:SubProcess create_model() end ==================================
2023-05-21 15:47:17,788:INFO:Creating metrics dataframe
2023-05-21 15:47:17,792:INFO:Initializing Linear Discriminant Analysis
2023-05-21 15:47:17,792:INFO:Total runtime is 0.08181010087331136 minutes
2023-05-21 15:47:17,792:INFO:SubProcess create_model() called ==================================
2023-05-21 15:47:17,793:INFO:Initializing create_model()
2023-05-21 15:47:17,793:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa966e63fd0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa966e94070>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:47:17,793:INFO:Checking exceptions
2023-05-21 15:47:17,793:INFO:Importing libraries
2023-05-21 15:47:17,793:INFO:Copying training dataset
2023-05-21 15:47:17,815:INFO:Defining folds
2023-05-21 15:47:17,815:INFO:Declaring metric variables
2023-05-21 15:47:17,815:INFO:Importing untrained model
2023-05-21 15:47:17,816:INFO:Linear Discriminant Analysis Imported successfully
2023-05-21 15:47:17,816:INFO:Starting cross validation
2023-05-21 15:47:17,817:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:47:18,478:INFO:Calculating mean and std
2023-05-21 15:47:18,479:INFO:Creating metrics dataframe
2023-05-21 15:47:18,495:INFO:Uploading results into container
2023-05-21 15:47:18,496:INFO:Uploading model into container now
2023-05-21 15:47:18,496:INFO:_master_model_container: 6
2023-05-21 15:47:18,496:INFO:_display_container: 2
2023-05-21 15:47:18,497:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-21 15:47:18,497:INFO:create_model() successfully completed......................................
2023-05-21 15:47:18,602:INFO:SubProcess create_model() end ==================================
2023-05-21 15:47:18,603:INFO:Creating metrics dataframe
2023-05-21 15:47:18,607:INFO:Initializing Extra Trees Classifier
2023-05-21 15:47:18,607:INFO:Total runtime is 0.09538445870081584 minutes
2023-05-21 15:47:18,607:INFO:SubProcess create_model() called ==================================
2023-05-21 15:47:18,607:INFO:Initializing create_model()
2023-05-21 15:47:18,607:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa966e63fd0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa966e94070>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:47:18,607:INFO:Checking exceptions
2023-05-21 15:47:18,607:INFO:Importing libraries
2023-05-21 15:47:18,607:INFO:Copying training dataset
2023-05-21 15:47:18,629:INFO:Defining folds
2023-05-21 15:47:18,629:INFO:Declaring metric variables
2023-05-21 15:47:18,629:INFO:Importing untrained model
2023-05-21 15:47:18,630:INFO:Extra Trees Classifier Imported successfully
2023-05-21 15:47:18,630:INFO:Starting cross validation
2023-05-21 15:47:18,631:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:47:20,170:INFO:Calculating mean and std
2023-05-21 15:47:20,171:INFO:Creating metrics dataframe
2023-05-21 15:47:20,195:INFO:Uploading results into container
2023-05-21 15:47:20,195:INFO:Uploading model into container now
2023-05-21 15:47:20,196:INFO:_master_model_container: 7
2023-05-21 15:47:20,196:INFO:_display_container: 2
2023-05-21 15:47:20,196:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-05-21 15:47:20,196:INFO:create_model() successfully completed......................................
2023-05-21 15:47:20,314:INFO:SubProcess create_model() end ==================================
2023-05-21 15:47:20,314:INFO:Creating metrics dataframe
2023-05-21 15:47:20,319:INFO:Initializing Extreme Gradient Boosting
2023-05-21 15:47:20,319:INFO:Total runtime is 0.12392281691233317 minutes
2023-05-21 15:47:20,319:INFO:SubProcess create_model() called ==================================
2023-05-21 15:47:20,320:INFO:Initializing create_model()
2023-05-21 15:47:20,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa966e63fd0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa966e94070>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:47:20,320:INFO:Checking exceptions
2023-05-21 15:47:20,320:INFO:Importing libraries
2023-05-21 15:47:20,320:INFO:Copying training dataset
2023-05-21 15:47:20,350:INFO:Defining folds
2023-05-21 15:47:20,350:INFO:Declaring metric variables
2023-05-21 15:47:20,350:INFO:Importing untrained model
2023-05-21 15:47:20,351:INFO:Extreme Gradient Boosting Imported successfully
2023-05-21 15:47:20,351:INFO:Starting cross validation
2023-05-21 15:47:20,352:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:47:21,198:INFO:Calculating mean and std
2023-05-21 15:47:21,199:INFO:Creating metrics dataframe
2023-05-21 15:47:21,223:INFO:Uploading results into container
2023-05-21 15:47:21,224:INFO:Uploading model into container now
2023-05-21 15:47:21,224:INFO:_master_model_container: 8
2023-05-21 15:47:21,224:INFO:_display_container: 2
2023-05-21 15:47:21,225:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-05-21 15:47:21,225:INFO:create_model() successfully completed......................................
2023-05-21 15:47:21,341:INFO:SubProcess create_model() end ==================================
2023-05-21 15:47:21,341:INFO:Creating metrics dataframe
2023-05-21 15:47:21,345:INFO:Initializing Light Gradient Boosting Machine
2023-05-21 15:47:21,345:INFO:Total runtime is 0.14103022813796998 minutes
2023-05-21 15:47:21,346:INFO:SubProcess create_model() called ==================================
2023-05-21 15:47:21,346:INFO:Initializing create_model()
2023-05-21 15:47:21,346:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa966e63fd0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa966e94070>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:47:21,346:INFO:Checking exceptions
2023-05-21 15:47:21,346:INFO:Importing libraries
2023-05-21 15:47:21,346:INFO:Copying training dataset
2023-05-21 15:47:21,375:INFO:Defining folds
2023-05-21 15:47:21,375:INFO:Declaring metric variables
2023-05-21 15:47:21,376:INFO:Importing untrained model
2023-05-21 15:47:21,376:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 15:47:21,376:INFO:Starting cross validation
2023-05-21 15:47:21,377:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:47:22,286:INFO:Calculating mean and std
2023-05-21 15:47:22,286:INFO:Creating metrics dataframe
2023-05-21 15:47:22,300:INFO:Uploading results into container
2023-05-21 15:47:22,300:INFO:Uploading model into container now
2023-05-21 15:47:22,300:INFO:_master_model_container: 9
2023-05-21 15:47:22,301:INFO:_display_container: 2
2023-05-21 15:47:22,301:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 15:47:22,301:INFO:create_model() successfully completed......................................
2023-05-21 15:47:22,403:INFO:SubProcess create_model() end ==================================
2023-05-21 15:47:22,403:INFO:Creating metrics dataframe
2023-05-21 15:47:22,409:INFO:Initializing create_model()
2023-05-21 15:47:22,409:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa966e63fd0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:47:22,409:INFO:Checking exceptions
2023-05-21 15:47:22,410:INFO:Importing libraries
2023-05-21 15:47:22,410:INFO:Copying training dataset
2023-05-21 15:47:22,433:INFO:Defining folds
2023-05-21 15:47:22,433:INFO:Declaring metric variables
2023-05-21 15:47:22,434:INFO:Importing untrained model
2023-05-21 15:47:22,434:INFO:Declaring custom model
2023-05-21 15:47:22,435:INFO:Extreme Gradient Boosting Imported successfully
2023-05-21 15:47:22,436:INFO:Cross validation set to False
2023-05-21 15:47:22,436:INFO:Fitting Model
2023-05-21 15:47:22,622:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-05-21 15:47:22,622:INFO:create_model() successfully completed......................................
2023-05-21 15:47:22,720:INFO:Creating Dashboard logs
2023-05-21 15:47:22,720:INFO:Model: Extreme Gradient Boosting
2023-05-21 15:47:22,811:INFO:Logged params: {'objective': 'binary:logistic', 'use_label_encoder': None, 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': -1, 'num_parallel_tree': None, 'predictor': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2023-05-21 15:47:23,385:INFO:Initializing predict_model()
2023-05-21 15:47:23,385:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa966e63fd0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fa9506ebe20>)
2023-05-21 15:47:23,385:INFO:Checking exceptions
2023-05-21 15:47:23,385:INFO:Preloading libraries
2023-05-21 15:47:23,828:INFO:SubProcess plot_model() called ==================================
2023-05-21 15:47:23,828:INFO:Initializing plot_model()
2023-05-21 15:47:23,828:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmplpcawr9y, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa966e63fd0>, system=False)
2023-05-21 15:47:23,828:INFO:Checking exceptions
2023-05-21 15:47:23,837:INFO:Preloading libraries
2023-05-21 15:47:23,842:INFO:Copying training dataset
2023-05-21 15:47:23,842:INFO:Plot type: auc
2023-05-21 15:47:24,020:INFO:Fitting Model
2023-05-21 15:47:24,025:INFO:Scoring test/hold-out set
2023-05-21 15:47:24,163:INFO:Saving '/tmp/tmplpcawr9y/AUC.png'
2023-05-21 15:47:24,332:INFO:Visual Rendered Successfully
2023-05-21 15:47:24,430:INFO:plot_model() successfully completed......................................
2023-05-21 15:47:24,431:INFO:Initializing plot_model()
2023-05-21 15:47:24,431:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmplpcawr9y, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa966e63fd0>, system=False)
2023-05-21 15:47:24,432:INFO:Checking exceptions
2023-05-21 15:47:24,440:INFO:Preloading libraries
2023-05-21 15:47:24,443:INFO:Copying training dataset
2023-05-21 15:47:24,443:INFO:Plot type: confusion_matrix
2023-05-21 15:47:24,622:INFO:Fitting Model
2023-05-21 15:47:24,625:INFO:Scoring test/hold-out set
2023-05-21 15:47:24,742:INFO:Saving '/tmp/tmplpcawr9y/Confusion Matrix.png'
2023-05-21 15:47:24,825:INFO:Visual Rendered Successfully
2023-05-21 15:47:24,923:INFO:plot_model() successfully completed......................................
2023-05-21 15:47:24,924:INFO:Initializing plot_model()
2023-05-21 15:47:24,924:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmplpcawr9y, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa966e63fd0>, system=False)
2023-05-21 15:47:24,924:INFO:Checking exceptions
2023-05-21 15:47:24,933:INFO:Preloading libraries
2023-05-21 15:47:24,937:INFO:Copying training dataset
2023-05-21 15:47:24,937:INFO:Plot type: feature
2023-05-21 15:47:24,938:WARNING:No coef_ found. Trying feature_importances_
2023-05-21 15:47:25,022:INFO:Saving '/tmp/tmplpcawr9y/Feature Importance.png'
2023-05-21 15:47:25,157:INFO:Visual Rendered Successfully
2023-05-21 15:47:25,255:INFO:plot_model() successfully completed......................................
2023-05-21 15:47:25,255:INFO:SubProcess plot_model() end ==================================
2023-05-21 15:47:25,500:INFO:Creating Dashboard logs
2023-05-21 15:47:25,500:INFO:Model: Light Gradient Boosting Machine
2023-05-21 15:47:25,596:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-21 15:47:26,407:INFO:Creating Dashboard logs
2023-05-21 15:47:26,408:INFO:Model: Random Forest Classifier
2023-05-21 15:47:26,508:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 15:47:27,432:INFO:Creating Dashboard logs
2023-05-21 15:47:27,433:INFO:Model: Extra Trees Classifier
2023-05-21 15:47:27,510:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 15:47:28,482:INFO:Creating Dashboard logs
2023-05-21 15:47:28,482:INFO:Model: Decision Tree Classifier
2023-05-21 15:47:28,571:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2023-05-21 15:47:29,637:INFO:Creating Dashboard logs
2023-05-21 15:47:29,637:INFO:Model: Logistic Regression
2023-05-21 15:47:29,787:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-05-21 15:47:30,611:INFO:Creating Dashboard logs
2023-05-21 15:47:30,612:INFO:Model: Linear Discriminant Analysis
2023-05-21 15:47:30,693:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-05-21 15:47:31,664:INFO:Creating Dashboard logs
2023-05-21 15:47:31,665:INFO:Model: Naive Bayes
2023-05-21 15:47:31,760:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-05-21 15:47:32,605:INFO:Creating Dashboard logs
2023-05-21 15:47:32,606:INFO:Model: Ridge Classifier
2023-05-21 15:47:32,677:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2023-05-21 15:47:33,542:INFO:_master_model_container: 9
2023-05-21 15:47:33,542:INFO:_display_container: 2
2023-05-21 15:47:33,543:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-05-21 15:47:33,543:INFO:compare_models() successfully completed......................................
2023-05-21 15:49:54,228:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:49:54,228:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:49:54,228:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:49:54,228:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:49:57,154:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-21 15:50:00,256:INFO:PyCaret ClassificationExperiment
2023-05-21 15:50:00,256:INFO:Logging name: Lead_Scoring_Training_Pipeline
2023-05-21 15:50:00,256:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-21 15:50:00,256:INFO:version 3.0.0
2023-05-21 15:50:00,256:INFO:Initializing setup()
2023-05-21 15:50:00,256:INFO:self.USI: ef4a
2023-05-21 15:50:00,256:INFO:self._variable_keys: {'fold_groups_param', 'idx', 'y', 'y_test', 'memory', 'exp_name_log', 'data', 'is_multiclass', 'X_train', 'seed', 'fold_shuffle_param', 'USI', 'X', 'n_jobs_param', 'logging_param', 'gpu_param', 'y_train', 'exp_id', 'log_plots_param', 'fix_imbalance', 'target_param', 'X_test', '_ml_usecase', 'gpu_n_jobs_param', 'html_param', 'pipeline', '_available_plots', 'fold_generator'}
2023-05-21 15:50:00,256:INFO:Checking environment
2023-05-21 15:50:00,256:INFO:python_version: 3.10.10
2023-05-21 15:50:00,256:INFO:python_build: ('main', 'Mar  5 2023 22:26:53')
2023-05-21 15:50:00,256:INFO:machine: x86_64
2023-05-21 15:50:00,257:INFO:platform: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 15:50:00,257:INFO:Memory: svmem(total=16717086720, available=4850683904, percent=71.0, used=9583775744, free=4021387264, active=6096494592, inactive=2032754688, buffers=25866240, cached=3086057472, shared=1935003648, slab=514187264)
2023-05-21 15:50:00,258:INFO:Physical Core: 6
2023-05-21 15:50:00,259:INFO:Logical Core: 12
2023-05-21 15:50:00,259:INFO:Checking libraries
2023-05-21 15:50:00,259:INFO:System:
2023-05-21 15:50:00,259:INFO:    python: 3.10.10 (main, Mar  5 2023, 22:26:53) [GCC 12.2.1 20230201]
2023-05-21 15:50:00,259:INFO:executable: /usr/bin/python3.10
2023-05-21 15:50:00,259:INFO:   machine: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 15:50:00,259:INFO:PyCaret required dependencies:
2023-05-21 15:50:00,259:INFO:                 pip: 23.0.1
2023-05-21 15:50:00,259:INFO:          setuptools: 67.6.1
2023-05-21 15:50:00,259:INFO:             pycaret: 3.0.0
2023-05-21 15:50:00,259:INFO:             IPython: 8.12.0
2023-05-21 15:50:00,259:INFO:          ipywidgets: 7.7.5
2023-05-21 15:50:00,259:INFO:                tqdm: 4.64.1
2023-05-21 15:50:00,259:INFO:               numpy: 1.23.0
2023-05-21 15:50:00,259:INFO:              pandas: 1.5.3
2023-05-21 15:50:00,259:INFO:              jinja2: 3.1.2
2023-05-21 15:50:00,260:INFO:               scipy: 1.9.3
2023-05-21 15:50:00,260:INFO:              joblib: 1.2.0
2023-05-21 15:50:00,260:INFO:             sklearn: 1.2.2
2023-05-21 15:50:00,260:INFO:                pyod: 1.0.9
2023-05-21 15:50:00,260:INFO:            imblearn: 0.10.1
2023-05-21 15:50:00,260:INFO:   category_encoders: 2.6.0
2023-05-21 15:50:00,260:INFO:            lightgbm: 3.3.5
2023-05-21 15:50:00,260:INFO:               numba: 0.57.0
2023-05-21 15:50:00,260:INFO:            requests: 2.28.2
2023-05-21 15:50:00,260:INFO:          matplotlib: 3.6.3
2023-05-21 15:50:00,260:INFO:          scikitplot: 0.3.7
2023-05-21 15:50:00,260:INFO:         yellowbrick: 1.5
2023-05-21 15:50:00,260:INFO:              plotly: 5.14.1
2023-05-21 15:50:00,260:INFO:             kaleido: 0.2.1
2023-05-21 15:50:00,260:INFO:         statsmodels: 0.13.5
2023-05-21 15:50:00,260:INFO:              sktime: 0.18.0
2023-05-21 15:50:00,260:INFO:               tbats: 1.1.3
2023-05-21 15:50:00,260:INFO:            pmdarima: 2.0.3
2023-05-21 15:50:00,260:INFO:              psutil: 5.9.4
2023-05-21 15:50:00,260:INFO:PyCaret optional dependencies:
2023-05-21 15:50:00,270:INFO:                shap: 0.41.0
2023-05-21 15:50:00,270:INFO:           interpret: 0.3.2
2023-05-21 15:50:00,270:INFO:                umap: 0.5.3
2023-05-21 15:50:00,270:INFO:    pandas_profiling: 3.6.6
2023-05-21 15:50:00,270:INFO:  explainerdashboard: 0.4.2.2
2023-05-21 15:50:00,270:INFO:             autoviz: 0.1.603
2023-05-21 15:50:00,270:INFO:           fairlearn: 0.7.0
2023-05-21 15:50:00,270:INFO:             xgboost: 1.7.5
2023-05-21 15:50:00,270:INFO:            catboost: Not installed
2023-05-21 15:50:00,270:INFO:              kmodes: Not installed
2023-05-21 15:50:00,270:INFO:             mlxtend: Not installed
2023-05-21 15:50:00,270:INFO:       statsforecast: Not installed
2023-05-21 15:50:00,270:INFO:        tune_sklearn: Not installed
2023-05-21 15:50:00,270:INFO:                 ray: Not installed
2023-05-21 15:50:00,270:INFO:            hyperopt: Not installed
2023-05-21 15:50:00,270:INFO:              optuna: 3.1.1
2023-05-21 15:50:00,270:INFO:               skopt: Not installed
2023-05-21 15:50:00,270:INFO:              mlflow: 2.3.1
2023-05-21 15:50:00,271:INFO:              gradio: Not installed
2023-05-21 15:50:00,271:INFO:             fastapi: Not installed
2023-05-21 15:50:00,271:INFO:             uvicorn: Not installed
2023-05-21 15:50:00,271:INFO:              m2cgen: Not installed
2023-05-21 15:50:00,271:INFO:           evidently: Not installed
2023-05-21 15:50:00,271:INFO:               fugue: Not installed
2023-05-21 15:50:00,271:INFO:           streamlit: Not installed
2023-05-21 15:50:00,271:INFO:             prophet: Not installed
2023-05-21 15:50:00,271:INFO:None
2023-05-21 15:50:00,271:INFO:Set up data.
2023-05-21 15:50:00,436:INFO:Set up train/test split.
2023-05-21 15:50:00,501:INFO:Set up index.
2023-05-21 15:50:00,501:INFO:Set up folding strategy.
2023-05-21 15:50:00,502:INFO:Assigning column types.
2023-05-21 15:50:00,509:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-21 15:50:00,557:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 15:50:00,570:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:50:00,660:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:50:00,737:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:50:00,781:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 15:50:00,782:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:50:00,810:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:50:00,812:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:50:00,812:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-21 15:50:00,857:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:50:00,884:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:50:00,887:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:50:00,934:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:50:00,964:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:50:00,967:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:50:00,969:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-21 15:50:01,047:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:50:01,050:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:50:01,129:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:50:01,131:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:50:01,132:INFO:Preparing preprocessing pipeline...
2023-05-21 15:50:01,135:INFO:Set up simple imputation.
2023-05-21 15:50:01,149:INFO:Set up encoding of categorical features.
2023-05-21 15:50:01,326:INFO:Finished creating preprocessing pipeline.
2023-05-21 15:50:01,338:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 15:50:01,338:INFO:Creating final display dataframe.
2023-05-21 15:50:01,553:INFO:Setup _display_container:                     Description                           Value
0                    Session id                              42
1                        Target               app_complete_flag
2                   Target type                          Binary
3           Original data shape                     (238964, 7)
4        Transformed data shape                    (238964, 39)
5   Transformed train set shape                    (167274, 39)
6    Transformed test set shape                     (71690, 39)
7              Numeric features                               3
8          Categorical features                               3
9                    Preprocess                            True
10              Imputation type                          simple
11           Numeric imputation                            mean
12       Categorical imputation                            mode
13     Maximum one-hot encoding                              25
14              Encoding method                            None
15               Fold Generator                 StratifiedKFold
16                  Fold Number                              10
17                     CPU Jobs                              -1
18                      Use GPU                           False
19               Log Experiment                    MlflowLogger
20              Experiment Name  Lead_Scoring_Training_Pipeline
21                          USI                            ef4a
2023-05-21 15:50:01,629:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:50:01,632:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:50:01,704:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:50:01,706:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:50:01,707:INFO:Logging experiment in loggers
2023-05-21 15:50:02,402:INFO:SubProcess save_model() called ==================================
2023-05-21 15:50:02,419:INFO:Initializing save_model()
2023-05-21 15:50:02,419:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/tmp/tmpn1iuh_7x/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-21 15:50:02,419:INFO:Adding model into prep_pipe
2023-05-21 15:50:02,420:WARNING:Only Model saved as it was a pipeline.
2023-05-21 15:50:02,430:INFO:/tmp/tmpn1iuh_7x/Transformation Pipeline.pkl saved in current working directory
2023-05-21 15:50:02,438:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 15:50:02,438:INFO:save_model() successfully completed......................................
2023-05-21 15:50:02,550:INFO:SubProcess save_model() end ==================================
2023-05-21 15:50:03,219:INFO:setup() successfully completed in 1.47s...............
2023-05-21 15:50:03,220:INFO:Initializing compare_models()
2023-05-21 15:50:03,220:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b4d6d4820>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f4b4d6d4820>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'])
2023-05-21 15:50:03,220:INFO:Checking exceptions
2023-05-21 15:50:03,231:INFO:Preparing display monitor
2023-05-21 15:50:03,234:INFO:Initializing Logistic Regression
2023-05-21 15:50:03,234:INFO:Total runtime is 1.1722246805826824e-06 minutes
2023-05-21 15:50:03,234:INFO:SubProcess create_model() called ==================================
2023-05-21 15:50:03,234:INFO:Initializing create_model()
2023-05-21 15:50:03,234:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b4d6d4820>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4b30c59000>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:50:03,234:INFO:Checking exceptions
2023-05-21 15:50:03,234:INFO:Importing libraries
2023-05-21 15:50:03,234:INFO:Copying training dataset
2023-05-21 15:50:03,257:INFO:Defining folds
2023-05-21 15:50:03,257:INFO:Declaring metric variables
2023-05-21 15:50:03,257:INFO:Importing untrained model
2023-05-21 15:50:03,258:INFO:Logistic Regression Imported successfully
2023-05-21 15:50:03,258:INFO:Starting cross validation
2023-05-21 15:50:03,259:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:50:06,076:INFO:Calculating mean and std
2023-05-21 15:50:06,077:INFO:Creating metrics dataframe
2023-05-21 15:50:06,090:INFO:Uploading results into container
2023-05-21 15:50:06,091:INFO:Uploading model into container now
2023-05-21 15:50:06,091:INFO:_master_model_container: 1
2023-05-21 15:50:06,091:INFO:_display_container: 2
2023-05-21 15:50:06,091:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-21 15:50:06,091:INFO:create_model() successfully completed......................................
2023-05-21 15:50:06,195:INFO:SubProcess create_model() end ==================================
2023-05-21 15:50:06,195:INFO:Creating metrics dataframe
2023-05-21 15:50:06,198:INFO:Initializing Naive Bayes
2023-05-21 15:50:06,199:INFO:Total runtime is 0.04941057364145914 minutes
2023-05-21 15:50:06,199:INFO:SubProcess create_model() called ==================================
2023-05-21 15:50:06,199:INFO:Initializing create_model()
2023-05-21 15:50:06,199:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b4d6d4820>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4b30c59000>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:50:06,199:INFO:Checking exceptions
2023-05-21 15:50:06,199:INFO:Importing libraries
2023-05-21 15:50:06,199:INFO:Copying training dataset
2023-05-21 15:50:06,227:INFO:Defining folds
2023-05-21 15:50:06,227:INFO:Declaring metric variables
2023-05-21 15:50:06,228:INFO:Importing untrained model
2023-05-21 15:50:06,228:INFO:Naive Bayes Imported successfully
2023-05-21 15:50:06,228:INFO:Starting cross validation
2023-05-21 15:50:06,229:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:50:07,787:INFO:Calculating mean and std
2023-05-21 15:50:07,788:INFO:Creating metrics dataframe
2023-05-21 15:50:07,805:INFO:Uploading results into container
2023-05-21 15:50:07,806:INFO:Uploading model into container now
2023-05-21 15:50:07,806:INFO:_master_model_container: 2
2023-05-21 15:50:07,806:INFO:_display_container: 2
2023-05-21 15:50:07,807:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-21 15:50:07,807:INFO:create_model() successfully completed......................................
2023-05-21 15:50:07,901:INFO:SubProcess create_model() end ==================================
2023-05-21 15:50:07,901:INFO:Creating metrics dataframe
2023-05-21 15:50:07,905:INFO:Initializing Decision Tree Classifier
2023-05-21 15:50:07,905:INFO:Total runtime is 0.07785746653874714 minutes
2023-05-21 15:50:07,906:INFO:SubProcess create_model() called ==================================
2023-05-21 15:50:07,906:INFO:Initializing create_model()
2023-05-21 15:50:07,906:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b4d6d4820>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4b30c59000>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:50:07,906:INFO:Checking exceptions
2023-05-21 15:50:07,906:INFO:Importing libraries
2023-05-21 15:50:07,906:INFO:Copying training dataset
2023-05-21 15:50:07,929:INFO:Defining folds
2023-05-21 15:50:07,929:INFO:Declaring metric variables
2023-05-21 15:50:07,929:INFO:Importing untrained model
2023-05-21 15:50:07,929:INFO:Decision Tree Classifier Imported successfully
2023-05-21 15:50:07,930:INFO:Starting cross validation
2023-05-21 15:50:07,930:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:50:08,591:INFO:Calculating mean and std
2023-05-21 15:50:08,592:INFO:Creating metrics dataframe
2023-05-21 15:50:08,617:INFO:Uploading results into container
2023-05-21 15:50:08,618:INFO:Uploading model into container now
2023-05-21 15:50:08,618:INFO:_master_model_container: 3
2023-05-21 15:50:08,618:INFO:_display_container: 2
2023-05-21 15:50:08,619:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-05-21 15:50:08,619:INFO:create_model() successfully completed......................................
2023-05-21 15:50:08,723:INFO:SubProcess create_model() end ==================================
2023-05-21 15:50:08,723:INFO:Creating metrics dataframe
2023-05-21 15:50:08,727:INFO:Initializing Ridge Classifier
2023-05-21 15:50:08,727:INFO:Total runtime is 0.0915557861328125 minutes
2023-05-21 15:50:08,727:INFO:SubProcess create_model() called ==================================
2023-05-21 15:50:08,728:INFO:Initializing create_model()
2023-05-21 15:50:08,728:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b4d6d4820>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4b30c59000>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:50:08,728:INFO:Checking exceptions
2023-05-21 15:50:08,728:INFO:Importing libraries
2023-05-21 15:50:08,728:INFO:Copying training dataset
2023-05-21 15:50:08,755:INFO:Defining folds
2023-05-21 15:50:08,755:INFO:Declaring metric variables
2023-05-21 15:50:08,756:INFO:Importing untrained model
2023-05-21 15:50:08,756:INFO:Ridge Classifier Imported successfully
2023-05-21 15:50:08,756:INFO:Starting cross validation
2023-05-21 15:50:08,757:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:50:09,079:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:50:09,104:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:50:09,150:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:50:09,171:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:50:09,176:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:50:09,184:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:50:09,191:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:50:09,197:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:50:09,208:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:50:09,235:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:50:09,398:INFO:Calculating mean and std
2023-05-21 15:50:09,399:INFO:Creating metrics dataframe
2023-05-21 15:50:09,423:INFO:Uploading results into container
2023-05-21 15:50:09,424:INFO:Uploading model into container now
2023-05-21 15:50:09,425:INFO:_master_model_container: 4
2023-05-21 15:50:09,425:INFO:_display_container: 2
2023-05-21 15:50:09,425:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-05-21 15:50:09,425:INFO:create_model() successfully completed......................................
2023-05-21 15:50:09,529:INFO:SubProcess create_model() end ==================================
2023-05-21 15:50:09,530:INFO:Creating metrics dataframe
2023-05-21 15:50:09,534:INFO:Initializing Random Forest Classifier
2023-05-21 15:50:09,534:INFO:Total runtime is 0.10499748388926188 minutes
2023-05-21 15:50:09,534:INFO:SubProcess create_model() called ==================================
2023-05-21 15:50:09,534:INFO:Initializing create_model()
2023-05-21 15:50:09,534:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b4d6d4820>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4b30c59000>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:50:09,534:INFO:Checking exceptions
2023-05-21 15:50:09,534:INFO:Importing libraries
2023-05-21 15:50:09,534:INFO:Copying training dataset
2023-05-21 15:50:09,557:INFO:Defining folds
2023-05-21 15:50:09,558:INFO:Declaring metric variables
2023-05-21 15:50:09,558:INFO:Importing untrained model
2023-05-21 15:50:09,558:INFO:Random Forest Classifier Imported successfully
2023-05-21 15:50:09,558:INFO:Starting cross validation
2023-05-21 15:50:09,559:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:50:11,067:INFO:Calculating mean and std
2023-05-21 15:50:11,068:INFO:Creating metrics dataframe
2023-05-21 15:50:11,091:INFO:Uploading results into container
2023-05-21 15:50:11,091:INFO:Uploading model into container now
2023-05-21 15:50:11,092:INFO:_master_model_container: 5
2023-05-21 15:50:11,092:INFO:_display_container: 2
2023-05-21 15:50:11,093:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-05-21 15:50:11,093:INFO:create_model() successfully completed......................................
2023-05-21 15:50:11,197:INFO:SubProcess create_model() end ==================================
2023-05-21 15:50:11,197:INFO:Creating metrics dataframe
2023-05-21 15:50:11,201:INFO:Initializing Linear Discriminant Analysis
2023-05-21 15:50:11,201:INFO:Total runtime is 0.13278467257817586 minutes
2023-05-21 15:50:11,201:INFO:SubProcess create_model() called ==================================
2023-05-21 15:50:11,201:INFO:Initializing create_model()
2023-05-21 15:50:11,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b4d6d4820>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4b30c59000>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:50:11,201:INFO:Checking exceptions
2023-05-21 15:50:11,201:INFO:Importing libraries
2023-05-21 15:50:11,201:INFO:Copying training dataset
2023-05-21 15:50:11,224:INFO:Defining folds
2023-05-21 15:50:11,224:INFO:Declaring metric variables
2023-05-21 15:50:11,224:INFO:Importing untrained model
2023-05-21 15:50:11,225:INFO:Linear Discriminant Analysis Imported successfully
2023-05-21 15:50:11,225:INFO:Starting cross validation
2023-05-21 15:50:11,226:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:50:11,878:INFO:Calculating mean and std
2023-05-21 15:50:11,879:INFO:Creating metrics dataframe
2023-05-21 15:50:11,903:INFO:Uploading results into container
2023-05-21 15:50:11,904:INFO:Uploading model into container now
2023-05-21 15:50:11,904:INFO:_master_model_container: 6
2023-05-21 15:50:11,904:INFO:_display_container: 2
2023-05-21 15:50:11,905:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-21 15:50:11,905:INFO:create_model() successfully completed......................................
2023-05-21 15:50:12,008:INFO:SubProcess create_model() end ==================================
2023-05-21 15:50:12,008:INFO:Creating metrics dataframe
2023-05-21 15:50:12,012:INFO:Initializing Extra Trees Classifier
2023-05-21 15:50:12,012:INFO:Total runtime is 0.14629933039347331 minutes
2023-05-21 15:50:12,012:INFO:SubProcess create_model() called ==================================
2023-05-21 15:50:12,012:INFO:Initializing create_model()
2023-05-21 15:50:12,012:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b4d6d4820>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4b30c59000>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:50:12,012:INFO:Checking exceptions
2023-05-21 15:50:12,012:INFO:Importing libraries
2023-05-21 15:50:12,012:INFO:Copying training dataset
2023-05-21 15:50:12,038:INFO:Defining folds
2023-05-21 15:50:12,038:INFO:Declaring metric variables
2023-05-21 15:50:12,039:INFO:Importing untrained model
2023-05-21 15:50:12,039:INFO:Extra Trees Classifier Imported successfully
2023-05-21 15:50:12,039:INFO:Starting cross validation
2023-05-21 15:50:12,040:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:50:13,553:INFO:Calculating mean and std
2023-05-21 15:50:13,554:INFO:Creating metrics dataframe
2023-05-21 15:50:13,577:INFO:Uploading results into container
2023-05-21 15:50:13,578:INFO:Uploading model into container now
2023-05-21 15:50:13,578:INFO:_master_model_container: 7
2023-05-21 15:50:13,578:INFO:_display_container: 2
2023-05-21 15:50:13,579:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-05-21 15:50:13,579:INFO:create_model() successfully completed......................................
2023-05-21 15:50:13,683:INFO:SubProcess create_model() end ==================================
2023-05-21 15:50:13,683:INFO:Creating metrics dataframe
2023-05-21 15:50:13,687:INFO:Initializing Extreme Gradient Boosting
2023-05-21 15:50:13,687:INFO:Total runtime is 0.17421542406082155 minutes
2023-05-21 15:50:13,687:INFO:SubProcess create_model() called ==================================
2023-05-21 15:50:13,687:INFO:Initializing create_model()
2023-05-21 15:50:13,687:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b4d6d4820>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4b30c59000>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:50:13,687:INFO:Checking exceptions
2023-05-21 15:50:13,687:INFO:Importing libraries
2023-05-21 15:50:13,687:INFO:Copying training dataset
2023-05-21 15:50:13,710:INFO:Defining folds
2023-05-21 15:50:13,710:INFO:Declaring metric variables
2023-05-21 15:50:13,710:INFO:Importing untrained model
2023-05-21 15:50:13,711:INFO:Extreme Gradient Boosting Imported successfully
2023-05-21 15:50:13,711:INFO:Starting cross validation
2023-05-21 15:50:13,712:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:50:14,492:INFO:Calculating mean and std
2023-05-21 15:50:14,493:INFO:Creating metrics dataframe
2023-05-21 15:50:14,516:INFO:Uploading results into container
2023-05-21 15:50:14,517:INFO:Uploading model into container now
2023-05-21 15:50:14,517:INFO:_master_model_container: 8
2023-05-21 15:50:14,517:INFO:_display_container: 2
2023-05-21 15:50:14,518:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-05-21 15:50:14,518:INFO:create_model() successfully completed......................................
2023-05-21 15:50:14,622:INFO:SubProcess create_model() end ==================================
2023-05-21 15:50:14,622:INFO:Creating metrics dataframe
2023-05-21 15:50:14,626:INFO:Initializing Light Gradient Boosting Machine
2023-05-21 15:50:14,626:INFO:Total runtime is 0.1898729205131531 minutes
2023-05-21 15:50:14,626:INFO:SubProcess create_model() called ==================================
2023-05-21 15:50:14,627:INFO:Initializing create_model()
2023-05-21 15:50:14,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b4d6d4820>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4b30c59000>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:50:14,627:INFO:Checking exceptions
2023-05-21 15:50:14,627:INFO:Importing libraries
2023-05-21 15:50:14,627:INFO:Copying training dataset
2023-05-21 15:50:14,650:INFO:Defining folds
2023-05-21 15:50:14,650:INFO:Declaring metric variables
2023-05-21 15:50:14,650:INFO:Importing untrained model
2023-05-21 15:50:14,651:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 15:50:14,651:INFO:Starting cross validation
2023-05-21 15:50:14,652:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:50:15,527:INFO:Calculating mean and std
2023-05-21 15:50:15,527:INFO:Creating metrics dataframe
2023-05-21 15:50:15,550:INFO:Uploading results into container
2023-05-21 15:50:15,551:INFO:Uploading model into container now
2023-05-21 15:50:15,551:INFO:_master_model_container: 9
2023-05-21 15:50:15,552:INFO:_display_container: 2
2023-05-21 15:50:15,552:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 15:50:15,552:INFO:create_model() successfully completed......................................
2023-05-21 15:50:15,656:INFO:SubProcess create_model() end ==================================
2023-05-21 15:50:15,656:INFO:Creating metrics dataframe
2023-05-21 15:50:15,662:INFO:Initializing create_model()
2023-05-21 15:50:15,662:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b4d6d4820>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:50:15,662:INFO:Checking exceptions
2023-05-21 15:50:15,662:INFO:Importing libraries
2023-05-21 15:50:15,662:INFO:Copying training dataset
2023-05-21 15:50:15,685:INFO:Defining folds
2023-05-21 15:50:15,685:INFO:Declaring metric variables
2023-05-21 15:50:15,685:INFO:Importing untrained model
2023-05-21 15:50:15,686:INFO:Declaring custom model
2023-05-21 15:50:15,687:INFO:Extreme Gradient Boosting Imported successfully
2023-05-21 15:50:15,687:INFO:Cross validation set to False
2023-05-21 15:50:15,687:INFO:Fitting Model
2023-05-21 15:50:15,868:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-05-21 15:50:15,868:INFO:create_model() successfully completed......................................
2023-05-21 15:50:15,974:INFO:Creating Dashboard logs
2023-05-21 15:50:15,974:INFO:Model: Extreme Gradient Boosting
2023-05-21 15:50:16,060:INFO:Logged params: {'objective': 'binary:logistic', 'use_label_encoder': None, 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': -1, 'num_parallel_tree': None, 'predictor': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2023-05-21 15:50:16,606:INFO:Initializing predict_model()
2023-05-21 15:50:16,606:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b4d6d4820>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7f4b3507bd90>)
2023-05-21 15:50:16,606:INFO:Checking exceptions
2023-05-21 15:50:16,606:INFO:Preloading libraries
2023-05-21 15:50:17,030:INFO:SubProcess plot_model() called ==================================
2023-05-21 15:50:17,030:INFO:Initializing plot_model()
2023-05-21 15:50:17,030:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp80xs_fxm, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b4d6d4820>, system=False)
2023-05-21 15:50:17,030:INFO:Checking exceptions
2023-05-21 15:50:17,038:INFO:Preloading libraries
2023-05-21 15:50:17,042:INFO:Copying training dataset
2023-05-21 15:50:17,042:INFO:Plot type: auc
2023-05-21 15:50:17,549:INFO:Fitting Model
2023-05-21 15:50:17,559:INFO:Scoring test/hold-out set
2023-05-21 15:50:17,714:INFO:Saving '/tmp/tmp80xs_fxm/AUC.png'
2023-05-21 15:50:18,115:INFO:Visual Rendered Successfully
2023-05-21 15:50:18,215:INFO:plot_model() successfully completed......................................
2023-05-21 15:50:18,216:INFO:Initializing plot_model()
2023-05-21 15:50:18,216:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp80xs_fxm, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b4d6d4820>, system=False)
2023-05-21 15:50:18,216:INFO:Checking exceptions
2023-05-21 15:50:18,225:INFO:Preloading libraries
2023-05-21 15:50:18,228:INFO:Copying training dataset
2023-05-21 15:50:18,228:INFO:Plot type: confusion_matrix
2023-05-21 15:50:18,412:INFO:Fitting Model
2023-05-21 15:50:18,416:INFO:Scoring test/hold-out set
2023-05-21 15:50:18,535:INFO:Saving '/tmp/tmp80xs_fxm/Confusion Matrix.png'
2023-05-21 15:50:18,633:INFO:Visual Rendered Successfully
2023-05-21 15:50:18,740:INFO:plot_model() successfully completed......................................
2023-05-21 15:50:18,741:INFO:Initializing plot_model()
2023-05-21 15:50:18,741:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp80xs_fxm, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b4d6d4820>, system=False)
2023-05-21 15:50:18,742:INFO:Checking exceptions
2023-05-21 15:50:18,750:INFO:Preloading libraries
2023-05-21 15:50:18,753:INFO:Copying training dataset
2023-05-21 15:50:18,754:INFO:Plot type: feature
2023-05-21 15:50:18,754:WARNING:No coef_ found. Trying feature_importances_
2023-05-21 15:50:18,845:INFO:Saving '/tmp/tmp80xs_fxm/Feature Importance.png'
2023-05-21 15:50:18,988:INFO:Visual Rendered Successfully
2023-05-21 15:50:19,091:INFO:plot_model() successfully completed......................................
2023-05-21 15:50:19,092:INFO:SubProcess plot_model() end ==================================
2023-05-21 15:50:19,130:WARNING:/home/feuer/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-05-21 15:50:19,524:INFO:Creating Dashboard logs
2023-05-21 15:50:19,524:INFO:Model: Light Gradient Boosting Machine
2023-05-21 15:50:19,602:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-21 15:50:20,469:INFO:Creating Dashboard logs
2023-05-21 15:50:20,469:INFO:Model: Random Forest Classifier
2023-05-21 15:50:20,551:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 15:50:21,438:INFO:Creating Dashboard logs
2023-05-21 15:50:21,438:INFO:Model: Extra Trees Classifier
2023-05-21 15:50:21,525:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 15:50:22,452:INFO:Creating Dashboard logs
2023-05-21 15:50:22,452:INFO:Model: Decision Tree Classifier
2023-05-21 15:50:22,526:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2023-05-21 15:50:23,411:INFO:Creating Dashboard logs
2023-05-21 15:50:23,412:INFO:Model: Logistic Regression
2023-05-21 15:50:23,501:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-05-21 15:50:24,519:INFO:Creating Dashboard logs
2023-05-21 15:50:24,519:INFO:Model: Linear Discriminant Analysis
2023-05-21 15:50:24,616:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-05-21 15:50:25,518:INFO:Creating Dashboard logs
2023-05-21 15:50:25,518:INFO:Model: Naive Bayes
2023-05-21 15:50:25,635:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-05-21 15:50:26,439:INFO:Creating Dashboard logs
2023-05-21 15:50:26,440:INFO:Model: Ridge Classifier
2023-05-21 15:50:26,519:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2023-05-21 15:50:27,560:INFO:_master_model_container: 9
2023-05-21 15:50:27,560:INFO:_display_container: 2
2023-05-21 15:50:27,561:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-05-21 15:50:27,561:INFO:compare_models() successfully completed......................................
2023-05-21 15:50:27,573:INFO:PyCaret ClassificationExperiment
2023-05-21 15:50:27,573:INFO:Logging name: OnlyImportantFeatures
2023-05-21 15:50:27,573:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-21 15:50:27,573:INFO:version 3.0.0
2023-05-21 15:50:27,573:INFO:Initializing setup()
2023-05-21 15:50:27,573:INFO:self.USI: 28c3
2023-05-21 15:50:27,573:INFO:self._variable_keys: {'fold_groups_param', 'idx', 'y', 'y_test', 'memory', 'exp_name_log', 'data', 'is_multiclass', 'X_train', 'seed', 'fold_shuffle_param', 'USI', 'X', 'n_jobs_param', 'logging_param', 'gpu_param', 'y_train', 'exp_id', 'log_plots_param', 'fix_imbalance', 'target_param', 'X_test', '_ml_usecase', 'gpu_n_jobs_param', 'html_param', 'pipeline', '_available_plots', 'fold_generator'}
2023-05-21 15:50:27,573:INFO:Checking environment
2023-05-21 15:50:27,573:INFO:python_version: 3.10.10
2023-05-21 15:50:27,573:INFO:python_build: ('main', 'Mar  5 2023 22:26:53')
2023-05-21 15:50:27,573:INFO:machine: x86_64
2023-05-21 15:50:27,573:INFO:platform: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 15:50:27,573:INFO:Memory: svmem(total=16717086720, available=2485014528, percent=85.1, used=11949334528, free=1695178752, active=8470855680, inactive=1976549376, buffers=26968064, cached=3045605376, shared=1935101952, slab=518123520)
2023-05-21 15:50:27,574:INFO:Physical Core: 6
2023-05-21 15:50:27,574:INFO:Logical Core: 12
2023-05-21 15:50:27,574:INFO:Checking libraries
2023-05-21 15:50:27,574:INFO:System:
2023-05-21 15:50:27,574:INFO:    python: 3.10.10 (main, Mar  5 2023, 22:26:53) [GCC 12.2.1 20230201]
2023-05-21 15:50:27,574:INFO:executable: /usr/bin/python3.10
2023-05-21 15:50:27,574:INFO:   machine: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 15:50:27,574:INFO:PyCaret required dependencies:
2023-05-21 15:50:27,574:INFO:                 pip: 23.0.1
2023-05-21 15:50:27,574:INFO:          setuptools: 67.6.1
2023-05-21 15:50:27,574:INFO:             pycaret: 3.0.0
2023-05-21 15:50:27,574:INFO:             IPython: 8.12.0
2023-05-21 15:50:27,574:INFO:          ipywidgets: 7.7.5
2023-05-21 15:50:27,574:INFO:                tqdm: 4.64.1
2023-05-21 15:50:27,574:INFO:               numpy: 1.23.0
2023-05-21 15:50:27,574:INFO:              pandas: 1.5.3
2023-05-21 15:50:27,574:INFO:              jinja2: 3.1.2
2023-05-21 15:50:27,574:INFO:               scipy: 1.9.3
2023-05-21 15:50:27,574:INFO:              joblib: 1.2.0
2023-05-21 15:50:27,574:INFO:             sklearn: 1.2.2
2023-05-21 15:50:27,575:INFO:                pyod: 1.0.9
2023-05-21 15:50:27,575:INFO:            imblearn: 0.10.1
2023-05-21 15:50:27,575:INFO:   category_encoders: 2.6.0
2023-05-21 15:50:27,575:INFO:            lightgbm: 3.3.5
2023-05-21 15:50:27,575:INFO:               numba: 0.57.0
2023-05-21 15:50:27,575:INFO:            requests: 2.28.2
2023-05-21 15:50:27,575:INFO:          matplotlib: 3.6.3
2023-05-21 15:50:27,575:INFO:          scikitplot: 0.3.7
2023-05-21 15:50:27,575:INFO:         yellowbrick: 1.5
2023-05-21 15:50:27,575:INFO:              plotly: 5.14.1
2023-05-21 15:50:27,575:INFO:             kaleido: 0.2.1
2023-05-21 15:50:27,575:INFO:         statsmodels: 0.13.5
2023-05-21 15:50:27,575:INFO:              sktime: 0.18.0
2023-05-21 15:50:27,575:INFO:               tbats: 1.1.3
2023-05-21 15:50:27,575:INFO:            pmdarima: 2.0.3
2023-05-21 15:50:27,575:INFO:              psutil: 5.9.4
2023-05-21 15:50:27,575:INFO:PyCaret optional dependencies:
2023-05-21 15:50:27,575:INFO:                shap: 0.41.0
2023-05-21 15:50:27,575:INFO:           interpret: 0.3.2
2023-05-21 15:50:27,575:INFO:                umap: 0.5.3
2023-05-21 15:50:27,575:INFO:    pandas_profiling: 3.6.6
2023-05-21 15:50:27,575:INFO:  explainerdashboard: 0.4.2.2
2023-05-21 15:50:27,575:INFO:             autoviz: 0.1.603
2023-05-21 15:50:27,575:INFO:           fairlearn: 0.7.0
2023-05-21 15:50:27,575:INFO:             xgboost: 1.7.5
2023-05-21 15:50:27,575:INFO:            catboost: Not installed
2023-05-21 15:50:27,576:INFO:              kmodes: Not installed
2023-05-21 15:50:27,576:INFO:             mlxtend: Not installed
2023-05-21 15:50:27,576:INFO:       statsforecast: Not installed
2023-05-21 15:50:27,576:INFO:        tune_sklearn: Not installed
2023-05-21 15:50:27,576:INFO:                 ray: Not installed
2023-05-21 15:50:27,576:INFO:            hyperopt: Not installed
2023-05-21 15:50:27,576:INFO:              optuna: 3.1.1
2023-05-21 15:50:27,576:INFO:               skopt: Not installed
2023-05-21 15:50:27,576:INFO:              mlflow: 2.3.1
2023-05-21 15:50:27,576:INFO:              gradio: Not installed
2023-05-21 15:50:27,576:INFO:             fastapi: Not installed
2023-05-21 15:50:27,576:INFO:             uvicorn: Not installed
2023-05-21 15:50:27,576:INFO:              m2cgen: Not installed
2023-05-21 15:50:27,576:INFO:           evidently: Not installed
2023-05-21 15:50:27,576:INFO:               fugue: Not installed
2023-05-21 15:50:27,576:INFO:           streamlit: Not installed
2023-05-21 15:50:27,576:INFO:             prophet: Not installed
2023-05-21 15:50:27,576:INFO:None
2023-05-21 15:50:27,576:INFO:Set up data.
2023-05-21 15:50:27,703:INFO:Set up train/test split.
2023-05-21 15:50:27,761:INFO:Set up index.
2023-05-21 15:50:27,761:INFO:Set up folding strategy.
2023-05-21 15:50:27,761:INFO:Assigning column types.
2023-05-21 15:50:27,768:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-21 15:50:27,817:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 15:50:27,818:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:50:27,849:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:50:27,852:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:50:27,899:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 15:50:27,900:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:50:27,928:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:50:27,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:50:27,931:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-21 15:50:27,975:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:50:28,003:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:50:28,005:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:50:28,050:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:50:28,080:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:50:28,083:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:50:28,083:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-21 15:50:28,155:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:50:28,158:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:50:28,233:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:50:28,235:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:50:28,236:INFO:Preparing preprocessing pipeline...
2023-05-21 15:50:28,238:INFO:Set up simple imputation.
2023-05-21 15:50:28,249:INFO:Set up encoding of categorical features.
2023-05-21 15:50:28,385:INFO:Finished creating preprocessing pipeline.
2023-05-21 15:50:28,390:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 15:50:28,390:INFO:Creating final display dataframe.
2023-05-21 15:50:28,581:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     42
1                        Target      app_complete_flag
2                   Target type                 Binary
3           Original data shape            (238964, 7)
4        Transformed data shape           (238964, 39)
5   Transformed train set shape           (167274, 39)
6    Transformed test set shape            (71690, 39)
7              Numeric features                      3
8          Categorical features                      3
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13     Maximum one-hot encoding                     25
14              Encoding method                   None
15               Fold Generator        StratifiedKFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                  False
19               Log Experiment           MlflowLogger
20              Experiment Name  OnlyImportantFeatures
21                          USI                   28c3
2023-05-21 15:50:28,657:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:50:28,659:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:50:28,731:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:50:28,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:50:28,734:INFO:Logging experiment in loggers
2023-05-21 15:50:29,409:INFO:SubProcess save_model() called ==================================
2023-05-21 15:50:29,427:INFO:Initializing save_model()
2023-05-21 15:50:29,427:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/tmp/tmpjdptw0m7/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-21 15:50:29,427:INFO:Adding model into prep_pipe
2023-05-21 15:50:29,429:WARNING:Only Model saved as it was a pipeline.
2023-05-21 15:50:29,441:INFO:/tmp/tmpjdptw0m7/Transformation Pipeline.pkl saved in current working directory
2023-05-21 15:50:29,451:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 15:50:29,451:INFO:save_model() successfully completed......................................
2023-05-21 15:50:29,570:INFO:SubProcess save_model() end ==================================
2023-05-21 15:50:30,150:INFO:setup() successfully completed in 1.17s...............
2023-05-21 15:50:30,150:INFO:Initializing compare_models()
2023-05-21 15:50:30,150:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b36348280>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f4b36348280>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'])
2023-05-21 15:50:30,150:INFO:Checking exceptions
2023-05-21 15:50:30,162:INFO:Preparing display monitor
2023-05-21 15:50:30,164:INFO:Initializing Logistic Regression
2023-05-21 15:50:30,164:INFO:Total runtime is 1.0848045349121093e-06 minutes
2023-05-21 15:50:30,164:INFO:SubProcess create_model() called ==================================
2023-05-21 15:50:30,164:INFO:Initializing create_model()
2023-05-21 15:50:30,164:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b36348280>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4b35bc8430>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:50:30,164:INFO:Checking exceptions
2023-05-21 15:50:30,164:INFO:Importing libraries
2023-05-21 15:50:30,164:INFO:Copying training dataset
2023-05-21 15:50:30,187:INFO:Defining folds
2023-05-21 15:50:30,187:INFO:Declaring metric variables
2023-05-21 15:50:30,187:INFO:Importing untrained model
2023-05-21 15:50:30,187:INFO:Logistic Regression Imported successfully
2023-05-21 15:50:30,187:INFO:Starting cross validation
2023-05-21 15:50:30,188:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:50:30,820:INFO:Calculating mean and std
2023-05-21 15:50:30,821:INFO:Creating metrics dataframe
2023-05-21 15:50:30,845:INFO:Uploading results into container
2023-05-21 15:50:30,846:INFO:Uploading model into container now
2023-05-21 15:50:30,846:INFO:_master_model_container: 1
2023-05-21 15:50:30,847:INFO:_display_container: 2
2023-05-21 15:50:30,847:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-21 15:50:30,847:INFO:create_model() successfully completed......................................
2023-05-21 15:50:30,964:INFO:SubProcess create_model() end ==================================
2023-05-21 15:50:30,964:INFO:Creating metrics dataframe
2023-05-21 15:50:30,968:INFO:Initializing Naive Bayes
2023-05-21 15:50:30,968:INFO:Total runtime is 0.01339948574701945 minutes
2023-05-21 15:50:30,968:INFO:SubProcess create_model() called ==================================
2023-05-21 15:50:30,968:INFO:Initializing create_model()
2023-05-21 15:50:30,968:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b36348280>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4b35bc8430>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:50:30,968:INFO:Checking exceptions
2023-05-21 15:50:30,968:INFO:Importing libraries
2023-05-21 15:50:30,968:INFO:Copying training dataset
2023-05-21 15:50:30,996:INFO:Defining folds
2023-05-21 15:50:30,996:INFO:Declaring metric variables
2023-05-21 15:50:30,996:INFO:Importing untrained model
2023-05-21 15:50:30,996:INFO:Naive Bayes Imported successfully
2023-05-21 15:50:30,996:INFO:Starting cross validation
2023-05-21 15:50:30,997:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:50:31,698:INFO:Calculating mean and std
2023-05-21 15:50:31,699:INFO:Creating metrics dataframe
2023-05-21 15:50:31,725:INFO:Uploading results into container
2023-05-21 15:50:31,726:INFO:Uploading model into container now
2023-05-21 15:50:31,726:INFO:_master_model_container: 2
2023-05-21 15:50:31,727:INFO:_display_container: 2
2023-05-21 15:50:31,727:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-21 15:50:31,727:INFO:create_model() successfully completed......................................
2023-05-21 15:50:31,842:INFO:SubProcess create_model() end ==================================
2023-05-21 15:50:31,842:INFO:Creating metrics dataframe
2023-05-21 15:50:31,846:INFO:Initializing Decision Tree Classifier
2023-05-21 15:50:31,846:INFO:Total runtime is 0.02804112434387207 minutes
2023-05-21 15:50:31,846:INFO:SubProcess create_model() called ==================================
2023-05-21 15:50:31,846:INFO:Initializing create_model()
2023-05-21 15:50:31,847:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b36348280>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4b35bc8430>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:50:31,847:INFO:Checking exceptions
2023-05-21 15:50:31,847:INFO:Importing libraries
2023-05-21 15:50:31,847:INFO:Copying training dataset
2023-05-21 15:50:31,874:INFO:Defining folds
2023-05-21 15:50:31,874:INFO:Declaring metric variables
2023-05-21 15:50:31,875:INFO:Importing untrained model
2023-05-21 15:50:31,875:INFO:Decision Tree Classifier Imported successfully
2023-05-21 15:50:31,875:INFO:Starting cross validation
2023-05-21 15:50:31,876:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:50:32,538:INFO:Calculating mean and std
2023-05-21 15:50:32,539:INFO:Creating metrics dataframe
2023-05-21 15:50:32,565:INFO:Uploading results into container
2023-05-21 15:50:32,566:INFO:Uploading model into container now
2023-05-21 15:50:32,566:INFO:_master_model_container: 3
2023-05-21 15:50:32,566:INFO:_display_container: 2
2023-05-21 15:50:32,567:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-05-21 15:50:32,567:INFO:create_model() successfully completed......................................
2023-05-21 15:50:32,682:INFO:SubProcess create_model() end ==================================
2023-05-21 15:50:32,682:INFO:Creating metrics dataframe
2023-05-21 15:50:32,686:INFO:Initializing Ridge Classifier
2023-05-21 15:50:32,686:INFO:Total runtime is 0.042038377126057944 minutes
2023-05-21 15:50:32,686:INFO:SubProcess create_model() called ==================================
2023-05-21 15:50:32,686:INFO:Initializing create_model()
2023-05-21 15:50:32,686:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b36348280>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4b35bc8430>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:50:32,686:INFO:Checking exceptions
2023-05-21 15:50:32,686:INFO:Importing libraries
2023-05-21 15:50:32,686:INFO:Copying training dataset
2023-05-21 15:50:32,709:INFO:Defining folds
2023-05-21 15:50:32,709:INFO:Declaring metric variables
2023-05-21 15:50:32,709:INFO:Importing untrained model
2023-05-21 15:50:32,709:INFO:Ridge Classifier Imported successfully
2023-05-21 15:50:32,709:INFO:Starting cross validation
2023-05-21 15:50:32,710:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:50:32,987:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:50:33,091:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:50:33,092:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:50:33,100:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:50:33,125:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:50:33,140:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:50:33,142:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:50:33,151:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:50:33,153:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:50:33,190:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:50:33,316:INFO:Calculating mean and std
2023-05-21 15:50:33,317:INFO:Creating metrics dataframe
2023-05-21 15:50:33,343:INFO:Uploading results into container
2023-05-21 15:50:33,344:INFO:Uploading model into container now
2023-05-21 15:50:33,344:INFO:_master_model_container: 4
2023-05-21 15:50:33,344:INFO:_display_container: 2
2023-05-21 15:50:33,345:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-05-21 15:50:33,345:INFO:create_model() successfully completed......................................
2023-05-21 15:50:33,462:INFO:SubProcess create_model() end ==================================
2023-05-21 15:50:33,462:INFO:Creating metrics dataframe
2023-05-21 15:50:33,467:INFO:Initializing Random Forest Classifier
2023-05-21 15:50:33,467:INFO:Total runtime is 0.0550526777903239 minutes
2023-05-21 15:50:33,467:INFO:SubProcess create_model() called ==================================
2023-05-21 15:50:33,467:INFO:Initializing create_model()
2023-05-21 15:50:33,467:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b36348280>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4b35bc8430>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:50:33,467:INFO:Checking exceptions
2023-05-21 15:50:33,467:INFO:Importing libraries
2023-05-21 15:50:33,467:INFO:Copying training dataset
2023-05-21 15:50:33,496:INFO:Defining folds
2023-05-21 15:50:33,496:INFO:Declaring metric variables
2023-05-21 15:50:33,496:INFO:Importing untrained model
2023-05-21 15:50:33,497:INFO:Random Forest Classifier Imported successfully
2023-05-21 15:50:33,497:INFO:Starting cross validation
2023-05-21 15:50:33,498:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:50:34,950:INFO:Calculating mean and std
2023-05-21 15:50:34,951:INFO:Creating metrics dataframe
2023-05-21 15:50:34,974:INFO:Uploading results into container
2023-05-21 15:50:34,974:INFO:Uploading model into container now
2023-05-21 15:50:34,975:INFO:_master_model_container: 5
2023-05-21 15:50:34,975:INFO:_display_container: 2
2023-05-21 15:50:34,976:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-05-21 15:50:34,976:INFO:create_model() successfully completed......................................
2023-05-21 15:50:35,083:INFO:SubProcess create_model() end ==================================
2023-05-21 15:50:35,083:INFO:Creating metrics dataframe
2023-05-21 15:50:35,087:INFO:Initializing Linear Discriminant Analysis
2023-05-21 15:50:35,087:INFO:Total runtime is 0.08205313682556153 minutes
2023-05-21 15:50:35,087:INFO:SubProcess create_model() called ==================================
2023-05-21 15:50:35,087:INFO:Initializing create_model()
2023-05-21 15:50:35,087:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b36348280>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4b35bc8430>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:50:35,087:INFO:Checking exceptions
2023-05-21 15:50:35,087:INFO:Importing libraries
2023-05-21 15:50:35,087:INFO:Copying training dataset
2023-05-21 15:50:35,109:INFO:Defining folds
2023-05-21 15:50:35,109:INFO:Declaring metric variables
2023-05-21 15:50:35,110:INFO:Importing untrained model
2023-05-21 15:50:35,110:INFO:Linear Discriminant Analysis Imported successfully
2023-05-21 15:50:35,110:INFO:Starting cross validation
2023-05-21 15:50:35,111:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:50:35,768:INFO:Calculating mean and std
2023-05-21 15:50:35,769:INFO:Creating metrics dataframe
2023-05-21 15:50:35,792:INFO:Uploading results into container
2023-05-21 15:50:35,792:INFO:Uploading model into container now
2023-05-21 15:50:35,793:INFO:_master_model_container: 6
2023-05-21 15:50:35,793:INFO:_display_container: 2
2023-05-21 15:50:35,793:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-21 15:50:35,793:INFO:create_model() successfully completed......................................
2023-05-21 15:50:35,901:INFO:SubProcess create_model() end ==================================
2023-05-21 15:50:35,901:INFO:Creating metrics dataframe
2023-05-21 15:50:35,906:INFO:Initializing Extra Trees Classifier
2023-05-21 15:50:35,906:INFO:Total runtime is 0.09570308526357016 minutes
2023-05-21 15:50:35,906:INFO:SubProcess create_model() called ==================================
2023-05-21 15:50:35,906:INFO:Initializing create_model()
2023-05-21 15:50:35,906:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b36348280>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4b35bc8430>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:50:35,906:INFO:Checking exceptions
2023-05-21 15:50:35,906:INFO:Importing libraries
2023-05-21 15:50:35,906:INFO:Copying training dataset
2023-05-21 15:50:35,929:INFO:Defining folds
2023-05-21 15:50:35,929:INFO:Declaring metric variables
2023-05-21 15:50:35,929:INFO:Importing untrained model
2023-05-21 15:50:35,930:INFO:Extra Trees Classifier Imported successfully
2023-05-21 15:50:35,930:INFO:Starting cross validation
2023-05-21 15:50:35,931:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:50:37,440:INFO:Calculating mean and std
2023-05-21 15:50:37,440:INFO:Creating metrics dataframe
2023-05-21 15:50:37,453:INFO:Uploading results into container
2023-05-21 15:50:37,453:INFO:Uploading model into container now
2023-05-21 15:50:37,453:INFO:_master_model_container: 7
2023-05-21 15:50:37,453:INFO:_display_container: 2
2023-05-21 15:50:37,454:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-05-21 15:50:37,454:INFO:create_model() successfully completed......................................
2023-05-21 15:50:37,563:INFO:SubProcess create_model() end ==================================
2023-05-21 15:50:37,563:INFO:Creating metrics dataframe
2023-05-21 15:50:37,567:INFO:Initializing Extreme Gradient Boosting
2023-05-21 15:50:37,567:INFO:Total runtime is 0.12339192231496177 minutes
2023-05-21 15:50:37,567:INFO:SubProcess create_model() called ==================================
2023-05-21 15:50:37,568:INFO:Initializing create_model()
2023-05-21 15:50:37,568:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b36348280>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4b35bc8430>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:50:37,568:INFO:Checking exceptions
2023-05-21 15:50:37,568:INFO:Importing libraries
2023-05-21 15:50:37,568:INFO:Copying training dataset
2023-05-21 15:50:37,590:INFO:Defining folds
2023-05-21 15:50:37,590:INFO:Declaring metric variables
2023-05-21 15:50:37,590:INFO:Importing untrained model
2023-05-21 15:50:37,591:INFO:Extreme Gradient Boosting Imported successfully
2023-05-21 15:50:37,591:INFO:Starting cross validation
2023-05-21 15:50:37,592:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:50:38,382:INFO:Calculating mean and std
2023-05-21 15:50:38,383:INFO:Creating metrics dataframe
2023-05-21 15:50:38,407:INFO:Uploading results into container
2023-05-21 15:50:38,407:INFO:Uploading model into container now
2023-05-21 15:50:38,408:INFO:_master_model_container: 8
2023-05-21 15:50:38,408:INFO:_display_container: 2
2023-05-21 15:50:38,409:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-05-21 15:50:38,409:INFO:create_model() successfully completed......................................
2023-05-21 15:50:38,515:INFO:SubProcess create_model() end ==================================
2023-05-21 15:50:38,515:INFO:Creating metrics dataframe
2023-05-21 15:50:38,520:INFO:Initializing Light Gradient Boosting Machine
2023-05-21 15:50:38,520:INFO:Total runtime is 0.13927348057428998 minutes
2023-05-21 15:50:38,520:INFO:SubProcess create_model() called ==================================
2023-05-21 15:50:38,520:INFO:Initializing create_model()
2023-05-21 15:50:38,520:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b36348280>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4b35bc8430>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:50:38,521:INFO:Checking exceptions
2023-05-21 15:50:38,521:INFO:Importing libraries
2023-05-21 15:50:38,521:INFO:Copying training dataset
2023-05-21 15:50:38,545:INFO:Defining folds
2023-05-21 15:50:38,545:INFO:Declaring metric variables
2023-05-21 15:50:38,545:INFO:Importing untrained model
2023-05-21 15:50:38,546:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 15:50:38,546:INFO:Starting cross validation
2023-05-21 15:50:38,547:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:50:39,414:INFO:Calculating mean and std
2023-05-21 15:50:39,414:INFO:Creating metrics dataframe
2023-05-21 15:50:39,432:INFO:Uploading results into container
2023-05-21 15:50:39,433:INFO:Uploading model into container now
2023-05-21 15:50:39,433:INFO:_master_model_container: 9
2023-05-21 15:50:39,433:INFO:_display_container: 2
2023-05-21 15:50:39,434:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 15:50:39,434:INFO:create_model() successfully completed......................................
2023-05-21 15:50:39,545:INFO:SubProcess create_model() end ==================================
2023-05-21 15:50:39,545:INFO:Creating metrics dataframe
2023-05-21 15:50:39,552:INFO:Initializing create_model()
2023-05-21 15:50:39,552:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b36348280>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:50:39,552:INFO:Checking exceptions
2023-05-21 15:50:39,552:INFO:Importing libraries
2023-05-21 15:50:39,552:INFO:Copying training dataset
2023-05-21 15:50:39,578:INFO:Defining folds
2023-05-21 15:50:39,578:INFO:Declaring metric variables
2023-05-21 15:50:39,578:INFO:Importing untrained model
2023-05-21 15:50:39,578:INFO:Declaring custom model
2023-05-21 15:50:39,579:INFO:Extreme Gradient Boosting Imported successfully
2023-05-21 15:50:39,580:INFO:Cross validation set to False
2023-05-21 15:50:39,580:INFO:Fitting Model
2023-05-21 15:50:39,762:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-05-21 15:50:39,762:INFO:create_model() successfully completed......................................
2023-05-21 15:50:39,874:INFO:Creating Dashboard logs
2023-05-21 15:50:39,875:INFO:Model: Extreme Gradient Boosting
2023-05-21 15:50:39,952:INFO:Logged params: {'objective': 'binary:logistic', 'use_label_encoder': None, 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': -1, 'num_parallel_tree': None, 'predictor': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2023-05-21 15:50:40,419:INFO:Initializing predict_model()
2023-05-21 15:50:40,419:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b36348280>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7f4b33b6a050>)
2023-05-21 15:50:40,420:INFO:Checking exceptions
2023-05-21 15:50:40,420:INFO:Preloading libraries
2023-05-21 15:50:40,844:INFO:SubProcess plot_model() called ==================================
2023-05-21 15:50:40,844:INFO:Initializing plot_model()
2023-05-21 15:50:40,844:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp7f0_fy33, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b36348280>, system=False)
2023-05-21 15:50:40,845:INFO:Checking exceptions
2023-05-21 15:50:40,854:INFO:Preloading libraries
2023-05-21 15:50:40,858:INFO:Copying training dataset
2023-05-21 15:50:40,858:INFO:Plot type: auc
2023-05-21 15:50:41,056:INFO:Fitting Model
2023-05-21 15:50:41,061:INFO:Scoring test/hold-out set
2023-05-21 15:50:41,212:INFO:Saving '/tmp/tmp7f0_fy33/AUC.png'
2023-05-21 15:50:41,375:INFO:Visual Rendered Successfully
2023-05-21 15:50:41,475:INFO:plot_model() successfully completed......................................
2023-05-21 15:50:41,477:INFO:Initializing plot_model()
2023-05-21 15:50:41,477:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp7f0_fy33, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b36348280>, system=False)
2023-05-21 15:50:41,477:INFO:Checking exceptions
2023-05-21 15:50:41,485:INFO:Preloading libraries
2023-05-21 15:50:41,489:INFO:Copying training dataset
2023-05-21 15:50:41,490:INFO:Plot type: confusion_matrix
2023-05-21 15:50:41,668:INFO:Fitting Model
2023-05-21 15:50:41,671:INFO:Scoring test/hold-out set
2023-05-21 15:50:41,786:INFO:Saving '/tmp/tmp7f0_fy33/Confusion Matrix.png'
2023-05-21 15:50:41,875:INFO:Visual Rendered Successfully
2023-05-21 15:50:41,987:INFO:plot_model() successfully completed......................................
2023-05-21 15:50:41,988:INFO:Initializing plot_model()
2023-05-21 15:50:41,988:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp7f0_fy33, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4b36348280>, system=False)
2023-05-21 15:50:41,988:INFO:Checking exceptions
2023-05-21 15:50:41,997:INFO:Preloading libraries
2023-05-21 15:50:42,000:INFO:Copying training dataset
2023-05-21 15:50:42,001:INFO:Plot type: feature
2023-05-21 15:50:42,001:WARNING:No coef_ found. Trying feature_importances_
2023-05-21 15:50:42,082:INFO:Saving '/tmp/tmp7f0_fy33/Feature Importance.png'
2023-05-21 15:50:42,220:INFO:Visual Rendered Successfully
2023-05-21 15:50:42,318:INFO:plot_model() successfully completed......................................
2023-05-21 15:50:42,318:INFO:SubProcess plot_model() end ==================================
2023-05-21 15:50:42,556:INFO:Creating Dashboard logs
2023-05-21 15:50:42,556:INFO:Model: Light Gradient Boosting Machine
2023-05-21 15:50:42,631:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-21 15:50:43,560:INFO:Creating Dashboard logs
2023-05-21 15:50:43,560:INFO:Model: Random Forest Classifier
2023-05-21 15:50:43,650:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 15:50:44,526:INFO:Creating Dashboard logs
2023-05-21 15:50:44,527:INFO:Model: Extra Trees Classifier
2023-05-21 15:50:44,629:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 15:50:45,471:INFO:Creating Dashboard logs
2023-05-21 15:50:45,471:INFO:Model: Decision Tree Classifier
2023-05-21 15:50:45,551:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2023-05-21 15:50:46,409:INFO:Creating Dashboard logs
2023-05-21 15:50:46,410:INFO:Model: Logistic Regression
2023-05-21 15:50:46,505:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-05-21 15:50:47,274:INFO:Creating Dashboard logs
2023-05-21 15:50:47,274:INFO:Model: Linear Discriminant Analysis
2023-05-21 15:50:47,352:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-05-21 15:50:48,192:INFO:Creating Dashboard logs
2023-05-21 15:50:48,193:INFO:Model: Naive Bayes
2023-05-21 15:50:48,277:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-05-21 15:50:49,111:INFO:Creating Dashboard logs
2023-05-21 15:50:49,111:INFO:Model: Ridge Classifier
2023-05-21 15:50:49,189:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2023-05-21 15:50:49,962:INFO:_master_model_container: 9
2023-05-21 15:50:49,962:INFO:_display_container: 2
2023-05-21 15:50:49,962:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-05-21 15:50:49,962:INFO:compare_models() successfully completed......................................
2023-05-21 15:53:44,141:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:53:44,142:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:53:44,142:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:53:44,142:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 15:53:45,322:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-21 15:53:55,219:INFO:PyCaret ClassificationExperiment
2023-05-21 15:53:55,219:INFO:Logging name: Lead_Scoring_Training_Pipeline
2023-05-21 15:53:55,219:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-21 15:53:55,219:INFO:version 3.0.0
2023-05-21 15:53:55,219:INFO:Initializing setup()
2023-05-21 15:53:55,220:INFO:self.USI: 1ef0
2023-05-21 15:53:55,220:INFO:self._variable_keys: {'pipeline', 'html_param', 'target_param', 'fold_shuffle_param', 'logging_param', 'gpu_n_jobs_param', 'fold_groups_param', 'y', '_ml_usecase', 'memory', 'USI', 'y_train', '_available_plots', 'X', 'fix_imbalance', 'exp_id', 'X_train', 'exp_name_log', 'idx', 'X_test', 'log_plots_param', 'data', 'y_test', 'is_multiclass', 'n_jobs_param', 'fold_generator', 'seed', 'gpu_param'}
2023-05-21 15:53:55,220:INFO:Checking environment
2023-05-21 15:53:55,220:INFO:python_version: 3.10.10
2023-05-21 15:53:55,220:INFO:python_build: ('main', 'Mar  5 2023 22:26:53')
2023-05-21 15:53:55,220:INFO:machine: x86_64
2023-05-21 15:53:55,222:INFO:platform: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 15:53:55,222:INFO:Memory: svmem(total=16717086720, available=4618706944, percent=72.4, used=9810444288, free=3676254208, active=6393208832, inactive=2083500032, buffers=35078144, cached=3195310080, shared=1940303872, slab=515903488)
2023-05-21 15:53:55,224:INFO:Physical Core: 6
2023-05-21 15:53:55,224:INFO:Logical Core: 12
2023-05-21 15:53:55,224:INFO:Checking libraries
2023-05-21 15:53:55,224:INFO:System:
2023-05-21 15:53:55,225:INFO:    python: 3.10.10 (main, Mar  5 2023, 22:26:53) [GCC 12.2.1 20230201]
2023-05-21 15:53:55,225:INFO:executable: /usr/bin/python3.10
2023-05-21 15:53:55,225:INFO:   machine: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 15:53:55,225:INFO:PyCaret required dependencies:
2023-05-21 15:53:55,225:INFO:                 pip: 23.0.1
2023-05-21 15:53:55,225:INFO:          setuptools: 67.6.1
2023-05-21 15:53:55,225:INFO:             pycaret: 3.0.0
2023-05-21 15:53:55,226:INFO:             IPython: 8.12.0
2023-05-21 15:53:55,226:INFO:          ipywidgets: 7.7.5
2023-05-21 15:53:55,226:INFO:                tqdm: 4.64.1
2023-05-21 15:53:55,226:INFO:               numpy: 1.23.0
2023-05-21 15:53:55,226:INFO:              pandas: 1.5.3
2023-05-21 15:53:55,226:INFO:              jinja2: 3.1.2
2023-05-21 15:53:55,226:INFO:               scipy: 1.9.3
2023-05-21 15:53:55,226:INFO:              joblib: 1.2.0
2023-05-21 15:53:55,226:INFO:             sklearn: 1.2.2
2023-05-21 15:53:55,226:INFO:                pyod: 1.0.9
2023-05-21 15:53:55,226:INFO:            imblearn: 0.10.1
2023-05-21 15:53:55,227:INFO:   category_encoders: 2.6.0
2023-05-21 15:53:55,227:INFO:            lightgbm: 3.3.5
2023-05-21 15:53:55,227:INFO:               numba: 0.57.0
2023-05-21 15:53:55,227:INFO:            requests: 2.28.2
2023-05-21 15:53:55,227:INFO:          matplotlib: 3.6.3
2023-05-21 15:53:55,227:INFO:          scikitplot: 0.3.7
2023-05-21 15:53:55,227:INFO:         yellowbrick: 1.5
2023-05-21 15:53:55,227:INFO:              plotly: 5.14.1
2023-05-21 15:53:55,227:INFO:             kaleido: 0.2.1
2023-05-21 15:53:55,227:INFO:         statsmodels: 0.13.5
2023-05-21 15:53:55,228:INFO:              sktime: 0.18.0
2023-05-21 15:53:55,228:INFO:               tbats: 1.1.3
2023-05-21 15:53:55,228:INFO:            pmdarima: 2.0.3
2023-05-21 15:53:55,228:INFO:              psutil: 5.9.4
2023-05-21 15:53:55,228:INFO:PyCaret optional dependencies:
2023-05-21 15:53:55,260:INFO:                shap: 0.41.0
2023-05-21 15:53:55,260:INFO:           interpret: 0.3.2
2023-05-21 15:53:55,260:INFO:                umap: 0.5.3
2023-05-21 15:53:55,260:INFO:    pandas_profiling: 3.6.6
2023-05-21 15:53:55,260:INFO:  explainerdashboard: 0.4.2.2
2023-05-21 15:53:55,260:INFO:             autoviz: 0.1.603
2023-05-21 15:53:55,261:INFO:           fairlearn: 0.7.0
2023-05-21 15:53:55,261:INFO:             xgboost: 1.7.5
2023-05-21 15:53:55,261:INFO:            catboost: Not installed
2023-05-21 15:53:55,261:INFO:              kmodes: Not installed
2023-05-21 15:53:55,261:INFO:             mlxtend: Not installed
2023-05-21 15:53:55,261:INFO:       statsforecast: Not installed
2023-05-21 15:53:55,261:INFO:        tune_sklearn: Not installed
2023-05-21 15:53:55,262:INFO:                 ray: Not installed
2023-05-21 15:53:55,262:INFO:            hyperopt: Not installed
2023-05-21 15:53:55,262:INFO:              optuna: 3.1.1
2023-05-21 15:53:55,262:INFO:               skopt: Not installed
2023-05-21 15:53:55,262:INFO:              mlflow: 2.3.1
2023-05-21 15:53:55,262:INFO:              gradio: Not installed
2023-05-21 15:53:55,262:INFO:             fastapi: Not installed
2023-05-21 15:53:55,263:INFO:             uvicorn: Not installed
2023-05-21 15:53:55,263:INFO:              m2cgen: Not installed
2023-05-21 15:53:55,263:INFO:           evidently: Not installed
2023-05-21 15:53:55,263:INFO:               fugue: Not installed
2023-05-21 15:53:55,263:INFO:           streamlit: Not installed
2023-05-21 15:53:55,263:INFO:             prophet: Not installed
2023-05-21 15:53:55,263:INFO:None
2023-05-21 15:53:55,264:INFO:Set up data.
2023-05-21 15:53:55,391:INFO:Set up train/test split.
2023-05-21 15:53:55,454:INFO:Set up index.
2023-05-21 15:53:55,454:INFO:Set up folding strategy.
2023-05-21 15:53:55,455:INFO:Assigning column types.
2023-05-21 15:53:55,466:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-21 15:53:55,515:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 15:53:55,518:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:53:55,554:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:53:55,598:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:53:55,650:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 15:53:55,651:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:53:55,685:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:53:55,688:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:53:55,689:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-21 15:53:55,747:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:53:55,783:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:53:55,787:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:53:55,838:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:53:55,870:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:53:55,874:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:53:55,875:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-21 15:53:55,957:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:53:55,960:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:53:56,042:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:53:56,045:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:53:56,049:INFO:Preparing preprocessing pipeline...
2023-05-21 15:53:56,052:INFO:Set up simple imputation.
2023-05-21 15:53:56,068:INFO:Set up encoding of categorical features.
2023-05-21 15:53:56,311:INFO:Finished creating preprocessing pipeline.
2023-05-21 15:53:56,346:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 15:53:56,346:INFO:Creating final display dataframe.
2023-05-21 15:53:56,700:INFO:Setup _display_container:                     Description                           Value
0                    Session id                              42
1                        Target               app_complete_flag
2                   Target type                          Binary
3           Original data shape                     (238964, 7)
4        Transformed data shape                    (238964, 39)
5   Transformed train set shape                    (167274, 39)
6    Transformed test set shape                     (71690, 39)
7              Numeric features                               3
8          Categorical features                               3
9                    Preprocess                            True
10              Imputation type                          simple
11           Numeric imputation                            mean
12       Categorical imputation                            mode
13     Maximum one-hot encoding                              25
14              Encoding method                            None
15               Fold Generator                 StratifiedKFold
16                  Fold Number                              10
17                     CPU Jobs                              -1
18                      Use GPU                           False
19               Log Experiment                    MlflowLogger
20              Experiment Name  Lead_Scoring_Training_Pipeline
21                          USI                            1ef0
2023-05-21 15:53:56,807:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:53:56,812:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:53:56,895:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:53:56,898:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:53:56,899:INFO:Logging experiment in loggers
2023-05-21 15:53:57,496:INFO:SubProcess save_model() called ==================================
2023-05-21 15:53:57,579:INFO:Initializing save_model()
2023-05-21 15:53:57,580:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/tmp/tmpl0p4t_7m/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-21 15:53:57,580:INFO:Adding model into prep_pipe
2023-05-21 15:53:57,584:WARNING:Only Model saved as it was a pipeline.
2023-05-21 15:53:57,606:INFO:/tmp/tmpl0p4t_7m/Transformation Pipeline.pkl saved in current working directory
2023-05-21 15:53:57,629:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 15:53:57,629:INFO:save_model() successfully completed......................................
2023-05-21 15:53:57,785:INFO:SubProcess save_model() end ==================================
2023-05-21 15:53:58,370:INFO:setup() successfully completed in 1.73s...............
2023-05-21 15:53:58,370:INFO:Initializing compare_models()
2023-05-21 15:53:58,370:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc3c8d13df0>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fc3c8d13df0>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'])
2023-05-21 15:53:58,370:INFO:Checking exceptions
2023-05-21 15:53:58,387:INFO:Preparing display monitor
2023-05-21 15:53:58,394:INFO:Initializing Logistic Regression
2023-05-21 15:53:58,394:INFO:Total runtime is 4.120667775472006e-06 minutes
2023-05-21 15:53:58,395:INFO:SubProcess create_model() called ==================================
2023-05-21 15:53:58,395:INFO:Initializing create_model()
2023-05-21 15:53:58,395:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc3c8d13df0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc38cd89f00>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:53:58,395:INFO:Checking exceptions
2023-05-21 15:53:58,395:INFO:Importing libraries
2023-05-21 15:53:58,396:INFO:Copying training dataset
2023-05-21 15:53:58,425:INFO:Defining folds
2023-05-21 15:53:58,426:INFO:Declaring metric variables
2023-05-21 15:53:58,426:INFO:Importing untrained model
2023-05-21 15:53:58,427:INFO:Logistic Regression Imported successfully
2023-05-21 15:53:58,428:INFO:Starting cross validation
2023-05-21 15:53:58,432:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:54:06,287:INFO:Calculating mean and std
2023-05-21 15:54:06,290:INFO:Creating metrics dataframe
2023-05-21 15:54:06,378:INFO:Uploading results into container
2023-05-21 15:54:06,380:INFO:Uploading model into container now
2023-05-21 15:54:06,381:INFO:_master_model_container: 1
2023-05-21 15:54:06,381:INFO:_display_container: 2
2023-05-21 15:54:06,382:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-21 15:54:06,382:INFO:create_model() successfully completed......................................
2023-05-21 15:54:06,502:INFO:SubProcess create_model() end ==================================
2023-05-21 15:54:06,502:INFO:Creating metrics dataframe
2023-05-21 15:54:06,514:INFO:Initializing Naive Bayes
2023-05-21 15:54:06,514:INFO:Total runtime is 0.13533511956532795 minutes
2023-05-21 15:54:06,515:INFO:SubProcess create_model() called ==================================
2023-05-21 15:54:06,515:INFO:Initializing create_model()
2023-05-21 15:54:06,515:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc3c8d13df0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc38cd89f00>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:54:06,515:INFO:Checking exceptions
2023-05-21 15:54:06,515:INFO:Importing libraries
2023-05-21 15:54:06,515:INFO:Copying training dataset
2023-05-21 15:54:06,546:INFO:Defining folds
2023-05-21 15:54:06,547:INFO:Declaring metric variables
2023-05-21 15:54:06,547:INFO:Importing untrained model
2023-05-21 15:54:06,548:INFO:Naive Bayes Imported successfully
2023-05-21 15:54:06,548:INFO:Starting cross validation
2023-05-21 15:54:06,552:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:54:10,291:INFO:Calculating mean and std
2023-05-21 15:54:10,295:INFO:Creating metrics dataframe
2023-05-21 15:54:10,349:INFO:Uploading results into container
2023-05-21 15:54:10,351:INFO:Uploading model into container now
2023-05-21 15:54:10,352:INFO:_master_model_container: 2
2023-05-21 15:54:10,352:INFO:_display_container: 2
2023-05-21 15:54:10,352:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-21 15:54:10,352:INFO:create_model() successfully completed......................................
2023-05-21 15:54:10,463:INFO:SubProcess create_model() end ==================================
2023-05-21 15:54:10,463:INFO:Creating metrics dataframe
2023-05-21 15:54:10,476:INFO:Initializing Decision Tree Classifier
2023-05-21 15:54:10,477:INFO:Total runtime is 0.20137555996576945 minutes
2023-05-21 15:54:10,477:INFO:SubProcess create_model() called ==================================
2023-05-21 15:54:10,477:INFO:Initializing create_model()
2023-05-21 15:54:10,478:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc3c8d13df0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc38cd89f00>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:54:10,478:INFO:Checking exceptions
2023-05-21 15:54:10,478:INFO:Importing libraries
2023-05-21 15:54:10,478:INFO:Copying training dataset
2023-05-21 15:54:10,507:INFO:Defining folds
2023-05-21 15:54:10,507:INFO:Declaring metric variables
2023-05-21 15:54:10,508:INFO:Importing untrained model
2023-05-21 15:54:10,509:INFO:Decision Tree Classifier Imported successfully
2023-05-21 15:54:10,509:INFO:Starting cross validation
2023-05-21 15:54:10,514:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:54:11,837:INFO:Calculating mean and std
2023-05-21 15:54:11,839:INFO:Creating metrics dataframe
2023-05-21 15:54:11,924:INFO:Uploading results into container
2023-05-21 15:54:11,926:INFO:Uploading model into container now
2023-05-21 15:54:11,927:INFO:_master_model_container: 3
2023-05-21 15:54:11,927:INFO:_display_container: 2
2023-05-21 15:54:11,928:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-05-21 15:54:11,928:INFO:create_model() successfully completed......................................
2023-05-21 15:54:12,046:INFO:SubProcess create_model() end ==================================
2023-05-21 15:54:12,046:INFO:Creating metrics dataframe
2023-05-21 15:54:12,060:INFO:Initializing Ridge Classifier
2023-05-21 15:54:12,060:INFO:Total runtime is 0.22776597340901691 minutes
2023-05-21 15:54:12,061:INFO:SubProcess create_model() called ==================================
2023-05-21 15:54:12,061:INFO:Initializing create_model()
2023-05-21 15:54:12,061:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc3c8d13df0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc38cd89f00>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:54:12,061:INFO:Checking exceptions
2023-05-21 15:54:12,061:INFO:Importing libraries
2023-05-21 15:54:12,062:INFO:Copying training dataset
2023-05-21 15:54:12,097:INFO:Defining folds
2023-05-21 15:54:12,097:INFO:Declaring metric variables
2023-05-21 15:54:12,098:INFO:Importing untrained model
2023-05-21 15:54:12,099:INFO:Ridge Classifier Imported successfully
2023-05-21 15:54:12,099:INFO:Starting cross validation
2023-05-21 15:54:12,104:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:54:12,669:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:54:12,677:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:54:12,777:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:54:12,848:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:54:12,864:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:54:12,864:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:54:12,877:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:54:12,880:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:54:12,907:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:54:13,056:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:54:13,305:INFO:Calculating mean and std
2023-05-21 15:54:13,307:INFO:Creating metrics dataframe
2023-05-21 15:54:13,401:INFO:Uploading results into container
2023-05-21 15:54:13,403:INFO:Uploading model into container now
2023-05-21 15:54:13,404:INFO:_master_model_container: 4
2023-05-21 15:54:13,404:INFO:_display_container: 2
2023-05-21 15:54:13,405:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-05-21 15:54:13,405:INFO:create_model() successfully completed......................................
2023-05-21 15:54:13,521:INFO:SubProcess create_model() end ==================================
2023-05-21 15:54:13,521:INFO:Creating metrics dataframe
2023-05-21 15:54:13,537:INFO:Initializing Random Forest Classifier
2023-05-21 15:54:13,537:INFO:Total runtime is 0.25238802830378215 minutes
2023-05-21 15:54:13,538:INFO:SubProcess create_model() called ==================================
2023-05-21 15:54:13,538:INFO:Initializing create_model()
2023-05-21 15:54:13,538:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc3c8d13df0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc38cd89f00>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:54:13,539:INFO:Checking exceptions
2023-05-21 15:54:13,539:INFO:Importing libraries
2023-05-21 15:54:13,539:INFO:Copying training dataset
2023-05-21 15:54:13,580:INFO:Defining folds
2023-05-21 15:54:13,580:INFO:Declaring metric variables
2023-05-21 15:54:13,580:INFO:Importing untrained model
2023-05-21 15:54:13,582:INFO:Random Forest Classifier Imported successfully
2023-05-21 15:54:13,583:INFO:Starting cross validation
2023-05-21 15:54:13,589:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:54:16,668:INFO:Calculating mean and std
2023-05-21 15:54:16,670:INFO:Creating metrics dataframe
2023-05-21 15:54:16,750:INFO:Uploading results into container
2023-05-21 15:54:16,751:INFO:Uploading model into container now
2023-05-21 15:54:16,752:INFO:_master_model_container: 5
2023-05-21 15:54:16,752:INFO:_display_container: 2
2023-05-21 15:54:16,753:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-05-21 15:54:16,754:INFO:create_model() successfully completed......................................
2023-05-21 15:54:16,864:INFO:SubProcess create_model() end ==================================
2023-05-21 15:54:16,864:INFO:Creating metrics dataframe
2023-05-21 15:54:16,878:INFO:Initializing Linear Discriminant Analysis
2023-05-21 15:54:16,878:INFO:Total runtime is 0.3080708940823873 minutes
2023-05-21 15:54:16,879:INFO:SubProcess create_model() called ==================================
2023-05-21 15:54:16,879:INFO:Initializing create_model()
2023-05-21 15:54:16,879:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc3c8d13df0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc38cd89f00>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:54:16,879:INFO:Checking exceptions
2023-05-21 15:54:16,879:INFO:Importing libraries
2023-05-21 15:54:16,880:INFO:Copying training dataset
2023-05-21 15:54:16,909:INFO:Defining folds
2023-05-21 15:54:16,909:INFO:Declaring metric variables
2023-05-21 15:54:16,909:INFO:Importing untrained model
2023-05-21 15:54:16,910:INFO:Linear Discriminant Analysis Imported successfully
2023-05-21 15:54:16,911:INFO:Starting cross validation
2023-05-21 15:54:16,915:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:54:18,248:INFO:Calculating mean and std
2023-05-21 15:54:18,249:INFO:Creating metrics dataframe
2023-05-21 15:54:18,337:INFO:Uploading results into container
2023-05-21 15:54:18,339:INFO:Uploading model into container now
2023-05-21 15:54:18,339:INFO:_master_model_container: 6
2023-05-21 15:54:18,340:INFO:_display_container: 2
2023-05-21 15:54:18,340:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-21 15:54:18,340:INFO:create_model() successfully completed......................................
2023-05-21 15:54:18,466:INFO:SubProcess create_model() end ==================================
2023-05-21 15:54:18,466:INFO:Creating metrics dataframe
2023-05-21 15:54:18,480:INFO:Initializing Extra Trees Classifier
2023-05-21 15:54:18,480:INFO:Total runtime is 0.3347638408342997 minutes
2023-05-21 15:54:18,480:INFO:SubProcess create_model() called ==================================
2023-05-21 15:54:18,481:INFO:Initializing create_model()
2023-05-21 15:54:18,481:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc3c8d13df0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc38cd89f00>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:54:18,481:INFO:Checking exceptions
2023-05-21 15:54:18,481:INFO:Importing libraries
2023-05-21 15:54:18,481:INFO:Copying training dataset
2023-05-21 15:54:18,511:INFO:Defining folds
2023-05-21 15:54:18,511:INFO:Declaring metric variables
2023-05-21 15:54:18,511:INFO:Importing untrained model
2023-05-21 15:54:18,513:INFO:Extra Trees Classifier Imported successfully
2023-05-21 15:54:18,513:INFO:Starting cross validation
2023-05-21 15:54:18,518:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:54:21,255:INFO:Calculating mean and std
2023-05-21 15:54:21,257:INFO:Creating metrics dataframe
2023-05-21 15:54:21,343:INFO:Uploading results into container
2023-05-21 15:54:21,344:INFO:Uploading model into container now
2023-05-21 15:54:21,345:INFO:_master_model_container: 7
2023-05-21 15:54:21,345:INFO:_display_container: 2
2023-05-21 15:54:21,347:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-05-21 15:54:21,347:INFO:create_model() successfully completed......................................
2023-05-21 15:54:21,456:INFO:SubProcess create_model() end ==================================
2023-05-21 15:54:21,456:INFO:Creating metrics dataframe
2023-05-21 15:54:21,469:INFO:Initializing Extreme Gradient Boosting
2023-05-21 15:54:21,469:INFO:Total runtime is 0.38458340167999266 minutes
2023-05-21 15:54:21,469:INFO:SubProcess create_model() called ==================================
2023-05-21 15:54:21,470:INFO:Initializing create_model()
2023-05-21 15:54:21,470:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc3c8d13df0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc38cd89f00>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:54:21,470:INFO:Checking exceptions
2023-05-21 15:54:21,470:INFO:Importing libraries
2023-05-21 15:54:21,470:INFO:Copying training dataset
2023-05-21 15:54:21,499:INFO:Defining folds
2023-05-21 15:54:21,500:INFO:Declaring metric variables
2023-05-21 15:54:21,500:INFO:Importing untrained model
2023-05-21 15:54:21,502:INFO:Extreme Gradient Boosting Imported successfully
2023-05-21 15:54:21,503:INFO:Starting cross validation
2023-05-21 15:54:21,507:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:54:22,968:INFO:Calculating mean and std
2023-05-21 15:54:22,971:INFO:Creating metrics dataframe
2023-05-21 15:54:23,058:INFO:Uploading results into container
2023-05-21 15:54:23,059:INFO:Uploading model into container now
2023-05-21 15:54:23,060:INFO:_master_model_container: 8
2023-05-21 15:54:23,060:INFO:_display_container: 2
2023-05-21 15:54:23,064:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-05-21 15:54:23,064:INFO:create_model() successfully completed......................................
2023-05-21 15:54:23,188:INFO:SubProcess create_model() end ==================================
2023-05-21 15:54:23,189:INFO:Creating metrics dataframe
2023-05-21 15:54:23,202:INFO:Initializing Light Gradient Boosting Machine
2023-05-21 15:54:23,202:INFO:Total runtime is 0.4134615103403727 minutes
2023-05-21 15:54:23,202:INFO:SubProcess create_model() called ==================================
2023-05-21 15:54:23,203:INFO:Initializing create_model()
2023-05-21 15:54:23,203:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc3c8d13df0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc38cd89f00>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:54:23,203:INFO:Checking exceptions
2023-05-21 15:54:23,203:INFO:Importing libraries
2023-05-21 15:54:23,203:INFO:Copying training dataset
2023-05-21 15:54:23,232:INFO:Defining folds
2023-05-21 15:54:23,232:INFO:Declaring metric variables
2023-05-21 15:54:23,232:INFO:Importing untrained model
2023-05-21 15:54:23,234:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 15:54:23,234:INFO:Starting cross validation
2023-05-21 15:54:23,238:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:54:24,720:INFO:Calculating mean and std
2023-05-21 15:54:24,721:INFO:Creating metrics dataframe
2023-05-21 15:54:24,783:INFO:Uploading results into container
2023-05-21 15:54:24,786:INFO:Uploading model into container now
2023-05-21 15:54:24,787:INFO:_master_model_container: 9
2023-05-21 15:54:24,787:INFO:_display_container: 2
2023-05-21 15:54:24,790:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 15:54:24,791:INFO:create_model() successfully completed......................................
2023-05-21 15:54:24,902:INFO:SubProcess create_model() end ==================================
2023-05-21 15:54:24,903:INFO:Creating metrics dataframe
2023-05-21 15:54:24,924:INFO:Initializing create_model()
2023-05-21 15:54:24,924:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc3c8d13df0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:54:24,924:INFO:Checking exceptions
2023-05-21 15:54:24,926:INFO:Importing libraries
2023-05-21 15:54:24,926:INFO:Copying training dataset
2023-05-21 15:54:24,955:INFO:Defining folds
2023-05-21 15:54:24,955:INFO:Declaring metric variables
2023-05-21 15:54:24,955:INFO:Importing untrained model
2023-05-21 15:54:24,955:INFO:Declaring custom model
2023-05-21 15:54:24,961:INFO:Extreme Gradient Boosting Imported successfully
2023-05-21 15:54:24,965:INFO:Cross validation set to False
2023-05-21 15:54:24,965:INFO:Fitting Model
2023-05-21 15:54:25,296:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-05-21 15:54:25,296:INFO:create_model() successfully completed......................................
2023-05-21 15:54:25,411:INFO:Creating Dashboard logs
2023-05-21 15:54:25,413:INFO:Model: Extreme Gradient Boosting
2023-05-21 15:54:25,576:INFO:Logged params: {'objective': 'binary:logistic', 'use_label_encoder': None, 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': -1, 'num_parallel_tree': None, 'predictor': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2023-05-21 15:54:26,272:INFO:Initializing predict_model()
2023-05-21 15:54:26,273:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc3c8d13df0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fc38be34c10>)
2023-05-21 15:54:26,273:INFO:Checking exceptions
2023-05-21 15:54:26,273:INFO:Preloading libraries
2023-05-21 15:54:26,867:INFO:SubProcess plot_model() called ==================================
2023-05-21 15:54:26,870:INFO:Initializing plot_model()
2023-05-21 15:54:26,870:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp0xa78663, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc3c8d13df0>, system=False)
2023-05-21 15:54:26,870:INFO:Checking exceptions
2023-05-21 15:54:26,882:INFO:Preloading libraries
2023-05-21 15:54:26,886:INFO:Copying training dataset
2023-05-21 15:54:26,886:INFO:Plot type: auc
2023-05-21 15:54:27,538:INFO:Fitting Model
2023-05-21 15:54:27,551:INFO:Scoring test/hold-out set
2023-05-21 15:54:27,800:INFO:Saving '/tmp/tmp0xa78663/AUC.png'
2023-05-21 15:54:28,640:INFO:Visual Rendered Successfully
2023-05-21 15:54:28,759:INFO:plot_model() successfully completed......................................
2023-05-21 15:54:28,764:INFO:Initializing plot_model()
2023-05-21 15:54:28,764:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp0xa78663, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc3c8d13df0>, system=False)
2023-05-21 15:54:28,764:INFO:Checking exceptions
2023-05-21 15:54:28,780:INFO:Preloading libraries
2023-05-21 15:54:28,783:INFO:Copying training dataset
2023-05-21 15:54:28,784:INFO:Plot type: confusion_matrix
2023-05-21 15:54:29,141:INFO:Fitting Model
2023-05-21 15:54:29,146:INFO:Scoring test/hold-out set
2023-05-21 15:54:29,324:INFO:Saving '/tmp/tmp0xa78663/Confusion Matrix.png'
2023-05-21 15:54:29,595:INFO:Visual Rendered Successfully
2023-05-21 15:54:29,738:INFO:plot_model() successfully completed......................................
2023-05-21 15:54:29,745:INFO:Initializing plot_model()
2023-05-21 15:54:29,745:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp0xa78663, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc3c8d13df0>, system=False)
2023-05-21 15:54:29,745:INFO:Checking exceptions
2023-05-21 15:54:29,767:INFO:Preloading libraries
2023-05-21 15:54:29,773:INFO:Copying training dataset
2023-05-21 15:54:29,773:INFO:Plot type: feature
2023-05-21 15:54:29,778:WARNING:No coef_ found. Trying feature_importances_
2023-05-21 15:54:30,011:INFO:Saving '/tmp/tmp0xa78663/Feature Importance.png'
2023-05-21 15:54:30,470:INFO:Visual Rendered Successfully
2023-05-21 15:54:30,621:INFO:plot_model() successfully completed......................................
2023-05-21 15:54:30,622:INFO:SubProcess plot_model() end ==================================
2023-05-21 15:54:30,641:WARNING:/home/feuer/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-05-21 15:54:31,454:INFO:Creating Dashboard logs
2023-05-21 15:54:31,455:INFO:Model: Light Gradient Boosting Machine
2023-05-21 15:54:31,737:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-21 15:54:33,674:INFO:Creating Dashboard logs
2023-05-21 15:54:33,675:INFO:Model: Random Forest Classifier
2023-05-21 15:54:33,854:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 15:54:35,463:INFO:Creating Dashboard logs
2023-05-21 15:54:35,464:INFO:Model: Extra Trees Classifier
2023-05-21 15:54:35,600:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 15:54:37,029:INFO:Creating Dashboard logs
2023-05-21 15:54:37,030:INFO:Model: Decision Tree Classifier
2023-05-21 15:54:37,124:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2023-05-21 15:54:38,132:INFO:Creating Dashboard logs
2023-05-21 15:54:38,132:INFO:Model: Logistic Regression
2023-05-21 15:54:38,260:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-05-21 15:54:39,901:INFO:Creating Dashboard logs
2023-05-21 15:54:39,902:INFO:Model: Linear Discriminant Analysis
2023-05-21 15:54:40,022:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-05-21 15:54:41,114:INFO:Creating Dashboard logs
2023-05-21 15:54:41,115:INFO:Model: Naive Bayes
2023-05-21 15:54:41,279:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-05-21 15:54:42,529:INFO:Creating Dashboard logs
2023-05-21 15:54:42,530:INFO:Model: Ridge Classifier
2023-05-21 15:54:42,645:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2023-05-21 15:54:43,701:INFO:_master_model_container: 9
2023-05-21 15:54:43,702:INFO:_display_container: 2
2023-05-21 15:54:43,705:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-05-21 15:54:43,705:INFO:compare_models() successfully completed......................................
2023-05-21 15:54:43,747:INFO:PyCaret ClassificationExperiment
2023-05-21 15:54:43,747:INFO:Logging name: OnlyImportantFeatures
2023-05-21 15:54:43,747:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-21 15:54:43,747:INFO:version 3.0.0
2023-05-21 15:54:43,747:INFO:Initializing setup()
2023-05-21 15:54:43,747:INFO:self.USI: 82b5
2023-05-21 15:54:43,747:INFO:self._variable_keys: {'pipeline', 'html_param', 'target_param', 'fold_shuffle_param', 'logging_param', 'gpu_n_jobs_param', 'fold_groups_param', 'y', '_ml_usecase', 'memory', 'USI', 'y_train', '_available_plots', 'X', 'fix_imbalance', 'exp_id', 'X_train', 'exp_name_log', 'idx', 'X_test', 'log_plots_param', 'data', 'y_test', 'is_multiclass', 'n_jobs_param', 'fold_generator', 'seed', 'gpu_param'}
2023-05-21 15:54:43,747:INFO:Checking environment
2023-05-21 15:54:43,747:INFO:python_version: 3.10.10
2023-05-21 15:54:43,747:INFO:python_build: ('main', 'Mar  5 2023 22:26:53')
2023-05-21 15:54:43,747:INFO:machine: x86_64
2023-05-21 15:54:43,748:INFO:platform: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 15:54:43,748:INFO:Memory: svmem(total=16717086720, available=1860915200, percent=88.9, used=12558573568, free=1003794432, active=9191133184, inactive=1947246592, buffers=31682560, cached=3123036160, shared=1949949952, slab=521826304)
2023-05-21 15:54:43,749:INFO:Physical Core: 6
2023-05-21 15:54:43,749:INFO:Logical Core: 12
2023-05-21 15:54:43,749:INFO:Checking libraries
2023-05-21 15:54:43,749:INFO:System:
2023-05-21 15:54:43,749:INFO:    python: 3.10.10 (main, Mar  5 2023, 22:26:53) [GCC 12.2.1 20230201]
2023-05-21 15:54:43,750:INFO:executable: /usr/bin/python3.10
2023-05-21 15:54:43,750:INFO:   machine: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 15:54:43,750:INFO:PyCaret required dependencies:
2023-05-21 15:54:43,750:INFO:                 pip: 23.0.1
2023-05-21 15:54:43,750:INFO:          setuptools: 67.6.1
2023-05-21 15:54:43,750:INFO:             pycaret: 3.0.0
2023-05-21 15:54:43,750:INFO:             IPython: 8.12.0
2023-05-21 15:54:43,750:INFO:          ipywidgets: 7.7.5
2023-05-21 15:54:43,750:INFO:                tqdm: 4.64.1
2023-05-21 15:54:43,750:INFO:               numpy: 1.23.0
2023-05-21 15:54:43,751:INFO:              pandas: 1.5.3
2023-05-21 15:54:43,751:INFO:              jinja2: 3.1.2
2023-05-21 15:54:43,751:INFO:               scipy: 1.9.3
2023-05-21 15:54:43,751:INFO:              joblib: 1.2.0
2023-05-21 15:54:43,751:INFO:             sklearn: 1.2.2
2023-05-21 15:54:43,751:INFO:                pyod: 1.0.9
2023-05-21 15:54:43,751:INFO:            imblearn: 0.10.1
2023-05-21 15:54:43,751:INFO:   category_encoders: 2.6.0
2023-05-21 15:54:43,751:INFO:            lightgbm: 3.3.5
2023-05-21 15:54:43,751:INFO:               numba: 0.57.0
2023-05-21 15:54:43,751:INFO:            requests: 2.28.2
2023-05-21 15:54:43,751:INFO:          matplotlib: 3.6.3
2023-05-21 15:54:43,751:INFO:          scikitplot: 0.3.7
2023-05-21 15:54:43,752:INFO:         yellowbrick: 1.5
2023-05-21 15:54:43,752:INFO:              plotly: 5.14.1
2023-05-21 15:54:43,752:INFO:             kaleido: 0.2.1
2023-05-21 15:54:43,752:INFO:         statsmodels: 0.13.5
2023-05-21 15:54:43,752:INFO:              sktime: 0.18.0
2023-05-21 15:54:43,752:INFO:               tbats: 1.1.3
2023-05-21 15:54:43,752:INFO:            pmdarima: 2.0.3
2023-05-21 15:54:43,752:INFO:              psutil: 5.9.4
2023-05-21 15:54:43,752:INFO:PyCaret optional dependencies:
2023-05-21 15:54:43,752:INFO:                shap: 0.41.0
2023-05-21 15:54:43,752:INFO:           interpret: 0.3.2
2023-05-21 15:54:43,753:INFO:                umap: 0.5.3
2023-05-21 15:54:43,753:INFO:    pandas_profiling: 3.6.6
2023-05-21 15:54:43,753:INFO:  explainerdashboard: 0.4.2.2
2023-05-21 15:54:43,753:INFO:             autoviz: 0.1.603
2023-05-21 15:54:43,753:INFO:           fairlearn: 0.7.0
2023-05-21 15:54:43,753:INFO:             xgboost: 1.7.5
2023-05-21 15:54:43,753:INFO:            catboost: Not installed
2023-05-21 15:54:43,753:INFO:              kmodes: Not installed
2023-05-21 15:54:43,753:INFO:             mlxtend: Not installed
2023-05-21 15:54:43,753:INFO:       statsforecast: Not installed
2023-05-21 15:54:43,753:INFO:        tune_sklearn: Not installed
2023-05-21 15:54:43,753:INFO:                 ray: Not installed
2023-05-21 15:54:43,753:INFO:            hyperopt: Not installed
2023-05-21 15:54:43,754:INFO:              optuna: 3.1.1
2023-05-21 15:54:43,754:INFO:               skopt: Not installed
2023-05-21 15:54:43,754:INFO:              mlflow: 2.3.1
2023-05-21 15:54:43,754:INFO:              gradio: Not installed
2023-05-21 15:54:43,754:INFO:             fastapi: Not installed
2023-05-21 15:54:43,754:INFO:             uvicorn: Not installed
2023-05-21 15:54:43,754:INFO:              m2cgen: Not installed
2023-05-21 15:54:43,754:INFO:           evidently: Not installed
2023-05-21 15:54:43,754:INFO:               fugue: Not installed
2023-05-21 15:54:43,754:INFO:           streamlit: Not installed
2023-05-21 15:54:43,754:INFO:             prophet: Not installed
2023-05-21 15:54:43,754:INFO:None
2023-05-21 15:54:43,755:INFO:Set up data.
2023-05-21 15:54:43,887:INFO:Set up train/test split.
2023-05-21 15:54:43,950:INFO:Set up index.
2023-05-21 15:54:43,950:INFO:Set up folding strategy.
2023-05-21 15:54:43,950:INFO:Assigning column types.
2023-05-21 15:54:43,962:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-21 15:54:44,021:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 15:54:44,023:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:54:44,055:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:54:44,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:54:44,110:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 15:54:44,111:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:54:44,143:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:54:44,146:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:54:44,147:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-21 15:54:44,199:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:54:44,231:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:54:44,234:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:54:44,286:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 15:54:44,320:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:54:44,323:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:54:44,323:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-21 15:54:44,406:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:54:44,409:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:54:44,492:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:54:44,495:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:54:44,497:INFO:Preparing preprocessing pipeline...
2023-05-21 15:54:44,500:INFO:Set up simple imputation.
2023-05-21 15:54:44,514:INFO:Set up encoding of categorical features.
2023-05-21 15:54:44,761:INFO:Finished creating preprocessing pipeline.
2023-05-21 15:54:44,786:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 15:54:44,786:INFO:Creating final display dataframe.
2023-05-21 15:54:45,163:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     42
1                        Target      app_complete_flag
2                   Target type                 Binary
3           Original data shape            (238964, 7)
4        Transformed data shape           (238964, 39)
5   Transformed train set shape           (167274, 39)
6    Transformed test set shape            (71690, 39)
7              Numeric features                      3
8          Categorical features                      3
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13     Maximum one-hot encoding                     25
14              Encoding method                   None
15               Fold Generator        StratifiedKFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                  False
19               Log Experiment           MlflowLogger
20              Experiment Name  OnlyImportantFeatures
21                          USI                   82b5
2023-05-21 15:54:45,264:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:54:45,268:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:54:45,352:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 15:54:45,356:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 15:54:45,357:INFO:Logging experiment in loggers
2023-05-21 15:54:46,001:INFO:SubProcess save_model() called ==================================
2023-05-21 15:54:46,092:INFO:Initializing save_model()
2023-05-21 15:54:46,092:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/tmp/tmp1r3s5i6u/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-21 15:54:46,092:INFO:Adding model into prep_pipe
2023-05-21 15:54:46,098:WARNING:Only Model saved as it was a pipeline.
2023-05-21 15:54:46,124:INFO:/tmp/tmp1r3s5i6u/Transformation Pipeline.pkl saved in current working directory
2023-05-21 15:54:46,152:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 15:54:46,152:INFO:save_model() successfully completed......................................
2023-05-21 15:54:46,334:INFO:SubProcess save_model() end ==================================
2023-05-21 15:54:46,951:INFO:setup() successfully completed in 1.65s...............
2023-05-21 15:54:46,951:INFO:Initializing compare_models()
2023-05-21 15:54:46,951:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc38765bbb0>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fc38765bbb0>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'])
2023-05-21 15:54:46,951:INFO:Checking exceptions
2023-05-21 15:54:46,967:INFO:Preparing display monitor
2023-05-21 15:54:46,972:INFO:Initializing Logistic Regression
2023-05-21 15:54:46,972:INFO:Total runtime is 2.7378400166829425e-06 minutes
2023-05-21 15:54:46,972:INFO:SubProcess create_model() called ==================================
2023-05-21 15:54:46,973:INFO:Initializing create_model()
2023-05-21 15:54:46,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc38765bbb0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc3888ece20>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:54:46,973:INFO:Checking exceptions
2023-05-21 15:54:46,973:INFO:Importing libraries
2023-05-21 15:54:46,973:INFO:Copying training dataset
2023-05-21 15:54:47,002:INFO:Defining folds
2023-05-21 15:54:47,002:INFO:Declaring metric variables
2023-05-21 15:54:47,003:INFO:Importing untrained model
2023-05-21 15:54:47,004:INFO:Logistic Regression Imported successfully
2023-05-21 15:54:47,004:INFO:Starting cross validation
2023-05-21 15:54:47,009:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:54:48,253:INFO:Calculating mean and std
2023-05-21 15:54:48,255:INFO:Creating metrics dataframe
2023-05-21 15:54:48,342:INFO:Uploading results into container
2023-05-21 15:54:48,344:INFO:Uploading model into container now
2023-05-21 15:54:48,344:INFO:_master_model_container: 1
2023-05-21 15:54:48,345:INFO:_display_container: 2
2023-05-21 15:54:48,346:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-21 15:54:48,346:INFO:create_model() successfully completed......................................
2023-05-21 15:54:48,463:INFO:SubProcess create_model() end ==================================
2023-05-21 15:54:48,463:INFO:Creating metrics dataframe
2023-05-21 15:54:48,475:INFO:Initializing Naive Bayes
2023-05-21 15:54:48,475:INFO:Total runtime is 0.025047667821248374 minutes
2023-05-21 15:54:48,475:INFO:SubProcess create_model() called ==================================
2023-05-21 15:54:48,476:INFO:Initializing create_model()
2023-05-21 15:54:48,476:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc38765bbb0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc3888ece20>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:54:48,476:INFO:Checking exceptions
2023-05-21 15:54:48,476:INFO:Importing libraries
2023-05-21 15:54:48,476:INFO:Copying training dataset
2023-05-21 15:54:48,503:INFO:Defining folds
2023-05-21 15:54:48,503:INFO:Declaring metric variables
2023-05-21 15:54:48,504:INFO:Importing untrained model
2023-05-21 15:54:48,504:INFO:Naive Bayes Imported successfully
2023-05-21 15:54:48,505:INFO:Starting cross validation
2023-05-21 15:54:48,509:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:54:49,757:INFO:Calculating mean and std
2023-05-21 15:54:49,758:INFO:Creating metrics dataframe
2023-05-21 15:54:49,844:INFO:Uploading results into container
2023-05-21 15:54:49,845:INFO:Uploading model into container now
2023-05-21 15:54:49,846:INFO:_master_model_container: 2
2023-05-21 15:54:49,847:INFO:_display_container: 2
2023-05-21 15:54:49,847:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-21 15:54:49,847:INFO:create_model() successfully completed......................................
2023-05-21 15:54:49,967:INFO:SubProcess create_model() end ==================================
2023-05-21 15:54:49,968:INFO:Creating metrics dataframe
2023-05-21 15:54:49,981:INFO:Initializing Decision Tree Classifier
2023-05-21 15:54:49,981:INFO:Total runtime is 0.050150859355926516 minutes
2023-05-21 15:54:49,981:INFO:SubProcess create_model() called ==================================
2023-05-21 15:54:49,982:INFO:Initializing create_model()
2023-05-21 15:54:49,982:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc38765bbb0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc3888ece20>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:54:49,982:INFO:Checking exceptions
2023-05-21 15:54:49,982:INFO:Importing libraries
2023-05-21 15:54:49,982:INFO:Copying training dataset
2023-05-21 15:54:50,010:INFO:Defining folds
2023-05-21 15:54:50,010:INFO:Declaring metric variables
2023-05-21 15:54:50,011:INFO:Importing untrained model
2023-05-21 15:54:50,012:INFO:Decision Tree Classifier Imported successfully
2023-05-21 15:54:50,012:INFO:Starting cross validation
2023-05-21 15:54:50,016:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:54:51,239:INFO:Calculating mean and std
2023-05-21 15:54:51,241:INFO:Creating metrics dataframe
2023-05-21 15:54:51,352:INFO:Uploading results into container
2023-05-21 15:54:51,354:INFO:Uploading model into container now
2023-05-21 15:54:51,355:INFO:_master_model_container: 3
2023-05-21 15:54:51,355:INFO:_display_container: 2
2023-05-21 15:54:51,356:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-05-21 15:54:51,356:INFO:create_model() successfully completed......................................
2023-05-21 15:54:51,478:INFO:SubProcess create_model() end ==================================
2023-05-21 15:54:51,478:INFO:Creating metrics dataframe
2023-05-21 15:54:51,491:INFO:Initializing Ridge Classifier
2023-05-21 15:54:51,491:INFO:Total runtime is 0.07531981865564982 minutes
2023-05-21 15:54:51,491:INFO:SubProcess create_model() called ==================================
2023-05-21 15:54:51,492:INFO:Initializing create_model()
2023-05-21 15:54:51,492:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc38765bbb0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc3888ece20>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:54:51,492:INFO:Checking exceptions
2023-05-21 15:54:51,492:INFO:Importing libraries
2023-05-21 15:54:51,492:INFO:Copying training dataset
2023-05-21 15:54:51,525:INFO:Defining folds
2023-05-21 15:54:51,525:INFO:Declaring metric variables
2023-05-21 15:54:51,525:INFO:Importing untrained model
2023-05-21 15:54:51,526:INFO:Ridge Classifier Imported successfully
2023-05-21 15:54:51,527:INFO:Starting cross validation
2023-05-21 15:54:51,531:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:54:52,088:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:54:52,101:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:54:52,117:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:54:52,187:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:54:52,196:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:54:52,205:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:54:52,277:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:54:52,289:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:54:52,290:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:54:52,301:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 15:54:52,686:INFO:Calculating mean and std
2023-05-21 15:54:52,688:INFO:Creating metrics dataframe
2023-05-21 15:54:52,742:INFO:Uploading results into container
2023-05-21 15:54:52,744:INFO:Uploading model into container now
2023-05-21 15:54:52,745:INFO:_master_model_container: 4
2023-05-21 15:54:52,745:INFO:_display_container: 2
2023-05-21 15:54:52,746:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-05-21 15:54:52,746:INFO:create_model() successfully completed......................................
2023-05-21 15:54:52,869:INFO:SubProcess create_model() end ==================================
2023-05-21 15:54:52,869:INFO:Creating metrics dataframe
2023-05-21 15:54:52,883:INFO:Initializing Random Forest Classifier
2023-05-21 15:54:52,883:INFO:Total runtime is 0.09852630297342936 minutes
2023-05-21 15:54:52,884:INFO:SubProcess create_model() called ==================================
2023-05-21 15:54:52,884:INFO:Initializing create_model()
2023-05-21 15:54:52,884:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc38765bbb0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc3888ece20>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:54:52,885:INFO:Checking exceptions
2023-05-21 15:54:52,885:INFO:Importing libraries
2023-05-21 15:54:52,885:INFO:Copying training dataset
2023-05-21 15:54:52,917:INFO:Defining folds
2023-05-21 15:54:52,918:INFO:Declaring metric variables
2023-05-21 15:54:52,918:INFO:Importing untrained model
2023-05-21 15:54:52,919:INFO:Random Forest Classifier Imported successfully
2023-05-21 15:54:52,920:INFO:Starting cross validation
2023-05-21 15:54:52,925:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:54:55,680:INFO:Calculating mean and std
2023-05-21 15:54:55,681:INFO:Creating metrics dataframe
2023-05-21 15:54:55,769:INFO:Uploading results into container
2023-05-21 15:54:55,770:INFO:Uploading model into container now
2023-05-21 15:54:55,771:INFO:_master_model_container: 5
2023-05-21 15:54:55,771:INFO:_display_container: 2
2023-05-21 15:54:55,772:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-05-21 15:54:55,772:INFO:create_model() successfully completed......................................
2023-05-21 15:54:55,887:INFO:SubProcess create_model() end ==================================
2023-05-21 15:54:55,887:INFO:Creating metrics dataframe
2023-05-21 15:54:55,901:INFO:Initializing Linear Discriminant Analysis
2023-05-21 15:54:55,901:INFO:Total runtime is 0.14881519476572672 minutes
2023-05-21 15:54:55,901:INFO:SubProcess create_model() called ==================================
2023-05-21 15:54:55,902:INFO:Initializing create_model()
2023-05-21 15:54:55,902:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc38765bbb0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc3888ece20>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:54:55,902:INFO:Checking exceptions
2023-05-21 15:54:55,902:INFO:Importing libraries
2023-05-21 15:54:55,902:INFO:Copying training dataset
2023-05-21 15:54:55,929:INFO:Defining folds
2023-05-21 15:54:55,929:INFO:Declaring metric variables
2023-05-21 15:54:55,930:INFO:Importing untrained model
2023-05-21 15:54:55,931:INFO:Linear Discriminant Analysis Imported successfully
2023-05-21 15:54:55,931:INFO:Starting cross validation
2023-05-21 15:54:55,935:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:54:57,177:INFO:Calculating mean and std
2023-05-21 15:54:57,179:INFO:Creating metrics dataframe
2023-05-21 15:54:57,267:INFO:Uploading results into container
2023-05-21 15:54:57,268:INFO:Uploading model into container now
2023-05-21 15:54:57,269:INFO:_master_model_container: 6
2023-05-21 15:54:57,269:INFO:_display_container: 2
2023-05-21 15:54:57,270:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-21 15:54:57,270:INFO:create_model() successfully completed......................................
2023-05-21 15:54:57,385:INFO:SubProcess create_model() end ==================================
2023-05-21 15:54:57,385:INFO:Creating metrics dataframe
2023-05-21 15:54:57,399:INFO:Initializing Extra Trees Classifier
2023-05-21 15:54:57,399:INFO:Total runtime is 0.17378732363382973 minutes
2023-05-21 15:54:57,400:INFO:SubProcess create_model() called ==================================
2023-05-21 15:54:57,400:INFO:Initializing create_model()
2023-05-21 15:54:57,400:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc38765bbb0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc3888ece20>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:54:57,400:INFO:Checking exceptions
2023-05-21 15:54:57,400:INFO:Importing libraries
2023-05-21 15:54:57,400:INFO:Copying training dataset
2023-05-21 15:54:57,428:INFO:Defining folds
2023-05-21 15:54:57,428:INFO:Declaring metric variables
2023-05-21 15:54:57,429:INFO:Importing untrained model
2023-05-21 15:54:57,430:INFO:Extra Trees Classifier Imported successfully
2023-05-21 15:54:57,431:INFO:Starting cross validation
2023-05-21 15:54:57,435:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:55:00,156:INFO:Calculating mean and std
2023-05-21 15:55:00,158:INFO:Creating metrics dataframe
2023-05-21 15:55:00,246:INFO:Uploading results into container
2023-05-21 15:55:00,247:INFO:Uploading model into container now
2023-05-21 15:55:00,248:INFO:_master_model_container: 7
2023-05-21 15:55:00,248:INFO:_display_container: 2
2023-05-21 15:55:00,249:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-05-21 15:55:00,249:INFO:create_model() successfully completed......................................
2023-05-21 15:55:00,379:INFO:SubProcess create_model() end ==================================
2023-05-21 15:55:00,380:INFO:Creating metrics dataframe
2023-05-21 15:55:00,393:INFO:Initializing Extreme Gradient Boosting
2023-05-21 15:55:00,393:INFO:Total runtime is 0.22368663152058918 minutes
2023-05-21 15:55:00,393:INFO:SubProcess create_model() called ==================================
2023-05-21 15:55:00,394:INFO:Initializing create_model()
2023-05-21 15:55:00,394:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc38765bbb0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc3888ece20>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:55:00,394:INFO:Checking exceptions
2023-05-21 15:55:00,394:INFO:Importing libraries
2023-05-21 15:55:00,394:INFO:Copying training dataset
2023-05-21 15:55:00,423:INFO:Defining folds
2023-05-21 15:55:00,423:INFO:Declaring metric variables
2023-05-21 15:55:00,423:INFO:Importing untrained model
2023-05-21 15:55:00,426:INFO:Extreme Gradient Boosting Imported successfully
2023-05-21 15:55:00,426:INFO:Starting cross validation
2023-05-21 15:55:00,431:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:55:01,808:INFO:Calculating mean and std
2023-05-21 15:55:01,810:INFO:Creating metrics dataframe
2023-05-21 15:55:01,868:INFO:Uploading results into container
2023-05-21 15:55:01,869:INFO:Uploading model into container now
2023-05-21 15:55:01,870:INFO:_master_model_container: 8
2023-05-21 15:55:01,870:INFO:_display_container: 2
2023-05-21 15:55:01,873:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-05-21 15:55:01,874:INFO:create_model() successfully completed......................................
2023-05-21 15:55:01,990:INFO:SubProcess create_model() end ==================================
2023-05-21 15:55:01,990:INFO:Creating metrics dataframe
2023-05-21 15:55:02,003:INFO:Initializing Light Gradient Boosting Machine
2023-05-21 15:55:02,003:INFO:Total runtime is 0.25052076975504556 minutes
2023-05-21 15:55:02,003:INFO:SubProcess create_model() called ==================================
2023-05-21 15:55:02,004:INFO:Initializing create_model()
2023-05-21 15:55:02,004:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc38765bbb0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc3888ece20>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:55:02,004:INFO:Checking exceptions
2023-05-21 15:55:02,004:INFO:Importing libraries
2023-05-21 15:55:02,004:INFO:Copying training dataset
2023-05-21 15:55:02,032:INFO:Defining folds
2023-05-21 15:55:02,032:INFO:Declaring metric variables
2023-05-21 15:55:02,032:INFO:Importing untrained model
2023-05-21 15:55:02,034:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 15:55:02,034:INFO:Starting cross validation
2023-05-21 15:55:02,039:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 15:55:03,439:INFO:Calculating mean and std
2023-05-21 15:55:03,441:INFO:Creating metrics dataframe
2023-05-21 15:55:03,528:INFO:Uploading results into container
2023-05-21 15:55:03,529:INFO:Uploading model into container now
2023-05-21 15:55:03,530:INFO:_master_model_container: 9
2023-05-21 15:55:03,530:INFO:_display_container: 2
2023-05-21 15:55:03,532:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 15:55:03,532:INFO:create_model() successfully completed......................................
2023-05-21 15:55:03,648:INFO:SubProcess create_model() end ==================================
2023-05-21 15:55:03,648:INFO:Creating metrics dataframe
2023-05-21 15:55:03,669:INFO:Initializing create_model()
2023-05-21 15:55:03,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc38765bbb0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-21 15:55:03,669:INFO:Checking exceptions
2023-05-21 15:55:03,671:INFO:Importing libraries
2023-05-21 15:55:03,671:INFO:Copying training dataset
2023-05-21 15:55:03,699:INFO:Defining folds
2023-05-21 15:55:03,699:INFO:Declaring metric variables
2023-05-21 15:55:03,700:INFO:Importing untrained model
2023-05-21 15:55:03,700:INFO:Declaring custom model
2023-05-21 15:55:03,705:INFO:Extreme Gradient Boosting Imported successfully
2023-05-21 15:55:03,710:INFO:Cross validation set to False
2023-05-21 15:55:03,710:INFO:Fitting Model
2023-05-21 15:55:04,031:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-05-21 15:55:04,031:INFO:create_model() successfully completed......................................
2023-05-21 15:55:04,149:INFO:Creating Dashboard logs
2023-05-21 15:55:04,152:INFO:Model: Extreme Gradient Boosting
2023-05-21 15:55:04,269:INFO:Logged params: {'objective': 'binary:logistic', 'use_label_encoder': None, 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': -1, 'num_parallel_tree': None, 'predictor': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2023-05-21 15:55:05,000:INFO:Initializing predict_model()
2023-05-21 15:55:05,001:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc38765bbb0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fc387dfb250>)
2023-05-21 15:55:05,001:INFO:Checking exceptions
2023-05-21 15:55:05,001:INFO:Preloading libraries
2023-05-21 15:55:05,569:INFO:SubProcess plot_model() called ==================================
2023-05-21 15:55:05,572:INFO:Initializing plot_model()
2023-05-21 15:55:05,572:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpkhhw9svo, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc38765bbb0>, system=False)
2023-05-21 15:55:05,572:INFO:Checking exceptions
2023-05-21 15:55:05,584:INFO:Preloading libraries
2023-05-21 15:55:05,588:INFO:Copying training dataset
2023-05-21 15:55:05,588:INFO:Plot type: auc
2023-05-21 15:55:05,935:INFO:Fitting Model
2023-05-21 15:55:05,943:INFO:Scoring test/hold-out set
2023-05-21 15:55:06,137:INFO:Saving '/tmp/tmpkhhw9svo/AUC.png'
2023-05-21 15:55:06,610:INFO:Visual Rendered Successfully
2023-05-21 15:55:06,735:INFO:plot_model() successfully completed......................................
2023-05-21 15:55:06,739:INFO:Initializing plot_model()
2023-05-21 15:55:06,740:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpkhhw9svo, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc38765bbb0>, system=False)
2023-05-21 15:55:06,740:INFO:Checking exceptions
2023-05-21 15:55:06,753:INFO:Preloading libraries
2023-05-21 15:55:06,760:INFO:Copying training dataset
2023-05-21 15:55:06,760:INFO:Plot type: confusion_matrix
2023-05-21 15:55:07,126:INFO:Fitting Model
2023-05-21 15:55:07,130:INFO:Scoring test/hold-out set
2023-05-21 15:55:07,300:INFO:Saving '/tmp/tmpkhhw9svo/Confusion Matrix.png'
2023-05-21 15:55:07,577:INFO:Visual Rendered Successfully
2023-05-21 15:55:07,738:INFO:plot_model() successfully completed......................................
2023-05-21 15:55:07,745:INFO:Initializing plot_model()
2023-05-21 15:55:07,745:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpkhhw9svo, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc38765bbb0>, system=False)
2023-05-21 15:55:07,745:INFO:Checking exceptions
2023-05-21 15:55:07,764:INFO:Preloading libraries
2023-05-21 15:55:07,774:INFO:Copying training dataset
2023-05-21 15:55:07,774:INFO:Plot type: feature
2023-05-21 15:55:07,778:WARNING:No coef_ found. Trying feature_importances_
2023-05-21 15:55:08,079:INFO:Saving '/tmp/tmpkhhw9svo/Feature Importance.png'
2023-05-21 15:55:08,519:INFO:Visual Rendered Successfully
2023-05-21 15:55:08,675:INFO:plot_model() successfully completed......................................
2023-05-21 15:55:08,676:INFO:SubProcess plot_model() end ==================================
2023-05-21 15:55:09,046:INFO:Creating Dashboard logs
2023-05-21 15:55:09,047:INFO:Model: Light Gradient Boosting Machine
2023-05-21 15:55:09,163:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-21 15:55:10,503:INFO:Creating Dashboard logs
2023-05-21 15:55:10,504:INFO:Model: Random Forest Classifier
2023-05-21 15:55:10,633:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 15:55:11,856:INFO:Creating Dashboard logs
2023-05-21 15:55:11,858:INFO:Model: Extra Trees Classifier
2023-05-21 15:55:11,967:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 15:55:13,108:INFO:Creating Dashboard logs
2023-05-21 15:55:13,109:INFO:Model: Decision Tree Classifier
2023-05-21 15:55:13,431:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2023-05-21 15:55:14,706:INFO:Creating Dashboard logs
2023-05-21 15:55:14,707:INFO:Model: Logistic Regression
2023-05-21 15:55:14,836:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-05-21 15:55:16,056:INFO:Creating Dashboard logs
2023-05-21 15:55:16,057:INFO:Model: Linear Discriminant Analysis
2023-05-21 15:55:16,174:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-05-21 15:55:17,160:INFO:Creating Dashboard logs
2023-05-21 15:55:17,161:INFO:Model: Naive Bayes
2023-05-21 15:55:17,269:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-05-21 15:55:18,413:INFO:Creating Dashboard logs
2023-05-21 15:55:18,414:INFO:Model: Ridge Classifier
2023-05-21 15:55:18,750:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2023-05-21 15:55:19,896:INFO:_master_model_container: 9
2023-05-21 15:55:19,896:INFO:_display_container: 2
2023-05-21 15:55:19,900:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-05-21 15:55:19,900:INFO:compare_models() successfully completed......................................
2023-05-21 15:55:53,029:INFO:Initializing get_config()
2023-05-21 15:55:53,029:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc38765bbb0>, variable=X_train)
2023-05-21 15:55:53,030:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2023-05-21 15:55:53,030:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/pycaret_experiment.py:322: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-05-21 15:55:53,058:INFO:Variable:  returned as         total_leads_dropped  city_tier  ...  first_utm_medium_c first_utm_source_c
149381                  1.0        3.0  ...              Level0             Level0
23956                   1.0        1.0  ...              Level0             Level0
187671                  1.0        1.0  ...              Level2             Level2
4798                    1.0        1.0  ...              others            Level16
50707                   1.0        2.0  ...              Level0             Level0
...                     ...        ...  ...                 ...                ...
151557                  1.0        1.0  ...              Level6             Level7
25054                   2.0        1.0  ...             Level20            Level14
134681                  1.0        2.0  ...              Level4             Level2
114585                  1.0        3.0  ...              Level8             Level2
148045                  4.0        1.0  ...             Level11             Level2

[167274 rows x 6 columns]
2023-05-21 15:55:53,058:INFO:get_config() successfully completed......................................
2023-05-21 15:56:00,155:INFO:Initializing get_config()
2023-05-21 15:56:00,155:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc38765bbb0>, variable=y_train)
2023-05-21 15:56:00,156:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2023-05-21 15:56:00,156:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/pycaret_experiment.py:322: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-05-21 15:56:00,170:INFO:Variable:  returned as 149381    0
23956     1
187671    1
4798      0
50707     0
         ..
151557    0
25054     1
134681    1
114585    1
148045    1
Name: app_complete_flag, Length: 167274, dtype: int8
2023-05-21 15:56:00,171:INFO:get_config() successfully completed......................................
2023-05-21 15:56:08,922:INFO:Initializing get_config()
2023-05-21 15:56:08,923:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc38765bbb0>, variable=y_test)
2023-05-21 15:56:08,923:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2023-05-21 15:56:08,923:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/pycaret_experiment.py:322: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-05-21 15:56:08,931:INFO:Variable:  returned as 84141     0
53191     1
178391    0
236260    1
130064    0
         ..
208694    0
63479     0
1580      0
203050    0
2137      1
Name: app_complete_flag, Length: 71690, dtype: int8
2023-05-21 15:56:08,931:INFO:get_config() successfully completed......................................
2023-05-21 15:56:15,671:INFO:Initializing get_config()
2023-05-21 15:56:15,671:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc38765bbb0>, variable=X_test)
2023-05-21 15:56:15,671:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2023-05-21 15:56:15,671:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/pycaret_experiment.py:322: UserWarning: Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-05-21 15:56:15,700:INFO:Variable:  returned as         total_leads_dropped  city_tier  ...  first_utm_medium_c first_utm_source_c
84141                   1.0        2.0  ...              Level0             Level0
53191                   2.0        1.0  ...             Level11             Level2
178391                  2.0        1.0  ...              Level9             Level2
236260                  3.0        1.0  ...              Level3            Level16
130064                  2.0        2.0  ...              others             Level6
...                     ...        ...  ...                 ...                ...
208694                  1.0        3.0  ...             Level30             Level0
63479                   1.0        3.0  ...              Level5             Level4
1580                    1.0        1.0  ...             Level11             Level2
203050                  1.0        1.0  ...              Level0             Level0
2137                    6.0        2.0  ...              Level0             Level0

[71690 rows x 6 columns]
2023-05-21 15:56:15,700:INFO:get_config() successfully completed......................................
2023-05-21 16:05:48,927:INFO:Initializing plot_model()
2023-05-21 16:05:48,928:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc38765bbb0>, system=True)
2023-05-21 16:05:48,928:INFO:Checking exceptions
2023-05-21 16:05:48,939:INFO:Preloading libraries
2023-05-21 16:05:48,946:INFO:Copying training dataset
2023-05-21 16:05:48,946:INFO:Plot type: auc
2023-05-21 16:05:49,156:INFO:Fitting Model
2023-05-21 16:05:49,162:INFO:Scoring test/hold-out set
2023-05-21 16:05:49,341:INFO:Visual Rendered Successfully
2023-05-21 16:05:49,476:INFO:plot_model() successfully completed......................................
2023-05-21 16:13:42,134:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:13:42,134:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:13:42,135:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:13:42,135:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:13:45,318:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-21 16:13:48,070:INFO:PyCaret ClassificationExperiment
2023-05-21 16:13:48,070:INFO:Logging name: Lead_Scoring_Training_Pipeline
2023-05-21 16:13:48,070:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-21 16:13:48,071:INFO:version 3.0.0
2023-05-21 16:13:48,071:INFO:Initializing setup()
2023-05-21 16:13:48,071:INFO:self.USI: 99ef
2023-05-21 16:13:48,071:INFO:self._variable_keys: {'USI', '_available_plots', 'y_test', 'is_multiclass', 'fold_generator', 'log_plots_param', 'memory', 'data', 'idx', 'X', 'target_param', 'exp_id', 'gpu_param', 'y_train', 'fold_groups_param', 'fix_imbalance', 'y', 'gpu_n_jobs_param', 'pipeline', '_ml_usecase', 'html_param', 'seed', 'logging_param', 'exp_name_log', 'n_jobs_param', 'X_test', 'X_train', 'fold_shuffle_param'}
2023-05-21 16:13:48,071:INFO:Checking environment
2023-05-21 16:13:48,071:INFO:python_version: 3.10.10
2023-05-21 16:13:48,071:INFO:python_build: ('main', 'Mar  5 2023 22:26:53')
2023-05-21 16:13:48,071:INFO:machine: x86_64
2023-05-21 16:13:48,072:INFO:platform: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 16:13:48,072:INFO:Memory: svmem(total=16717086720, available=4542308352, percent=72.8, used=9847148544, free=3542609920, active=6654402560, inactive=2007650304, buffers=55099392, cached=3272228864, shared=1980002304, slab=519344128)
2023-05-21 16:13:48,074:INFO:Physical Core: 6
2023-05-21 16:13:48,074:INFO:Logical Core: 12
2023-05-21 16:13:48,074:INFO:Checking libraries
2023-05-21 16:13:48,074:INFO:System:
2023-05-21 16:13:48,074:INFO:    python: 3.10.10 (main, Mar  5 2023, 22:26:53) [GCC 12.2.1 20230201]
2023-05-21 16:13:48,074:INFO:executable: /usr/bin/python3.10
2023-05-21 16:13:48,074:INFO:   machine: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 16:13:48,074:INFO:PyCaret required dependencies:
2023-05-21 16:13:48,074:INFO:                 pip: 23.0.1
2023-05-21 16:13:48,074:INFO:          setuptools: 67.6.1
2023-05-21 16:13:48,075:INFO:             pycaret: 3.0.0
2023-05-21 16:13:48,075:INFO:             IPython: 8.12.0
2023-05-21 16:13:48,075:INFO:          ipywidgets: 7.7.5
2023-05-21 16:13:48,075:INFO:                tqdm: 4.64.1
2023-05-21 16:13:48,075:INFO:               numpy: 1.23.0
2023-05-21 16:13:48,075:INFO:              pandas: 1.5.3
2023-05-21 16:13:48,075:INFO:              jinja2: 3.1.2
2023-05-21 16:13:48,075:INFO:               scipy: 1.9.3
2023-05-21 16:13:48,075:INFO:              joblib: 1.2.0
2023-05-21 16:13:48,075:INFO:             sklearn: 1.2.2
2023-05-21 16:13:48,075:INFO:                pyod: 1.0.9
2023-05-21 16:13:48,075:INFO:            imblearn: 0.10.1
2023-05-21 16:13:48,075:INFO:   category_encoders: 2.6.0
2023-05-21 16:13:48,075:INFO:            lightgbm: 3.3.5
2023-05-21 16:13:48,076:INFO:               numba: 0.57.0
2023-05-21 16:13:48,076:INFO:            requests: 2.28.2
2023-05-21 16:13:48,076:INFO:          matplotlib: 3.6.3
2023-05-21 16:13:48,076:INFO:          scikitplot: 0.3.7
2023-05-21 16:13:48,076:INFO:         yellowbrick: 1.5
2023-05-21 16:13:48,076:INFO:              plotly: 5.14.1
2023-05-21 16:13:48,076:INFO:             kaleido: 0.2.1
2023-05-21 16:13:48,076:INFO:         statsmodels: 0.13.5
2023-05-21 16:13:48,076:INFO:              sktime: 0.18.0
2023-05-21 16:13:48,076:INFO:               tbats: 1.1.3
2023-05-21 16:13:48,076:INFO:            pmdarima: 2.0.3
2023-05-21 16:13:48,076:INFO:              psutil: 5.9.4
2023-05-21 16:13:48,076:INFO:PyCaret optional dependencies:
2023-05-21 16:13:48,086:INFO:                shap: 0.41.0
2023-05-21 16:13:48,086:INFO:           interpret: 0.3.2
2023-05-21 16:13:48,086:INFO:                umap: 0.5.3
2023-05-21 16:13:48,086:INFO:    pandas_profiling: 3.6.6
2023-05-21 16:13:48,086:INFO:  explainerdashboard: 0.4.2.2
2023-05-21 16:13:48,086:INFO:             autoviz: 0.1.603
2023-05-21 16:13:48,086:INFO:           fairlearn: 0.7.0
2023-05-21 16:13:48,086:INFO:             xgboost: 1.7.5
2023-05-21 16:13:48,087:INFO:            catboost: Not installed
2023-05-21 16:13:48,087:INFO:              kmodes: Not installed
2023-05-21 16:13:48,087:INFO:             mlxtend: Not installed
2023-05-21 16:13:48,087:INFO:       statsforecast: Not installed
2023-05-21 16:13:48,087:INFO:        tune_sklearn: Not installed
2023-05-21 16:13:48,087:INFO:                 ray: Not installed
2023-05-21 16:13:48,087:INFO:            hyperopt: Not installed
2023-05-21 16:13:48,087:INFO:              optuna: 3.1.1
2023-05-21 16:13:48,087:INFO:               skopt: Not installed
2023-05-21 16:13:48,087:INFO:              mlflow: 2.3.1
2023-05-21 16:13:48,087:INFO:              gradio: Not installed
2023-05-21 16:13:48,087:INFO:             fastapi: Not installed
2023-05-21 16:13:48,087:INFO:             uvicorn: Not installed
2023-05-21 16:13:48,087:INFO:              m2cgen: Not installed
2023-05-21 16:13:48,087:INFO:           evidently: Not installed
2023-05-21 16:13:48,087:INFO:               fugue: Not installed
2023-05-21 16:13:48,087:INFO:           streamlit: Not installed
2023-05-21 16:13:48,087:INFO:             prophet: Not installed
2023-05-21 16:13:48,088:INFO:None
2023-05-21 16:13:48,088:INFO:Set up data.
2023-05-21 16:13:48,289:INFO:Set up train/test split.
2023-05-21 16:13:48,348:INFO:Set up index.
2023-05-21 16:13:48,348:INFO:Set up folding strategy.
2023-05-21 16:13:48,349:INFO:Assigning column types.
2023-05-21 16:13:48,356:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-21 16:13:48,399:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 16:13:48,409:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:13:48,499:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:13:48,551:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:13:48,598:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 16:13:48,599:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:13:48,626:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:13:48,628:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:13:48,629:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-21 16:13:48,673:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:13:48,700:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:13:48,702:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:13:48,748:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:13:48,775:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:13:48,778:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:13:48,780:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-21 16:13:48,854:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:13:48,856:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:13:48,929:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:13:48,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:13:48,932:INFO:Preparing preprocessing pipeline...
2023-05-21 16:13:48,935:INFO:Set up simple imputation.
2023-05-21 16:13:48,947:INFO:Set up encoding of categorical features.
2023-05-21 16:13:49,115:INFO:Finished creating preprocessing pipeline.
2023-05-21 16:13:49,135:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 16:13:49,135:INFO:Creating final display dataframe.
2023-05-21 16:13:49,341:INFO:Setup _display_container:                     Description                           Value
0                    Session id                              42
1                        Target               app_complete_flag
2                   Target type                          Binary
3           Original data shape                     (238964, 7)
4        Transformed data shape                    (238964, 39)
5   Transformed train set shape                    (167274, 39)
6    Transformed test set shape                     (71690, 39)
7              Numeric features                               3
8          Categorical features                               3
9                    Preprocess                            True
10              Imputation type                          simple
11           Numeric imputation                            mean
12       Categorical imputation                            mode
13     Maximum one-hot encoding                              25
14              Encoding method                            None
15               Fold Generator                 StratifiedKFold
16                  Fold Number                              10
17                     CPU Jobs                              -1
18                      Use GPU                           False
19               Log Experiment                    MlflowLogger
20              Experiment Name  Lead_Scoring_Training_Pipeline
21                          USI                            99ef
2023-05-21 16:13:49,417:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:13:49,420:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:13:49,510:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:13:49,512:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:13:49,513:INFO:Logging experiment in loggers
2023-05-21 16:13:49,998:INFO:SubProcess save_model() called ==================================
2023-05-21 16:13:50,016:INFO:Initializing save_model()
2023-05-21 16:13:50,017:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/tmp/tmpoqi5eeag/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-21 16:13:50,017:INFO:Adding model into prep_pipe
2023-05-21 16:13:50,018:WARNING:Only Model saved as it was a pipeline.
2023-05-21 16:13:50,029:INFO:/tmp/tmpoqi5eeag/Transformation Pipeline.pkl saved in current working directory
2023-05-21 16:13:50,038:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 16:13:50,039:INFO:save_model() successfully completed......................................
2023-05-21 16:13:50,161:INFO:SubProcess save_model() end ==================================
2023-05-21 16:13:50,777:INFO:setup() successfully completed in 1.46s...............
2023-05-21 16:13:50,777:INFO:Initializing compare_models()
2023-05-21 16:13:50,777:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedcb1b7e80>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fedcb1b7e80>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'])
2023-05-21 16:13:50,777:INFO:Checking exceptions
2023-05-21 16:13:50,790:INFO:Preparing display monitor
2023-05-21 16:13:50,792:INFO:Initializing Logistic Regression
2023-05-21 16:13:50,793:INFO:Total runtime is 1.2040138244628906e-06 minutes
2023-05-21 16:13:50,793:INFO:SubProcess create_model() called ==================================
2023-05-21 16:13:50,793:INFO:Initializing create_model()
2023-05-21 16:13:50,793:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedcb1b7e80>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fedaf3e8f70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:13:50,793:INFO:Checking exceptions
2023-05-21 16:13:50,793:INFO:Importing libraries
2023-05-21 16:13:50,793:INFO:Copying training dataset
2023-05-21 16:13:50,816:INFO:Defining folds
2023-05-21 16:13:50,816:INFO:Declaring metric variables
2023-05-21 16:13:50,816:INFO:Importing untrained model
2023-05-21 16:13:50,816:INFO:Logistic Regression Imported successfully
2023-05-21 16:13:50,816:INFO:Starting cross validation
2023-05-21 16:13:50,817:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:13:53,656:INFO:Calculating mean and std
2023-05-21 16:13:53,657:INFO:Creating metrics dataframe
2023-05-21 16:13:53,681:INFO:Uploading results into container
2023-05-21 16:13:53,682:INFO:Uploading model into container now
2023-05-21 16:13:53,683:INFO:_master_model_container: 1
2023-05-21 16:13:53,683:INFO:_display_container: 2
2023-05-21 16:13:53,684:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-21 16:13:53,684:INFO:create_model() successfully completed......................................
2023-05-21 16:13:53,800:INFO:SubProcess create_model() end ==================================
2023-05-21 16:13:53,800:INFO:Creating metrics dataframe
2023-05-21 16:13:53,804:INFO:Initializing Naive Bayes
2023-05-21 16:13:53,804:INFO:Total runtime is 0.05019041299819946 minutes
2023-05-21 16:13:53,804:INFO:SubProcess create_model() called ==================================
2023-05-21 16:13:53,804:INFO:Initializing create_model()
2023-05-21 16:13:53,804:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedcb1b7e80>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fedaf3e8f70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:13:53,804:INFO:Checking exceptions
2023-05-21 16:13:53,804:INFO:Importing libraries
2023-05-21 16:13:53,804:INFO:Copying training dataset
2023-05-21 16:13:53,832:INFO:Defining folds
2023-05-21 16:13:53,832:INFO:Declaring metric variables
2023-05-21 16:13:53,832:INFO:Importing untrained model
2023-05-21 16:13:53,832:INFO:Naive Bayes Imported successfully
2023-05-21 16:13:53,832:INFO:Starting cross validation
2023-05-21 16:13:53,833:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:13:55,426:INFO:Calculating mean and std
2023-05-21 16:13:55,426:INFO:Creating metrics dataframe
2023-05-21 16:13:55,447:INFO:Uploading results into container
2023-05-21 16:13:55,448:INFO:Uploading model into container now
2023-05-21 16:13:55,448:INFO:_master_model_container: 2
2023-05-21 16:13:55,448:INFO:_display_container: 2
2023-05-21 16:13:55,448:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-21 16:13:55,448:INFO:create_model() successfully completed......................................
2023-05-21 16:13:55,553:INFO:SubProcess create_model() end ==================================
2023-05-21 16:13:55,553:INFO:Creating metrics dataframe
2023-05-21 16:13:55,557:INFO:Initializing Decision Tree Classifier
2023-05-21 16:13:55,557:INFO:Total runtime is 0.07941489219665526 minutes
2023-05-21 16:13:55,557:INFO:SubProcess create_model() called ==================================
2023-05-21 16:13:55,558:INFO:Initializing create_model()
2023-05-21 16:13:55,558:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedcb1b7e80>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fedaf3e8f70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:13:55,558:INFO:Checking exceptions
2023-05-21 16:13:55,558:INFO:Importing libraries
2023-05-21 16:13:55,558:INFO:Copying training dataset
2023-05-21 16:13:55,586:INFO:Defining folds
2023-05-21 16:13:55,586:INFO:Declaring metric variables
2023-05-21 16:13:55,587:INFO:Importing untrained model
2023-05-21 16:13:55,587:INFO:Decision Tree Classifier Imported successfully
2023-05-21 16:13:55,587:INFO:Starting cross validation
2023-05-21 16:13:55,589:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:13:56,239:INFO:Calculating mean and std
2023-05-21 16:13:56,240:INFO:Creating metrics dataframe
2023-05-21 16:13:56,264:INFO:Uploading results into container
2023-05-21 16:13:56,264:INFO:Uploading model into container now
2023-05-21 16:13:56,265:INFO:_master_model_container: 3
2023-05-21 16:13:56,265:INFO:_display_container: 2
2023-05-21 16:13:56,266:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-05-21 16:13:56,266:INFO:create_model() successfully completed......................................
2023-05-21 16:13:56,379:INFO:SubProcess create_model() end ==================================
2023-05-21 16:13:56,379:INFO:Creating metrics dataframe
2023-05-21 16:13:56,384:INFO:Initializing Ridge Classifier
2023-05-21 16:13:56,384:INFO:Total runtime is 0.09319055080413817 minutes
2023-05-21 16:13:56,384:INFO:SubProcess create_model() called ==================================
2023-05-21 16:13:56,384:INFO:Initializing create_model()
2023-05-21 16:13:56,384:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedcb1b7e80>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fedaf3e8f70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:13:56,384:INFO:Checking exceptions
2023-05-21 16:13:56,384:INFO:Importing libraries
2023-05-21 16:13:56,384:INFO:Copying training dataset
2023-05-21 16:13:56,411:INFO:Defining folds
2023-05-21 16:13:56,411:INFO:Declaring metric variables
2023-05-21 16:13:56,411:INFO:Importing untrained model
2023-05-21 16:13:56,411:INFO:Ridge Classifier Imported successfully
2023-05-21 16:13:56,412:INFO:Starting cross validation
2023-05-21 16:13:56,413:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:13:56,742:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:13:56,755:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:13:56,757:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:13:56,780:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:13:56,810:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:13:56,823:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:13:56,832:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:13:56,833:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:13:56,851:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:13:56,855:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:13:57,007:INFO:Calculating mean and std
2023-05-21 16:13:57,008:INFO:Creating metrics dataframe
2023-05-21 16:13:57,032:INFO:Uploading results into container
2023-05-21 16:13:57,033:INFO:Uploading model into container now
2023-05-21 16:13:57,033:INFO:_master_model_container: 4
2023-05-21 16:13:57,033:INFO:_display_container: 2
2023-05-21 16:13:57,034:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-05-21 16:13:57,034:INFO:create_model() successfully completed......................................
2023-05-21 16:13:57,138:INFO:SubProcess create_model() end ==================================
2023-05-21 16:13:57,139:INFO:Creating metrics dataframe
2023-05-21 16:13:57,143:INFO:Initializing Random Forest Classifier
2023-05-21 16:13:57,143:INFO:Total runtime is 0.10584032138188679 minutes
2023-05-21 16:13:57,143:INFO:SubProcess create_model() called ==================================
2023-05-21 16:13:57,143:INFO:Initializing create_model()
2023-05-21 16:13:57,143:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedcb1b7e80>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fedaf3e8f70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:13:57,143:INFO:Checking exceptions
2023-05-21 16:13:57,143:INFO:Importing libraries
2023-05-21 16:13:57,143:INFO:Copying training dataset
2023-05-21 16:13:57,172:INFO:Defining folds
2023-05-21 16:13:57,172:INFO:Declaring metric variables
2023-05-21 16:13:57,172:INFO:Importing untrained model
2023-05-21 16:13:57,173:INFO:Random Forest Classifier Imported successfully
2023-05-21 16:13:57,173:INFO:Starting cross validation
2023-05-21 16:13:57,174:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:13:58,656:INFO:Calculating mean and std
2023-05-21 16:13:58,658:INFO:Creating metrics dataframe
2023-05-21 16:13:58,689:INFO:Uploading results into container
2023-05-21 16:13:58,690:INFO:Uploading model into container now
2023-05-21 16:13:58,691:INFO:_master_model_container: 5
2023-05-21 16:13:58,691:INFO:_display_container: 2
2023-05-21 16:13:58,691:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-05-21 16:13:58,691:INFO:create_model() successfully completed......................................
2023-05-21 16:13:58,795:INFO:SubProcess create_model() end ==================================
2023-05-21 16:13:58,795:INFO:Creating metrics dataframe
2023-05-21 16:13:58,800:INFO:Initializing Linear Discriminant Analysis
2023-05-21 16:13:58,800:INFO:Total runtime is 0.13345301151275635 minutes
2023-05-21 16:13:58,800:INFO:SubProcess create_model() called ==================================
2023-05-21 16:13:58,800:INFO:Initializing create_model()
2023-05-21 16:13:58,800:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedcb1b7e80>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fedaf3e8f70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:13:58,800:INFO:Checking exceptions
2023-05-21 16:13:58,800:INFO:Importing libraries
2023-05-21 16:13:58,800:INFO:Copying training dataset
2023-05-21 16:13:58,823:INFO:Defining folds
2023-05-21 16:13:58,823:INFO:Declaring metric variables
2023-05-21 16:13:58,823:INFO:Importing untrained model
2023-05-21 16:13:58,823:INFO:Linear Discriminant Analysis Imported successfully
2023-05-21 16:13:58,823:INFO:Starting cross validation
2023-05-21 16:13:58,824:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:13:59,460:INFO:Calculating mean and std
2023-05-21 16:13:59,461:INFO:Creating metrics dataframe
2023-05-21 16:13:59,485:INFO:Uploading results into container
2023-05-21 16:13:59,486:INFO:Uploading model into container now
2023-05-21 16:13:59,486:INFO:_master_model_container: 6
2023-05-21 16:13:59,486:INFO:_display_container: 2
2023-05-21 16:13:59,486:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-21 16:13:59,487:INFO:create_model() successfully completed......................................
2023-05-21 16:13:59,589:INFO:SubProcess create_model() end ==================================
2023-05-21 16:13:59,589:INFO:Creating metrics dataframe
2023-05-21 16:13:59,593:INFO:Initializing Extra Trees Classifier
2023-05-21 16:13:59,593:INFO:Total runtime is 0.14667559067408245 minutes
2023-05-21 16:13:59,593:INFO:SubProcess create_model() called ==================================
2023-05-21 16:13:59,593:INFO:Initializing create_model()
2023-05-21 16:13:59,593:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedcb1b7e80>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fedaf3e8f70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:13:59,593:INFO:Checking exceptions
2023-05-21 16:13:59,593:INFO:Importing libraries
2023-05-21 16:13:59,593:INFO:Copying training dataset
2023-05-21 16:13:59,617:INFO:Defining folds
2023-05-21 16:13:59,617:INFO:Declaring metric variables
2023-05-21 16:13:59,617:INFO:Importing untrained model
2023-05-21 16:13:59,617:INFO:Extra Trees Classifier Imported successfully
2023-05-21 16:13:59,617:INFO:Starting cross validation
2023-05-21 16:13:59,618:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:14:01,114:INFO:Calculating mean and std
2023-05-21 16:14:01,115:INFO:Creating metrics dataframe
2023-05-21 16:14:01,138:INFO:Uploading results into container
2023-05-21 16:14:01,139:INFO:Uploading model into container now
2023-05-21 16:14:01,139:INFO:_master_model_container: 7
2023-05-21 16:14:01,140:INFO:_display_container: 2
2023-05-21 16:14:01,140:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-05-21 16:14:01,140:INFO:create_model() successfully completed......................................
2023-05-21 16:14:01,243:INFO:SubProcess create_model() end ==================================
2023-05-21 16:14:01,244:INFO:Creating metrics dataframe
2023-05-21 16:14:01,248:INFO:Initializing Light Gradient Boosting Machine
2023-05-21 16:14:01,248:INFO:Total runtime is 0.17425365845362348 minutes
2023-05-21 16:14:01,248:INFO:SubProcess create_model() called ==================================
2023-05-21 16:14:01,248:INFO:Initializing create_model()
2023-05-21 16:14:01,248:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedcb1b7e80>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fedaf3e8f70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:14:01,248:INFO:Checking exceptions
2023-05-21 16:14:01,248:INFO:Importing libraries
2023-05-21 16:14:01,248:INFO:Copying training dataset
2023-05-21 16:14:01,273:INFO:Defining folds
2023-05-21 16:14:01,273:INFO:Declaring metric variables
2023-05-21 16:14:01,273:INFO:Importing untrained model
2023-05-21 16:14:01,274:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 16:14:01,274:INFO:Starting cross validation
2023-05-21 16:14:01,275:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:14:02,166:INFO:Calculating mean and std
2023-05-21 16:14:02,167:INFO:Creating metrics dataframe
2023-05-21 16:14:02,191:INFO:Uploading results into container
2023-05-21 16:14:02,192:INFO:Uploading model into container now
2023-05-21 16:14:02,192:INFO:_master_model_container: 8
2023-05-21 16:14:02,192:INFO:_display_container: 2
2023-05-21 16:14:02,193:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 16:14:02,193:INFO:create_model() successfully completed......................................
2023-05-21 16:14:02,307:INFO:SubProcess create_model() end ==================================
2023-05-21 16:14:02,307:INFO:Creating metrics dataframe
2023-05-21 16:14:02,313:INFO:Initializing create_model()
2023-05-21 16:14:02,313:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedcb1b7e80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:14:02,313:INFO:Checking exceptions
2023-05-21 16:14:02,314:INFO:Importing libraries
2023-05-21 16:14:02,314:INFO:Copying training dataset
2023-05-21 16:14:02,344:INFO:Defining folds
2023-05-21 16:14:02,344:INFO:Declaring metric variables
2023-05-21 16:14:02,344:INFO:Importing untrained model
2023-05-21 16:14:02,344:INFO:Declaring custom model
2023-05-21 16:14:02,345:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 16:14:02,346:INFO:Cross validation set to False
2023-05-21 16:14:02,346:INFO:Fitting Model
2023-05-21 16:14:03,005:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 16:14:03,005:INFO:create_model() successfully completed......................................
2023-05-21 16:14:03,104:INFO:Creating Dashboard logs
2023-05-21 16:14:03,104:INFO:Model: Light Gradient Boosting Machine
2023-05-21 16:14:03,223:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-21 16:14:03,963:INFO:Initializing predict_model()
2023-05-21 16:14:03,964:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedcb1b7e80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fedb2b4bd00>)
2023-05-21 16:14:03,964:INFO:Checking exceptions
2023-05-21 16:14:03,964:INFO:Preloading libraries
2023-05-21 16:14:04,416:INFO:SubProcess plot_model() called ==================================
2023-05-21 16:14:04,417:INFO:Initializing plot_model()
2023-05-21 16:14:04,417:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpxxohgrcj, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedcb1b7e80>, system=False)
2023-05-21 16:14:04,417:INFO:Checking exceptions
2023-05-21 16:14:04,425:INFO:Preloading libraries
2023-05-21 16:14:04,428:INFO:Copying training dataset
2023-05-21 16:14:04,428:INFO:Plot type: auc
2023-05-21 16:14:04,919:INFO:Fitting Model
2023-05-21 16:14:04,923:INFO:Scoring test/hold-out set
2023-05-21 16:14:05,162:INFO:Saving '/tmp/tmpxxohgrcj/AUC.png'
2023-05-21 16:14:05,437:INFO:Visual Rendered Successfully
2023-05-21 16:14:05,544:INFO:plot_model() successfully completed......................................
2023-05-21 16:14:05,545:INFO:Initializing plot_model()
2023-05-21 16:14:05,545:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpxxohgrcj, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedcb1b7e80>, system=False)
2023-05-21 16:14:05,545:INFO:Checking exceptions
2023-05-21 16:14:05,554:INFO:Preloading libraries
2023-05-21 16:14:05,560:INFO:Copying training dataset
2023-05-21 16:14:05,560:INFO:Plot type: confusion_matrix
2023-05-21 16:14:05,773:INFO:Fitting Model
2023-05-21 16:14:05,775:INFO:Scoring test/hold-out set
2023-05-21 16:14:05,963:INFO:Saving '/tmp/tmpxxohgrcj/Confusion Matrix.png'
2023-05-21 16:14:06,066:INFO:Visual Rendered Successfully
2023-05-21 16:14:06,170:INFO:plot_model() successfully completed......................................
2023-05-21 16:14:06,171:INFO:Initializing plot_model()
2023-05-21 16:14:06,171:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpxxohgrcj, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedcb1b7e80>, system=False)
2023-05-21 16:14:06,171:INFO:Checking exceptions
2023-05-21 16:14:06,180:INFO:Preloading libraries
2023-05-21 16:14:06,186:INFO:Copying training dataset
2023-05-21 16:14:06,186:INFO:Plot type: feature
2023-05-21 16:14:06,186:WARNING:No coef_ found. Trying feature_importances_
2023-05-21 16:14:06,284:INFO:Saving '/tmp/tmpxxohgrcj/Feature Importance.png'
2023-05-21 16:14:06,419:INFO:Visual Rendered Successfully
2023-05-21 16:14:06,515:INFO:plot_model() successfully completed......................................
2023-05-21 16:14:06,515:INFO:SubProcess plot_model() end ==================================
2023-05-21 16:14:06,536:WARNING:/home/feuer/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-05-21 16:14:06,880:INFO:Creating Dashboard logs
2023-05-21 16:14:06,880:INFO:Model: Random Forest Classifier
2023-05-21 16:14:06,967:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 16:14:07,905:INFO:Creating Dashboard logs
2023-05-21 16:14:07,905:INFO:Model: Extra Trees Classifier
2023-05-21 16:14:07,983:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 16:14:08,972:INFO:Creating Dashboard logs
2023-05-21 16:14:08,972:INFO:Model: Decision Tree Classifier
2023-05-21 16:14:09,066:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2023-05-21 16:14:09,898:INFO:Creating Dashboard logs
2023-05-21 16:14:09,898:INFO:Model: Logistic Regression
2023-05-21 16:14:09,990:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-05-21 16:14:10,830:INFO:Creating Dashboard logs
2023-05-21 16:14:10,830:INFO:Model: Linear Discriminant Analysis
2023-05-21 16:14:10,924:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-05-21 16:14:11,737:INFO:Creating Dashboard logs
2023-05-21 16:14:11,738:INFO:Model: Naive Bayes
2023-05-21 16:14:11,839:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-05-21 16:14:12,712:INFO:Creating Dashboard logs
2023-05-21 16:14:12,712:INFO:Model: Ridge Classifier
2023-05-21 16:14:12,857:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2023-05-21 16:14:13,709:INFO:_master_model_container: 8
2023-05-21 16:14:13,709:INFO:_display_container: 2
2023-05-21 16:14:13,709:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 16:14:13,710:INFO:compare_models() successfully completed......................................
2023-05-21 16:14:13,720:INFO:PyCaret ClassificationExperiment
2023-05-21 16:14:13,720:INFO:Logging name: OnlyImportantFeatures
2023-05-21 16:14:13,720:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-21 16:14:13,720:INFO:version 3.0.0
2023-05-21 16:14:13,720:INFO:Initializing setup()
2023-05-21 16:14:13,720:INFO:self.USI: 74ee
2023-05-21 16:14:13,720:INFO:self._variable_keys: {'USI', '_available_plots', 'y_test', 'is_multiclass', 'fold_generator', 'log_plots_param', 'memory', 'data', 'idx', 'X', 'target_param', 'exp_id', 'gpu_param', 'y_train', 'fold_groups_param', 'fix_imbalance', 'y', 'gpu_n_jobs_param', 'pipeline', '_ml_usecase', 'html_param', 'seed', 'logging_param', 'exp_name_log', 'n_jobs_param', 'X_test', 'X_train', 'fold_shuffle_param'}
2023-05-21 16:14:13,720:INFO:Checking environment
2023-05-21 16:14:13,720:INFO:python_version: 3.10.10
2023-05-21 16:14:13,720:INFO:python_build: ('main', 'Mar  5 2023 22:26:53')
2023-05-21 16:14:13,720:INFO:machine: x86_64
2023-05-21 16:14:13,720:INFO:platform: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 16:14:13,720:INFO:Memory: svmem(total=16717086720, available=2122952704, percent=87.3, used=12272156672, free=1105137664, active=9039503360, inactive=2018525184, buffers=56238080, cached=3283554304, shared=1974296576, slab=524292096)
2023-05-21 16:14:13,721:INFO:Physical Core: 6
2023-05-21 16:14:13,721:INFO:Logical Core: 12
2023-05-21 16:14:13,721:INFO:Checking libraries
2023-05-21 16:14:13,721:INFO:System:
2023-05-21 16:14:13,721:INFO:    python: 3.10.10 (main, Mar  5 2023, 22:26:53) [GCC 12.2.1 20230201]
2023-05-21 16:14:13,721:INFO:executable: /usr/bin/python3.10
2023-05-21 16:14:13,721:INFO:   machine: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 16:14:13,721:INFO:PyCaret required dependencies:
2023-05-21 16:14:13,721:INFO:                 pip: 23.0.1
2023-05-21 16:14:13,721:INFO:          setuptools: 67.6.1
2023-05-21 16:14:13,721:INFO:             pycaret: 3.0.0
2023-05-21 16:14:13,721:INFO:             IPython: 8.12.0
2023-05-21 16:14:13,721:INFO:          ipywidgets: 7.7.5
2023-05-21 16:14:13,721:INFO:                tqdm: 4.64.1
2023-05-21 16:14:13,721:INFO:               numpy: 1.23.0
2023-05-21 16:14:13,721:INFO:              pandas: 1.5.3
2023-05-21 16:14:13,721:INFO:              jinja2: 3.1.2
2023-05-21 16:14:13,721:INFO:               scipy: 1.9.3
2023-05-21 16:14:13,721:INFO:              joblib: 1.2.0
2023-05-21 16:14:13,721:INFO:             sklearn: 1.2.2
2023-05-21 16:14:13,721:INFO:                pyod: 1.0.9
2023-05-21 16:14:13,721:INFO:            imblearn: 0.10.1
2023-05-21 16:14:13,721:INFO:   category_encoders: 2.6.0
2023-05-21 16:14:13,722:INFO:            lightgbm: 3.3.5
2023-05-21 16:14:13,722:INFO:               numba: 0.57.0
2023-05-21 16:14:13,722:INFO:            requests: 2.28.2
2023-05-21 16:14:13,722:INFO:          matplotlib: 3.6.3
2023-05-21 16:14:13,722:INFO:          scikitplot: 0.3.7
2023-05-21 16:14:13,722:INFO:         yellowbrick: 1.5
2023-05-21 16:14:13,722:INFO:              plotly: 5.14.1
2023-05-21 16:14:13,722:INFO:             kaleido: 0.2.1
2023-05-21 16:14:13,722:INFO:         statsmodels: 0.13.5
2023-05-21 16:14:13,722:INFO:              sktime: 0.18.0
2023-05-21 16:14:13,722:INFO:               tbats: 1.1.3
2023-05-21 16:14:13,722:INFO:            pmdarima: 2.0.3
2023-05-21 16:14:13,722:INFO:              psutil: 5.9.4
2023-05-21 16:14:13,722:INFO:PyCaret optional dependencies:
2023-05-21 16:14:13,722:INFO:                shap: 0.41.0
2023-05-21 16:14:13,722:INFO:           interpret: 0.3.2
2023-05-21 16:14:13,722:INFO:                umap: 0.5.3
2023-05-21 16:14:13,722:INFO:    pandas_profiling: 3.6.6
2023-05-21 16:14:13,722:INFO:  explainerdashboard: 0.4.2.2
2023-05-21 16:14:13,722:INFO:             autoviz: 0.1.603
2023-05-21 16:14:13,722:INFO:           fairlearn: 0.7.0
2023-05-21 16:14:13,722:INFO:             xgboost: 1.7.5
2023-05-21 16:14:13,722:INFO:            catboost: Not installed
2023-05-21 16:14:13,722:INFO:              kmodes: Not installed
2023-05-21 16:14:13,722:INFO:             mlxtend: Not installed
2023-05-21 16:14:13,722:INFO:       statsforecast: Not installed
2023-05-21 16:14:13,722:INFO:        tune_sklearn: Not installed
2023-05-21 16:14:13,722:INFO:                 ray: Not installed
2023-05-21 16:14:13,722:INFO:            hyperopt: Not installed
2023-05-21 16:14:13,722:INFO:              optuna: 3.1.1
2023-05-21 16:14:13,722:INFO:               skopt: Not installed
2023-05-21 16:14:13,722:INFO:              mlflow: 2.3.1
2023-05-21 16:14:13,722:INFO:              gradio: Not installed
2023-05-21 16:14:13,722:INFO:             fastapi: Not installed
2023-05-21 16:14:13,722:INFO:             uvicorn: Not installed
2023-05-21 16:14:13,722:INFO:              m2cgen: Not installed
2023-05-21 16:14:13,722:INFO:           evidently: Not installed
2023-05-21 16:14:13,723:INFO:               fugue: Not installed
2023-05-21 16:14:13,723:INFO:           streamlit: Not installed
2023-05-21 16:14:13,723:INFO:             prophet: Not installed
2023-05-21 16:14:13,723:INFO:None
2023-05-21 16:14:13,723:INFO:Set up data.
2023-05-21 16:14:13,840:INFO:Set up train/test split.
2023-05-21 16:14:13,897:INFO:Set up index.
2023-05-21 16:14:13,897:INFO:Set up folding strategy.
2023-05-21 16:14:13,898:INFO:Assigning column types.
2023-05-21 16:14:13,904:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-21 16:14:13,949:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 16:14:13,949:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:14:13,979:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:14:13,981:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:14:14,026:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 16:14:14,027:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:14:14,054:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:14:14,057:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:14:14,057:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-21 16:14:14,101:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:14:14,128:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:14:14,131:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:14:14,176:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:14:14,204:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:14:14,206:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:14:14,206:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-21 16:14:14,279:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:14:14,281:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:14:14,354:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:14:14,356:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:14:14,357:INFO:Preparing preprocessing pipeline...
2023-05-21 16:14:14,359:INFO:Set up simple imputation.
2023-05-21 16:14:14,370:INFO:Set up encoding of categorical features.
2023-05-21 16:14:14,503:INFO:Finished creating preprocessing pipeline.
2023-05-21 16:14:14,508:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 16:14:14,508:INFO:Creating final display dataframe.
2023-05-21 16:14:14,688:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     42
1                        Target      app_complete_flag
2                   Target type                 Binary
3           Original data shape            (238964, 7)
4        Transformed data shape           (238964, 39)
5   Transformed train set shape           (167274, 39)
6    Transformed test set shape            (71690, 39)
7              Numeric features                      3
8          Categorical features                      3
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13     Maximum one-hot encoding                     25
14              Encoding method                   None
15               Fold Generator        StratifiedKFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                  False
19               Log Experiment           MlflowLogger
20              Experiment Name  OnlyImportantFeatures
21                          USI                   74ee
2023-05-21 16:14:14,764:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:14:14,767:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:14:14,839:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:14:14,842:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:14:14,842:INFO:Logging experiment in loggers
2023-05-21 16:14:15,356:INFO:SubProcess save_model() called ==================================
2023-05-21 16:14:15,372:INFO:Initializing save_model()
2023-05-21 16:14:15,372:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/tmp/tmp_1bd68rv/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-21 16:14:15,372:INFO:Adding model into prep_pipe
2023-05-21 16:14:15,373:WARNING:Only Model saved as it was a pipeline.
2023-05-21 16:14:15,382:INFO:/tmp/tmp_1bd68rv/Transformation Pipeline.pkl saved in current working directory
2023-05-21 16:14:15,390:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 16:14:15,390:INFO:save_model() successfully completed......................................
2023-05-21 16:14:15,503:INFO:SubProcess save_model() end ==================================
2023-05-21 16:14:16,086:INFO:setup() successfully completed in 1.13s...............
2023-05-21 16:14:16,086:INFO:Initializing compare_models()
2023-05-21 16:14:16,086:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedb2f18310>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fedb2f18310>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'])
2023-05-21 16:14:16,086:INFO:Checking exceptions
2023-05-21 16:14:16,097:INFO:Preparing display monitor
2023-05-21 16:14:16,099:INFO:Initializing Logistic Regression
2023-05-21 16:14:16,099:INFO:Total runtime is 1.0132789611816406e-06 minutes
2023-05-21 16:14:16,099:INFO:SubProcess create_model() called ==================================
2023-05-21 16:14:16,099:INFO:Initializing create_model()
2023-05-21 16:14:16,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedb2f18310>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fedc8597fd0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:14:16,099:INFO:Checking exceptions
2023-05-21 16:14:16,099:INFO:Importing libraries
2023-05-21 16:14:16,099:INFO:Copying training dataset
2023-05-21 16:14:16,121:INFO:Defining folds
2023-05-21 16:14:16,121:INFO:Declaring metric variables
2023-05-21 16:14:16,121:INFO:Importing untrained model
2023-05-21 16:14:16,121:INFO:Logistic Regression Imported successfully
2023-05-21 16:14:16,121:INFO:Starting cross validation
2023-05-21 16:14:16,122:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:14:16,776:INFO:Calculating mean and std
2023-05-21 16:14:16,776:INFO:Creating metrics dataframe
2023-05-21 16:14:16,798:INFO:Uploading results into container
2023-05-21 16:14:16,798:INFO:Uploading model into container now
2023-05-21 16:14:16,799:INFO:_master_model_container: 1
2023-05-21 16:14:16,799:INFO:_display_container: 2
2023-05-21 16:14:16,799:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-21 16:14:16,799:INFO:create_model() successfully completed......................................
2023-05-21 16:14:16,907:INFO:SubProcess create_model() end ==================================
2023-05-21 16:14:16,908:INFO:Creating metrics dataframe
2023-05-21 16:14:16,911:INFO:Initializing Naive Bayes
2023-05-21 16:14:16,911:INFO:Total runtime is 0.01353599230448405 minutes
2023-05-21 16:14:16,911:INFO:SubProcess create_model() called ==================================
2023-05-21 16:14:16,911:INFO:Initializing create_model()
2023-05-21 16:14:16,911:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedb2f18310>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fedc8597fd0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:14:16,911:INFO:Checking exceptions
2023-05-21 16:14:16,911:INFO:Importing libraries
2023-05-21 16:14:16,912:INFO:Copying training dataset
2023-05-21 16:14:16,933:INFO:Defining folds
2023-05-21 16:14:16,933:INFO:Declaring metric variables
2023-05-21 16:14:16,933:INFO:Importing untrained model
2023-05-21 16:14:16,933:INFO:Naive Bayes Imported successfully
2023-05-21 16:14:16,934:INFO:Starting cross validation
2023-05-21 16:14:16,934:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:14:17,616:INFO:Calculating mean and std
2023-05-21 16:14:17,616:INFO:Creating metrics dataframe
2023-05-21 16:14:17,629:INFO:Uploading results into container
2023-05-21 16:14:17,630:INFO:Uploading model into container now
2023-05-21 16:14:17,630:INFO:_master_model_container: 2
2023-05-21 16:14:17,630:INFO:_display_container: 2
2023-05-21 16:14:17,630:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-21 16:14:17,630:INFO:create_model() successfully completed......................................
2023-05-21 16:14:17,728:INFO:SubProcess create_model() end ==================================
2023-05-21 16:14:17,728:INFO:Creating metrics dataframe
2023-05-21 16:14:17,732:INFO:Initializing Decision Tree Classifier
2023-05-21 16:14:17,732:INFO:Total runtime is 0.027218413352966306 minutes
2023-05-21 16:14:17,732:INFO:SubProcess create_model() called ==================================
2023-05-21 16:14:17,732:INFO:Initializing create_model()
2023-05-21 16:14:17,732:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedb2f18310>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fedc8597fd0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:14:17,732:INFO:Checking exceptions
2023-05-21 16:14:17,732:INFO:Importing libraries
2023-05-21 16:14:17,732:INFO:Copying training dataset
2023-05-21 16:14:17,754:INFO:Defining folds
2023-05-21 16:14:17,754:INFO:Declaring metric variables
2023-05-21 16:14:17,755:INFO:Importing untrained model
2023-05-21 16:14:17,755:INFO:Decision Tree Classifier Imported successfully
2023-05-21 16:14:17,755:INFO:Starting cross validation
2023-05-21 16:14:17,756:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:14:18,387:INFO:Calculating mean and std
2023-05-21 16:14:18,388:INFO:Creating metrics dataframe
2023-05-21 16:14:18,406:INFO:Uploading results into container
2023-05-21 16:14:18,407:INFO:Uploading model into container now
2023-05-21 16:14:18,407:INFO:_master_model_container: 3
2023-05-21 16:14:18,407:INFO:_display_container: 2
2023-05-21 16:14:18,408:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-05-21 16:14:18,408:INFO:create_model() successfully completed......................................
2023-05-21 16:14:18,514:INFO:SubProcess create_model() end ==================================
2023-05-21 16:14:18,514:INFO:Creating metrics dataframe
2023-05-21 16:14:18,518:INFO:Initializing Ridge Classifier
2023-05-21 16:14:18,518:INFO:Total runtime is 0.040317416191101074 minutes
2023-05-21 16:14:18,518:INFO:SubProcess create_model() called ==================================
2023-05-21 16:14:18,518:INFO:Initializing create_model()
2023-05-21 16:14:18,518:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedb2f18310>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fedc8597fd0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:14:18,518:INFO:Checking exceptions
2023-05-21 16:14:18,518:INFO:Importing libraries
2023-05-21 16:14:18,518:INFO:Copying training dataset
2023-05-21 16:14:18,540:INFO:Defining folds
2023-05-21 16:14:18,540:INFO:Declaring metric variables
2023-05-21 16:14:18,541:INFO:Importing untrained model
2023-05-21 16:14:18,541:INFO:Ridge Classifier Imported successfully
2023-05-21 16:14:18,541:INFO:Starting cross validation
2023-05-21 16:14:18,542:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:14:18,858:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:14:18,910:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:14:18,913:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:14:18,940:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:14:18,944:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:14:18,971:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:14:18,975:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:14:18,980:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:14:18,982:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:14:18,982:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:14:19,167:INFO:Calculating mean and std
2023-05-21 16:14:19,167:INFO:Creating metrics dataframe
2023-05-21 16:14:19,193:INFO:Uploading results into container
2023-05-21 16:14:19,194:INFO:Uploading model into container now
2023-05-21 16:14:19,195:INFO:_master_model_container: 4
2023-05-21 16:14:19,195:INFO:_display_container: 2
2023-05-21 16:14:19,195:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-05-21 16:14:19,196:INFO:create_model() successfully completed......................................
2023-05-21 16:14:19,315:INFO:SubProcess create_model() end ==================================
2023-05-21 16:14:19,315:INFO:Creating metrics dataframe
2023-05-21 16:14:19,320:INFO:Initializing Random Forest Classifier
2023-05-21 16:14:19,320:INFO:Total runtime is 0.05368465979894002 minutes
2023-05-21 16:14:19,320:INFO:SubProcess create_model() called ==================================
2023-05-21 16:14:19,320:INFO:Initializing create_model()
2023-05-21 16:14:19,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedb2f18310>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fedc8597fd0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:14:19,320:INFO:Checking exceptions
2023-05-21 16:14:19,320:INFO:Importing libraries
2023-05-21 16:14:19,321:INFO:Copying training dataset
2023-05-21 16:14:19,350:INFO:Defining folds
2023-05-21 16:14:19,350:INFO:Declaring metric variables
2023-05-21 16:14:19,351:INFO:Importing untrained model
2023-05-21 16:14:19,351:INFO:Random Forest Classifier Imported successfully
2023-05-21 16:14:19,351:INFO:Starting cross validation
2023-05-21 16:14:19,352:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:14:20,842:INFO:Calculating mean and std
2023-05-21 16:14:20,843:INFO:Creating metrics dataframe
2023-05-21 16:14:20,867:INFO:Uploading results into container
2023-05-21 16:14:20,867:INFO:Uploading model into container now
2023-05-21 16:14:20,868:INFO:_master_model_container: 5
2023-05-21 16:14:20,868:INFO:_display_container: 2
2023-05-21 16:14:20,869:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-05-21 16:14:20,869:INFO:create_model() successfully completed......................................
2023-05-21 16:14:20,978:INFO:SubProcess create_model() end ==================================
2023-05-21 16:14:20,978:INFO:Creating metrics dataframe
2023-05-21 16:14:20,982:INFO:Initializing Linear Discriminant Analysis
2023-05-21 16:14:20,982:INFO:Total runtime is 0.08139025767644247 minutes
2023-05-21 16:14:20,982:INFO:SubProcess create_model() called ==================================
2023-05-21 16:14:20,983:INFO:Initializing create_model()
2023-05-21 16:14:20,983:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedb2f18310>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fedc8597fd0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:14:20,983:INFO:Checking exceptions
2023-05-21 16:14:20,983:INFO:Importing libraries
2023-05-21 16:14:20,983:INFO:Copying training dataset
2023-05-21 16:14:21,007:INFO:Defining folds
2023-05-21 16:14:21,007:INFO:Declaring metric variables
2023-05-21 16:14:21,007:INFO:Importing untrained model
2023-05-21 16:14:21,007:INFO:Linear Discriminant Analysis Imported successfully
2023-05-21 16:14:21,007:INFO:Starting cross validation
2023-05-21 16:14:21,008:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:14:21,662:INFO:Calculating mean and std
2023-05-21 16:14:21,662:INFO:Creating metrics dataframe
2023-05-21 16:14:21,688:INFO:Uploading results into container
2023-05-21 16:14:21,689:INFO:Uploading model into container now
2023-05-21 16:14:21,690:INFO:_master_model_container: 6
2023-05-21 16:14:21,690:INFO:_display_container: 2
2023-05-21 16:14:21,690:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-21 16:14:21,690:INFO:create_model() successfully completed......................................
2023-05-21 16:14:21,810:INFO:SubProcess create_model() end ==================================
2023-05-21 16:14:21,810:INFO:Creating metrics dataframe
2023-05-21 16:14:21,814:INFO:Initializing Extra Trees Classifier
2023-05-21 16:14:21,814:INFO:Total runtime is 0.09525400797526042 minutes
2023-05-21 16:14:21,814:INFO:SubProcess create_model() called ==================================
2023-05-21 16:14:21,814:INFO:Initializing create_model()
2023-05-21 16:14:21,815:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedb2f18310>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fedc8597fd0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:14:21,815:INFO:Checking exceptions
2023-05-21 16:14:21,815:INFO:Importing libraries
2023-05-21 16:14:21,815:INFO:Copying training dataset
2023-05-21 16:14:21,844:INFO:Defining folds
2023-05-21 16:14:21,844:INFO:Declaring metric variables
2023-05-21 16:14:21,844:INFO:Importing untrained model
2023-05-21 16:14:21,844:INFO:Extra Trees Classifier Imported successfully
2023-05-21 16:14:21,845:INFO:Starting cross validation
2023-05-21 16:14:21,846:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:14:23,432:INFO:Calculating mean and std
2023-05-21 16:14:23,433:INFO:Creating metrics dataframe
2023-05-21 16:14:23,459:INFO:Uploading results into container
2023-05-21 16:14:23,460:INFO:Uploading model into container now
2023-05-21 16:14:23,461:INFO:_master_model_container: 7
2023-05-21 16:14:23,461:INFO:_display_container: 2
2023-05-21 16:14:23,461:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-05-21 16:14:23,461:INFO:create_model() successfully completed......................................
2023-05-21 16:14:23,573:INFO:SubProcess create_model() end ==================================
2023-05-21 16:14:23,573:INFO:Creating metrics dataframe
2023-05-21 16:14:23,577:INFO:Initializing Light Gradient Boosting Machine
2023-05-21 16:14:23,577:INFO:Total runtime is 0.12463207642237345 minutes
2023-05-21 16:14:23,577:INFO:SubProcess create_model() called ==================================
2023-05-21 16:14:23,577:INFO:Initializing create_model()
2023-05-21 16:14:23,577:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedb2f18310>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fedc8597fd0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:14:23,577:INFO:Checking exceptions
2023-05-21 16:14:23,577:INFO:Importing libraries
2023-05-21 16:14:23,577:INFO:Copying training dataset
2023-05-21 16:14:23,599:INFO:Defining folds
2023-05-21 16:14:23,600:INFO:Declaring metric variables
2023-05-21 16:14:23,600:INFO:Importing untrained model
2023-05-21 16:14:23,600:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 16:14:23,600:INFO:Starting cross validation
2023-05-21 16:14:23,601:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:14:24,461:INFO:Calculating mean and std
2023-05-21 16:14:24,462:INFO:Creating metrics dataframe
2023-05-21 16:14:24,485:INFO:Uploading results into container
2023-05-21 16:14:24,486:INFO:Uploading model into container now
2023-05-21 16:14:24,486:INFO:_master_model_container: 8
2023-05-21 16:14:24,486:INFO:_display_container: 2
2023-05-21 16:14:24,487:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 16:14:24,487:INFO:create_model() successfully completed......................................
2023-05-21 16:14:24,595:INFO:SubProcess create_model() end ==================================
2023-05-21 16:14:24,596:INFO:Creating metrics dataframe
2023-05-21 16:14:24,601:INFO:Initializing create_model()
2023-05-21 16:14:24,601:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedb2f18310>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:14:24,601:INFO:Checking exceptions
2023-05-21 16:14:24,602:INFO:Importing libraries
2023-05-21 16:14:24,602:INFO:Copying training dataset
2023-05-21 16:14:24,623:INFO:Defining folds
2023-05-21 16:14:24,623:INFO:Declaring metric variables
2023-05-21 16:14:24,624:INFO:Importing untrained model
2023-05-21 16:14:24,624:INFO:Declaring custom model
2023-05-21 16:14:24,624:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 16:14:24,625:INFO:Cross validation set to False
2023-05-21 16:14:24,625:INFO:Fitting Model
2023-05-21 16:14:24,802:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 16:14:24,802:INFO:create_model() successfully completed......................................
2023-05-21 16:14:24,899:INFO:Creating Dashboard logs
2023-05-21 16:14:24,899:INFO:Model: Light Gradient Boosting Machine
2023-05-21 16:14:24,999:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-21 16:14:25,556:INFO:Initializing predict_model()
2023-05-21 16:14:25,557:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedb2f18310>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fedb20e64d0>)
2023-05-21 16:14:25,557:INFO:Checking exceptions
2023-05-21 16:14:25,557:INFO:Preloading libraries
2023-05-21 16:14:26,057:INFO:SubProcess plot_model() called ==================================
2023-05-21 16:14:26,057:INFO:Initializing plot_model()
2023-05-21 16:14:26,057:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpw3o2ows5, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedb2f18310>, system=False)
2023-05-21 16:14:26,057:INFO:Checking exceptions
2023-05-21 16:14:26,066:INFO:Preloading libraries
2023-05-21 16:14:26,069:INFO:Copying training dataset
2023-05-21 16:14:26,069:INFO:Plot type: auc
2023-05-21 16:14:26,253:INFO:Fitting Model
2023-05-21 16:14:26,257:INFO:Scoring test/hold-out set
2023-05-21 16:14:26,457:INFO:Saving '/tmp/tmpw3o2ows5/AUC.png'
2023-05-21 16:14:26,613:INFO:Visual Rendered Successfully
2023-05-21 16:14:26,710:INFO:plot_model() successfully completed......................................
2023-05-21 16:14:26,711:INFO:Initializing plot_model()
2023-05-21 16:14:26,711:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpw3o2ows5, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedb2f18310>, system=False)
2023-05-21 16:14:26,711:INFO:Checking exceptions
2023-05-21 16:14:26,718:INFO:Preloading libraries
2023-05-21 16:14:26,722:INFO:Copying training dataset
2023-05-21 16:14:26,723:INFO:Plot type: confusion_matrix
2023-05-21 16:14:26,918:INFO:Fitting Model
2023-05-21 16:14:26,920:INFO:Scoring test/hold-out set
2023-05-21 16:14:27,102:INFO:Saving '/tmp/tmpw3o2ows5/Confusion Matrix.png'
2023-05-21 16:14:27,190:INFO:Visual Rendered Successfully
2023-05-21 16:14:27,300:INFO:plot_model() successfully completed......................................
2023-05-21 16:14:27,300:INFO:Initializing plot_model()
2023-05-21 16:14:27,301:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpw3o2ows5, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fedb2f18310>, system=False)
2023-05-21 16:14:27,301:INFO:Checking exceptions
2023-05-21 16:14:27,308:INFO:Preloading libraries
2023-05-21 16:14:27,312:INFO:Copying training dataset
2023-05-21 16:14:27,312:INFO:Plot type: feature
2023-05-21 16:14:27,313:WARNING:No coef_ found. Trying feature_importances_
2023-05-21 16:14:27,391:INFO:Saving '/tmp/tmpw3o2ows5/Feature Importance.png'
2023-05-21 16:14:27,521:INFO:Visual Rendered Successfully
2023-05-21 16:14:27,630:INFO:plot_model() successfully completed......................................
2023-05-21 16:14:27,631:INFO:SubProcess plot_model() end ==================================
2023-05-21 16:14:27,903:INFO:Creating Dashboard logs
2023-05-21 16:14:27,903:INFO:Model: Random Forest Classifier
2023-05-21 16:14:28,036:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 16:14:29,002:INFO:Creating Dashboard logs
2023-05-21 16:14:29,002:INFO:Model: Extra Trees Classifier
2023-05-21 16:14:29,082:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 16:14:30,019:INFO:Creating Dashboard logs
2023-05-21 16:14:30,019:INFO:Model: Decision Tree Classifier
2023-05-21 16:14:30,130:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2023-05-21 16:14:31,251:INFO:Creating Dashboard logs
2023-05-21 16:14:31,252:INFO:Model: Logistic Regression
2023-05-21 16:14:31,359:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-05-21 16:14:32,153:INFO:Creating Dashboard logs
2023-05-21 16:14:32,153:INFO:Model: Linear Discriminant Analysis
2023-05-21 16:14:32,329:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-05-21 16:14:33,510:INFO:Creating Dashboard logs
2023-05-21 16:14:33,510:INFO:Model: Naive Bayes
2023-05-21 16:14:33,610:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-05-21 16:14:34,936:INFO:Creating Dashboard logs
2023-05-21 16:14:34,936:INFO:Model: Ridge Classifier
2023-05-21 16:14:35,057:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2023-05-21 16:14:36,505:INFO:_master_model_container: 8
2023-05-21 16:14:36,505:INFO:_display_container: 2
2023-05-21 16:14:36,506:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 16:14:36,506:INFO:compare_models() successfully completed......................................
2023-05-21 16:16:38,018:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:16:38,018:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:16:38,018:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:16:38,018:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:16:39,061:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-21 16:16:42,439:INFO:PyCaret ClassificationExperiment
2023-05-21 16:16:42,439:INFO:Logging name: Lead_Scoring_Training_Pipeline
2023-05-21 16:16:42,439:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-21 16:16:42,439:INFO:version 3.0.0
2023-05-21 16:16:42,439:INFO:Initializing setup()
2023-05-21 16:16:42,439:INFO:self.USI: 3912
2023-05-21 16:16:42,439:INFO:self._variable_keys: {'target_param', 'fold_groups_param', 'fold_generator', 'USI', 'logging_param', 'pipeline', 'gpu_param', 'X', 'seed', 'X_train', 'log_plots_param', 'fold_shuffle_param', 'y', 'exp_id', 'y_train', 'is_multiclass', 'idx', 'n_jobs_param', 'gpu_n_jobs_param', 'y_test', 'memory', 'X_test', 'exp_name_log', '_ml_usecase', 'data', 'fix_imbalance', 'html_param', '_available_plots'}
2023-05-21 16:16:42,439:INFO:Checking environment
2023-05-21 16:16:42,440:INFO:python_version: 3.10.10
2023-05-21 16:16:42,440:INFO:python_build: ('main', 'Mar  5 2023 22:26:53')
2023-05-21 16:16:42,440:INFO:machine: x86_64
2023-05-21 16:16:42,441:INFO:platform: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 16:16:42,442:INFO:Memory: svmem(total=16717086720, available=4234244096, percent=74.7, used=10159644672, free=3163840512, active=7002562560, inactive=2070429696, buffers=50511872, cached=3343089664, shared=1975558144, slab=521179136)
2023-05-21 16:16:42,444:INFO:Physical Core: 6
2023-05-21 16:16:42,445:INFO:Logical Core: 12
2023-05-21 16:16:42,445:INFO:Checking libraries
2023-05-21 16:16:42,445:INFO:System:
2023-05-21 16:16:42,445:INFO:    python: 3.10.10 (main, Mar  5 2023, 22:26:53) [GCC 12.2.1 20230201]
2023-05-21 16:16:42,445:INFO:executable: /usr/bin/python3.10
2023-05-21 16:16:42,445:INFO:   machine: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 16:16:42,445:INFO:PyCaret required dependencies:
2023-05-21 16:16:42,446:INFO:                 pip: 23.0.1
2023-05-21 16:16:42,446:INFO:          setuptools: 67.6.1
2023-05-21 16:16:42,446:INFO:             pycaret: 3.0.0
2023-05-21 16:16:42,446:INFO:             IPython: 8.12.0
2023-05-21 16:16:42,446:INFO:          ipywidgets: 7.7.5
2023-05-21 16:16:42,446:INFO:                tqdm: 4.64.1
2023-05-21 16:16:42,446:INFO:               numpy: 1.23.0
2023-05-21 16:16:42,446:INFO:              pandas: 1.5.3
2023-05-21 16:16:42,446:INFO:              jinja2: 3.1.2
2023-05-21 16:16:42,446:INFO:               scipy: 1.9.3
2023-05-21 16:16:42,446:INFO:              joblib: 1.2.0
2023-05-21 16:16:42,447:INFO:             sklearn: 1.2.2
2023-05-21 16:16:42,447:INFO:                pyod: 1.0.9
2023-05-21 16:16:42,447:INFO:            imblearn: 0.10.1
2023-05-21 16:16:42,447:INFO:   category_encoders: 2.6.0
2023-05-21 16:16:42,447:INFO:            lightgbm: 3.3.5
2023-05-21 16:16:42,447:INFO:               numba: 0.57.0
2023-05-21 16:16:42,447:INFO:            requests: 2.28.2
2023-05-21 16:16:42,447:INFO:          matplotlib: 3.6.3
2023-05-21 16:16:42,447:INFO:          scikitplot: 0.3.7
2023-05-21 16:16:42,447:INFO:         yellowbrick: 1.5
2023-05-21 16:16:42,447:INFO:              plotly: 5.14.1
2023-05-21 16:16:42,447:INFO:             kaleido: 0.2.1
2023-05-21 16:16:42,447:INFO:         statsmodels: 0.13.5
2023-05-21 16:16:42,448:INFO:              sktime: 0.18.0
2023-05-21 16:16:42,448:INFO:               tbats: 1.1.3
2023-05-21 16:16:42,448:INFO:            pmdarima: 2.0.3
2023-05-21 16:16:42,448:INFO:              psutil: 5.9.4
2023-05-21 16:16:42,448:INFO:PyCaret optional dependencies:
2023-05-21 16:16:42,474:INFO:                shap: 0.41.0
2023-05-21 16:16:42,475:INFO:           interpret: 0.3.2
2023-05-21 16:16:42,475:INFO:                umap: 0.5.3
2023-05-21 16:16:42,475:INFO:    pandas_profiling: 3.6.6
2023-05-21 16:16:42,475:INFO:  explainerdashboard: 0.4.2.2
2023-05-21 16:16:42,475:INFO:             autoviz: 0.1.603
2023-05-21 16:16:42,475:INFO:           fairlearn: 0.7.0
2023-05-21 16:16:42,475:INFO:             xgboost: 1.7.5
2023-05-21 16:16:42,476:INFO:            catboost: Not installed
2023-05-21 16:16:42,476:INFO:              kmodes: Not installed
2023-05-21 16:16:42,476:INFO:             mlxtend: Not installed
2023-05-21 16:16:42,476:INFO:       statsforecast: Not installed
2023-05-21 16:16:42,476:INFO:        tune_sklearn: Not installed
2023-05-21 16:16:42,476:INFO:                 ray: Not installed
2023-05-21 16:16:42,476:INFO:            hyperopt: Not installed
2023-05-21 16:16:42,476:INFO:              optuna: 3.1.1
2023-05-21 16:16:42,477:INFO:               skopt: Not installed
2023-05-21 16:16:42,477:INFO:              mlflow: 2.3.1
2023-05-21 16:16:42,477:INFO:              gradio: Not installed
2023-05-21 16:16:42,477:INFO:             fastapi: Not installed
2023-05-21 16:16:42,477:INFO:             uvicorn: Not installed
2023-05-21 16:16:42,477:INFO:              m2cgen: Not installed
2023-05-21 16:16:42,477:INFO:           evidently: Not installed
2023-05-21 16:16:42,478:INFO:               fugue: Not installed
2023-05-21 16:16:42,478:INFO:           streamlit: Not installed
2023-05-21 16:16:42,478:INFO:             prophet: Not installed
2023-05-21 16:16:42,478:INFO:None
2023-05-21 16:16:42,478:INFO:Set up data.
2023-05-21 16:16:42,616:INFO:Set up train/test split.
2023-05-21 16:16:42,677:INFO:Set up index.
2023-05-21 16:16:42,678:INFO:Set up folding strategy.
2023-05-21 16:16:42,678:INFO:Assigning column types.
2023-05-21 16:16:42,690:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-21 16:16:42,741:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 16:16:42,743:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:16:42,780:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:16:42,845:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:16:42,896:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 16:16:42,897:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:16:42,928:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:16:42,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:16:42,932:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-21 16:16:42,982:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:16:43,014:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:16:43,018:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:16:43,071:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:16:43,102:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:16:43,106:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:16:43,106:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-21 16:16:43,188:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:16:43,192:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:16:43,274:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:16:43,277:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:16:43,280:INFO:Preparing preprocessing pipeline...
2023-05-21 16:16:43,283:INFO:Set up simple imputation.
2023-05-21 16:16:43,301:INFO:Set up encoding of categorical features.
2023-05-21 16:16:43,552:INFO:Finished creating preprocessing pipeline.
2023-05-21 16:16:43,580:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 16:16:43,581:INFO:Creating final display dataframe.
2023-05-21 16:16:43,937:INFO:Setup _display_container:                     Description                           Value
0                    Session id                              42
1                        Target               app_complete_flag
2                   Target type                          Binary
3           Original data shape                     (238964, 7)
4        Transformed data shape                    (238964, 39)
5   Transformed train set shape                    (167274, 39)
6    Transformed test set shape                     (71690, 39)
7              Numeric features                               3
8          Categorical features                               3
9                    Preprocess                            True
10              Imputation type                          simple
11           Numeric imputation                            mean
12       Categorical imputation                            mode
13     Maximum one-hot encoding                              25
14              Encoding method                            None
15               Fold Generator                 StratifiedKFold
16                  Fold Number                              10
17                     CPU Jobs                              -1
18                      Use GPU                           False
19               Log Experiment                    MlflowLogger
20              Experiment Name  Lead_Scoring_Training_Pipeline
21                          USI                            3912
2023-05-21 16:16:44,032:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:16:44,036:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:16:44,119:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:16:44,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:16:44,123:INFO:Logging experiment in loggers
2023-05-21 16:16:44,810:INFO:SubProcess save_model() called ==================================
2023-05-21 16:16:44,897:INFO:Initializing save_model()
2023-05-21 16:16:44,897:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/tmp/tmprkgnjjuv/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-21 16:16:44,897:INFO:Adding model into prep_pipe
2023-05-21 16:16:44,901:WARNING:Only Model saved as it was a pipeline.
2023-05-21 16:16:44,924:INFO:/tmp/tmprkgnjjuv/Transformation Pipeline.pkl saved in current working directory
2023-05-21 16:16:44,948:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 16:16:44,948:INFO:save_model() successfully completed......................................
2023-05-21 16:16:45,112:INFO:SubProcess save_model() end ==================================
2023-05-21 16:16:45,702:INFO:setup() successfully completed in 1.73s...............
2023-05-21 16:16:45,703:INFO:Initializing compare_models()
2023-05-21 16:16:45,703:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff79b8456c0>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7ff79b8456c0>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'])
2023-05-21 16:16:45,703:INFO:Checking exceptions
2023-05-21 16:16:45,719:INFO:Preparing display monitor
2023-05-21 16:16:45,726:INFO:Initializing Logistic Regression
2023-05-21 16:16:45,726:INFO:Total runtime is 3.2107035319010417e-06 minutes
2023-05-21 16:16:45,726:INFO:SubProcess create_model() called ==================================
2023-05-21 16:16:45,727:INFO:Initializing create_model()
2023-05-21 16:16:45,727:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff79b8456c0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff7843e3c70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:16:45,727:INFO:Checking exceptions
2023-05-21 16:16:45,727:INFO:Importing libraries
2023-05-21 16:16:45,727:INFO:Copying training dataset
2023-05-21 16:16:45,756:INFO:Defining folds
2023-05-21 16:16:45,757:INFO:Declaring metric variables
2023-05-21 16:16:45,757:INFO:Importing untrained model
2023-05-21 16:16:45,758:INFO:Logistic Regression Imported successfully
2023-05-21 16:16:45,759:INFO:Starting cross validation
2023-05-21 16:16:45,764:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:16:53,470:INFO:Calculating mean and std
2023-05-21 16:16:53,472:INFO:Creating metrics dataframe
2023-05-21 16:16:53,561:INFO:Uploading results into container
2023-05-21 16:16:53,563:INFO:Uploading model into container now
2023-05-21 16:16:53,564:INFO:_master_model_container: 1
2023-05-21 16:16:53,564:INFO:_display_container: 2
2023-05-21 16:16:53,565:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-21 16:16:53,566:INFO:create_model() successfully completed......................................
2023-05-21 16:16:53,692:INFO:SubProcess create_model() end ==================================
2023-05-21 16:16:53,692:INFO:Creating metrics dataframe
2023-05-21 16:16:53,703:INFO:Initializing Naive Bayes
2023-05-21 16:16:53,704:INFO:Total runtime is 0.13296519120534261 minutes
2023-05-21 16:16:53,704:INFO:SubProcess create_model() called ==================================
2023-05-21 16:16:53,704:INFO:Initializing create_model()
2023-05-21 16:16:53,705:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff79b8456c0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff7843e3c70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:16:53,705:INFO:Checking exceptions
2023-05-21 16:16:53,705:INFO:Importing libraries
2023-05-21 16:16:53,705:INFO:Copying training dataset
2023-05-21 16:16:53,736:INFO:Defining folds
2023-05-21 16:16:53,736:INFO:Declaring metric variables
2023-05-21 16:16:53,736:INFO:Importing untrained model
2023-05-21 16:16:53,737:INFO:Naive Bayes Imported successfully
2023-05-21 16:16:53,738:INFO:Starting cross validation
2023-05-21 16:16:53,742:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:16:57,295:INFO:Calculating mean and std
2023-05-21 16:16:57,297:INFO:Creating metrics dataframe
2023-05-21 16:16:57,386:INFO:Uploading results into container
2023-05-21 16:16:57,387:INFO:Uploading model into container now
2023-05-21 16:16:57,388:INFO:_master_model_container: 2
2023-05-21 16:16:57,388:INFO:_display_container: 2
2023-05-21 16:16:57,389:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-21 16:16:57,389:INFO:create_model() successfully completed......................................
2023-05-21 16:16:57,505:INFO:SubProcess create_model() end ==================================
2023-05-21 16:16:57,505:INFO:Creating metrics dataframe
2023-05-21 16:16:57,518:INFO:Initializing Decision Tree Classifier
2023-05-21 16:16:57,519:INFO:Total runtime is 0.19654908577601116 minutes
2023-05-21 16:16:57,519:INFO:SubProcess create_model() called ==================================
2023-05-21 16:16:57,519:INFO:Initializing create_model()
2023-05-21 16:16:57,520:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff79b8456c0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff7843e3c70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:16:57,520:INFO:Checking exceptions
2023-05-21 16:16:57,520:INFO:Importing libraries
2023-05-21 16:16:57,520:INFO:Copying training dataset
2023-05-21 16:16:57,550:INFO:Defining folds
2023-05-21 16:16:57,550:INFO:Declaring metric variables
2023-05-21 16:16:57,551:INFO:Importing untrained model
2023-05-21 16:16:57,552:INFO:Decision Tree Classifier Imported successfully
2023-05-21 16:16:57,552:INFO:Starting cross validation
2023-05-21 16:16:57,557:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:16:58,861:INFO:Calculating mean and std
2023-05-21 16:16:58,863:INFO:Creating metrics dataframe
2023-05-21 16:16:58,940:INFO:Uploading results into container
2023-05-21 16:16:58,941:INFO:Uploading model into container now
2023-05-21 16:16:58,942:INFO:_master_model_container: 3
2023-05-21 16:16:58,942:INFO:_display_container: 2
2023-05-21 16:16:58,943:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-05-21 16:16:58,943:INFO:create_model() successfully completed......................................
2023-05-21 16:16:59,052:INFO:SubProcess create_model() end ==================================
2023-05-21 16:16:59,052:INFO:Creating metrics dataframe
2023-05-21 16:16:59,065:INFO:Initializing Ridge Classifier
2023-05-21 16:16:59,065:INFO:Total runtime is 0.22232582171758017 minutes
2023-05-21 16:16:59,066:INFO:SubProcess create_model() called ==================================
2023-05-21 16:16:59,066:INFO:Initializing create_model()
2023-05-21 16:16:59,066:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff79b8456c0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff7843e3c70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:16:59,066:INFO:Checking exceptions
2023-05-21 16:16:59,066:INFO:Importing libraries
2023-05-21 16:16:59,066:INFO:Copying training dataset
2023-05-21 16:16:59,096:INFO:Defining folds
2023-05-21 16:16:59,096:INFO:Declaring metric variables
2023-05-21 16:16:59,096:INFO:Importing untrained model
2023-05-21 16:16:59,097:INFO:Ridge Classifier Imported successfully
2023-05-21 16:16:59,098:INFO:Starting cross validation
2023-05-21 16:16:59,102:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:16:59,650:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:16:59,739:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:16:59,761:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:16:59,816:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:16:59,858:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:16:59,900:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:16:59,913:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:16:59,916:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:16:59,926:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:16:59,952:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:17:00,306:INFO:Calculating mean and std
2023-05-21 16:17:00,308:INFO:Creating metrics dataframe
2023-05-21 16:17:00,408:INFO:Uploading results into container
2023-05-21 16:17:00,411:INFO:Uploading model into container now
2023-05-21 16:17:00,413:INFO:_master_model_container: 4
2023-05-21 16:17:00,413:INFO:_display_container: 2
2023-05-21 16:17:00,415:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-05-21 16:17:00,415:INFO:create_model() successfully completed......................................
2023-05-21 16:17:00,591:INFO:SubProcess create_model() end ==================================
2023-05-21 16:17:00,591:INFO:Creating metrics dataframe
2023-05-21 16:17:00,621:INFO:Initializing Random Forest Classifier
2023-05-21 16:17:00,622:INFO:Total runtime is 0.24826354185740154 minutes
2023-05-21 16:17:00,622:INFO:SubProcess create_model() called ==================================
2023-05-21 16:17:00,623:INFO:Initializing create_model()
2023-05-21 16:17:00,624:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff79b8456c0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff7843e3c70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:17:00,624:INFO:Checking exceptions
2023-05-21 16:17:00,624:INFO:Importing libraries
2023-05-21 16:17:00,624:INFO:Copying training dataset
2023-05-21 16:17:00,670:INFO:Defining folds
2023-05-21 16:17:00,670:INFO:Declaring metric variables
2023-05-21 16:17:00,671:INFO:Importing untrained model
2023-05-21 16:17:00,672:INFO:Random Forest Classifier Imported successfully
2023-05-21 16:17:00,673:INFO:Starting cross validation
2023-05-21 16:17:00,679:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:17:03,654:INFO:Calculating mean and std
2023-05-21 16:17:03,656:INFO:Creating metrics dataframe
2023-05-21 16:17:03,744:INFO:Uploading results into container
2023-05-21 16:17:03,745:INFO:Uploading model into container now
2023-05-21 16:17:03,746:INFO:_master_model_container: 5
2023-05-21 16:17:03,746:INFO:_display_container: 2
2023-05-21 16:17:03,747:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-05-21 16:17:03,748:INFO:create_model() successfully completed......................................
2023-05-21 16:17:03,877:INFO:SubProcess create_model() end ==================================
2023-05-21 16:17:03,877:INFO:Creating metrics dataframe
2023-05-21 16:17:03,893:INFO:Initializing Linear Discriminant Analysis
2023-05-21 16:17:03,893:INFO:Total runtime is 0.30278855164845786 minutes
2023-05-21 16:17:03,893:INFO:SubProcess create_model() called ==================================
2023-05-21 16:17:03,894:INFO:Initializing create_model()
2023-05-21 16:17:03,894:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff79b8456c0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff7843e3c70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:17:03,894:INFO:Checking exceptions
2023-05-21 16:17:03,894:INFO:Importing libraries
2023-05-21 16:17:03,894:INFO:Copying training dataset
2023-05-21 16:17:03,929:INFO:Defining folds
2023-05-21 16:17:03,929:INFO:Declaring metric variables
2023-05-21 16:17:03,929:INFO:Importing untrained model
2023-05-21 16:17:03,930:INFO:Linear Discriminant Analysis Imported successfully
2023-05-21 16:17:03,931:INFO:Starting cross validation
2023-05-21 16:17:03,936:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:17:05,271:INFO:Calculating mean and std
2023-05-21 16:17:05,273:INFO:Creating metrics dataframe
2023-05-21 16:17:05,364:INFO:Uploading results into container
2023-05-21 16:17:05,365:INFO:Uploading model into container now
2023-05-21 16:17:05,366:INFO:_master_model_container: 6
2023-05-21 16:17:05,366:INFO:_display_container: 2
2023-05-21 16:17:05,367:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-21 16:17:05,367:INFO:create_model() successfully completed......................................
2023-05-21 16:17:05,481:INFO:SubProcess create_model() end ==================================
2023-05-21 16:17:05,481:INFO:Creating metrics dataframe
2023-05-21 16:17:05,494:INFO:Initializing Extra Trees Classifier
2023-05-21 16:17:05,494:INFO:Total runtime is 0.32947473526000975 minutes
2023-05-21 16:17:05,495:INFO:SubProcess create_model() called ==================================
2023-05-21 16:17:05,495:INFO:Initializing create_model()
2023-05-21 16:17:05,495:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff79b8456c0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff7843e3c70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:17:05,495:INFO:Checking exceptions
2023-05-21 16:17:05,495:INFO:Importing libraries
2023-05-21 16:17:05,495:INFO:Copying training dataset
2023-05-21 16:17:05,525:INFO:Defining folds
2023-05-21 16:17:05,525:INFO:Declaring metric variables
2023-05-21 16:17:05,526:INFO:Importing untrained model
2023-05-21 16:17:05,527:INFO:Extra Trees Classifier Imported successfully
2023-05-21 16:17:05,528:INFO:Starting cross validation
2023-05-21 16:17:05,532:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:17:08,435:INFO:Calculating mean and std
2023-05-21 16:17:08,437:INFO:Creating metrics dataframe
2023-05-21 16:17:08,486:INFO:Uploading results into container
2023-05-21 16:17:08,487:INFO:Uploading model into container now
2023-05-21 16:17:08,488:INFO:_master_model_container: 7
2023-05-21 16:17:08,488:INFO:_display_container: 2
2023-05-21 16:17:08,489:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-05-21 16:17:08,490:INFO:create_model() successfully completed......................................
2023-05-21 16:17:08,601:INFO:SubProcess create_model() end ==================================
2023-05-21 16:17:08,601:INFO:Creating metrics dataframe
2023-05-21 16:17:08,614:INFO:Initializing Light Gradient Boosting Machine
2023-05-21 16:17:08,615:INFO:Total runtime is 0.38148132562637327 minutes
2023-05-21 16:17:08,615:INFO:SubProcess create_model() called ==================================
2023-05-21 16:17:08,615:INFO:Initializing create_model()
2023-05-21 16:17:08,615:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff79b8456c0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff7843e3c70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:17:08,616:INFO:Checking exceptions
2023-05-21 16:17:08,616:INFO:Importing libraries
2023-05-21 16:17:08,616:INFO:Copying training dataset
2023-05-21 16:17:08,645:INFO:Defining folds
2023-05-21 16:17:08,646:INFO:Declaring metric variables
2023-05-21 16:17:08,646:INFO:Importing untrained model
2023-05-21 16:17:08,647:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 16:17:08,648:INFO:Starting cross validation
2023-05-21 16:17:08,652:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:17:10,148:INFO:Calculating mean and std
2023-05-21 16:17:10,150:INFO:Creating metrics dataframe
2023-05-21 16:17:10,236:INFO:Uploading results into container
2023-05-21 16:17:10,237:INFO:Uploading model into container now
2023-05-21 16:17:10,238:INFO:_master_model_container: 8
2023-05-21 16:17:10,238:INFO:_display_container: 2
2023-05-21 16:17:10,240:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 16:17:10,240:INFO:create_model() successfully completed......................................
2023-05-21 16:17:10,351:INFO:SubProcess create_model() end ==================================
2023-05-21 16:17:10,351:INFO:Creating metrics dataframe
2023-05-21 16:17:10,370:INFO:Initializing create_model()
2023-05-21 16:17:10,370:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff79b8456c0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:17:10,370:INFO:Checking exceptions
2023-05-21 16:17:10,372:INFO:Importing libraries
2023-05-21 16:17:10,372:INFO:Copying training dataset
2023-05-21 16:17:10,402:INFO:Defining folds
2023-05-21 16:17:10,402:INFO:Declaring metric variables
2023-05-21 16:17:10,402:INFO:Importing untrained model
2023-05-21 16:17:10,402:INFO:Declaring custom model
2023-05-21 16:17:10,405:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 16:17:10,409:INFO:Cross validation set to False
2023-05-21 16:17:10,409:INFO:Fitting Model
2023-05-21 16:17:10,740:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 16:17:10,740:INFO:create_model() successfully completed......................................
2023-05-21 16:17:10,852:INFO:Creating Dashboard logs
2023-05-21 16:17:10,853:INFO:Model: Light Gradient Boosting Machine
2023-05-21 16:17:10,983:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-21 16:17:11,720:INFO:Initializing predict_model()
2023-05-21 16:17:11,720:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff79b8456c0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7ff7851a0940>)
2023-05-21 16:17:11,720:INFO:Checking exceptions
2023-05-21 16:17:11,720:INFO:Preloading libraries
2023-05-21 16:17:12,345:INFO:SubProcess plot_model() called ==================================
2023-05-21 16:17:12,347:INFO:Initializing plot_model()
2023-05-21 16:17:12,347:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpvf4pj46s, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff79b8456c0>, system=False)
2023-05-21 16:17:12,347:INFO:Checking exceptions
2023-05-21 16:17:12,357:INFO:Preloading libraries
2023-05-21 16:17:12,362:INFO:Copying training dataset
2023-05-21 16:17:12,362:INFO:Plot type: auc
2023-05-21 16:17:13,119:INFO:Fitting Model
2023-05-21 16:17:13,129:INFO:Scoring test/hold-out set
2023-05-21 16:17:13,444:INFO:Saving '/tmp/tmpvf4pj46s/AUC.png'
2023-05-21 16:17:14,167:INFO:Visual Rendered Successfully
2023-05-21 16:17:14,299:INFO:plot_model() successfully completed......................................
2023-05-21 16:17:14,302:INFO:Initializing plot_model()
2023-05-21 16:17:14,302:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpvf4pj46s, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff79b8456c0>, system=False)
2023-05-21 16:17:14,302:INFO:Checking exceptions
2023-05-21 16:17:14,315:INFO:Preloading libraries
2023-05-21 16:17:14,322:INFO:Copying training dataset
2023-05-21 16:17:14,322:INFO:Plot type: confusion_matrix
2023-05-21 16:17:14,743:INFO:Fitting Model
2023-05-21 16:17:14,746:INFO:Scoring test/hold-out set
2023-05-21 16:17:14,982:INFO:Saving '/tmp/tmpvf4pj46s/Confusion Matrix.png'
2023-05-21 16:17:15,257:INFO:Visual Rendered Successfully
2023-05-21 16:17:15,377:INFO:plot_model() successfully completed......................................
2023-05-21 16:17:15,379:INFO:Initializing plot_model()
2023-05-21 16:17:15,379:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpvf4pj46s, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff79b8456c0>, system=False)
2023-05-21 16:17:15,380:INFO:Checking exceptions
2023-05-21 16:17:15,390:INFO:Preloading libraries
2023-05-21 16:17:15,395:INFO:Copying training dataset
2023-05-21 16:17:15,395:INFO:Plot type: feature
2023-05-21 16:17:15,397:WARNING:No coef_ found. Trying feature_importances_
2023-05-21 16:17:15,585:INFO:Saving '/tmp/tmpvf4pj46s/Feature Importance.png'
2023-05-21 16:17:15,927:INFO:Visual Rendered Successfully
2023-05-21 16:17:16,047:INFO:plot_model() successfully completed......................................
2023-05-21 16:17:16,048:INFO:SubProcess plot_model() end ==================================
2023-05-21 16:17:16,072:WARNING:/home/feuer/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-05-21 16:17:16,520:INFO:Creating Dashboard logs
2023-05-21 16:17:16,521:INFO:Model: Random Forest Classifier
2023-05-21 16:17:16,642:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 16:17:17,653:INFO:Creating Dashboard logs
2023-05-21 16:17:17,654:INFO:Model: Extra Trees Classifier
2023-05-21 16:17:17,759:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 16:17:18,904:INFO:Creating Dashboard logs
2023-05-21 16:17:18,904:INFO:Model: Decision Tree Classifier
2023-05-21 16:17:19,009:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2023-05-21 16:17:20,429:INFO:Creating Dashboard logs
2023-05-21 16:17:20,430:INFO:Model: Logistic Regression
2023-05-21 16:17:20,586:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-05-21 16:17:22,143:INFO:Creating Dashboard logs
2023-05-21 16:17:22,144:INFO:Model: Linear Discriminant Analysis
2023-05-21 16:17:22,265:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-05-21 16:17:24,428:INFO:Creating Dashboard logs
2023-05-21 16:17:24,428:INFO:Model: Naive Bayes
2023-05-21 16:17:24,568:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-05-21 16:17:25,729:INFO:Creating Dashboard logs
2023-05-21 16:17:25,730:INFO:Model: Ridge Classifier
2023-05-21 16:17:25,877:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2023-05-21 16:17:27,716:INFO:_master_model_container: 8
2023-05-21 16:17:27,717:INFO:_display_container: 2
2023-05-21 16:17:27,719:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 16:17:27,719:INFO:compare_models() successfully completed......................................
2023-05-21 16:17:27,771:INFO:PyCaret ClassificationExperiment
2023-05-21 16:17:27,771:INFO:Logging name: OnlyImportantFeatures
2023-05-21 16:17:27,772:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-21 16:17:27,772:INFO:version 3.0.0
2023-05-21 16:17:27,772:INFO:Initializing setup()
2023-05-21 16:17:27,772:INFO:self.USI: b87c
2023-05-21 16:17:27,772:INFO:self._variable_keys: {'target_param', 'fold_groups_param', 'fold_generator', 'USI', 'logging_param', 'pipeline', 'gpu_param', 'X', 'seed', 'X_train', 'log_plots_param', 'fold_shuffle_param', 'y', 'exp_id', 'y_train', 'is_multiclass', 'idx', 'n_jobs_param', 'gpu_n_jobs_param', 'y_test', 'memory', 'X_test', 'exp_name_log', '_ml_usecase', 'data', 'fix_imbalance', 'html_param', '_available_plots'}
2023-05-21 16:17:27,772:INFO:Checking environment
2023-05-21 16:17:27,772:INFO:python_version: 3.10.10
2023-05-21 16:17:27,772:INFO:python_build: ('main', 'Mar  5 2023 22:26:53')
2023-05-21 16:17:27,772:INFO:machine: x86_64
2023-05-21 16:17:27,773:INFO:platform: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 16:17:27,773:INFO:Memory: svmem(total=16717086720, available=1320898560, percent=92.1, used=13041270784, free=577224704, active=10284040192, inactive=1324392448, buffers=29159424, cached=3069431808, shared=2007150592, slab=525692928)
2023-05-21 16:17:27,774:INFO:Physical Core: 6
2023-05-21 16:17:27,774:INFO:Logical Core: 12
2023-05-21 16:17:27,774:INFO:Checking libraries
2023-05-21 16:17:27,775:INFO:System:
2023-05-21 16:17:27,775:INFO:    python: 3.10.10 (main, Mar  5 2023, 22:26:53) [GCC 12.2.1 20230201]
2023-05-21 16:17:27,775:INFO:executable: /usr/bin/python3.10
2023-05-21 16:17:27,775:INFO:   machine: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 16:17:27,775:INFO:PyCaret required dependencies:
2023-05-21 16:17:27,775:INFO:                 pip: 23.0.1
2023-05-21 16:17:27,775:INFO:          setuptools: 67.6.1
2023-05-21 16:17:27,776:INFO:             pycaret: 3.0.0
2023-05-21 16:17:27,776:INFO:             IPython: 8.12.0
2023-05-21 16:17:27,776:INFO:          ipywidgets: 7.7.5
2023-05-21 16:17:27,776:INFO:                tqdm: 4.64.1
2023-05-21 16:17:27,776:INFO:               numpy: 1.23.0
2023-05-21 16:17:27,776:INFO:              pandas: 1.5.3
2023-05-21 16:17:27,776:INFO:              jinja2: 3.1.2
2023-05-21 16:17:27,776:INFO:               scipy: 1.9.3
2023-05-21 16:17:27,776:INFO:              joblib: 1.2.0
2023-05-21 16:17:27,776:INFO:             sklearn: 1.2.2
2023-05-21 16:17:27,777:INFO:                pyod: 1.0.9
2023-05-21 16:17:27,777:INFO:            imblearn: 0.10.1
2023-05-21 16:17:27,777:INFO:   category_encoders: 2.6.0
2023-05-21 16:17:27,777:INFO:            lightgbm: 3.3.5
2023-05-21 16:17:27,777:INFO:               numba: 0.57.0
2023-05-21 16:17:27,777:INFO:            requests: 2.28.2
2023-05-21 16:17:27,777:INFO:          matplotlib: 3.6.3
2023-05-21 16:17:27,777:INFO:          scikitplot: 0.3.7
2023-05-21 16:17:27,778:INFO:         yellowbrick: 1.5
2023-05-21 16:17:27,778:INFO:              plotly: 5.14.1
2023-05-21 16:17:27,778:INFO:             kaleido: 0.2.1
2023-05-21 16:17:27,778:INFO:         statsmodels: 0.13.5
2023-05-21 16:17:27,778:INFO:              sktime: 0.18.0
2023-05-21 16:17:27,778:INFO:               tbats: 1.1.3
2023-05-21 16:17:27,778:INFO:            pmdarima: 2.0.3
2023-05-21 16:17:27,778:INFO:              psutil: 5.9.4
2023-05-21 16:17:27,779:INFO:PyCaret optional dependencies:
2023-05-21 16:17:27,779:INFO:                shap: 0.41.0
2023-05-21 16:17:27,779:INFO:           interpret: 0.3.2
2023-05-21 16:17:27,779:INFO:                umap: 0.5.3
2023-05-21 16:17:27,779:INFO:    pandas_profiling: 3.6.6
2023-05-21 16:17:27,779:INFO:  explainerdashboard: 0.4.2.2
2023-05-21 16:17:27,780:INFO:             autoviz: 0.1.603
2023-05-21 16:17:27,780:INFO:           fairlearn: 0.7.0
2023-05-21 16:17:27,780:INFO:             xgboost: 1.7.5
2023-05-21 16:17:27,780:INFO:            catboost: Not installed
2023-05-21 16:17:27,780:INFO:              kmodes: Not installed
2023-05-21 16:17:27,780:INFO:             mlxtend: Not installed
2023-05-21 16:17:27,780:INFO:       statsforecast: Not installed
2023-05-21 16:17:27,780:INFO:        tune_sklearn: Not installed
2023-05-21 16:17:27,781:INFO:                 ray: Not installed
2023-05-21 16:17:27,781:INFO:            hyperopt: Not installed
2023-05-21 16:17:27,781:INFO:              optuna: 3.1.1
2023-05-21 16:17:27,781:INFO:               skopt: Not installed
2023-05-21 16:17:27,781:INFO:              mlflow: 2.3.1
2023-05-21 16:17:27,781:INFO:              gradio: Not installed
2023-05-21 16:17:27,781:INFO:             fastapi: Not installed
2023-05-21 16:17:27,781:INFO:             uvicorn: Not installed
2023-05-21 16:17:27,782:INFO:              m2cgen: Not installed
2023-05-21 16:17:27,782:INFO:           evidently: Not installed
2023-05-21 16:17:27,782:INFO:               fugue: Not installed
2023-05-21 16:17:27,782:INFO:           streamlit: Not installed
2023-05-21 16:17:27,782:INFO:             prophet: Not installed
2023-05-21 16:17:27,782:INFO:None
2023-05-21 16:17:27,782:INFO:Set up data.
2023-05-21 16:17:27,926:INFO:Set up train/test split.
2023-05-21 16:17:27,991:INFO:Set up index.
2023-05-21 16:17:27,991:INFO:Set up folding strategy.
2023-05-21 16:17:27,992:INFO:Assigning column types.
2023-05-21 16:17:28,003:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-21 16:17:28,054:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 16:17:28,056:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:17:28,088:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:17:28,091:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:17:28,142:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 16:17:28,144:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:17:28,176:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:17:28,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:17:28,180:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-21 16:17:28,233:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:17:28,266:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:17:28,269:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:17:28,321:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:17:28,355:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:17:28,358:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:17:28,359:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-21 16:17:28,445:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:17:28,448:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:17:28,530:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:17:28,533:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:17:28,535:INFO:Preparing preprocessing pipeline...
2023-05-21 16:17:28,538:INFO:Set up simple imputation.
2023-05-21 16:17:28,553:INFO:Set up encoding of categorical features.
2023-05-21 16:17:28,824:INFO:Finished creating preprocessing pipeline.
2023-05-21 16:17:28,854:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 16:17:28,854:INFO:Creating final display dataframe.
2023-05-21 16:17:29,463:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     42
1                        Target      app_complete_flag
2                   Target type                 Binary
3           Original data shape            (238964, 7)
4        Transformed data shape           (238964, 39)
5   Transformed train set shape           (167274, 39)
6    Transformed test set shape            (71690, 39)
7              Numeric features                      3
8          Categorical features                      3
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13     Maximum one-hot encoding                     25
14              Encoding method                   None
15               Fold Generator        StratifiedKFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                  False
19               Log Experiment           MlflowLogger
20              Experiment Name  OnlyImportantFeatures
21                          USI                   b87c
2023-05-21 16:17:29,563:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:17:29,566:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:17:29,655:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:17:29,658:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:17:29,659:INFO:Logging experiment in loggers
2023-05-21 16:17:30,511:INFO:SubProcess save_model() called ==================================
2023-05-21 16:17:30,563:INFO:Initializing save_model()
2023-05-21 16:17:30,563:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/tmp/tmpkauc5ybt/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-21 16:17:30,563:INFO:Adding model into prep_pipe
2023-05-21 16:17:30,568:WARNING:Only Model saved as it was a pipeline.
2023-05-21 16:17:30,594:INFO:/tmp/tmpkauc5ybt/Transformation Pipeline.pkl saved in current working directory
2023-05-21 16:17:30,622:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 16:17:30,622:INFO:save_model() successfully completed......................................
2023-05-21 16:17:30,798:INFO:SubProcess save_model() end ==================================
2023-05-21 16:17:31,460:INFO:setup() successfully completed in 1.94s...............
2023-05-21 16:17:31,461:INFO:Initializing compare_models()
2023-05-21 16:17:31,461:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff787047280>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7ff787047280>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'])
2023-05-21 16:17:31,461:INFO:Checking exceptions
2023-05-21 16:17:31,481:INFO:Preparing display monitor
2023-05-21 16:17:31,489:INFO:Initializing Logistic Regression
2023-05-21 16:17:31,489:INFO:Total runtime is 6.282329559326172e-06 minutes
2023-05-21 16:17:31,490:INFO:SubProcess create_model() called ==================================
2023-05-21 16:17:31,490:INFO:Initializing create_model()
2023-05-21 16:17:31,490:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff787047280>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff785a12080>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:17:31,490:INFO:Checking exceptions
2023-05-21 16:17:31,491:INFO:Importing libraries
2023-05-21 16:17:31,491:INFO:Copying training dataset
2023-05-21 16:17:31,554:INFO:Defining folds
2023-05-21 16:17:31,554:INFO:Declaring metric variables
2023-05-21 16:17:31,555:INFO:Importing untrained model
2023-05-21 16:17:31,557:INFO:Logistic Regression Imported successfully
2023-05-21 16:17:31,558:INFO:Starting cross validation
2023-05-21 16:17:31,565:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:17:36,452:INFO:Calculating mean and std
2023-05-21 16:17:36,454:INFO:Creating metrics dataframe
2023-05-21 16:17:36,545:INFO:Uploading results into container
2023-05-21 16:17:36,546:INFO:Uploading model into container now
2023-05-21 16:17:36,547:INFO:_master_model_container: 1
2023-05-21 16:17:36,547:INFO:_display_container: 2
2023-05-21 16:17:36,549:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-21 16:17:36,549:INFO:create_model() successfully completed......................................
2023-05-21 16:17:36,685:INFO:SubProcess create_model() end ==================================
2023-05-21 16:17:36,685:INFO:Creating metrics dataframe
2023-05-21 16:17:36,697:INFO:Initializing Naive Bayes
2023-05-21 16:17:36,697:INFO:Total runtime is 0.08681266705195108 minutes
2023-05-21 16:17:36,698:INFO:SubProcess create_model() called ==================================
2023-05-21 16:17:36,698:INFO:Initializing create_model()
2023-05-21 16:17:36,698:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff787047280>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff785a12080>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:17:36,698:INFO:Checking exceptions
2023-05-21 16:17:36,698:INFO:Importing libraries
2023-05-21 16:17:36,698:INFO:Copying training dataset
2023-05-21 16:17:36,734:INFO:Defining folds
2023-05-21 16:17:36,734:INFO:Declaring metric variables
2023-05-21 16:17:36,735:INFO:Importing untrained model
2023-05-21 16:17:36,735:INFO:Naive Bayes Imported successfully
2023-05-21 16:17:36,736:INFO:Starting cross validation
2023-05-21 16:17:36,742:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:17:39,604:INFO:Calculating mean and std
2023-05-21 16:17:39,606:INFO:Creating metrics dataframe
2023-05-21 16:17:39,665:INFO:Uploading results into container
2023-05-21 16:17:39,666:INFO:Uploading model into container now
2023-05-21 16:17:39,667:INFO:_master_model_container: 2
2023-05-21 16:17:39,667:INFO:_display_container: 2
2023-05-21 16:17:39,667:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-21 16:17:39,667:INFO:create_model() successfully completed......................................
2023-05-21 16:17:39,810:INFO:SubProcess create_model() end ==================================
2023-05-21 16:17:39,810:INFO:Creating metrics dataframe
2023-05-21 16:17:39,830:INFO:Initializing Decision Tree Classifier
2023-05-21 16:17:39,830:INFO:Total runtime is 0.13902194102605184 minutes
2023-05-21 16:17:39,830:INFO:SubProcess create_model() called ==================================
2023-05-21 16:17:39,831:INFO:Initializing create_model()
2023-05-21 16:17:39,831:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff787047280>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff785a12080>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:17:39,831:INFO:Checking exceptions
2023-05-21 16:17:39,831:INFO:Importing libraries
2023-05-21 16:17:39,832:INFO:Copying training dataset
2023-05-21 16:17:39,865:INFO:Defining folds
2023-05-21 16:17:39,865:INFO:Declaring metric variables
2023-05-21 16:17:39,866:INFO:Importing untrained model
2023-05-21 16:17:39,867:INFO:Decision Tree Classifier Imported successfully
2023-05-21 16:17:39,869:INFO:Starting cross validation
2023-05-21 16:17:39,876:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:17:41,713:INFO:Calculating mean and std
2023-05-21 16:17:41,715:INFO:Creating metrics dataframe
2023-05-21 16:17:41,779:INFO:Uploading results into container
2023-05-21 16:17:41,781:INFO:Uploading model into container now
2023-05-21 16:17:41,782:INFO:_master_model_container: 3
2023-05-21 16:17:41,782:INFO:_display_container: 2
2023-05-21 16:17:41,784:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-05-21 16:17:41,784:INFO:create_model() successfully completed......................................
2023-05-21 16:17:41,938:INFO:SubProcess create_model() end ==================================
2023-05-21 16:17:41,938:INFO:Creating metrics dataframe
2023-05-21 16:17:41,955:INFO:Initializing Ridge Classifier
2023-05-21 16:17:41,955:INFO:Total runtime is 0.1744480013847351 minutes
2023-05-21 16:17:41,956:INFO:SubProcess create_model() called ==================================
2023-05-21 16:17:41,957:INFO:Initializing create_model()
2023-05-21 16:17:41,957:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff787047280>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff785a12080>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:17:41,957:INFO:Checking exceptions
2023-05-21 16:17:41,957:INFO:Importing libraries
2023-05-21 16:17:41,957:INFO:Copying training dataset
2023-05-21 16:17:41,999:INFO:Defining folds
2023-05-21 16:17:41,999:INFO:Declaring metric variables
2023-05-21 16:17:41,999:INFO:Importing untrained model
2023-05-21 16:17:42,001:INFO:Ridge Classifier Imported successfully
2023-05-21 16:17:42,001:INFO:Starting cross validation
2023-05-21 16:17:42,006:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:17:42,859:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:17:42,859:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:17:42,931:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:17:42,938:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:17:42,955:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:17:42,962:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:17:42,998:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:17:43,064:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:17:43,074:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:17:43,133:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:17:43,573:INFO:Calculating mean and std
2023-05-21 16:17:43,574:INFO:Creating metrics dataframe
2023-05-21 16:17:43,628:INFO:Uploading results into container
2023-05-21 16:17:43,630:INFO:Uploading model into container now
2023-05-21 16:17:43,631:INFO:_master_model_container: 4
2023-05-21 16:17:43,631:INFO:_display_container: 2
2023-05-21 16:17:43,632:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-05-21 16:17:43,632:INFO:create_model() successfully completed......................................
2023-05-21 16:17:43,774:INFO:SubProcess create_model() end ==================================
2023-05-21 16:17:43,774:INFO:Creating metrics dataframe
2023-05-21 16:17:43,788:INFO:Initializing Random Forest Classifier
2023-05-21 16:17:43,788:INFO:Total runtime is 0.20498895645141602 minutes
2023-05-21 16:17:43,788:INFO:SubProcess create_model() called ==================================
2023-05-21 16:17:43,789:INFO:Initializing create_model()
2023-05-21 16:17:43,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff787047280>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff785a12080>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:17:43,789:INFO:Checking exceptions
2023-05-21 16:17:43,789:INFO:Importing libraries
2023-05-21 16:17:43,789:INFO:Copying training dataset
2023-05-21 16:17:43,819:INFO:Defining folds
2023-05-21 16:17:43,820:INFO:Declaring metric variables
2023-05-21 16:17:43,820:INFO:Importing untrained model
2023-05-21 16:17:43,821:INFO:Random Forest Classifier Imported successfully
2023-05-21 16:17:43,822:INFO:Starting cross validation
2023-05-21 16:17:43,826:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:17:47,237:INFO:Calculating mean and std
2023-05-21 16:17:47,239:INFO:Creating metrics dataframe
2023-05-21 16:17:47,331:INFO:Uploading results into container
2023-05-21 16:17:47,332:INFO:Uploading model into container now
2023-05-21 16:17:47,333:INFO:_master_model_container: 5
2023-05-21 16:17:47,333:INFO:_display_container: 2
2023-05-21 16:17:47,335:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-05-21 16:17:47,335:INFO:create_model() successfully completed......................................
2023-05-21 16:17:47,456:INFO:SubProcess create_model() end ==================================
2023-05-21 16:17:47,456:INFO:Creating metrics dataframe
2023-05-21 16:17:47,470:INFO:Initializing Linear Discriminant Analysis
2023-05-21 16:17:47,470:INFO:Total runtime is 0.26635576089223223 minutes
2023-05-21 16:17:47,470:INFO:SubProcess create_model() called ==================================
2023-05-21 16:17:47,471:INFO:Initializing create_model()
2023-05-21 16:17:47,471:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff787047280>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff785a12080>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:17:47,471:INFO:Checking exceptions
2023-05-21 16:17:47,471:INFO:Importing libraries
2023-05-21 16:17:47,471:INFO:Copying training dataset
2023-05-21 16:17:47,502:INFO:Defining folds
2023-05-21 16:17:47,503:INFO:Declaring metric variables
2023-05-21 16:17:47,503:INFO:Importing untrained model
2023-05-21 16:17:47,504:INFO:Linear Discriminant Analysis Imported successfully
2023-05-21 16:17:47,505:INFO:Starting cross validation
2023-05-21 16:17:47,509:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:17:49,047:INFO:Calculating mean and std
2023-05-21 16:17:49,049:INFO:Creating metrics dataframe
2023-05-21 16:17:49,148:INFO:Uploading results into container
2023-05-21 16:17:49,149:INFO:Uploading model into container now
2023-05-21 16:17:49,150:INFO:_master_model_container: 6
2023-05-21 16:17:49,150:INFO:_display_container: 2
2023-05-21 16:17:49,151:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-21 16:17:49,151:INFO:create_model() successfully completed......................................
2023-05-21 16:17:49,274:INFO:SubProcess create_model() end ==================================
2023-05-21 16:17:49,274:INFO:Creating metrics dataframe
2023-05-21 16:17:49,288:INFO:Initializing Extra Trees Classifier
2023-05-21 16:17:49,288:INFO:Total runtime is 0.2966556708017985 minutes
2023-05-21 16:17:49,288:INFO:SubProcess create_model() called ==================================
2023-05-21 16:17:49,289:INFO:Initializing create_model()
2023-05-21 16:17:49,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff787047280>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff785a12080>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:17:49,289:INFO:Checking exceptions
2023-05-21 16:17:49,289:INFO:Importing libraries
2023-05-21 16:17:49,289:INFO:Copying training dataset
2023-05-21 16:17:49,319:INFO:Defining folds
2023-05-21 16:17:49,319:INFO:Declaring metric variables
2023-05-21 16:17:49,319:INFO:Importing untrained model
2023-05-21 16:17:49,321:INFO:Extra Trees Classifier Imported successfully
2023-05-21 16:17:49,321:INFO:Starting cross validation
2023-05-21 16:17:49,326:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:17:52,632:INFO:Calculating mean and std
2023-05-21 16:17:52,634:INFO:Creating metrics dataframe
2023-05-21 16:17:52,726:INFO:Uploading results into container
2023-05-21 16:17:52,727:INFO:Uploading model into container now
2023-05-21 16:17:52,728:INFO:_master_model_container: 7
2023-05-21 16:17:52,728:INFO:_display_container: 2
2023-05-21 16:17:52,730:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-05-21 16:17:52,730:INFO:create_model() successfully completed......................................
2023-05-21 16:17:52,861:INFO:SubProcess create_model() end ==================================
2023-05-21 16:17:52,861:INFO:Creating metrics dataframe
2023-05-21 16:17:52,876:INFO:Initializing Light Gradient Boosting Machine
2023-05-21 16:17:52,877:INFO:Total runtime is 0.3564659158388774 minutes
2023-05-21 16:17:52,877:INFO:SubProcess create_model() called ==================================
2023-05-21 16:17:52,877:INFO:Initializing create_model()
2023-05-21 16:17:52,877:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff787047280>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff785a12080>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:17:52,878:INFO:Checking exceptions
2023-05-21 16:17:52,878:INFO:Importing libraries
2023-05-21 16:17:52,878:INFO:Copying training dataset
2023-05-21 16:17:52,922:INFO:Defining folds
2023-05-21 16:17:52,922:INFO:Declaring metric variables
2023-05-21 16:17:52,923:INFO:Importing untrained model
2023-05-21 16:17:52,924:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 16:17:52,925:INFO:Starting cross validation
2023-05-21 16:17:52,929:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:17:54,774:INFO:Calculating mean and std
2023-05-21 16:17:54,776:INFO:Creating metrics dataframe
2023-05-21 16:17:54,865:INFO:Uploading results into container
2023-05-21 16:17:54,867:INFO:Uploading model into container now
2023-05-21 16:17:54,867:INFO:_master_model_container: 8
2023-05-21 16:17:54,868:INFO:_display_container: 2
2023-05-21 16:17:54,870:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 16:17:54,870:INFO:create_model() successfully completed......................................
2023-05-21 16:17:54,988:INFO:SubProcess create_model() end ==================================
2023-05-21 16:17:54,989:INFO:Creating metrics dataframe
2023-05-21 16:17:55,010:INFO:Initializing create_model()
2023-05-21 16:17:55,010:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff787047280>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:17:55,011:INFO:Checking exceptions
2023-05-21 16:17:55,012:INFO:Importing libraries
2023-05-21 16:17:55,012:INFO:Copying training dataset
2023-05-21 16:17:55,047:INFO:Defining folds
2023-05-21 16:17:55,048:INFO:Declaring metric variables
2023-05-21 16:17:55,048:INFO:Importing untrained model
2023-05-21 16:17:55,048:INFO:Declaring custom model
2023-05-21 16:17:55,051:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 16:17:55,056:INFO:Cross validation set to False
2023-05-21 16:17:55,056:INFO:Fitting Model
2023-05-21 16:17:55,395:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 16:17:55,395:INFO:create_model() successfully completed......................................
2023-05-21 16:17:55,509:INFO:Creating Dashboard logs
2023-05-21 16:17:55,510:INFO:Model: Light Gradient Boosting Machine
2023-05-21 16:17:55,745:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-21 16:17:57,280:INFO:Initializing predict_model()
2023-05-21 16:17:57,280:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff787047280>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7ff7851a0550>)
2023-05-21 16:17:57,280:INFO:Checking exceptions
2023-05-21 16:17:57,281:INFO:Preloading libraries
2023-05-21 16:17:57,954:INFO:SubProcess plot_model() called ==================================
2023-05-21 16:17:57,957:INFO:Initializing plot_model()
2023-05-21 16:17:57,957:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpy0lrob48, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff787047280>, system=False)
2023-05-21 16:17:57,958:INFO:Checking exceptions
2023-05-21 16:17:57,972:INFO:Preloading libraries
2023-05-21 16:17:57,978:INFO:Copying training dataset
2023-05-21 16:17:57,978:INFO:Plot type: auc
2023-05-21 16:17:59,172:INFO:Fitting Model
2023-05-21 16:17:59,181:INFO:Scoring test/hold-out set
2023-05-21 16:18:00,298:INFO:Saving '/tmp/tmpy0lrob48/AUC.png'
2023-05-21 16:18:00,794:INFO:Visual Rendered Successfully
2023-05-21 16:18:00,917:INFO:plot_model() successfully completed......................................
2023-05-21 16:18:00,920:INFO:Initializing plot_model()
2023-05-21 16:18:00,920:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpy0lrob48, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff787047280>, system=False)
2023-05-21 16:18:00,920:INFO:Checking exceptions
2023-05-21 16:18:00,933:INFO:Preloading libraries
2023-05-21 16:18:00,937:INFO:Copying training dataset
2023-05-21 16:18:00,938:INFO:Plot type: confusion_matrix
2023-05-21 16:18:01,695:INFO:Fitting Model
2023-05-21 16:18:01,698:INFO:Scoring test/hold-out set
2023-05-21 16:18:02,064:INFO:Saving '/tmp/tmpy0lrob48/Confusion Matrix.png'
2023-05-21 16:18:02,338:INFO:Visual Rendered Successfully
2023-05-21 16:18:02,479:INFO:plot_model() successfully completed......................................
2023-05-21 16:18:02,483:INFO:Initializing plot_model()
2023-05-21 16:18:02,483:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpy0lrob48, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff787047280>, system=False)
2023-05-21 16:18:02,483:INFO:Checking exceptions
2023-05-21 16:18:02,498:INFO:Preloading libraries
2023-05-21 16:18:02,505:INFO:Copying training dataset
2023-05-21 16:18:02,505:INFO:Plot type: feature
2023-05-21 16:18:02,507:WARNING:No coef_ found. Trying feature_importances_
2023-05-21 16:18:02,732:INFO:Saving '/tmp/tmpy0lrob48/Feature Importance.png'
2023-05-21 16:18:03,132:INFO:Visual Rendered Successfully
2023-05-21 16:18:03,265:INFO:plot_model() successfully completed......................................
2023-05-21 16:18:03,266:INFO:SubProcess plot_model() end ==================================
2023-05-21 16:18:04,785:INFO:Creating Dashboard logs
2023-05-21 16:18:04,786:INFO:Model: Random Forest Classifier
2023-05-21 16:18:05,300:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 16:18:10,485:INFO:Creating Dashboard logs
2023-05-21 16:18:10,487:INFO:Model: Extra Trees Classifier
2023-05-21 16:18:10,708:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 16:18:12,596:INFO:Creating Dashboard logs
2023-05-21 16:18:12,597:INFO:Model: Decision Tree Classifier
2023-05-21 16:18:12,742:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2023-05-21 16:18:13,901:INFO:Creating Dashboard logs
2023-05-21 16:18:13,902:INFO:Model: Logistic Regression
2023-05-21 16:18:14,039:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-05-21 16:18:15,133:INFO:Creating Dashboard logs
2023-05-21 16:18:15,134:INFO:Model: Linear Discriminant Analysis
2023-05-21 16:18:15,336:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-05-21 16:18:17,103:INFO:Creating Dashboard logs
2023-05-21 16:18:17,103:INFO:Model: Naive Bayes
2023-05-21 16:18:17,215:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-05-21 16:18:18,718:INFO:Creating Dashboard logs
2023-05-21 16:18:18,719:INFO:Model: Ridge Classifier
2023-05-21 16:18:18,833:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2023-05-21 16:18:19,832:INFO:_master_model_container: 8
2023-05-21 16:18:19,832:INFO:_display_container: 2
2023-05-21 16:18:19,834:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 16:18:19,834:INFO:compare_models() successfully completed......................................
2023-05-21 16:19:56,571:INFO:Initializing get_config()
2023-05-21 16:19:56,619:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff787047280>, variable=X_train)
2023-05-21 16:19:56,620:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2023-05-21 16:19:56,620:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/pycaret_experiment.py:322: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-05-21 16:19:56,654:INFO:Variable:  returned as         total_leads_dropped  city_tier  ...  first_utm_medium_c first_utm_source_c
149381                  1.0        3.0  ...              Level0             Level0
23956                   1.0        1.0  ...              Level0             Level0
187671                  1.0        1.0  ...              Level2             Level2
4798                    1.0        1.0  ...              others            Level16
50707                   1.0        2.0  ...              Level0             Level0
...                     ...        ...  ...                 ...                ...
151557                  1.0        1.0  ...              Level6             Level7
25054                   2.0        1.0  ...             Level20            Level14
134681                  1.0        2.0  ...              Level4             Level2
114585                  1.0        3.0  ...              Level8             Level2
148045                  4.0        1.0  ...             Level11             Level2

[167274 rows x 6 columns]
2023-05-21 16:19:56,654:INFO:get_config() successfully completed......................................
2023-05-21 16:22:48,683:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:22:48,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:22:48,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:22:48,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:22:51,523:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-21 16:23:06,439:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:23:06,439:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:23:06,439:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:23:06,439:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:23:07,339:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-21 16:23:11,330:INFO:PyCaret ClassificationExperiment
2023-05-21 16:23:11,330:INFO:Logging name: OnlyImportantFeatures
2023-05-21 16:23:11,330:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-21 16:23:11,330:INFO:version 3.0.0
2023-05-21 16:23:11,330:INFO:Initializing setup()
2023-05-21 16:23:11,330:INFO:self.USI: bebf
2023-05-21 16:23:11,330:INFO:self._variable_keys: {'USI', 'gpu_n_jobs_param', 'idx', 'target_param', 'logging_param', 'is_multiclass', 'fold_groups_param', '_ml_usecase', 'y', 'fix_imbalance', 'log_plots_param', 'X_train', 'gpu_param', 'fold_generator', 'seed', 'memory', 'pipeline', 'X_test', '_available_plots', 'exp_id', 'html_param', 'y_test', 'data', 'exp_name_log', 'X', 'fold_shuffle_param', 'y_train', 'n_jobs_param'}
2023-05-21 16:23:11,330:INFO:Checking environment
2023-05-21 16:23:11,331:INFO:python_version: 3.10.10
2023-05-21 16:23:11,331:INFO:python_build: ('main', 'Mar  5 2023 22:26:53')
2023-05-21 16:23:11,331:INFO:machine: x86_64
2023-05-21 16:23:11,332:INFO:platform: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 16:23:11,333:INFO:Memory: svmem(total=16717086720, available=4515540992, percent=73.0, used=10149015552, free=3652591616, active=5203943424, inactive=3119763456, buffers=28696576, cached=2886782976, shared=1709084672, slab=528912384)
2023-05-21 16:23:11,334:INFO:Physical Core: 6
2023-05-21 16:23:11,335:INFO:Logical Core: 12
2023-05-21 16:23:11,335:INFO:Checking libraries
2023-05-21 16:23:11,335:INFO:System:
2023-05-21 16:23:11,335:INFO:    python: 3.10.10 (main, Mar  5 2023, 22:26:53) [GCC 12.2.1 20230201]
2023-05-21 16:23:11,335:INFO:executable: /usr/bin/python3.10
2023-05-21 16:23:11,335:INFO:   machine: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 16:23:11,335:INFO:PyCaret required dependencies:
2023-05-21 16:23:11,335:INFO:                 pip: 23.0.1
2023-05-21 16:23:11,335:INFO:          setuptools: 67.6.1
2023-05-21 16:23:11,336:INFO:             pycaret: 3.0.0
2023-05-21 16:23:11,336:INFO:             IPython: 8.12.0
2023-05-21 16:23:11,336:INFO:          ipywidgets: 7.7.5
2023-05-21 16:23:11,336:INFO:                tqdm: 4.64.1
2023-05-21 16:23:11,336:INFO:               numpy: 1.23.0
2023-05-21 16:23:11,336:INFO:              pandas: 1.5.3
2023-05-21 16:23:11,336:INFO:              jinja2: 3.1.2
2023-05-21 16:23:11,336:INFO:               scipy: 1.9.3
2023-05-21 16:23:11,336:INFO:              joblib: 1.2.0
2023-05-21 16:23:11,336:INFO:             sklearn: 1.2.2
2023-05-21 16:23:11,336:INFO:                pyod: 1.0.9
2023-05-21 16:23:11,336:INFO:            imblearn: 0.10.1
2023-05-21 16:23:11,336:INFO:   category_encoders: 2.6.0
2023-05-21 16:23:11,337:INFO:            lightgbm: 3.3.5
2023-05-21 16:23:11,337:INFO:               numba: 0.57.0
2023-05-21 16:23:11,337:INFO:            requests: 2.28.2
2023-05-21 16:23:11,337:INFO:          matplotlib: 3.6.3
2023-05-21 16:23:11,337:INFO:          scikitplot: 0.3.7
2023-05-21 16:23:11,337:INFO:         yellowbrick: 1.5
2023-05-21 16:23:11,337:INFO:              plotly: 5.14.1
2023-05-21 16:23:11,337:INFO:             kaleido: 0.2.1
2023-05-21 16:23:11,337:INFO:         statsmodels: 0.13.5
2023-05-21 16:23:11,337:INFO:              sktime: 0.18.0
2023-05-21 16:23:11,337:INFO:               tbats: 1.1.3
2023-05-21 16:23:11,337:INFO:            pmdarima: 2.0.3
2023-05-21 16:23:11,337:INFO:              psutil: 5.9.4
2023-05-21 16:23:11,338:INFO:PyCaret optional dependencies:
2023-05-21 16:23:11,364:INFO:                shap: 0.41.0
2023-05-21 16:23:11,364:INFO:           interpret: 0.3.2
2023-05-21 16:23:11,364:INFO:                umap: 0.5.3
2023-05-21 16:23:11,365:INFO:    pandas_profiling: 3.6.6
2023-05-21 16:23:11,365:INFO:  explainerdashboard: 0.4.2.2
2023-05-21 16:23:11,365:INFO:             autoviz: 0.1.603
2023-05-21 16:23:11,365:INFO:           fairlearn: 0.7.0
2023-05-21 16:23:11,365:INFO:             xgboost: 1.7.5
2023-05-21 16:23:11,365:INFO:            catboost: Not installed
2023-05-21 16:23:11,365:INFO:              kmodes: Not installed
2023-05-21 16:23:11,365:INFO:             mlxtend: Not installed
2023-05-21 16:23:11,365:INFO:       statsforecast: Not installed
2023-05-21 16:23:11,365:INFO:        tune_sklearn: Not installed
2023-05-21 16:23:11,365:INFO:                 ray: Not installed
2023-05-21 16:23:11,365:INFO:            hyperopt: Not installed
2023-05-21 16:23:11,366:INFO:              optuna: 3.1.1
2023-05-21 16:23:11,366:INFO:               skopt: Not installed
2023-05-21 16:23:11,366:INFO:              mlflow: 2.3.1
2023-05-21 16:23:11,366:INFO:              gradio: Not installed
2023-05-21 16:23:11,366:INFO:             fastapi: Not installed
2023-05-21 16:23:11,366:INFO:             uvicorn: Not installed
2023-05-21 16:23:11,366:INFO:              m2cgen: Not installed
2023-05-21 16:23:11,366:INFO:           evidently: Not installed
2023-05-21 16:23:11,366:INFO:               fugue: Not installed
2023-05-21 16:23:11,366:INFO:           streamlit: Not installed
2023-05-21 16:23:11,366:INFO:             prophet: Not installed
2023-05-21 16:23:11,366:INFO:None
2023-05-21 16:23:11,367:INFO:Set up data.
2023-05-21 16:23:11,494:INFO:Set up train/test split.
2023-05-21 16:23:11,555:INFO:Set up index.
2023-05-21 16:23:11,556:INFO:Set up folding strategy.
2023-05-21 16:23:11,556:INFO:Assigning column types.
2023-05-21 16:23:11,569:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-21 16:23:11,621:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 16:23:11,644:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:23:11,726:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:23:11,817:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:23:11,869:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 16:23:11,870:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:23:11,901:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:23:11,905:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:23:11,905:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-21 16:23:11,957:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:23:11,989:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:23:11,992:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:23:12,044:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:23:12,077:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:23:12,081:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:23:12,081:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-21 16:23:12,165:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:23:12,168:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:23:12,252:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:23:12,255:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:23:12,259:INFO:Preparing preprocessing pipeline...
2023-05-21 16:23:12,262:INFO:Set up simple imputation.
2023-05-21 16:23:12,279:INFO:Set up encoding of categorical features.
2023-05-21 16:23:12,522:INFO:Finished creating preprocessing pipeline.
2023-05-21 16:23:12,558:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 16:23:12,558:INFO:Creating final display dataframe.
2023-05-21 16:23:12,913:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     42
1                        Target      app_complete_flag
2                   Target type                 Binary
3           Original data shape            (238964, 7)
4        Transformed data shape           (238964, 39)
5   Transformed train set shape           (167274, 39)
6    Transformed test set shape            (71690, 39)
7              Numeric features                      3
8          Categorical features                      3
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13     Maximum one-hot encoding                     25
14              Encoding method                   None
15               Fold Generator        StratifiedKFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                  False
19               Log Experiment           MlflowLogger
20              Experiment Name  OnlyImportantFeatures
21                          USI                   bebf
2023-05-21 16:23:13,011:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:23:13,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:23:13,098:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:23:13,101:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:23:13,102:INFO:Logging experiment in loggers
2023-05-21 16:23:13,851:INFO:SubProcess save_model() called ==================================
2023-05-21 16:23:13,937:INFO:Initializing save_model()
2023-05-21 16:23:13,937:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/tmp/tmpffahodbv/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-21 16:23:13,937:INFO:Adding model into prep_pipe
2023-05-21 16:23:13,941:WARNING:Only Model saved as it was a pipeline.
2023-05-21 16:23:13,963:INFO:/tmp/tmpffahodbv/Transformation Pipeline.pkl saved in current working directory
2023-05-21 16:23:13,987:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 16:23:13,987:INFO:save_model() successfully completed......................................
2023-05-21 16:23:14,144:INFO:SubProcess save_model() end ==================================
2023-05-21 16:23:14,753:INFO:setup() successfully completed in 1.85s...............
2023-05-21 16:23:14,753:INFO:Initializing compare_models()
2023-05-21 16:23:14,753:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f5cea5cd6c0>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f5cea5cd6c0>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'])
2023-05-21 16:23:14,753:INFO:Checking exceptions
2023-05-21 16:23:14,769:INFO:Preparing display monitor
2023-05-21 16:23:14,776:INFO:Initializing Logistic Regression
2023-05-21 16:23:14,777:INFO:Total runtime is 3.4570693969726562e-06 minutes
2023-05-21 16:23:14,777:INFO:SubProcess create_model() called ==================================
2023-05-21 16:23:14,777:INFO:Initializing create_model()
2023-05-21 16:23:14,777:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f5cea5cd6c0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5cd06e0700>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:23:14,777:INFO:Checking exceptions
2023-05-21 16:23:14,778:INFO:Importing libraries
2023-05-21 16:23:14,778:INFO:Copying training dataset
2023-05-21 16:23:14,807:INFO:Defining folds
2023-05-21 16:23:14,807:INFO:Declaring metric variables
2023-05-21 16:23:14,807:INFO:Importing untrained model
2023-05-21 16:23:14,808:INFO:Logistic Regression Imported successfully
2023-05-21 16:23:14,809:INFO:Starting cross validation
2023-05-21 16:23:14,813:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:23:22,555:INFO:Calculating mean and std
2023-05-21 16:23:22,558:INFO:Creating metrics dataframe
2023-05-21 16:23:22,646:INFO:Uploading results into container
2023-05-21 16:23:22,648:INFO:Uploading model into container now
2023-05-21 16:23:22,649:INFO:_master_model_container: 1
2023-05-21 16:23:22,649:INFO:_display_container: 2
2023-05-21 16:23:22,650:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-21 16:23:22,650:INFO:create_model() successfully completed......................................
2023-05-21 16:23:22,783:INFO:SubProcess create_model() end ==================================
2023-05-21 16:23:22,783:INFO:Creating metrics dataframe
2023-05-21 16:23:22,797:INFO:Initializing Naive Bayes
2023-05-21 16:23:22,797:INFO:Total runtime is 0.1336751937866211 minutes
2023-05-21 16:23:22,797:INFO:SubProcess create_model() called ==================================
2023-05-21 16:23:22,798:INFO:Initializing create_model()
2023-05-21 16:23:22,798:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f5cea5cd6c0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5cd06e0700>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:23:22,798:INFO:Checking exceptions
2023-05-21 16:23:22,798:INFO:Importing libraries
2023-05-21 16:23:22,798:INFO:Copying training dataset
2023-05-21 16:23:22,832:INFO:Defining folds
2023-05-21 16:23:22,832:INFO:Declaring metric variables
2023-05-21 16:23:22,833:INFO:Importing untrained model
2023-05-21 16:23:22,834:INFO:Naive Bayes Imported successfully
2023-05-21 16:23:22,834:INFO:Starting cross validation
2023-05-21 16:23:22,839:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:23:26,631:INFO:Calculating mean and std
2023-05-21 16:23:26,633:INFO:Creating metrics dataframe
2023-05-21 16:23:26,720:INFO:Uploading results into container
2023-05-21 16:23:26,722:INFO:Uploading model into container now
2023-05-21 16:23:26,723:INFO:_master_model_container: 2
2023-05-21 16:23:26,723:INFO:_display_container: 2
2023-05-21 16:23:26,723:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-21 16:23:26,723:INFO:create_model() successfully completed......................................
2023-05-21 16:23:26,847:INFO:SubProcess create_model() end ==================================
2023-05-21 16:23:26,848:INFO:Creating metrics dataframe
2023-05-21 16:23:26,864:INFO:Initializing Decision Tree Classifier
2023-05-21 16:23:26,864:INFO:Total runtime is 0.2014652371406555 minutes
2023-05-21 16:23:26,865:INFO:SubProcess create_model() called ==================================
2023-05-21 16:23:26,865:INFO:Initializing create_model()
2023-05-21 16:23:26,865:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f5cea5cd6c0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5cd06e0700>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:23:26,865:INFO:Checking exceptions
2023-05-21 16:23:26,865:INFO:Importing libraries
2023-05-21 16:23:26,866:INFO:Copying training dataset
2023-05-21 16:23:26,909:INFO:Defining folds
2023-05-21 16:23:26,909:INFO:Declaring metric variables
2023-05-21 16:23:26,909:INFO:Importing untrained model
2023-05-21 16:23:26,911:INFO:Decision Tree Classifier Imported successfully
2023-05-21 16:23:26,911:INFO:Starting cross validation
2023-05-21 16:23:26,916:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:23:28,256:INFO:Calculating mean and std
2023-05-21 16:23:28,259:INFO:Creating metrics dataframe
2023-05-21 16:23:28,324:INFO:Uploading results into container
2023-05-21 16:23:28,327:INFO:Uploading model into container now
2023-05-21 16:23:28,328:INFO:_master_model_container: 3
2023-05-21 16:23:28,328:INFO:_display_container: 2
2023-05-21 16:23:28,330:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-05-21 16:23:28,330:INFO:create_model() successfully completed......................................
2023-05-21 16:23:28,450:INFO:SubProcess create_model() end ==================================
2023-05-21 16:23:28,450:INFO:Creating metrics dataframe
2023-05-21 16:23:28,465:INFO:Initializing Ridge Classifier
2023-05-21 16:23:28,465:INFO:Total runtime is 0.22815223137537638 minutes
2023-05-21 16:23:28,466:INFO:SubProcess create_model() called ==================================
2023-05-21 16:23:28,466:INFO:Initializing create_model()
2023-05-21 16:23:28,466:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f5cea5cd6c0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5cd06e0700>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:23:28,467:INFO:Checking exceptions
2023-05-21 16:23:28,467:INFO:Importing libraries
2023-05-21 16:23:28,467:INFO:Copying training dataset
2023-05-21 16:23:28,503:INFO:Defining folds
2023-05-21 16:23:28,503:INFO:Declaring metric variables
2023-05-21 16:23:28,504:INFO:Importing untrained model
2023-05-21 16:23:28,505:INFO:Ridge Classifier Imported successfully
2023-05-21 16:23:28,505:INFO:Starting cross validation
2023-05-21 16:23:28,510:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:23:29,128:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:23:29,130:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:23:29,202:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:23:29,247:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:23:29,278:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:23:29,280:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:23:29,296:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:23:29,357:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:23:29,386:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:23:29,391:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:23:29,872:INFO:Calculating mean and std
2023-05-21 16:23:29,874:INFO:Creating metrics dataframe
2023-05-21 16:23:29,963:INFO:Uploading results into container
2023-05-21 16:23:29,964:INFO:Uploading model into container now
2023-05-21 16:23:29,965:INFO:_master_model_container: 4
2023-05-21 16:23:29,965:INFO:_display_container: 2
2023-05-21 16:23:29,966:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-05-21 16:23:29,966:INFO:create_model() successfully completed......................................
2023-05-21 16:23:30,075:INFO:SubProcess create_model() end ==================================
2023-05-21 16:23:30,075:INFO:Creating metrics dataframe
2023-05-21 16:23:30,089:INFO:Initializing Random Forest Classifier
2023-05-21 16:23:30,089:INFO:Total runtime is 0.25520655314127605 minutes
2023-05-21 16:23:30,089:INFO:SubProcess create_model() called ==================================
2023-05-21 16:23:30,089:INFO:Initializing create_model()
2023-05-21 16:23:30,090:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f5cea5cd6c0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5cd06e0700>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:23:30,090:INFO:Checking exceptions
2023-05-21 16:23:30,090:INFO:Importing libraries
2023-05-21 16:23:30,090:INFO:Copying training dataset
2023-05-21 16:23:30,119:INFO:Defining folds
2023-05-21 16:23:30,120:INFO:Declaring metric variables
2023-05-21 16:23:30,120:INFO:Importing untrained model
2023-05-21 16:23:30,121:INFO:Random Forest Classifier Imported successfully
2023-05-21 16:23:30,122:INFO:Starting cross validation
2023-05-21 16:23:30,126:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:23:33,180:INFO:Calculating mean and std
2023-05-21 16:23:33,182:INFO:Creating metrics dataframe
2023-05-21 16:23:33,286:INFO:Uploading results into container
2023-05-21 16:23:33,288:INFO:Uploading model into container now
2023-05-21 16:23:33,289:INFO:_master_model_container: 5
2023-05-21 16:23:33,289:INFO:_display_container: 2
2023-05-21 16:23:33,291:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-05-21 16:23:33,292:INFO:create_model() successfully completed......................................
2023-05-21 16:23:33,437:INFO:SubProcess create_model() end ==================================
2023-05-21 16:23:33,438:INFO:Creating metrics dataframe
2023-05-21 16:23:33,453:INFO:Initializing Linear Discriminant Analysis
2023-05-21 16:23:33,453:INFO:Total runtime is 0.3112748702367147 minutes
2023-05-21 16:23:33,453:INFO:SubProcess create_model() called ==================================
2023-05-21 16:23:33,454:INFO:Initializing create_model()
2023-05-21 16:23:33,454:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f5cea5cd6c0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5cd06e0700>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:23:33,454:INFO:Checking exceptions
2023-05-21 16:23:33,454:INFO:Importing libraries
2023-05-21 16:23:33,454:INFO:Copying training dataset
2023-05-21 16:23:33,487:INFO:Defining folds
2023-05-21 16:23:33,487:INFO:Declaring metric variables
2023-05-21 16:23:33,487:INFO:Importing untrained model
2023-05-21 16:23:33,488:INFO:Linear Discriminant Analysis Imported successfully
2023-05-21 16:23:33,489:INFO:Starting cross validation
2023-05-21 16:23:33,494:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:23:34,848:INFO:Calculating mean and std
2023-05-21 16:23:34,850:INFO:Creating metrics dataframe
2023-05-21 16:23:34,938:INFO:Uploading results into container
2023-05-21 16:23:34,940:INFO:Uploading model into container now
2023-05-21 16:23:34,940:INFO:_master_model_container: 6
2023-05-21 16:23:34,941:INFO:_display_container: 2
2023-05-21 16:23:34,941:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-21 16:23:34,941:INFO:create_model() successfully completed......................................
2023-05-21 16:23:35,064:INFO:SubProcess create_model() end ==================================
2023-05-21 16:23:35,064:INFO:Creating metrics dataframe
2023-05-21 16:23:35,078:INFO:Initializing Extra Trees Classifier
2023-05-21 16:23:35,078:INFO:Total runtime is 0.338364839553833 minutes
2023-05-21 16:23:35,079:INFO:SubProcess create_model() called ==================================
2023-05-21 16:23:35,079:INFO:Initializing create_model()
2023-05-21 16:23:35,079:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f5cea5cd6c0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5cd06e0700>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:23:35,079:INFO:Checking exceptions
2023-05-21 16:23:35,079:INFO:Importing libraries
2023-05-21 16:23:35,080:INFO:Copying training dataset
2023-05-21 16:23:35,123:INFO:Defining folds
2023-05-21 16:23:35,123:INFO:Declaring metric variables
2023-05-21 16:23:35,123:INFO:Importing untrained model
2023-05-21 16:23:35,124:INFO:Extra Trees Classifier Imported successfully
2023-05-21 16:23:35,125:INFO:Starting cross validation
2023-05-21 16:23:35,129:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:23:38,058:INFO:Calculating mean and std
2023-05-21 16:23:38,060:INFO:Creating metrics dataframe
2023-05-21 16:23:38,119:INFO:Uploading results into container
2023-05-21 16:23:38,121:INFO:Uploading model into container now
2023-05-21 16:23:38,122:INFO:_master_model_container: 7
2023-05-21 16:23:38,122:INFO:_display_container: 2
2023-05-21 16:23:38,123:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-05-21 16:23:38,123:INFO:create_model() successfully completed......................................
2023-05-21 16:23:38,245:INFO:SubProcess create_model() end ==================================
2023-05-21 16:23:38,245:INFO:Creating metrics dataframe
2023-05-21 16:23:38,259:INFO:Initializing Light Gradient Boosting Machine
2023-05-21 16:23:38,259:INFO:Total runtime is 0.39137813647588093 minutes
2023-05-21 16:23:38,259:INFO:SubProcess create_model() called ==================================
2023-05-21 16:23:38,260:INFO:Initializing create_model()
2023-05-21 16:23:38,260:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f5cea5cd6c0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f5cd06e0700>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:23:38,260:INFO:Checking exceptions
2023-05-21 16:23:38,260:INFO:Importing libraries
2023-05-21 16:23:38,260:INFO:Copying training dataset
2023-05-21 16:23:38,291:INFO:Defining folds
2023-05-21 16:23:38,291:INFO:Declaring metric variables
2023-05-21 16:23:38,291:INFO:Importing untrained model
2023-05-21 16:23:38,293:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 16:23:38,293:INFO:Starting cross validation
2023-05-21 16:23:38,298:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:23:40,007:INFO:Calculating mean and std
2023-05-21 16:23:40,008:INFO:Creating metrics dataframe
2023-05-21 16:23:40,090:INFO:Uploading results into container
2023-05-21 16:23:40,093:INFO:Uploading model into container now
2023-05-21 16:23:40,094:INFO:_master_model_container: 8
2023-05-21 16:23:40,094:INFO:_display_container: 2
2023-05-21 16:23:40,097:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 16:23:40,097:INFO:create_model() successfully completed......................................
2023-05-21 16:23:40,236:INFO:SubProcess create_model() end ==================================
2023-05-21 16:23:40,236:INFO:Creating metrics dataframe
2023-05-21 16:23:40,262:INFO:Initializing create_model()
2023-05-21 16:23:40,262:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f5cea5cd6c0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:23:40,263:INFO:Checking exceptions
2023-05-21 16:23:40,266:INFO:Importing libraries
2023-05-21 16:23:40,266:INFO:Copying training dataset
2023-05-21 16:23:40,309:INFO:Defining folds
2023-05-21 16:23:40,310:INFO:Declaring metric variables
2023-05-21 16:23:40,310:INFO:Importing untrained model
2023-05-21 16:23:40,310:INFO:Declaring custom model
2023-05-21 16:23:40,313:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 16:23:40,319:INFO:Cross validation set to False
2023-05-21 16:23:40,319:INFO:Fitting Model
2023-05-21 16:23:40,654:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 16:23:40,655:INFO:create_model() successfully completed......................................
2023-05-21 16:23:40,782:INFO:Creating Dashboard logs
2023-05-21 16:23:40,783:INFO:Model: Light Gradient Boosting Machine
2023-05-21 16:23:41,063:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-21 16:23:42,704:INFO:Initializing predict_model()
2023-05-21 16:23:42,704:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f5cea5cd6c0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7f5cd4ea0a60>)
2023-05-21 16:23:42,704:INFO:Checking exceptions
2023-05-21 16:23:42,705:INFO:Preloading libraries
2023-05-21 16:23:43,406:INFO:SubProcess plot_model() called ==================================
2023-05-21 16:23:43,408:INFO:Initializing plot_model()
2023-05-21 16:23:43,408:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp0f61hm1s, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f5cea5cd6c0>, system=False)
2023-05-21 16:23:43,408:INFO:Checking exceptions
2023-05-21 16:23:43,421:INFO:Preloading libraries
2023-05-21 16:23:43,426:INFO:Copying training dataset
2023-05-21 16:23:43,426:INFO:Plot type: auc
2023-05-21 16:23:44,686:INFO:Fitting Model
2023-05-21 16:23:44,698:INFO:Scoring test/hold-out set
2023-05-21 16:23:45,009:INFO:Saving '/tmp/tmp0f61hm1s/AUC.png'
2023-05-21 16:23:45,896:INFO:Visual Rendered Successfully
2023-05-21 16:23:46,031:INFO:plot_model() successfully completed......................................
2023-05-21 16:23:46,033:INFO:Initializing plot_model()
2023-05-21 16:23:46,034:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp0f61hm1s, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f5cea5cd6c0>, system=False)
2023-05-21 16:23:46,034:INFO:Checking exceptions
2023-05-21 16:23:46,048:INFO:Preloading libraries
2023-05-21 16:23:46,055:INFO:Copying training dataset
2023-05-21 16:23:46,055:INFO:Plot type: confusion_matrix
2023-05-21 16:23:46,850:INFO:Fitting Model
2023-05-21 16:23:46,855:INFO:Scoring test/hold-out set
2023-05-21 16:23:47,108:INFO:Saving '/tmp/tmp0f61hm1s/Confusion Matrix.png'
2023-05-21 16:23:47,396:INFO:Visual Rendered Successfully
2023-05-21 16:23:47,522:INFO:plot_model() successfully completed......................................
2023-05-21 16:23:47,529:INFO:Initializing plot_model()
2023-05-21 16:23:47,529:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp0f61hm1s, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f5cea5cd6c0>, system=False)
2023-05-21 16:23:47,529:INFO:Checking exceptions
2023-05-21 16:23:47,559:INFO:Preloading libraries
2023-05-21 16:23:47,583:INFO:Copying training dataset
2023-05-21 16:23:47,584:INFO:Plot type: feature
2023-05-21 16:23:47,587:WARNING:No coef_ found. Trying feature_importances_
2023-05-21 16:23:47,796:INFO:Saving '/tmp/tmp0f61hm1s/Feature Importance.png'
2023-05-21 16:23:48,198:INFO:Visual Rendered Successfully
2023-05-21 16:23:48,339:INFO:plot_model() successfully completed......................................
2023-05-21 16:23:48,340:INFO:SubProcess plot_model() end ==================================
2023-05-21 16:23:48,383:WARNING:/home/feuer/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-05-21 16:23:49,349:INFO:Creating Dashboard logs
2023-05-21 16:23:49,350:INFO:Model: Random Forest Classifier
2023-05-21 16:23:49,548:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 16:23:51,417:INFO:Creating Dashboard logs
2023-05-21 16:23:51,419:INFO:Model: Extra Trees Classifier
2023-05-21 16:23:51,628:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 16:23:53,295:INFO:Creating Dashboard logs
2023-05-21 16:23:53,296:INFO:Model: Decision Tree Classifier
2023-05-21 16:23:53,425:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2023-05-21 16:23:54,638:INFO:Creating Dashboard logs
2023-05-21 16:23:54,638:INFO:Model: Logistic Regression
2023-05-21 16:23:54,750:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-05-21 16:23:55,937:INFO:Creating Dashboard logs
2023-05-21 16:23:55,937:INFO:Model: Linear Discriminant Analysis
2023-05-21 16:23:56,081:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-05-21 16:23:57,321:INFO:Creating Dashboard logs
2023-05-21 16:23:57,322:INFO:Model: Naive Bayes
2023-05-21 16:23:57,433:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-05-21 16:23:58,943:INFO:Creating Dashboard logs
2023-05-21 16:23:58,944:INFO:Model: Ridge Classifier
2023-05-21 16:23:59,082:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2023-05-21 16:24:01,117:INFO:_master_model_container: 8
2023-05-21 16:24:01,117:INFO:_display_container: 2
2023-05-21 16:24:01,119:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 16:24:01,119:INFO:compare_models() successfully completed......................................
2023-05-21 16:25:21,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:25:21,467:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:25:21,467:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:25:21,468:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:25:23,974:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-21 16:25:30,486:INFO:PyCaret ClassificationExperiment
2023-05-21 16:25:30,486:INFO:Logging name: OnlyImportantFeatures
2023-05-21 16:25:30,486:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-21 16:25:30,486:INFO:version 3.0.0
2023-05-21 16:25:30,486:INFO:Initializing setup()
2023-05-21 16:25:30,486:INFO:self.USI: 0bf5
2023-05-21 16:25:30,487:INFO:self._variable_keys: {'fix_imbalance', 'log_plots_param', 'exp_name_log', 'fold_shuffle_param', 'y', 'exp_id', 'logging_param', 'is_multiclass', 'seed', 'y_test', '_available_plots', '_ml_usecase', 'data', 'idx', 'X_test', 'pipeline', 'X_train', 'n_jobs_param', 'USI', 'target_param', 'gpu_n_jobs_param', 'fold_groups_param', 'y_train', 'gpu_param', 'fold_generator', 'html_param', 'X', 'memory'}
2023-05-21 16:25:30,487:INFO:Checking environment
2023-05-21 16:25:30,487:INFO:python_version: 3.10.10
2023-05-21 16:25:30,487:INFO:python_build: ('main', 'Mar  5 2023 22:26:53')
2023-05-21 16:25:30,487:INFO:machine: x86_64
2023-05-21 16:25:30,489:INFO:platform: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 16:25:30,489:INFO:Memory: svmem(total=16717086720, available=3608952832, percent=78.4, used=10693132288, free=2835660800, active=5321949184, inactive=3849736192, buffers=21049344, cached=3167244288, shared=2071527424, slab=532918272)
2023-05-21 16:25:30,491:INFO:Physical Core: 6
2023-05-21 16:25:30,491:INFO:Logical Core: 12
2023-05-21 16:25:30,491:INFO:Checking libraries
2023-05-21 16:25:30,492:INFO:System:
2023-05-21 16:25:30,492:INFO:    python: 3.10.10 (main, Mar  5 2023, 22:26:53) [GCC 12.2.1 20230201]
2023-05-21 16:25:30,492:INFO:executable: /usr/bin/python3.10
2023-05-21 16:25:30,492:INFO:   machine: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 16:25:30,492:INFO:PyCaret required dependencies:
2023-05-21 16:25:30,492:INFO:                 pip: 23.0.1
2023-05-21 16:25:30,492:INFO:          setuptools: 67.6.1
2023-05-21 16:25:30,492:INFO:             pycaret: 3.0.0
2023-05-21 16:25:30,493:INFO:             IPython: 8.12.0
2023-05-21 16:25:30,493:INFO:          ipywidgets: 7.7.5
2023-05-21 16:25:30,493:INFO:                tqdm: 4.64.1
2023-05-21 16:25:30,493:INFO:               numpy: 1.23.0
2023-05-21 16:25:30,493:INFO:              pandas: 1.5.3
2023-05-21 16:25:30,493:INFO:              jinja2: 3.1.2
2023-05-21 16:25:30,493:INFO:               scipy: 1.9.3
2023-05-21 16:25:30,493:INFO:              joblib: 1.2.0
2023-05-21 16:25:30,493:INFO:             sklearn: 1.2.2
2023-05-21 16:25:30,493:INFO:                pyod: 1.0.9
2023-05-21 16:25:30,493:INFO:            imblearn: 0.10.1
2023-05-21 16:25:30,494:INFO:   category_encoders: 2.6.0
2023-05-21 16:25:30,494:INFO:            lightgbm: 3.3.5
2023-05-21 16:25:30,494:INFO:               numba: 0.57.0
2023-05-21 16:25:30,494:INFO:            requests: 2.28.2
2023-05-21 16:25:30,494:INFO:          matplotlib: 3.6.3
2023-05-21 16:25:30,494:INFO:          scikitplot: 0.3.7
2023-05-21 16:25:30,494:INFO:         yellowbrick: 1.5
2023-05-21 16:25:30,494:INFO:              plotly: 5.14.1
2023-05-21 16:25:30,494:INFO:             kaleido: 0.2.1
2023-05-21 16:25:30,494:INFO:         statsmodels: 0.13.5
2023-05-21 16:25:30,494:INFO:              sktime: 0.18.0
2023-05-21 16:25:30,495:INFO:               tbats: 1.1.3
2023-05-21 16:25:30,495:INFO:            pmdarima: 2.0.3
2023-05-21 16:25:30,495:INFO:              psutil: 5.9.4
2023-05-21 16:25:30,495:INFO:PyCaret optional dependencies:
2023-05-21 16:25:30,527:INFO:                shap: 0.41.0
2023-05-21 16:25:30,527:INFO:           interpret: 0.3.2
2023-05-21 16:25:30,527:INFO:                umap: 0.5.3
2023-05-21 16:25:30,527:INFO:    pandas_profiling: 3.6.6
2023-05-21 16:25:30,527:INFO:  explainerdashboard: 0.4.2.2
2023-05-21 16:25:30,527:INFO:             autoviz: 0.1.603
2023-05-21 16:25:30,527:INFO:           fairlearn: 0.7.0
2023-05-21 16:25:30,527:INFO:             xgboost: 1.7.5
2023-05-21 16:25:30,527:INFO:            catboost: Not installed
2023-05-21 16:25:30,528:INFO:              kmodes: Not installed
2023-05-21 16:25:30,528:INFO:             mlxtend: Not installed
2023-05-21 16:25:30,528:INFO:       statsforecast: Not installed
2023-05-21 16:25:30,528:INFO:        tune_sklearn: Not installed
2023-05-21 16:25:30,528:INFO:                 ray: Not installed
2023-05-21 16:25:30,528:INFO:            hyperopt: Not installed
2023-05-21 16:25:30,528:INFO:              optuna: 3.1.1
2023-05-21 16:25:30,528:INFO:               skopt: Not installed
2023-05-21 16:25:30,528:INFO:              mlflow: 2.3.1
2023-05-21 16:25:30,528:INFO:              gradio: Not installed
2023-05-21 16:25:30,529:INFO:             fastapi: Not installed
2023-05-21 16:25:30,529:INFO:             uvicorn: Not installed
2023-05-21 16:25:30,529:INFO:              m2cgen: Not installed
2023-05-21 16:25:30,529:INFO:           evidently: Not installed
2023-05-21 16:25:30,529:INFO:               fugue: Not installed
2023-05-21 16:25:30,529:INFO:           streamlit: Not installed
2023-05-21 16:25:30,529:INFO:             prophet: Not installed
2023-05-21 16:25:30,529:INFO:None
2023-05-21 16:25:30,529:INFO:Set up data.
2023-05-21 16:25:30,670:INFO:Set up train/test split.
2023-05-21 16:25:30,736:INFO:Set up index.
2023-05-21 16:25:30,737:INFO:Set up folding strategy.
2023-05-21 16:25:30,737:INFO:Assigning column types.
2023-05-21 16:25:30,749:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-21 16:25:30,801:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 16:25:30,820:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:25:30,902:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:25:30,993:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:25:31,048:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 16:25:31,049:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:25:31,086:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:25:31,089:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:25:31,090:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-21 16:25:31,142:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:25:31,174:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:25:31,178:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:25:31,230:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:25:31,264:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:25:31,267:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:25:31,267:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-21 16:25:31,351:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:25:31,354:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:25:31,438:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:25:31,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:25:31,444:INFO:Preparing preprocessing pipeline...
2023-05-21 16:25:31,448:INFO:Set up simple imputation.
2023-05-21 16:25:31,468:INFO:Set up encoding of categorical features.
2023-05-21 16:25:31,766:INFO:Finished creating preprocessing pipeline.
2023-05-21 16:25:31,799:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 16:25:31,799:INFO:Creating final display dataframe.
2023-05-21 16:25:32,174:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     42
1                        Target      app_complete_flag
2                   Target type                 Binary
3           Original data shape            (238964, 7)
4        Transformed data shape           (238964, 39)
5   Transformed train set shape           (167274, 39)
6    Transformed test set shape            (71690, 39)
7              Numeric features                      3
8          Categorical features                      3
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13     Maximum one-hot encoding                     25
14              Encoding method                   None
15               Fold Generator        StratifiedKFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                  False
19               Log Experiment           MlflowLogger
20              Experiment Name  OnlyImportantFeatures
21                          USI                   0bf5
2023-05-21 16:25:32,273:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:25:32,276:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:25:32,360:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:25:32,363:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:25:32,365:INFO:Logging experiment in loggers
2023-05-21 16:25:33,044:INFO:SubProcess save_model() called ==================================
2023-05-21 16:25:33,127:INFO:Initializing save_model()
2023-05-21 16:25:33,127:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/tmp/tmpt2jympkx/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-21 16:25:33,127:INFO:Adding model into prep_pipe
2023-05-21 16:25:33,131:WARNING:Only Model saved as it was a pipeline.
2023-05-21 16:25:33,153:INFO:/tmp/tmpt2jympkx/Transformation Pipeline.pkl saved in current working directory
2023-05-21 16:25:33,177:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 16:25:33,177:INFO:save_model() successfully completed......................................
2023-05-21 16:25:33,327:INFO:SubProcess save_model() end ==================================
2023-05-21 16:25:33,925:INFO:setup() successfully completed in 1.93s...............
2023-05-21 16:25:33,926:INFO:Initializing compare_models()
2023-05-21 16:25:33,926:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f714f4d16c0>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f714f4d16c0>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'])
2023-05-21 16:25:33,926:INFO:Checking exceptions
2023-05-21 16:25:33,942:INFO:Preparing display monitor
2023-05-21 16:25:33,949:INFO:Initializing Logistic Regression
2023-05-21 16:25:33,949:INFO:Total runtime is 3.854433695475261e-06 minutes
2023-05-21 16:25:33,949:INFO:SubProcess create_model() called ==================================
2023-05-21 16:25:33,949:INFO:Initializing create_model()
2023-05-21 16:25:33,950:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f714f4d16c0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f71381a06a0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:25:33,950:INFO:Checking exceptions
2023-05-21 16:25:33,950:INFO:Importing libraries
2023-05-21 16:25:33,950:INFO:Copying training dataset
2023-05-21 16:25:33,980:INFO:Defining folds
2023-05-21 16:25:33,980:INFO:Declaring metric variables
2023-05-21 16:25:33,980:INFO:Importing untrained model
2023-05-21 16:25:33,981:INFO:Logistic Regression Imported successfully
2023-05-21 16:25:33,982:INFO:Starting cross validation
2023-05-21 16:25:33,986:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:25:42,790:INFO:Calculating mean and std
2023-05-21 16:25:42,793:INFO:Creating metrics dataframe
2023-05-21 16:25:42,859:INFO:Uploading results into container
2023-05-21 16:25:42,861:INFO:Uploading model into container now
2023-05-21 16:25:42,862:INFO:_master_model_container: 1
2023-05-21 16:25:42,862:INFO:_display_container: 2
2023-05-21 16:25:42,864:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-21 16:25:42,864:INFO:create_model() successfully completed......................................
2023-05-21 16:25:43,010:INFO:SubProcess create_model() end ==================================
2023-05-21 16:25:43,010:INFO:Creating metrics dataframe
2023-05-21 16:25:43,024:INFO:Initializing Naive Bayes
2023-05-21 16:25:43,024:INFO:Total runtime is 0.151264750957489 minutes
2023-05-21 16:25:43,025:INFO:SubProcess create_model() called ==================================
2023-05-21 16:25:43,025:INFO:Initializing create_model()
2023-05-21 16:25:43,025:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f714f4d16c0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f71381a06a0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:25:43,026:INFO:Checking exceptions
2023-05-21 16:25:43,026:INFO:Importing libraries
2023-05-21 16:25:43,026:INFO:Copying training dataset
2023-05-21 16:25:43,075:INFO:Defining folds
2023-05-21 16:25:43,075:INFO:Declaring metric variables
2023-05-21 16:25:43,076:INFO:Importing untrained model
2023-05-21 16:25:43,077:INFO:Naive Bayes Imported successfully
2023-05-21 16:25:43,077:INFO:Starting cross validation
2023-05-21 16:25:43,082:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:25:47,207:INFO:Calculating mean and std
2023-05-21 16:25:47,209:INFO:Creating metrics dataframe
2023-05-21 16:25:47,306:INFO:Uploading results into container
2023-05-21 16:25:47,308:INFO:Uploading model into container now
2023-05-21 16:25:47,308:INFO:_master_model_container: 2
2023-05-21 16:25:47,309:INFO:_display_container: 2
2023-05-21 16:25:47,309:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-21 16:25:47,309:INFO:create_model() successfully completed......................................
2023-05-21 16:25:47,440:INFO:SubProcess create_model() end ==================================
2023-05-21 16:25:47,440:INFO:Creating metrics dataframe
2023-05-21 16:25:47,455:INFO:Initializing Decision Tree Classifier
2023-05-21 16:25:47,455:INFO:Total runtime is 0.2251105785369873 minutes
2023-05-21 16:25:47,456:INFO:SubProcess create_model() called ==================================
2023-05-21 16:25:47,456:INFO:Initializing create_model()
2023-05-21 16:25:47,456:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f714f4d16c0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f71381a06a0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:25:47,456:INFO:Checking exceptions
2023-05-21 16:25:47,456:INFO:Importing libraries
2023-05-21 16:25:47,456:INFO:Copying training dataset
2023-05-21 16:25:47,495:INFO:Defining folds
2023-05-21 16:25:47,495:INFO:Declaring metric variables
2023-05-21 16:25:47,496:INFO:Importing untrained model
2023-05-21 16:25:47,497:INFO:Decision Tree Classifier Imported successfully
2023-05-21 16:25:47,497:INFO:Starting cross validation
2023-05-21 16:25:47,502:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:25:48,966:INFO:Calculating mean and std
2023-05-21 16:25:48,968:INFO:Creating metrics dataframe
2023-05-21 16:25:49,059:INFO:Uploading results into container
2023-05-21 16:25:49,060:INFO:Uploading model into container now
2023-05-21 16:25:49,061:INFO:_master_model_container: 3
2023-05-21 16:25:49,061:INFO:_display_container: 2
2023-05-21 16:25:49,062:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-05-21 16:25:49,062:INFO:create_model() successfully completed......................................
2023-05-21 16:25:49,186:INFO:SubProcess create_model() end ==================================
2023-05-21 16:25:49,186:INFO:Creating metrics dataframe
2023-05-21 16:25:49,201:INFO:Initializing Ridge Classifier
2023-05-21 16:25:49,201:INFO:Total runtime is 0.2542060136795044 minutes
2023-05-21 16:25:49,201:INFO:SubProcess create_model() called ==================================
2023-05-21 16:25:49,202:INFO:Initializing create_model()
2023-05-21 16:25:49,202:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f714f4d16c0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f71381a06a0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:25:49,202:INFO:Checking exceptions
2023-05-21 16:25:49,202:INFO:Importing libraries
2023-05-21 16:25:49,202:INFO:Copying training dataset
2023-05-21 16:25:49,236:INFO:Defining folds
2023-05-21 16:25:49,236:INFO:Declaring metric variables
2023-05-21 16:25:49,237:INFO:Importing untrained model
2023-05-21 16:25:49,238:INFO:Ridge Classifier Imported successfully
2023-05-21 16:25:49,239:INFO:Starting cross validation
2023-05-21 16:25:49,244:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:25:49,861:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:25:49,965:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:25:49,971:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:25:50,052:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:25:50,103:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:25:50,116:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:25:50,116:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:25:50,119:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:25:50,134:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:25:50,157:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:25:50,626:INFO:Calculating mean and std
2023-05-21 16:25:50,629:INFO:Creating metrics dataframe
2023-05-21 16:25:50,718:INFO:Uploading results into container
2023-05-21 16:25:50,720:INFO:Uploading model into container now
2023-05-21 16:25:50,721:INFO:_master_model_container: 4
2023-05-21 16:25:50,721:INFO:_display_container: 2
2023-05-21 16:25:50,722:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-05-21 16:25:50,722:INFO:create_model() successfully completed......................................
2023-05-21 16:25:50,839:INFO:SubProcess create_model() end ==================================
2023-05-21 16:25:50,839:INFO:Creating metrics dataframe
2023-05-21 16:25:50,853:INFO:Initializing Random Forest Classifier
2023-05-21 16:25:50,853:INFO:Total runtime is 0.2817382216453552 minutes
2023-05-21 16:25:50,853:INFO:SubProcess create_model() called ==================================
2023-05-21 16:25:50,854:INFO:Initializing create_model()
2023-05-21 16:25:50,854:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f714f4d16c0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f71381a06a0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:25:50,854:INFO:Checking exceptions
2023-05-21 16:25:50,854:INFO:Importing libraries
2023-05-21 16:25:50,854:INFO:Copying training dataset
2023-05-21 16:25:50,889:INFO:Defining folds
2023-05-21 16:25:50,889:INFO:Declaring metric variables
2023-05-21 16:25:50,890:INFO:Importing untrained model
2023-05-21 16:25:50,891:INFO:Random Forest Classifier Imported successfully
2023-05-21 16:25:50,892:INFO:Starting cross validation
2023-05-21 16:25:50,896:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:25:54,084:INFO:Calculating mean and std
2023-05-21 16:25:54,086:INFO:Creating metrics dataframe
2023-05-21 16:25:54,177:INFO:Uploading results into container
2023-05-21 16:25:54,179:INFO:Uploading model into container now
2023-05-21 16:25:54,179:INFO:_master_model_container: 5
2023-05-21 16:25:54,180:INFO:_display_container: 2
2023-05-21 16:25:54,181:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-05-21 16:25:54,182:INFO:create_model() successfully completed......................................
2023-05-21 16:25:54,306:INFO:SubProcess create_model() end ==================================
2023-05-21 16:25:54,306:INFO:Creating metrics dataframe
2023-05-21 16:25:54,321:INFO:Initializing Linear Discriminant Analysis
2023-05-21 16:25:54,321:INFO:Total runtime is 0.33953819672266644 minutes
2023-05-21 16:25:54,321:INFO:SubProcess create_model() called ==================================
2023-05-21 16:25:54,322:INFO:Initializing create_model()
2023-05-21 16:25:54,322:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f714f4d16c0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f71381a06a0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:25:54,322:INFO:Checking exceptions
2023-05-21 16:25:54,322:INFO:Importing libraries
2023-05-21 16:25:54,322:INFO:Copying training dataset
2023-05-21 16:25:54,357:INFO:Defining folds
2023-05-21 16:25:54,357:INFO:Declaring metric variables
2023-05-21 16:25:54,358:INFO:Importing untrained model
2023-05-21 16:25:54,359:INFO:Linear Discriminant Analysis Imported successfully
2023-05-21 16:25:54,360:INFO:Starting cross validation
2023-05-21 16:25:54,365:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:25:55,714:INFO:Calculating mean and std
2023-05-21 16:25:55,716:INFO:Creating metrics dataframe
2023-05-21 16:25:55,806:INFO:Uploading results into container
2023-05-21 16:25:55,808:INFO:Uploading model into container now
2023-05-21 16:25:55,809:INFO:_master_model_container: 6
2023-05-21 16:25:55,809:INFO:_display_container: 2
2023-05-21 16:25:55,810:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-21 16:25:55,810:INFO:create_model() successfully completed......................................
2023-05-21 16:25:55,921:INFO:SubProcess create_model() end ==================================
2023-05-21 16:25:55,921:INFO:Creating metrics dataframe
2023-05-21 16:25:55,934:INFO:Initializing Extra Trees Classifier
2023-05-21 16:25:55,935:INFO:Total runtime is 0.36643501122792566 minutes
2023-05-21 16:25:55,935:INFO:SubProcess create_model() called ==================================
2023-05-21 16:25:55,935:INFO:Initializing create_model()
2023-05-21 16:25:55,935:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f714f4d16c0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f71381a06a0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:25:55,936:INFO:Checking exceptions
2023-05-21 16:25:55,936:INFO:Importing libraries
2023-05-21 16:25:55,936:INFO:Copying training dataset
2023-05-21 16:25:55,966:INFO:Defining folds
2023-05-21 16:25:55,966:INFO:Declaring metric variables
2023-05-21 16:25:55,967:INFO:Importing untrained model
2023-05-21 16:25:55,968:INFO:Extra Trees Classifier Imported successfully
2023-05-21 16:25:55,969:INFO:Starting cross validation
2023-05-21 16:25:55,973:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:25:58,810:INFO:Calculating mean and std
2023-05-21 16:25:58,812:INFO:Creating metrics dataframe
2023-05-21 16:25:58,899:INFO:Uploading results into container
2023-05-21 16:25:58,900:INFO:Uploading model into container now
2023-05-21 16:25:58,901:INFO:_master_model_container: 7
2023-05-21 16:25:58,901:INFO:_display_container: 2
2023-05-21 16:25:58,902:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-05-21 16:25:58,903:INFO:create_model() successfully completed......................................
2023-05-21 16:25:59,012:INFO:SubProcess create_model() end ==================================
2023-05-21 16:25:59,012:INFO:Creating metrics dataframe
2023-05-21 16:25:59,026:INFO:Initializing Light Gradient Boosting Machine
2023-05-21 16:25:59,026:INFO:Total runtime is 0.4179644703865052 minutes
2023-05-21 16:25:59,027:INFO:SubProcess create_model() called ==================================
2023-05-21 16:25:59,027:INFO:Initializing create_model()
2023-05-21 16:25:59,027:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f714f4d16c0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f71381a06a0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:25:59,027:INFO:Checking exceptions
2023-05-21 16:25:59,027:INFO:Importing libraries
2023-05-21 16:25:59,028:INFO:Copying training dataset
2023-05-21 16:25:59,063:INFO:Defining folds
2023-05-21 16:25:59,064:INFO:Declaring metric variables
2023-05-21 16:25:59,064:INFO:Importing untrained model
2023-05-21 16:25:59,066:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 16:25:59,066:INFO:Starting cross validation
2023-05-21 16:25:59,071:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:26:00,710:INFO:Calculating mean and std
2023-05-21 16:26:00,712:INFO:Creating metrics dataframe
2023-05-21 16:26:00,781:INFO:Uploading results into container
2023-05-21 16:26:00,782:INFO:Uploading model into container now
2023-05-21 16:26:00,783:INFO:_master_model_container: 8
2023-05-21 16:26:00,783:INFO:_display_container: 2
2023-05-21 16:26:00,786:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 16:26:00,786:INFO:create_model() successfully completed......................................
2023-05-21 16:26:00,912:INFO:SubProcess create_model() end ==================================
2023-05-21 16:26:00,912:INFO:Creating metrics dataframe
2023-05-21 16:26:00,934:INFO:Initializing create_model()
2023-05-21 16:26:00,935:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f714f4d16c0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:26:00,935:INFO:Checking exceptions
2023-05-21 16:26:00,937:INFO:Importing libraries
2023-05-21 16:26:00,937:INFO:Copying training dataset
2023-05-21 16:26:00,972:INFO:Defining folds
2023-05-21 16:26:00,972:INFO:Declaring metric variables
2023-05-21 16:26:00,972:INFO:Importing untrained model
2023-05-21 16:26:00,973:INFO:Declaring custom model
2023-05-21 16:26:00,976:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 16:26:00,980:INFO:Cross validation set to False
2023-05-21 16:26:00,980:INFO:Fitting Model
2023-05-21 16:26:01,333:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 16:26:01,334:INFO:create_model() successfully completed......................................
2023-05-21 16:26:01,463:INFO:Creating Dashboard logs
2023-05-21 16:26:01,464:INFO:Model: Light Gradient Boosting Machine
2023-05-21 16:26:01,727:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-21 16:26:02,640:INFO:Initializing predict_model()
2023-05-21 16:26:02,640:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f714f4d16c0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7f7139460940>)
2023-05-21 16:26:02,640:INFO:Checking exceptions
2023-05-21 16:26:02,640:INFO:Preloading libraries
2023-05-21 16:26:03,338:INFO:SubProcess plot_model() called ==================================
2023-05-21 16:26:03,339:INFO:Initializing plot_model()
2023-05-21 16:26:03,340:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpmzqqgffl, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f714f4d16c0>, system=False)
2023-05-21 16:26:03,340:INFO:Checking exceptions
2023-05-21 16:26:03,350:INFO:Preloading libraries
2023-05-21 16:26:03,357:INFO:Copying training dataset
2023-05-21 16:26:03,357:INFO:Plot type: auc
2023-05-21 16:26:04,344:INFO:Fitting Model
2023-05-21 16:26:04,354:INFO:Scoring test/hold-out set
2023-05-21 16:26:04,686:INFO:Saving '/tmp/tmpmzqqgffl/AUC.png'
2023-05-21 16:26:05,662:INFO:Visual Rendered Successfully
2023-05-21 16:26:05,802:INFO:plot_model() successfully completed......................................
2023-05-21 16:26:05,805:INFO:Initializing plot_model()
2023-05-21 16:26:05,805:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpmzqqgffl, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f714f4d16c0>, system=False)
2023-05-21 16:26:05,806:INFO:Checking exceptions
2023-05-21 16:26:05,820:INFO:Preloading libraries
2023-05-21 16:26:05,827:INFO:Copying training dataset
2023-05-21 16:26:05,827:INFO:Plot type: confusion_matrix
2023-05-21 16:26:06,469:INFO:Fitting Model
2023-05-21 16:26:06,489:INFO:Scoring test/hold-out set
2023-05-21 16:26:06,818:INFO:Saving '/tmp/tmpmzqqgffl/Confusion Matrix.png'
2023-05-21 16:26:07,142:INFO:Visual Rendered Successfully
2023-05-21 16:26:07,266:INFO:plot_model() successfully completed......................................
2023-05-21 16:26:07,268:INFO:Initializing plot_model()
2023-05-21 16:26:07,268:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpmzqqgffl, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f714f4d16c0>, system=False)
2023-05-21 16:26:07,269:INFO:Checking exceptions
2023-05-21 16:26:07,281:INFO:Preloading libraries
2023-05-21 16:26:07,286:INFO:Copying training dataset
2023-05-21 16:26:07,286:INFO:Plot type: feature
2023-05-21 16:26:07,288:WARNING:No coef_ found. Trying feature_importances_
2023-05-21 16:26:07,506:INFO:Saving '/tmp/tmpmzqqgffl/Feature Importance.png'
2023-05-21 16:26:07,863:INFO:Visual Rendered Successfully
2023-05-21 16:26:07,990:INFO:plot_model() successfully completed......................................
2023-05-21 16:26:07,991:INFO:SubProcess plot_model() end ==================================
2023-05-21 16:26:08,003:WARNING:/home/feuer/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-05-21 16:26:08,477:INFO:Creating Dashboard logs
2023-05-21 16:26:08,478:INFO:Model: Random Forest Classifier
2023-05-21 16:26:08,643:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 16:26:09,998:INFO:Creating Dashboard logs
2023-05-21 16:26:09,999:INFO:Model: Extra Trees Classifier
2023-05-21 16:26:10,193:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 16:26:11,549:INFO:Creating Dashboard logs
2023-05-21 16:26:11,550:INFO:Model: Decision Tree Classifier
2023-05-21 16:26:11,686:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2023-05-21 16:26:12,760:INFO:Creating Dashboard logs
2023-05-21 16:26:12,761:INFO:Model: Logistic Regression
2023-05-21 16:26:12,908:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-05-21 16:26:13,969:INFO:Creating Dashboard logs
2023-05-21 16:26:13,970:INFO:Model: Linear Discriminant Analysis
2023-05-21 16:26:14,108:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-05-21 16:26:15,207:INFO:Creating Dashboard logs
2023-05-21 16:26:15,208:INFO:Model: Naive Bayes
2023-05-21 16:26:15,341:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-05-21 16:26:16,652:INFO:Creating Dashboard logs
2023-05-21 16:26:16,653:INFO:Model: Ridge Classifier
2023-05-21 16:26:16,766:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2023-05-21 16:26:18,107:INFO:_master_model_container: 8
2023-05-21 16:26:18,107:INFO:_display_container: 2
2023-05-21 16:26:18,110:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 16:26:18,110:INFO:compare_models() successfully completed......................................
2023-05-21 16:26:55,091:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:26:55,091:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:26:55,091:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:26:55,091:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:26:58,235:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-21 16:27:15,728:INFO:PyCaret ClassificationExperiment
2023-05-21 16:27:15,728:INFO:Logging name: OnlyImportantFeatures
2023-05-21 16:27:15,728:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-21 16:27:15,729:INFO:version 3.0.0
2023-05-21 16:27:15,729:INFO:Initializing setup()
2023-05-21 16:27:15,729:INFO:self.USI: 64f1
2023-05-21 16:27:15,729:INFO:self._variable_keys: {'html_param', 'target_param', 'X_test', '_ml_usecase', 'exp_name_log', 'exp_id', 'seed', 'gpu_param', 'pipeline', 'gpu_n_jobs_param', 'y_test', '_available_plots', 'is_multiclass', 'memory', 'y_train', 'logging_param', 'n_jobs_param', 'y', 'idx', 'X_train', 'fold_generator', 'X', 'fold_groups_param', 'log_plots_param', 'fix_imbalance', 'USI', 'data', 'fold_shuffle_param'}
2023-05-21 16:27:15,729:INFO:Checking environment
2023-05-21 16:27:15,729:INFO:python_version: 3.10.10
2023-05-21 16:27:15,729:INFO:python_build: ('main', 'Mar  5 2023 22:26:53')
2023-05-21 16:27:15,729:INFO:machine: x86_64
2023-05-21 16:27:15,731:INFO:platform: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 16:27:15,732:INFO:Memory: svmem(total=16717086720, available=3651108864, percent=78.2, used=10664132608, free=2898251776, active=6231814144, inactive=2833567744, buffers=20312064, cached=3134390272, shared=2058407936, slab=532430848)
2023-05-21 16:27:15,734:INFO:Physical Core: 6
2023-05-21 16:27:15,734:INFO:Logical Core: 12
2023-05-21 16:27:15,734:INFO:Checking libraries
2023-05-21 16:27:15,734:INFO:System:
2023-05-21 16:27:15,734:INFO:    python: 3.10.10 (main, Mar  5 2023, 22:26:53) [GCC 12.2.1 20230201]
2023-05-21 16:27:15,734:INFO:executable: /usr/bin/python3.10
2023-05-21 16:27:15,734:INFO:   machine: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 16:27:15,735:INFO:PyCaret required dependencies:
2023-05-21 16:27:15,735:INFO:                 pip: 23.0.1
2023-05-21 16:27:15,735:INFO:          setuptools: 67.6.1
2023-05-21 16:27:15,735:INFO:             pycaret: 3.0.0
2023-05-21 16:27:15,735:INFO:             IPython: 8.12.0
2023-05-21 16:27:15,735:INFO:          ipywidgets: 7.7.5
2023-05-21 16:27:15,735:INFO:                tqdm: 4.64.1
2023-05-21 16:27:15,735:INFO:               numpy: 1.23.0
2023-05-21 16:27:15,736:INFO:              pandas: 1.5.3
2023-05-21 16:27:15,736:INFO:              jinja2: 3.1.2
2023-05-21 16:27:15,736:INFO:               scipy: 1.9.3
2023-05-21 16:27:15,736:INFO:              joblib: 1.2.0
2023-05-21 16:27:15,736:INFO:             sklearn: 1.2.2
2023-05-21 16:27:15,736:INFO:                pyod: 1.0.9
2023-05-21 16:27:15,736:INFO:            imblearn: 0.10.1
2023-05-21 16:27:15,736:INFO:   category_encoders: 2.6.0
2023-05-21 16:27:15,736:INFO:            lightgbm: 3.3.5
2023-05-21 16:27:15,736:INFO:               numba: 0.57.0
2023-05-21 16:27:15,736:INFO:            requests: 2.28.2
2023-05-21 16:27:15,737:INFO:          matplotlib: 3.6.3
2023-05-21 16:27:15,737:INFO:          scikitplot: 0.3.7
2023-05-21 16:27:15,737:INFO:         yellowbrick: 1.5
2023-05-21 16:27:15,737:INFO:              plotly: 5.14.1
2023-05-21 16:27:15,737:INFO:             kaleido: 0.2.1
2023-05-21 16:27:15,737:INFO:         statsmodels: 0.13.5
2023-05-21 16:27:15,737:INFO:              sktime: 0.18.0
2023-05-21 16:27:15,737:INFO:               tbats: 1.1.3
2023-05-21 16:27:15,737:INFO:            pmdarima: 2.0.3
2023-05-21 16:27:15,737:INFO:              psutil: 5.9.4
2023-05-21 16:27:15,737:INFO:PyCaret optional dependencies:
2023-05-21 16:27:15,772:INFO:                shap: 0.41.0
2023-05-21 16:27:15,772:INFO:           interpret: 0.3.2
2023-05-21 16:27:15,772:INFO:                umap: 0.5.3
2023-05-21 16:27:15,772:INFO:    pandas_profiling: 3.6.6
2023-05-21 16:27:15,772:INFO:  explainerdashboard: 0.4.2.2
2023-05-21 16:27:15,772:INFO:             autoviz: 0.1.603
2023-05-21 16:27:15,773:INFO:           fairlearn: 0.7.0
2023-05-21 16:27:15,773:INFO:             xgboost: 1.7.5
2023-05-21 16:27:15,773:INFO:            catboost: Not installed
2023-05-21 16:27:15,773:INFO:              kmodes: Not installed
2023-05-21 16:27:15,773:INFO:             mlxtend: Not installed
2023-05-21 16:27:15,773:INFO:       statsforecast: Not installed
2023-05-21 16:27:15,773:INFO:        tune_sklearn: Not installed
2023-05-21 16:27:15,773:INFO:                 ray: Not installed
2023-05-21 16:27:15,773:INFO:            hyperopt: Not installed
2023-05-21 16:27:15,773:INFO:              optuna: 3.1.1
2023-05-21 16:27:15,773:INFO:               skopt: Not installed
2023-05-21 16:27:15,774:INFO:              mlflow: 2.3.1
2023-05-21 16:27:15,774:INFO:              gradio: Not installed
2023-05-21 16:27:15,774:INFO:             fastapi: Not installed
2023-05-21 16:27:15,774:INFO:             uvicorn: Not installed
2023-05-21 16:27:15,774:INFO:              m2cgen: Not installed
2023-05-21 16:27:15,774:INFO:           evidently: Not installed
2023-05-21 16:27:15,774:INFO:               fugue: Not installed
2023-05-21 16:27:15,774:INFO:           streamlit: Not installed
2023-05-21 16:27:15,774:INFO:             prophet: Not installed
2023-05-21 16:27:15,774:INFO:None
2023-05-21 16:27:15,775:INFO:Set up data.
2023-05-21 16:27:15,922:INFO:Set up train/test split.
2023-05-21 16:27:15,985:INFO:Set up index.
2023-05-21 16:27:15,986:INFO:Set up folding strategy.
2023-05-21 16:27:15,986:INFO:Assigning column types.
2023-05-21 16:27:15,997:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-21 16:27:16,047:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 16:27:16,070:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:27:16,152:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:27:16,252:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:27:16,302:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 16:27:16,304:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:27:16,339:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:27:16,343:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:27:16,343:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-21 16:27:16,395:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:27:16,426:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:27:16,429:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:27:16,489:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:27:16,525:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:27:16,528:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:27:16,529:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-21 16:27:16,617:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:27:16,620:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:27:16,704:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:27:16,707:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:27:16,710:INFO:Preparing preprocessing pipeline...
2023-05-21 16:27:16,714:INFO:Set up simple imputation.
2023-05-21 16:27:16,731:INFO:Set up encoding of categorical features.
2023-05-21 16:27:17,000:INFO:Finished creating preprocessing pipeline.
2023-05-21 16:27:17,036:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 16:27:17,037:INFO:Creating final display dataframe.
2023-05-21 16:27:17,592:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     42
1                        Target      app_complete_flag
2                   Target type                 Binary
3           Original data shape            (238964, 7)
4        Transformed data shape           (238964, 39)
5   Transformed train set shape           (167274, 39)
6    Transformed test set shape            (71690, 39)
7              Numeric features                      3
8          Categorical features                      3
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13     Maximum one-hot encoding                     25
14              Encoding method                   None
15               Fold Generator        StratifiedKFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                  False
19               Log Experiment           MlflowLogger
20              Experiment Name  OnlyImportantFeatures
21                          USI                   64f1
2023-05-21 16:27:17,698:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:27:17,702:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:27:17,793:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:27:17,796:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:27:17,798:INFO:Logging experiment in loggers
2023-05-21 16:27:18,411:INFO:SubProcess save_model() called ==================================
2023-05-21 16:27:18,492:INFO:Initializing save_model()
2023-05-21 16:27:18,492:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/tmp/tmpulbvvovx/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-21 16:27:18,492:INFO:Adding model into prep_pipe
2023-05-21 16:27:18,496:WARNING:Only Model saved as it was a pipeline.
2023-05-21 16:27:18,519:INFO:/tmp/tmpulbvvovx/Transformation Pipeline.pkl saved in current working directory
2023-05-21 16:27:18,547:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 16:27:18,548:INFO:save_model() successfully completed......................................
2023-05-21 16:27:18,712:INFO:SubProcess save_model() end ==================================
2023-05-21 16:27:19,350:INFO:setup() successfully completed in 2.15s...............
2023-05-21 16:27:19,350:INFO:Initializing compare_models()
2023-05-21 16:27:19,350:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f68b0d3d6c0>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f68b0d3d6c0>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'])
2023-05-21 16:27:19,350:INFO:Checking exceptions
2023-05-21 16:27:19,366:INFO:Preparing display monitor
2023-05-21 16:27:19,373:INFO:Initializing Logistic Regression
2023-05-21 16:27:19,374:INFO:Total runtime is 3.7789344787597655e-06 minutes
2023-05-21 16:27:19,374:INFO:SubProcess create_model() called ==================================
2023-05-21 16:27:19,374:INFO:Initializing create_model()
2023-05-21 16:27:19,374:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f68b0d3d6c0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f68997a8a90>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:27:19,375:INFO:Checking exceptions
2023-05-21 16:27:19,375:INFO:Importing libraries
2023-05-21 16:27:19,375:INFO:Copying training dataset
2023-05-21 16:27:19,404:INFO:Defining folds
2023-05-21 16:27:19,404:INFO:Declaring metric variables
2023-05-21 16:27:19,404:INFO:Importing untrained model
2023-05-21 16:27:19,405:INFO:Logistic Regression Imported successfully
2023-05-21 16:27:19,406:INFO:Starting cross validation
2023-05-21 16:27:19,410:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:27:27,344:INFO:Calculating mean and std
2023-05-21 16:27:27,346:INFO:Creating metrics dataframe
2023-05-21 16:27:27,434:INFO:Uploading results into container
2023-05-21 16:27:27,435:INFO:Uploading model into container now
2023-05-21 16:27:27,436:INFO:_master_model_container: 1
2023-05-21 16:27:27,436:INFO:_display_container: 2
2023-05-21 16:27:27,438:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-21 16:27:27,438:INFO:create_model() successfully completed......................................
2023-05-21 16:27:27,556:INFO:SubProcess create_model() end ==================================
2023-05-21 16:27:27,557:INFO:Creating metrics dataframe
2023-05-21 16:27:27,569:INFO:Initializing Naive Bayes
2023-05-21 16:27:27,569:INFO:Total runtime is 0.13658901850382488 minutes
2023-05-21 16:27:27,569:INFO:SubProcess create_model() called ==================================
2023-05-21 16:27:27,570:INFO:Initializing create_model()
2023-05-21 16:27:27,570:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f68b0d3d6c0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f68997a8a90>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:27:27,570:INFO:Checking exceptions
2023-05-21 16:27:27,570:INFO:Importing libraries
2023-05-21 16:27:27,570:INFO:Copying training dataset
2023-05-21 16:27:27,600:INFO:Defining folds
2023-05-21 16:27:27,600:INFO:Declaring metric variables
2023-05-21 16:27:27,600:INFO:Importing untrained model
2023-05-21 16:27:27,601:INFO:Naive Bayes Imported successfully
2023-05-21 16:27:27,602:INFO:Starting cross validation
2023-05-21 16:27:27,606:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:27:31,863:INFO:Calculating mean and std
2023-05-21 16:27:31,865:INFO:Creating metrics dataframe
2023-05-21 16:27:31,956:INFO:Uploading results into container
2023-05-21 16:27:31,959:INFO:Uploading model into container now
2023-05-21 16:27:31,961:INFO:_master_model_container: 2
2023-05-21 16:27:31,961:INFO:_display_container: 2
2023-05-21 16:27:31,962:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-21 16:27:31,962:INFO:create_model() successfully completed......................................
2023-05-21 16:27:32,095:INFO:SubProcess create_model() end ==================================
2023-05-21 16:27:32,095:INFO:Creating metrics dataframe
2023-05-21 16:27:32,109:INFO:Initializing Decision Tree Classifier
2023-05-21 16:27:32,109:INFO:Total runtime is 0.21226386626561483 minutes
2023-05-21 16:27:32,110:INFO:SubProcess create_model() called ==================================
2023-05-21 16:27:32,110:INFO:Initializing create_model()
2023-05-21 16:27:32,110:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f68b0d3d6c0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f68997a8a90>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:27:32,110:INFO:Checking exceptions
2023-05-21 16:27:32,110:INFO:Importing libraries
2023-05-21 16:27:32,110:INFO:Copying training dataset
2023-05-21 16:27:32,142:INFO:Defining folds
2023-05-21 16:27:32,142:INFO:Declaring metric variables
2023-05-21 16:27:32,143:INFO:Importing untrained model
2023-05-21 16:27:32,144:INFO:Decision Tree Classifier Imported successfully
2023-05-21 16:27:32,144:INFO:Starting cross validation
2023-05-21 16:27:32,149:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:27:33,492:INFO:Calculating mean and std
2023-05-21 16:27:33,494:INFO:Creating metrics dataframe
2023-05-21 16:27:33,583:INFO:Uploading results into container
2023-05-21 16:27:33,584:INFO:Uploading model into container now
2023-05-21 16:27:33,585:INFO:_master_model_container: 3
2023-05-21 16:27:33,585:INFO:_display_container: 2
2023-05-21 16:27:33,586:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-05-21 16:27:33,587:INFO:create_model() successfully completed......................................
2023-05-21 16:27:33,709:INFO:SubProcess create_model() end ==================================
2023-05-21 16:27:33,709:INFO:Creating metrics dataframe
2023-05-21 16:27:33,722:INFO:Initializing Ridge Classifier
2023-05-21 16:27:33,722:INFO:Total runtime is 0.23914976517359415 minutes
2023-05-21 16:27:33,723:INFO:SubProcess create_model() called ==================================
2023-05-21 16:27:33,723:INFO:Initializing create_model()
2023-05-21 16:27:33,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f68b0d3d6c0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f68997a8a90>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:27:33,723:INFO:Checking exceptions
2023-05-21 16:27:33,723:INFO:Importing libraries
2023-05-21 16:27:33,724:INFO:Copying training dataset
2023-05-21 16:27:33,755:INFO:Defining folds
2023-05-21 16:27:33,755:INFO:Declaring metric variables
2023-05-21 16:27:33,755:INFO:Importing untrained model
2023-05-21 16:27:33,756:INFO:Ridge Classifier Imported successfully
2023-05-21 16:27:33,757:INFO:Starting cross validation
2023-05-21 16:27:33,761:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:27:34,253:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:27:34,372:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:27:34,377:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:27:34,393:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:27:34,410:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:27:34,432:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:27:34,445:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:27:34,461:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:27:34,491:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:27:34,509:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:27:34,886:INFO:Calculating mean and std
2023-05-21 16:27:34,887:INFO:Creating metrics dataframe
2023-05-21 16:27:34,958:INFO:Uploading results into container
2023-05-21 16:27:34,960:INFO:Uploading model into container now
2023-05-21 16:27:34,961:INFO:_master_model_container: 4
2023-05-21 16:27:34,961:INFO:_display_container: 2
2023-05-21 16:27:34,963:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-05-21 16:27:34,963:INFO:create_model() successfully completed......................................
2023-05-21 16:27:35,083:INFO:SubProcess create_model() end ==================================
2023-05-21 16:27:35,083:INFO:Creating metrics dataframe
2023-05-21 16:27:35,096:INFO:Initializing Random Forest Classifier
2023-05-21 16:27:35,097:INFO:Total runtime is 0.26205244461695354 minutes
2023-05-21 16:27:35,097:INFO:SubProcess create_model() called ==================================
2023-05-21 16:27:35,097:INFO:Initializing create_model()
2023-05-21 16:27:35,097:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f68b0d3d6c0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f68997a8a90>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:27:35,098:INFO:Checking exceptions
2023-05-21 16:27:35,098:INFO:Importing libraries
2023-05-21 16:27:35,098:INFO:Copying training dataset
2023-05-21 16:27:35,127:INFO:Defining folds
2023-05-21 16:27:35,127:INFO:Declaring metric variables
2023-05-21 16:27:35,128:INFO:Importing untrained model
2023-05-21 16:27:35,129:INFO:Random Forest Classifier Imported successfully
2023-05-21 16:27:35,130:INFO:Starting cross validation
2023-05-21 16:27:35,134:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:27:37,913:INFO:Calculating mean and std
2023-05-21 16:27:37,916:INFO:Creating metrics dataframe
2023-05-21 16:27:38,000:INFO:Uploading results into container
2023-05-21 16:27:38,001:INFO:Uploading model into container now
2023-05-21 16:27:38,002:INFO:_master_model_container: 5
2023-05-21 16:27:38,002:INFO:_display_container: 2
2023-05-21 16:27:38,003:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-05-21 16:27:38,004:INFO:create_model() successfully completed......................................
2023-05-21 16:27:38,121:INFO:SubProcess create_model() end ==================================
2023-05-21 16:27:38,121:INFO:Creating metrics dataframe
2023-05-21 16:27:38,136:INFO:Initializing Linear Discriminant Analysis
2023-05-21 16:27:38,136:INFO:Total runtime is 0.3127052346865336 minutes
2023-05-21 16:27:38,136:INFO:SubProcess create_model() called ==================================
2023-05-21 16:27:38,137:INFO:Initializing create_model()
2023-05-21 16:27:38,137:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f68b0d3d6c0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f68997a8a90>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:27:38,137:INFO:Checking exceptions
2023-05-21 16:27:38,137:INFO:Importing libraries
2023-05-21 16:27:38,137:INFO:Copying training dataset
2023-05-21 16:27:38,175:INFO:Defining folds
2023-05-21 16:27:38,175:INFO:Declaring metric variables
2023-05-21 16:27:38,175:INFO:Importing untrained model
2023-05-21 16:27:38,176:INFO:Linear Discriminant Analysis Imported successfully
2023-05-21 16:27:38,177:INFO:Starting cross validation
2023-05-21 16:27:38,182:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:27:39,500:INFO:Calculating mean and std
2023-05-21 16:27:39,502:INFO:Creating metrics dataframe
2023-05-21 16:27:39,595:INFO:Uploading results into container
2023-05-21 16:27:39,597:INFO:Uploading model into container now
2023-05-21 16:27:39,598:INFO:_master_model_container: 6
2023-05-21 16:27:39,598:INFO:_display_container: 2
2023-05-21 16:27:39,599:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-21 16:27:39,599:INFO:create_model() successfully completed......................................
2023-05-21 16:27:39,717:INFO:SubProcess create_model() end ==================================
2023-05-21 16:27:39,717:INFO:Creating metrics dataframe
2023-05-21 16:27:39,731:INFO:Initializing Extra Trees Classifier
2023-05-21 16:27:39,731:INFO:Total runtime is 0.3392911314964294 minutes
2023-05-21 16:27:39,731:INFO:SubProcess create_model() called ==================================
2023-05-21 16:27:39,732:INFO:Initializing create_model()
2023-05-21 16:27:39,732:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f68b0d3d6c0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f68997a8a90>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:27:39,732:INFO:Checking exceptions
2023-05-21 16:27:39,732:INFO:Importing libraries
2023-05-21 16:27:39,732:INFO:Copying training dataset
2023-05-21 16:27:39,761:INFO:Defining folds
2023-05-21 16:27:39,761:INFO:Declaring metric variables
2023-05-21 16:27:39,762:INFO:Importing untrained model
2023-05-21 16:27:39,763:INFO:Extra Trees Classifier Imported successfully
2023-05-21 16:27:39,764:INFO:Starting cross validation
2023-05-21 16:27:39,768:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:27:43,055:INFO:Calculating mean and std
2023-05-21 16:27:43,057:INFO:Creating metrics dataframe
2023-05-21 16:27:43,144:INFO:Uploading results into container
2023-05-21 16:27:43,145:INFO:Uploading model into container now
2023-05-21 16:27:43,146:INFO:_master_model_container: 7
2023-05-21 16:27:43,146:INFO:_display_container: 2
2023-05-21 16:27:43,148:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-05-21 16:27:43,148:INFO:create_model() successfully completed......................................
2023-05-21 16:27:43,257:INFO:SubProcess create_model() end ==================================
2023-05-21 16:27:43,258:INFO:Creating metrics dataframe
2023-05-21 16:27:43,272:INFO:Initializing Light Gradient Boosting Machine
2023-05-21 16:27:43,272:INFO:Total runtime is 0.3983147342999776 minutes
2023-05-21 16:27:43,273:INFO:SubProcess create_model() called ==================================
2023-05-21 16:27:43,273:INFO:Initializing create_model()
2023-05-21 16:27:43,273:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f68b0d3d6c0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f68997a8a90>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:27:43,273:INFO:Checking exceptions
2023-05-21 16:27:43,273:INFO:Importing libraries
2023-05-21 16:27:43,274:INFO:Copying training dataset
2023-05-21 16:27:43,311:INFO:Defining folds
2023-05-21 16:27:43,311:INFO:Declaring metric variables
2023-05-21 16:27:43,311:INFO:Importing untrained model
2023-05-21 16:27:43,313:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 16:27:43,314:INFO:Starting cross validation
2023-05-21 16:27:43,319:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:27:44,894:INFO:Calculating mean and std
2023-05-21 16:27:44,896:INFO:Creating metrics dataframe
2023-05-21 16:27:44,984:INFO:Uploading results into container
2023-05-21 16:27:44,986:INFO:Uploading model into container now
2023-05-21 16:27:44,986:INFO:_master_model_container: 8
2023-05-21 16:27:44,987:INFO:_display_container: 2
2023-05-21 16:27:44,988:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 16:27:44,988:INFO:create_model() successfully completed......................................
2023-05-21 16:27:45,100:INFO:SubProcess create_model() end ==================================
2023-05-21 16:27:45,101:INFO:Creating metrics dataframe
2023-05-21 16:27:45,120:INFO:Initializing create_model()
2023-05-21 16:27:45,120:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f68b0d3d6c0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:27:45,120:INFO:Checking exceptions
2023-05-21 16:27:45,122:INFO:Importing libraries
2023-05-21 16:27:45,122:INFO:Copying training dataset
2023-05-21 16:27:45,150:INFO:Defining folds
2023-05-21 16:27:45,151:INFO:Declaring metric variables
2023-05-21 16:27:45,151:INFO:Importing untrained model
2023-05-21 16:27:45,151:INFO:Declaring custom model
2023-05-21 16:27:45,154:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 16:27:45,158:INFO:Cross validation set to False
2023-05-21 16:27:45,158:INFO:Fitting Model
2023-05-21 16:27:45,493:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 16:27:45,493:INFO:create_model() successfully completed......................................
2023-05-21 16:27:45,605:INFO:Creating Dashboard logs
2023-05-21 16:27:45,606:INFO:Model: Light Gradient Boosting Machine
2023-05-21 16:27:45,802:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-21 16:27:46,667:INFO:Initializing predict_model()
2023-05-21 16:27:46,668:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f68b0d3d6c0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7f689b588940>)
2023-05-21 16:27:46,668:INFO:Checking exceptions
2023-05-21 16:27:46,668:INFO:Preloading libraries
2023-05-21 16:27:47,302:INFO:SubProcess plot_model() called ==================================
2023-05-21 16:27:47,304:INFO:Initializing plot_model()
2023-05-21 16:27:47,304:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpn5unjkn0, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f68b0d3d6c0>, system=False)
2023-05-21 16:27:47,304:INFO:Checking exceptions
2023-05-21 16:27:47,315:INFO:Preloading libraries
2023-05-21 16:27:47,319:INFO:Copying training dataset
2023-05-21 16:27:47,320:INFO:Plot type: auc
2023-05-21 16:27:48,494:INFO:Fitting Model
2023-05-21 16:27:48,500:INFO:Scoring test/hold-out set
2023-05-21 16:27:48,851:INFO:Saving '/tmp/tmpn5unjkn0/AUC.png'
2023-05-21 16:27:49,629:INFO:Visual Rendered Successfully
2023-05-21 16:27:49,754:INFO:plot_model() successfully completed......................................
2023-05-21 16:27:49,758:INFO:Initializing plot_model()
2023-05-21 16:27:49,758:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpn5unjkn0, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f68b0d3d6c0>, system=False)
2023-05-21 16:27:49,758:INFO:Checking exceptions
2023-05-21 16:27:49,772:INFO:Preloading libraries
2023-05-21 16:27:49,779:INFO:Copying training dataset
2023-05-21 16:27:49,779:INFO:Plot type: confusion_matrix
2023-05-21 16:27:50,463:INFO:Fitting Model
2023-05-21 16:27:50,467:INFO:Scoring test/hold-out set
2023-05-21 16:27:50,750:INFO:Saving '/tmp/tmpn5unjkn0/Confusion Matrix.png'
2023-05-21 16:27:51,078:INFO:Visual Rendered Successfully
2023-05-21 16:27:51,239:INFO:plot_model() successfully completed......................................
2023-05-21 16:27:51,243:INFO:Initializing plot_model()
2023-05-21 16:27:51,244:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpn5unjkn0, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f68b0d3d6c0>, system=False)
2023-05-21 16:27:51,245:INFO:Checking exceptions
2023-05-21 16:27:51,272:INFO:Preloading libraries
2023-05-21 16:27:51,294:INFO:Copying training dataset
2023-05-21 16:27:51,294:INFO:Plot type: feature
2023-05-21 16:27:51,296:WARNING:No coef_ found. Trying feature_importances_
2023-05-21 16:27:51,612:INFO:Saving '/tmp/tmpn5unjkn0/Feature Importance.png'
2023-05-21 16:27:51,991:INFO:Visual Rendered Successfully
2023-05-21 16:27:52,118:INFO:plot_model() successfully completed......................................
2023-05-21 16:27:52,119:INFO:SubProcess plot_model() end ==================================
2023-05-21 16:27:52,138:WARNING:/home/feuer/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-05-21 16:27:53,211:INFO:Creating Dashboard logs
2023-05-21 16:27:53,212:INFO:Model: Random Forest Classifier
2023-05-21 16:27:53,385:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 16:27:55,581:INFO:Creating Dashboard logs
2023-05-21 16:27:55,582:INFO:Model: Extra Trees Classifier
2023-05-21 16:27:55,826:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 16:27:57,247:INFO:Creating Dashboard logs
2023-05-21 16:27:57,248:INFO:Model: Decision Tree Classifier
2023-05-21 16:27:57,409:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2023-05-21 16:27:58,773:INFO:Creating Dashboard logs
2023-05-21 16:27:58,774:INFO:Model: Logistic Regression
2023-05-21 16:27:58,902:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-05-21 16:28:00,367:INFO:Creating Dashboard logs
2023-05-21 16:28:00,368:INFO:Model: Linear Discriminant Analysis
2023-05-21 16:28:00,519:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-05-21 16:28:01,850:INFO:Creating Dashboard logs
2023-05-21 16:28:01,851:INFO:Model: Naive Bayes
2023-05-21 16:28:02,015:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-05-21 16:28:03,438:INFO:Creating Dashboard logs
2023-05-21 16:28:03,439:INFO:Model: Ridge Classifier
2023-05-21 16:28:03,568:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2023-05-21 16:28:05,036:INFO:_master_model_container: 8
2023-05-21 16:28:05,036:INFO:_display_container: 2
2023-05-21 16:28:05,037:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 16:28:05,038:INFO:compare_models() successfully completed......................................
2023-05-21 16:39:09,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:39:09,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:39:09,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:39:09,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:39:19,765:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:39:19,766:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:39:19,766:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:39:19,766:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 16:39:21,731:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-21 16:39:30,236:INFO:PyCaret ClassificationExperiment
2023-05-21 16:39:30,236:INFO:Logging name: Lead_Scoring_Training_Pipeline
2023-05-21 16:39:30,237:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-21 16:39:30,237:INFO:version 3.0.0
2023-05-21 16:39:30,237:INFO:Initializing setup()
2023-05-21 16:39:30,237:INFO:self.USI: a57f
2023-05-21 16:39:30,237:INFO:self._variable_keys: {'html_param', 'fix_imbalance', 'n_jobs_param', 'exp_id', 'pipeline', 'fold_groups_param', 'seed', 'logging_param', 'log_plots_param', 'USI', 'gpu_param', 'X', 'y', 'X_train', 'gpu_n_jobs_param', '_available_plots', 'exp_name_log', 'is_multiclass', 'idx', 'y_train', 'data', 'y_test', '_ml_usecase', 'fold_shuffle_param', 'X_test', 'target_param', 'fold_generator', 'memory'}
2023-05-21 16:39:30,237:INFO:Checking environment
2023-05-21 16:39:30,237:INFO:python_version: 3.10.10
2023-05-21 16:39:30,237:INFO:python_build: ('main', 'Mar  5 2023 22:26:53')
2023-05-21 16:39:30,237:INFO:machine: x86_64
2023-05-21 16:39:30,239:INFO:platform: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 16:39:30,240:INFO:Memory: svmem(total=16717086720, available=4417556480, percent=73.6, used=10639265792, free=3578802176, active=6589861888, inactive=1662361600, buffers=30498816, cached=2468519936, shared=1316786176, slab=539103232)
2023-05-21 16:39:30,243:INFO:Physical Core: 6
2023-05-21 16:39:30,244:INFO:Logical Core: 12
2023-05-21 16:39:30,244:INFO:Checking libraries
2023-05-21 16:39:30,244:INFO:System:
2023-05-21 16:39:30,244:INFO:    python: 3.10.10 (main, Mar  5 2023, 22:26:53) [GCC 12.2.1 20230201]
2023-05-21 16:39:30,244:INFO:executable: /usr/bin/python3.10
2023-05-21 16:39:30,244:INFO:   machine: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 16:39:30,245:INFO:PyCaret required dependencies:
2023-05-21 16:39:30,245:INFO:                 pip: 23.0.1
2023-05-21 16:39:30,245:INFO:          setuptools: 67.6.1
2023-05-21 16:39:30,245:INFO:             pycaret: 3.0.0
2023-05-21 16:39:30,245:INFO:             IPython: 8.12.0
2023-05-21 16:39:30,246:INFO:          ipywidgets: 7.7.5
2023-05-21 16:39:30,246:INFO:                tqdm: 4.64.1
2023-05-21 16:39:30,246:INFO:               numpy: 1.23.0
2023-05-21 16:39:30,246:INFO:              pandas: 1.5.3
2023-05-21 16:39:30,246:INFO:              jinja2: 3.1.2
2023-05-21 16:39:30,246:INFO:               scipy: 1.9.3
2023-05-21 16:39:30,247:INFO:              joblib: 1.2.0
2023-05-21 16:39:30,247:INFO:             sklearn: 1.2.2
2023-05-21 16:39:30,247:INFO:                pyod: 1.0.9
2023-05-21 16:39:30,247:INFO:            imblearn: 0.10.1
2023-05-21 16:39:30,247:INFO:   category_encoders: 2.6.0
2023-05-21 16:39:30,247:INFO:            lightgbm: 3.3.5
2023-05-21 16:39:30,247:INFO:               numba: 0.57.0
2023-05-21 16:39:30,248:INFO:            requests: 2.28.2
2023-05-21 16:39:30,248:INFO:          matplotlib: 3.6.3
2023-05-21 16:39:30,248:INFO:          scikitplot: 0.3.7
2023-05-21 16:39:30,248:INFO:         yellowbrick: 1.5
2023-05-21 16:39:30,248:INFO:              plotly: 5.14.1
2023-05-21 16:39:30,248:INFO:             kaleido: 0.2.1
2023-05-21 16:39:30,248:INFO:         statsmodels: 0.13.5
2023-05-21 16:39:30,249:INFO:              sktime: 0.18.0
2023-05-21 16:39:30,249:INFO:               tbats: 1.1.3
2023-05-21 16:39:30,249:INFO:            pmdarima: 2.0.3
2023-05-21 16:39:30,249:INFO:              psutil: 5.9.4
2023-05-21 16:39:30,249:INFO:PyCaret optional dependencies:
2023-05-21 16:39:30,287:INFO:                shap: 0.41.0
2023-05-21 16:39:30,288:INFO:           interpret: 0.3.2
2023-05-21 16:39:30,288:INFO:                umap: 0.5.3
2023-05-21 16:39:30,288:INFO:    pandas_profiling: 3.6.6
2023-05-21 16:39:30,288:INFO:  explainerdashboard: 0.4.2.2
2023-05-21 16:39:30,288:INFO:             autoviz: 0.1.603
2023-05-21 16:39:30,288:INFO:           fairlearn: 0.7.0
2023-05-21 16:39:30,288:INFO:             xgboost: 1.7.5
2023-05-21 16:39:30,289:INFO:            catboost: Not installed
2023-05-21 16:39:30,289:INFO:              kmodes: Not installed
2023-05-21 16:39:30,289:INFO:             mlxtend: Not installed
2023-05-21 16:39:30,289:INFO:       statsforecast: Not installed
2023-05-21 16:39:30,289:INFO:        tune_sklearn: Not installed
2023-05-21 16:39:30,289:INFO:                 ray: Not installed
2023-05-21 16:39:30,289:INFO:            hyperopt: Not installed
2023-05-21 16:39:30,289:INFO:              optuna: 3.1.1
2023-05-21 16:39:30,290:INFO:               skopt: Not installed
2023-05-21 16:39:30,290:INFO:              mlflow: 2.3.1
2023-05-21 16:39:30,290:INFO:              gradio: Not installed
2023-05-21 16:39:30,290:INFO:             fastapi: Not installed
2023-05-21 16:39:30,290:INFO:             uvicorn: Not installed
2023-05-21 16:39:30,290:INFO:              m2cgen: Not installed
2023-05-21 16:39:30,290:INFO:           evidently: Not installed
2023-05-21 16:39:30,290:INFO:               fugue: Not installed
2023-05-21 16:39:30,290:INFO:           streamlit: Not installed
2023-05-21 16:39:30,291:INFO:             prophet: Not installed
2023-05-21 16:39:30,291:INFO:None
2023-05-21 16:39:30,291:INFO:Set up data.
2023-05-21 16:39:30,500:INFO:Set up train/test split.
2023-05-21 16:39:30,500:INFO:Set up data.
2023-05-21 16:39:30,556:INFO:Set up index.
2023-05-21 16:39:30,556:INFO:Set up folding strategy.
2023-05-21 16:39:30,556:INFO:Assigning column types.
2023-05-21 16:39:30,569:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-21 16:39:30,619:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 16:39:30,636:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:39:30,718:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:39:30,817:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:39:30,869:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 16:39:30,870:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:39:30,901:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:39:30,905:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:39:30,905:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-21 16:39:30,957:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:39:30,993:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:39:30,997:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:39:31,049:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 16:39:31,081:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:39:31,084:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:39:31,085:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-21 16:39:31,173:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:39:31,176:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:39:31,265:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:39:31,268:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:39:31,271:INFO:Preparing preprocessing pipeline...
2023-05-21 16:39:31,275:INFO:Set up simple imputation.
2023-05-21 16:39:31,295:INFO:Set up encoding of categorical features.
2023-05-21 16:39:32,188:INFO:Finished creating preprocessing pipeline.
2023-05-21 16:39:32,215:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 16:39:32,215:INFO:Creating final display dataframe.
2023-05-21 16:39:33,528:INFO:Setup _display_container:                     Description                           Value
0                    Session id                              42
1                        Target               app_complete_flag
2                   Target type                          Binary
3           Original data shape                     (238964, 7)
4        Transformed data shape                    (238964, 39)
5   Transformed train set shape                    (191171, 39)
6    Transformed test set shape                     (47793, 39)
7              Numeric features                               3
8          Categorical features                               3
9                    Preprocess                            True
10              Imputation type                          simple
11           Numeric imputation                            mean
12       Categorical imputation                            mode
13     Maximum one-hot encoding                              25
14              Encoding method                            None
15               Fold Generator                 StratifiedKFold
16                  Fold Number                              10
17                     CPU Jobs                              -1
18                      Use GPU                           False
19               Log Experiment                    MlflowLogger
20              Experiment Name  Lead_Scoring_Training_Pipeline
21                          USI                            a57f
2023-05-21 16:39:33,626:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:39:33,629:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:39:33,719:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 16:39:33,722:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 16:39:33,723:INFO:Logging experiment in loggers
2023-05-21 16:39:34,837:INFO:SubProcess save_model() called ==================================
2023-05-21 16:39:34,921:INFO:Initializing save_model()
2023-05-21 16:39:34,921:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/tmp/tmpytysnuiu/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-21 16:39:34,921:INFO:Adding model into prep_pipe
2023-05-21 16:39:34,925:WARNING:Only Model saved as it was a pipeline.
2023-05-21 16:39:34,946:INFO:/tmp/tmpytysnuiu/Transformation Pipeline.pkl saved in current working directory
2023-05-21 16:39:34,970:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 16:39:34,970:INFO:save_model() successfully completed......................................
2023-05-21 16:39:35,120:INFO:SubProcess save_model() end ==================================
2023-05-21 16:39:35,718:INFO:setup() successfully completed in 3.53s...............
2023-05-21 16:39:35,718:INFO:Initializing compare_models()
2023-05-21 16:39:35,718:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f30125d16c0>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f30125d16c0>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'])
2023-05-21 16:39:35,718:INFO:Checking exceptions
2023-05-21 16:39:35,735:INFO:Preparing display monitor
2023-05-21 16:39:35,742:INFO:Initializing Logistic Regression
2023-05-21 16:39:35,742:INFO:Total runtime is 3.0517578125e-06 minutes
2023-05-21 16:39:35,743:INFO:SubProcess create_model() called ==================================
2023-05-21 16:39:35,743:INFO:Initializing create_model()
2023-05-21 16:39:35,743:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f30125d16c0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2ff859fd00>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:39:35,743:INFO:Checking exceptions
2023-05-21 16:39:35,743:INFO:Importing libraries
2023-05-21 16:39:35,743:INFO:Copying training dataset
2023-05-21 16:39:35,775:INFO:Defining folds
2023-05-21 16:39:35,775:INFO:Declaring metric variables
2023-05-21 16:39:35,775:INFO:Importing untrained model
2023-05-21 16:39:35,777:INFO:Logistic Regression Imported successfully
2023-05-21 16:39:35,777:INFO:Starting cross validation
2023-05-21 16:39:35,782:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:39:57,589:INFO:Calculating mean and std
2023-05-21 16:39:57,591:INFO:Creating metrics dataframe
2023-05-21 16:39:57,609:INFO:Uploading results into container
2023-05-21 16:39:57,610:INFO:Uploading model into container now
2023-05-21 16:39:57,611:INFO:_master_model_container: 1
2023-05-21 16:39:57,612:INFO:_display_container: 2
2023-05-21 16:39:57,613:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-21 16:39:57,613:INFO:create_model() successfully completed......................................
2023-05-21 16:39:57,791:INFO:SubProcess create_model() end ==================================
2023-05-21 16:39:57,791:INFO:Creating metrics dataframe
2023-05-21 16:39:57,804:INFO:Initializing Naive Bayes
2023-05-21 16:39:57,804:INFO:Total runtime is 0.36770093043645224 minutes
2023-05-21 16:39:57,805:INFO:SubProcess create_model() called ==================================
2023-05-21 16:39:57,805:INFO:Initializing create_model()
2023-05-21 16:39:57,805:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f30125d16c0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2ff859fd00>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:39:57,805:INFO:Checking exceptions
2023-05-21 16:39:57,805:INFO:Importing libraries
2023-05-21 16:39:57,805:INFO:Copying training dataset
2023-05-21 16:39:57,841:INFO:Defining folds
2023-05-21 16:39:57,841:INFO:Declaring metric variables
2023-05-21 16:39:57,841:INFO:Importing untrained model
2023-05-21 16:39:57,842:INFO:Naive Bayes Imported successfully
2023-05-21 16:39:57,843:INFO:Starting cross validation
2023-05-21 16:39:57,847:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:40:09,419:INFO:Calculating mean and std
2023-05-21 16:40:09,446:INFO:Creating metrics dataframe
2023-05-21 16:40:09,556:INFO:Uploading results into container
2023-05-21 16:40:09,557:INFO:Uploading model into container now
2023-05-21 16:40:09,558:INFO:_master_model_container: 2
2023-05-21 16:40:09,558:INFO:_display_container: 2
2023-05-21 16:40:09,558:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-21 16:40:09,559:INFO:create_model() successfully completed......................................
2023-05-21 16:40:09,675:INFO:SubProcess create_model() end ==================================
2023-05-21 16:40:09,676:INFO:Creating metrics dataframe
2023-05-21 16:40:09,689:INFO:Initializing Decision Tree Classifier
2023-05-21 16:40:09,690:INFO:Total runtime is 0.5657917380332946 minutes
2023-05-21 16:40:09,690:INFO:SubProcess create_model() called ==================================
2023-05-21 16:40:09,690:INFO:Initializing create_model()
2023-05-21 16:40:09,690:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f30125d16c0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2ff859fd00>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:40:09,691:INFO:Checking exceptions
2023-05-21 16:40:09,691:INFO:Importing libraries
2023-05-21 16:40:09,691:INFO:Copying training dataset
2023-05-21 16:40:09,731:INFO:Defining folds
2023-05-21 16:40:09,732:INFO:Declaring metric variables
2023-05-21 16:40:09,732:INFO:Importing untrained model
2023-05-21 16:40:09,733:INFO:Decision Tree Classifier Imported successfully
2023-05-21 16:40:09,734:INFO:Starting cross validation
2023-05-21 16:40:09,739:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:40:13,717:INFO:Calculating mean and std
2023-05-21 16:40:13,719:INFO:Creating metrics dataframe
2023-05-21 16:40:13,801:INFO:Uploading results into container
2023-05-21 16:40:13,802:INFO:Uploading model into container now
2023-05-21 16:40:13,803:INFO:_master_model_container: 3
2023-05-21 16:40:13,803:INFO:_display_container: 2
2023-05-21 16:40:13,805:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-05-21 16:40:13,805:INFO:create_model() successfully completed......................................
2023-05-21 16:40:13,939:INFO:SubProcess create_model() end ==================================
2023-05-21 16:40:13,939:INFO:Creating metrics dataframe
2023-05-21 16:40:13,955:INFO:Initializing Ridge Classifier
2023-05-21 16:40:13,955:INFO:Total runtime is 0.6368904908498128 minutes
2023-05-21 16:40:13,956:INFO:SubProcess create_model() called ==================================
2023-05-21 16:40:13,956:INFO:Initializing create_model()
2023-05-21 16:40:13,957:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f30125d16c0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2ff859fd00>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:40:13,957:INFO:Checking exceptions
2023-05-21 16:40:13,957:INFO:Importing libraries
2023-05-21 16:40:13,957:INFO:Copying training dataset
2023-05-21 16:40:13,999:INFO:Defining folds
2023-05-21 16:40:13,999:INFO:Declaring metric variables
2023-05-21 16:40:13,999:INFO:Importing untrained model
2023-05-21 16:40:14,001:INFO:Ridge Classifier Imported successfully
2023-05-21 16:40:14,001:INFO:Starting cross validation
2023-05-21 16:40:14,006:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:40:43,107:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:40:43,107:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 3.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:40:43,107:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:40:43,108:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:40:43,126:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:40:43,127:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 3.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:40:43,127:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:40:43,127:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:40:43,131:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:40:43,132:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:40:44,872:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:40:44,872:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:40:44,872:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:40:44,872:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:40:44,872:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:40:44,873:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:40:44,874:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:40:45,113:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:40:45,124:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:40:45,144:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 16:40:46,656:INFO:Calculating mean and std
2023-05-21 16:40:46,675:INFO:Creating metrics dataframe
2023-05-21 16:40:46,874:INFO:Uploading results into container
2023-05-21 16:40:46,875:INFO:Uploading model into container now
2023-05-21 16:40:46,876:INFO:_master_model_container: 4
2023-05-21 16:40:46,876:INFO:_display_container: 2
2023-05-21 16:40:46,877:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-05-21 16:40:46,877:INFO:create_model() successfully completed......................................
2023-05-21 16:40:55,225:INFO:SubProcess create_model() end ==================================
2023-05-21 16:40:55,225:INFO:Creating metrics dataframe
2023-05-21 16:40:55,240:INFO:Initializing Random Forest Classifier
2023-05-21 16:40:55,240:INFO:Total runtime is 1.324963895479838 minutes
2023-05-21 16:40:55,240:INFO:SubProcess create_model() called ==================================
2023-05-21 16:40:55,241:INFO:Initializing create_model()
2023-05-21 16:40:55,241:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f30125d16c0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2ff859fd00>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:40:55,241:INFO:Checking exceptions
2023-05-21 16:40:55,241:INFO:Importing libraries
2023-05-21 16:40:55,279:INFO:Copying training dataset
2023-05-21 16:40:55,358:INFO:Defining folds
2023-05-21 16:40:55,358:INFO:Declaring metric variables
2023-05-21 16:40:55,359:INFO:Importing untrained model
2023-05-21 16:40:55,361:INFO:Random Forest Classifier Imported successfully
2023-05-21 16:40:55,362:INFO:Starting cross validation
2023-05-21 16:40:55,367:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:41:36,902:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 4.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:41:40,912:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 3.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:41:42,424:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-05-21 16:41:43,950:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 16:41:45,142:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 2.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 16:41:58,457:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:42:00,124:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:42:04,847:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 20.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:42:05,311:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 16:42:05,450:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 16:42:06,782:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:42:07,110:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:42:13,938:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:42:21,600:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 3.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:42:24,237:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 16:42:24,449:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 3.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:42:26,263:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 16:42:29,353:INFO:Calculating mean and std
2023-05-21 16:42:29,370:INFO:Creating metrics dataframe
2023-05-21 16:42:29,919:INFO:Uploading results into container
2023-05-21 16:42:29,921:INFO:Uploading model into container now
2023-05-21 16:42:29,923:INFO:_master_model_container: 5
2023-05-21 16:42:29,923:INFO:_display_container: 2
2023-05-21 16:42:30,011:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-05-21 16:42:30,011:INFO:create_model() successfully completed......................................
2023-05-21 16:42:31,406:INFO:SubProcess create_model() end ==================================
2023-05-21 16:42:31,406:INFO:Creating metrics dataframe
2023-05-21 16:42:31,439:INFO:Initializing Linear Discriminant Analysis
2023-05-21 16:42:31,439:INFO:Total runtime is 2.928282602628072 minutes
2023-05-21 16:42:31,439:INFO:SubProcess create_model() called ==================================
2023-05-21 16:42:31,440:INFO:Initializing create_model()
2023-05-21 16:42:31,440:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f30125d16c0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2ff859fd00>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:42:31,440:INFO:Checking exceptions
2023-05-21 16:42:31,440:INFO:Importing libraries
2023-05-21 16:42:31,440:INFO:Copying training dataset
2023-05-21 16:42:31,474:INFO:Defining folds
2023-05-21 16:42:31,474:INFO:Declaring metric variables
2023-05-21 16:42:31,474:INFO:Importing untrained model
2023-05-21 16:42:31,475:INFO:Linear Discriminant Analysis Imported successfully
2023-05-21 16:42:31,476:INFO:Starting cross validation
2023-05-21 16:42:31,480:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:50:04,761:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 7.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:50:04,794:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 7.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:50:04,795:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 7.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:50:04,974:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 7.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:50:05,007:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 7.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:50:05,023:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 7.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:50:05,027:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 7.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:50:05,039:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 7.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:50:47,934:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:55:06,542:INFO:Calculating mean and std
2023-05-21 16:55:06,543:INFO:Creating metrics dataframe
2023-05-21 16:55:06,650:INFO:Uploading results into container
2023-05-21 16:55:06,652:INFO:Uploading model into container now
2023-05-21 16:55:06,652:INFO:_master_model_container: 6
2023-05-21 16:55:06,653:INFO:_display_container: 2
2023-05-21 16:55:06,654:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-21 16:55:06,654:INFO:create_model() successfully completed......................................
2023-05-21 16:55:06,785:INFO:SubProcess create_model() end ==================================
2023-05-21 16:55:06,785:INFO:Creating metrics dataframe
2023-05-21 16:55:06,846:INFO:Initializing Extra Trees Classifier
2023-05-21 16:55:06,846:INFO:Total runtime is 15.518404908974965 minutes
2023-05-21 16:55:06,847:INFO:SubProcess create_model() called ==================================
2023-05-21 16:55:06,847:INFO:Initializing create_model()
2023-05-21 16:55:06,847:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f30125d16c0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2ff859fd00>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:55:06,847:INFO:Checking exceptions
2023-05-21 16:55:06,847:INFO:Importing libraries
2023-05-21 16:55:06,847:INFO:Copying training dataset
2023-05-21 16:55:06,886:INFO:Defining folds
2023-05-21 16:55:06,886:INFO:Declaring metric variables
2023-05-21 16:55:06,887:INFO:Importing untrained model
2023-05-21 16:55:06,888:INFO:Extra Trees Classifier Imported successfully
2023-05-21 16:55:06,889:INFO:Starting cross validation
2023-05-21 16:55:06,896:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:56:16,273:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:56:21,839:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 3.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 16:56:28,738:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:56:28,810:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:56:29,755:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:56:29,974:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 16:56:30,095:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 16:56:34,011:INFO:Calculating mean and std
2023-05-21 16:56:34,014:INFO:Creating metrics dataframe
2023-05-21 16:56:34,144:INFO:Uploading results into container
2023-05-21 16:56:34,146:INFO:Uploading model into container now
2023-05-21 16:56:34,147:INFO:_master_model_container: 7
2023-05-21 16:56:34,147:INFO:_display_container: 2
2023-05-21 16:56:34,149:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-05-21 16:56:34,149:INFO:create_model() successfully completed......................................
2023-05-21 16:56:34,393:INFO:SubProcess create_model() end ==================================
2023-05-21 16:56:34,393:INFO:Creating metrics dataframe
2023-05-21 16:56:34,419:INFO:Initializing Light Gradient Boosting Machine
2023-05-21 16:56:34,419:INFO:Total runtime is 16.977956136067707 minutes
2023-05-21 16:56:34,420:INFO:SubProcess create_model() called ==================================
2023-05-21 16:56:34,421:INFO:Initializing create_model()
2023-05-21 16:56:34,421:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f30125d16c0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2ff859fd00>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:56:34,421:INFO:Checking exceptions
2023-05-21 16:56:34,421:INFO:Importing libraries
2023-05-21 16:56:34,422:INFO:Copying training dataset
2023-05-21 16:56:34,476:INFO:Defining folds
2023-05-21 16:56:34,477:INFO:Declaring metric variables
2023-05-21 16:56:34,477:INFO:Importing untrained model
2023-05-21 16:56:34,479:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 16:56:34,479:INFO:Starting cross validation
2023-05-21 16:56:34,484:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 16:57:06,234:INFO:Calculating mean and std
2023-05-21 16:57:06,236:INFO:Creating metrics dataframe
2023-05-21 16:57:06,363:INFO:Uploading results into container
2023-05-21 16:57:06,364:INFO:Uploading model into container now
2023-05-21 16:57:06,365:INFO:_master_model_container: 8
2023-05-21 16:57:06,365:INFO:_display_container: 2
2023-05-21 16:57:06,367:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 16:57:06,367:INFO:create_model() successfully completed......................................
2023-05-21 16:57:06,671:INFO:SubProcess create_model() end ==================================
2023-05-21 16:57:06,671:INFO:Creating metrics dataframe
2023-05-21 16:57:06,833:INFO:Initializing create_model()
2023-05-21 16:57:06,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f30125d16c0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-21 16:57:06,833:INFO:Checking exceptions
2023-05-21 16:57:06,855:INFO:Importing libraries
2023-05-21 16:57:06,855:INFO:Copying training dataset
2023-05-21 16:57:08,974:INFO:Defining folds
2023-05-21 16:57:08,974:INFO:Declaring metric variables
2023-05-21 16:57:08,975:INFO:Importing untrained model
2023-05-21 16:57:08,975:INFO:Declaring custom model
2023-05-21 16:57:08,980:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 16:57:08,988:INFO:Cross validation set to False
2023-05-21 16:57:08,988:INFO:Fitting Model
2023-05-21 16:57:17,006:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 16:57:17,006:INFO:create_model() successfully completed......................................
2023-05-21 16:57:17,131:INFO:Creating Dashboard logs
2023-05-21 16:57:17,132:INFO:Model: Light Gradient Boosting Machine
2023-05-21 16:58:10,546:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-21 16:58:14,193:INFO:Initializing predict_model()
2023-05-21 16:58:14,193:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f30125d16c0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7f2ff947e0e0>)
2023-05-21 16:58:14,193:INFO:Checking exceptions
2023-05-21 16:58:14,193:INFO:Preloading libraries
2023-05-21 16:58:15,642:INFO:SubProcess plot_model() called ==================================
2023-05-21 16:58:15,644:INFO:Initializing plot_model()
2023-05-21 16:58:15,644:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpmh6mv39e, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f30125d16c0>, system=False)
2023-05-21 16:58:15,644:INFO:Checking exceptions
2023-05-21 16:58:15,656:INFO:Preloading libraries
2023-05-21 16:58:15,660:INFO:Copying training dataset
2023-05-21 16:58:15,660:INFO:Plot type: auc
2023-05-21 16:58:28,760:INFO:Fitting Model
2023-05-21 16:58:28,771:INFO:Scoring test/hold-out set
2023-05-21 16:58:30,677:INFO:Saving '/tmp/tmpmh6mv39e/AUC.png'
2023-05-21 16:58:33,575:INFO:Visual Rendered Successfully
2023-05-21 16:58:33,708:INFO:plot_model() successfully completed......................................
2023-05-21 16:58:33,711:INFO:Initializing plot_model()
2023-05-21 16:58:33,711:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpmh6mv39e, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f30125d16c0>, system=False)
2023-05-21 16:58:33,711:INFO:Checking exceptions
2023-05-21 16:58:33,745:INFO:Preloading libraries
2023-05-21 16:58:33,752:INFO:Copying training dataset
2023-05-21 16:58:33,752:INFO:Plot type: confusion_matrix
2023-05-21 16:58:34,132:INFO:Fitting Model
2023-05-21 16:58:34,135:INFO:Scoring test/hold-out set
2023-05-21 16:58:34,309:INFO:Saving '/tmp/tmpmh6mv39e/Confusion Matrix.png'
2023-05-21 16:58:34,621:INFO:Visual Rendered Successfully
2023-05-21 16:58:34,749:INFO:plot_model() successfully completed......................................
2023-05-21 16:58:34,755:INFO:Initializing plot_model()
2023-05-21 16:58:34,755:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpmh6mv39e, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f30125d16c0>, system=False)
2023-05-21 16:58:34,755:INFO:Checking exceptions
2023-05-21 16:58:34,766:INFO:Preloading libraries
2023-05-21 16:58:34,773:INFO:Copying training dataset
2023-05-21 16:58:34,773:INFO:Plot type: feature
2023-05-21 16:58:34,775:WARNING:No coef_ found. Trying feature_importances_
2023-05-21 16:58:34,998:INFO:Saving '/tmp/tmpmh6mv39e/Feature Importance.png'
2023-05-21 16:58:35,347:INFO:Visual Rendered Successfully
2023-05-21 16:58:35,464:INFO:plot_model() successfully completed......................................
2023-05-21 16:58:35,465:INFO:SubProcess plot_model() end ==================================
2023-05-21 16:58:35,500:WARNING:/home/feuer/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-05-21 16:58:36,681:INFO:Creating Dashboard logs
2023-05-21 16:58:36,682:INFO:Model: Random Forest Classifier
2023-05-21 16:58:36,930:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 16:58:39,114:INFO:Creating Dashboard logs
2023-05-21 16:58:39,115:INFO:Model: Extra Trees Classifier
2023-05-21 16:58:39,465:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 16:58:41,194:INFO:Creating Dashboard logs
2023-05-21 16:58:41,195:INFO:Model: Decision Tree Classifier
2023-05-21 16:58:41,337:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2023-05-21 16:58:42,988:INFO:Creating Dashboard logs
2023-05-21 16:58:42,989:INFO:Model: Logistic Regression
2023-05-21 16:58:43,224:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-05-21 16:58:44,832:INFO:Creating Dashboard logs
2023-05-21 16:58:44,833:INFO:Model: Linear Discriminant Analysis
2023-05-21 16:58:45,235:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-05-21 16:58:47,746:INFO:Creating Dashboard logs
2023-05-21 16:58:47,747:INFO:Model: Naive Bayes
2023-05-21 16:58:48,064:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-05-21 16:58:51,362:INFO:Creating Dashboard logs
2023-05-21 16:58:51,362:INFO:Model: Ridge Classifier
2023-05-21 16:58:51,699:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2023-05-21 16:58:55,201:INFO:_master_model_container: 8
2023-05-21 16:58:55,201:INFO:_display_container: 2
2023-05-21 16:58:55,203:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 16:58:55,203:INFO:compare_models() successfully completed......................................
2023-05-21 16:58:55,291:INFO:PyCaret ClassificationExperiment
2023-05-21 16:58:55,292:INFO:Logging name: OnlyImportantFeatures
2023-05-21 16:58:55,292:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-21 16:58:55,292:INFO:version 3.0.0
2023-05-21 16:58:55,292:INFO:Initializing setup()
2023-05-21 16:58:55,292:INFO:self.USI: 7b76
2023-05-21 16:58:55,292:INFO:self._variable_keys: {'html_param', 'fix_imbalance', 'n_jobs_param', 'exp_id', 'pipeline', 'fold_groups_param', 'seed', 'logging_param', 'log_plots_param', 'USI', 'gpu_param', 'X', 'y', 'X_train', 'gpu_n_jobs_param', '_available_plots', 'exp_name_log', 'is_multiclass', 'idx', 'y_train', 'data', 'y_test', '_ml_usecase', 'fold_shuffle_param', 'X_test', 'target_param', 'fold_generator', 'memory'}
2023-05-21 16:58:55,292:INFO:Checking environment
2023-05-21 16:58:55,292:INFO:python_version: 3.10.10
2023-05-21 16:58:55,292:INFO:python_build: ('main', 'Mar  5 2023 22:26:53')
2023-05-21 16:58:55,293:INFO:machine: x86_64
2023-05-21 16:58:55,293:INFO:platform: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 16:58:55,293:INFO:Memory: svmem(total=16717086720, available=920453120, percent=94.5, used=13763727360, free=417685504, active=6048096256, inactive=4883599360, buffers=23470080, cached=2512203776, shared=1689477120, slab=593371136)
2023-05-21 16:58:55,294:INFO:Physical Core: 6
2023-05-21 16:58:55,294:INFO:Logical Core: 12
2023-05-21 16:58:55,295:INFO:Checking libraries
2023-05-21 16:58:55,295:INFO:System:
2023-05-21 16:58:55,295:INFO:    python: 3.10.10 (main, Mar  5 2023, 22:26:53) [GCC 12.2.1 20230201]
2023-05-21 16:58:55,295:INFO:executable: /usr/bin/python3.10
2023-05-21 16:58:55,295:INFO:   machine: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 16:58:55,295:INFO:PyCaret required dependencies:
2023-05-21 16:58:55,295:INFO:                 pip: 23.0.1
2023-05-21 16:58:55,295:INFO:          setuptools: 67.6.1
2023-05-21 16:58:55,296:INFO:             pycaret: 3.0.0
2023-05-21 16:58:55,296:INFO:             IPython: 8.12.0
2023-05-21 16:58:55,296:INFO:          ipywidgets: 7.7.5
2023-05-21 16:58:55,296:INFO:                tqdm: 4.64.1
2023-05-21 16:58:55,296:INFO:               numpy: 1.23.0
2023-05-21 16:58:55,296:INFO:              pandas: 1.5.3
2023-05-21 16:58:55,296:INFO:              jinja2: 3.1.2
2023-05-21 16:58:55,296:INFO:               scipy: 1.9.3
2023-05-21 16:58:55,296:INFO:              joblib: 1.2.0
2023-05-21 16:58:55,296:INFO:             sklearn: 1.2.2
2023-05-21 16:58:55,296:INFO:                pyod: 1.0.9
2023-05-21 16:58:55,297:INFO:            imblearn: 0.10.1
2023-05-21 16:58:55,297:INFO:   category_encoders: 2.6.0
2023-05-21 16:58:55,297:INFO:            lightgbm: 3.3.5
2023-05-21 16:58:55,297:INFO:               numba: 0.57.0
2023-05-21 16:58:55,297:INFO:            requests: 2.28.2
2023-05-21 16:58:55,297:INFO:          matplotlib: 3.6.3
2023-05-21 16:58:55,297:INFO:          scikitplot: 0.3.7
2023-05-21 16:58:55,297:INFO:         yellowbrick: 1.5
2023-05-21 16:58:55,297:INFO:              plotly: 5.14.1
2023-05-21 16:58:55,297:INFO:             kaleido: 0.2.1
2023-05-21 16:58:55,297:INFO:         statsmodels: 0.13.5
2023-05-21 16:58:55,298:INFO:              sktime: 0.18.0
2023-05-21 16:58:55,298:INFO:               tbats: 1.1.3
2023-05-21 16:58:55,298:INFO:            pmdarima: 2.0.3
2023-05-21 16:58:55,298:INFO:              psutil: 5.9.4
2023-05-21 16:58:55,298:INFO:PyCaret optional dependencies:
2023-05-21 16:58:55,298:INFO:                shap: 0.41.0
2023-05-21 16:58:55,298:INFO:           interpret: 0.3.2
2023-05-21 16:58:55,298:INFO:                umap: 0.5.3
2023-05-21 16:58:55,298:INFO:    pandas_profiling: 3.6.6
2023-05-21 16:58:55,299:INFO:  explainerdashboard: 0.4.2.2
2023-05-21 16:58:55,299:INFO:             autoviz: 0.1.603
2023-05-21 16:58:55,299:INFO:           fairlearn: 0.7.0
2023-05-21 16:58:55,299:INFO:             xgboost: 1.7.5
2023-05-21 16:58:55,299:INFO:            catboost: Not installed
2023-05-21 16:58:55,299:INFO:              kmodes: Not installed
2023-05-21 16:58:55,299:INFO:             mlxtend: Not installed
2023-05-21 16:58:55,299:INFO:       statsforecast: Not installed
2023-05-21 16:58:55,299:INFO:        tune_sklearn: Not installed
2023-05-21 16:58:55,299:INFO:                 ray: Not installed
2023-05-21 16:58:55,299:INFO:            hyperopt: Not installed
2023-05-21 16:58:55,300:INFO:              optuna: 3.1.1
2023-05-21 16:58:55,300:INFO:               skopt: Not installed
2023-05-21 16:58:55,300:INFO:              mlflow: 2.3.1
2023-05-21 16:58:55,300:INFO:              gradio: Not installed
2023-05-21 16:58:55,300:INFO:             fastapi: Not installed
2023-05-21 16:58:55,300:INFO:             uvicorn: Not installed
2023-05-21 16:58:55,300:INFO:              m2cgen: Not installed
2023-05-21 16:58:55,300:INFO:           evidently: Not installed
2023-05-21 16:58:55,300:INFO:               fugue: Not installed
2023-05-21 16:58:55,300:INFO:           streamlit: Not installed
2023-05-21 16:58:55,300:INFO:             prophet: Not installed
2023-05-21 16:58:55,301:INFO:None
2023-05-21 16:58:55,301:INFO:Set up data.
2023-05-21 17:39:12,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 17:39:12,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 17:39:12,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 17:39:12,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 17:39:16,233:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-21 17:39:49,680:INFO:PyCaret ClassificationExperiment
2023-05-21 17:39:49,680:INFO:Logging name: Lead_Scoring_Training_Pipeline
2023-05-21 17:39:49,680:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-21 17:39:49,680:INFO:version 3.0.0
2023-05-21 17:39:49,680:INFO:Initializing setup()
2023-05-21 17:39:49,680:INFO:self.USI: 432f
2023-05-21 17:39:49,681:INFO:self._variable_keys: {'y', 'seed', 'n_jobs_param', 'logging_param', 'target_param', 'html_param', 'y_train', '_available_plots', 'exp_name_log', '_ml_usecase', 'data', 'fold_generator', 'USI', 'is_multiclass', 'X', 'X_test', 'gpu_n_jobs_param', 'fold_shuffle_param', 'pipeline', 'X_train', 'exp_id', 'idx', 'fold_groups_param', 'log_plots_param', 'y_test', 'gpu_param', 'fix_imbalance', 'memory'}
2023-05-21 17:39:49,681:INFO:Checking environment
2023-05-21 17:39:49,681:INFO:python_version: 3.10.10
2023-05-21 17:39:49,682:INFO:python_build: ('main', 'Mar  5 2023 22:26:53')
2023-05-21 17:39:49,682:INFO:machine: x86_64
2023-05-21 17:39:49,684:INFO:platform: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 17:39:49,685:INFO:Memory: svmem(total=16717086720, available=9774370816, percent=41.5, used=6426619904, free=6005006336, active=7602192384, inactive=2312826880, buffers=202289152, cached=4083171328, shared=172666880, slab=382996480)
2023-05-21 17:39:49,690:INFO:Physical Core: 6
2023-05-21 17:39:49,691:INFO:Logical Core: 12
2023-05-21 17:39:49,691:INFO:Checking libraries
2023-05-21 17:39:49,691:INFO:System:
2023-05-21 17:39:49,692:INFO:    python: 3.10.10 (main, Mar  5 2023, 22:26:53) [GCC 12.2.1 20230201]
2023-05-21 17:39:49,692:INFO:executable: /usr/bin/python3.10
2023-05-21 17:39:49,692:INFO:   machine: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 17:39:49,693:INFO:PyCaret required dependencies:
2023-05-21 17:39:49,694:INFO:                 pip: 23.0.1
2023-05-21 17:39:49,694:INFO:          setuptools: 67.6.1
2023-05-21 17:39:49,694:INFO:             pycaret: 3.0.0
2023-05-21 17:39:49,694:INFO:             IPython: 8.12.0
2023-05-21 17:39:49,694:INFO:          ipywidgets: 7.7.5
2023-05-21 17:39:49,695:INFO:                tqdm: 4.64.1
2023-05-21 17:39:49,695:INFO:               numpy: 1.23.0
2023-05-21 17:39:49,695:INFO:              pandas: 1.5.3
2023-05-21 17:39:49,695:INFO:              jinja2: 3.1.2
2023-05-21 17:39:49,696:INFO:               scipy: 1.9.3
2023-05-21 17:39:49,696:INFO:              joblib: 1.2.0
2023-05-21 17:39:49,696:INFO:             sklearn: 1.2.2
2023-05-21 17:39:49,696:INFO:                pyod: 1.0.9
2023-05-21 17:39:49,696:INFO:            imblearn: 0.10.1
2023-05-21 17:39:49,697:INFO:   category_encoders: 2.6.0
2023-05-21 17:39:49,697:INFO:            lightgbm: 3.3.5
2023-05-21 17:39:49,697:INFO:               numba: 0.57.0
2023-05-21 17:39:49,697:INFO:            requests: 2.28.2
2023-05-21 17:39:49,698:INFO:          matplotlib: 3.6.3
2023-05-21 17:39:49,698:INFO:          scikitplot: 0.3.7
2023-05-21 17:39:49,698:INFO:         yellowbrick: 1.5
2023-05-21 17:39:49,698:INFO:              plotly: 5.14.1
2023-05-21 17:39:49,699:INFO:             kaleido: 0.2.1
2023-05-21 17:39:49,699:INFO:         statsmodels: 0.13.5
2023-05-21 17:39:49,699:INFO:              sktime: 0.18.0
2023-05-21 17:39:49,699:INFO:               tbats: 1.1.3
2023-05-21 17:39:49,699:INFO:            pmdarima: 2.0.3
2023-05-21 17:39:49,700:INFO:              psutil: 5.9.4
2023-05-21 17:39:49,700:INFO:PyCaret optional dependencies:
2023-05-21 17:39:49,756:INFO:                shap: 0.41.0
2023-05-21 17:39:49,757:INFO:           interpret: 0.3.2
2023-05-21 17:39:49,757:INFO:                umap: 0.5.3
2023-05-21 17:39:49,757:INFO:    pandas_profiling: 3.6.6
2023-05-21 17:39:49,758:INFO:  explainerdashboard: 0.4.2.2
2023-05-21 17:39:49,758:INFO:             autoviz: 0.1.603
2023-05-21 17:39:49,758:INFO:           fairlearn: 0.7.0
2023-05-21 17:39:49,759:INFO:             xgboost: 1.7.5
2023-05-21 17:39:49,759:INFO:            catboost: Not installed
2023-05-21 17:39:49,759:INFO:              kmodes: Not installed
2023-05-21 17:39:49,760:INFO:             mlxtend: Not installed
2023-05-21 17:39:49,760:INFO:       statsforecast: Not installed
2023-05-21 17:39:49,761:INFO:        tune_sklearn: Not installed
2023-05-21 17:39:49,761:INFO:                 ray: Not installed
2023-05-21 17:39:49,761:INFO:            hyperopt: Not installed
2023-05-21 17:39:49,762:INFO:              optuna: 3.1.1
2023-05-21 17:39:49,762:INFO:               skopt: Not installed
2023-05-21 17:39:49,762:INFO:              mlflow: 2.3.1
2023-05-21 17:39:49,763:INFO:              gradio: Not installed
2023-05-21 17:39:49,763:INFO:             fastapi: Not installed
2023-05-21 17:39:49,763:INFO:             uvicorn: Not installed
2023-05-21 17:39:49,764:INFO:              m2cgen: Not installed
2023-05-21 17:39:49,764:INFO:           evidently: Not installed
2023-05-21 17:39:49,765:INFO:               fugue: Not installed
2023-05-21 17:39:49,765:INFO:           streamlit: Not installed
2023-05-21 17:39:49,765:INFO:             prophet: Not installed
2023-05-21 17:39:49,766:INFO:None
2023-05-21 17:39:49,766:INFO:Set up data.
2023-05-21 17:39:50,001:INFO:Set up train/test split.
2023-05-21 17:39:50,002:INFO:Set up data.
2023-05-21 17:39:50,073:INFO:Set up index.
2023-05-21 17:39:50,073:INFO:Set up folding strategy.
2023-05-21 17:39:50,074:INFO:Assigning column types.
2023-05-21 17:39:50,092:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-21 17:39:50,145:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 17:39:50,166:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 17:39:50,240:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 17:39:50,430:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 17:39:50,483:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 17:39:50,485:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 17:39:50,517:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 17:39:50,520:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 17:39:50,521:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-21 17:39:50,573:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 17:39:50,611:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 17:39:50,615:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 17:39:50,667:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 17:39:50,699:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 17:39:50,703:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 17:39:50,703:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-21 17:39:50,793:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 17:39:50,796:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 17:39:50,892:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 17:39:50,896:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 17:39:50,901:INFO:Preparing preprocessing pipeline...
2023-05-21 17:39:50,917:INFO:Set up simple imputation.
2023-05-21 17:39:50,950:INFO:Set up encoding of categorical features.
2023-05-21 17:39:52,085:INFO:Finished creating preprocessing pipeline.
2023-05-21 17:39:52,129:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 17:39:52,130:INFO:Creating final display dataframe.
2023-05-21 17:39:54,370:INFO:Setup _display_container:                     Description                           Value
0                    Session id                              42
1                        Target               app_complete_flag
2                   Target type                          Binary
3           Original data shape                     (238964, 7)
4        Transformed data shape                    (238964, 39)
5   Transformed train set shape                    (191171, 39)
6    Transformed test set shape                     (47793, 39)
7              Numeric features                               3
8          Categorical features                               3
9                    Preprocess                            True
10              Imputation type                          simple
11           Numeric imputation                            mean
12       Categorical imputation                            mode
13     Maximum one-hot encoding                              25
14              Encoding method                            None
15               Fold Generator                 StratifiedKFold
16                  Fold Number                              10
17                     CPU Jobs                              -1
18                      Use GPU                           False
19               Log Experiment                    MlflowLogger
20              Experiment Name  Lead_Scoring_Training_Pipeline
21                          USI                            432f
2023-05-21 17:39:54,481:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 17:39:54,484:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 17:39:54,568:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 17:39:54,572:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 17:39:54,573:INFO:Logging experiment in loggers
2023-05-21 17:39:55,322:INFO:SubProcess save_model() called ==================================
2023-05-21 17:39:55,415:INFO:Initializing save_model()
2023-05-21 17:39:55,415:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/tmp/tmp8mutxqw1/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-21 17:39:55,415:INFO:Adding model into prep_pipe
2023-05-21 17:39:55,422:WARNING:Only Model saved as it was a pipeline.
2023-05-21 17:39:55,464:INFO:/tmp/tmp8mutxqw1/Transformation Pipeline.pkl saved in current working directory
2023-05-21 17:39:55,505:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 17:39:55,506:INFO:save_model() successfully completed......................................
2023-05-21 17:39:55,624:INFO:SubProcess save_model() end ==================================
2023-05-21 17:39:56,266:INFO:setup() successfully completed in 4.9s...............
2023-05-21 17:40:27,857:INFO:Initializing compare_models()
2023-05-21 17:40:27,858:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc32cfc3070>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fc32cfc3070>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'])
2023-05-21 17:40:27,858:INFO:Checking exceptions
2023-05-21 17:40:27,885:INFO:Preparing display monitor
2023-05-21 17:40:27,908:INFO:Initializing Logistic Regression
2023-05-21 17:40:27,908:INFO:Total runtime is 5.046526590983073e-06 minutes
2023-05-21 17:40:27,908:INFO:SubProcess create_model() called ==================================
2023-05-21 17:40:27,909:INFO:Initializing create_model()
2023-05-21 17:40:27,909:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc32cfc3070>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc316108370>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:40:27,909:INFO:Checking exceptions
2023-05-21 17:40:27,910:INFO:Importing libraries
2023-05-21 17:40:27,910:INFO:Copying training dataset
2023-05-21 17:40:27,953:INFO:Defining folds
2023-05-21 17:40:27,953:INFO:Declaring metric variables
2023-05-21 17:40:27,954:INFO:Importing untrained model
2023-05-21 17:40:27,956:INFO:Logistic Regression Imported successfully
2023-05-21 17:40:27,957:INFO:Starting cross validation
2023-05-21 17:40:27,965:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 17:40:48,342:INFO:Calculating mean and std
2023-05-21 17:40:48,344:INFO:Creating metrics dataframe
2023-05-21 17:40:48,385:INFO:Uploading results into container
2023-05-21 17:40:48,389:INFO:Uploading model into container now
2023-05-21 17:40:48,391:INFO:_master_model_container: 1
2023-05-21 17:40:48,392:INFO:_display_container: 2
2023-05-21 17:40:48,395:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-21 17:40:48,395:INFO:create_model() successfully completed......................................
2023-05-21 17:40:48,532:INFO:SubProcess create_model() end ==================================
2023-05-21 17:40:48,532:INFO:Creating metrics dataframe
2023-05-21 17:40:48,554:INFO:Initializing Naive Bayes
2023-05-21 17:40:48,555:INFO:Total runtime is 0.3441199103991191 minutes
2023-05-21 17:40:48,555:INFO:SubProcess create_model() called ==================================
2023-05-21 17:40:48,556:INFO:Initializing create_model()
2023-05-21 17:40:48,556:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc32cfc3070>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc316108370>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:40:48,556:INFO:Checking exceptions
2023-05-21 17:40:48,557:INFO:Importing libraries
2023-05-21 17:40:48,557:INFO:Copying training dataset
2023-05-21 17:40:48,600:INFO:Defining folds
2023-05-21 17:40:48,600:INFO:Declaring metric variables
2023-05-21 17:40:48,601:INFO:Importing untrained model
2023-05-21 17:40:48,602:INFO:Naive Bayes Imported successfully
2023-05-21 17:40:48,603:INFO:Starting cross validation
2023-05-21 17:40:48,611:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 17:40:54,401:INFO:Calculating mean and std
2023-05-21 17:40:54,404:INFO:Creating metrics dataframe
2023-05-21 17:40:54,445:INFO:Uploading results into container
2023-05-21 17:40:54,447:INFO:Uploading model into container now
2023-05-21 17:40:54,448:INFO:_master_model_container: 2
2023-05-21 17:40:54,448:INFO:_display_container: 2
2023-05-21 17:40:54,449:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-21 17:40:54,449:INFO:create_model() successfully completed......................................
2023-05-21 17:40:54,577:INFO:SubProcess create_model() end ==================================
2023-05-21 17:40:54,578:INFO:Creating metrics dataframe
2023-05-21 17:40:54,601:INFO:Initializing Decision Tree Classifier
2023-05-21 17:40:54,602:INFO:Total runtime is 0.4449030756950379 minutes
2023-05-21 17:40:54,602:INFO:SubProcess create_model() called ==================================
2023-05-21 17:40:54,603:INFO:Initializing create_model()
2023-05-21 17:40:54,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc32cfc3070>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc316108370>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:40:54,603:INFO:Checking exceptions
2023-05-21 17:40:54,603:INFO:Importing libraries
2023-05-21 17:40:54,603:INFO:Copying training dataset
2023-05-21 17:40:54,662:INFO:Defining folds
2023-05-21 17:40:54,662:INFO:Declaring metric variables
2023-05-21 17:40:54,663:INFO:Importing untrained model
2023-05-21 17:40:54,666:INFO:Decision Tree Classifier Imported successfully
2023-05-21 17:40:54,669:INFO:Starting cross validation
2023-05-21 17:40:54,680:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 17:40:58,286:INFO:Calculating mean and std
2023-05-21 17:40:58,289:INFO:Creating metrics dataframe
2023-05-21 17:40:58,365:INFO:Uploading results into container
2023-05-21 17:40:58,367:INFO:Uploading model into container now
2023-05-21 17:40:58,369:INFO:_master_model_container: 3
2023-05-21 17:40:58,369:INFO:_display_container: 2
2023-05-21 17:40:58,371:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-05-21 17:40:58,372:INFO:create_model() successfully completed......................................
2023-05-21 17:40:58,483:INFO:SubProcess create_model() end ==================================
2023-05-21 17:40:58,483:INFO:Creating metrics dataframe
2023-05-21 17:40:58,506:INFO:Initializing Ridge Classifier
2023-05-21 17:40:58,506:INFO:Total runtime is 0.5099827647209167 minutes
2023-05-21 17:40:58,507:INFO:SubProcess create_model() called ==================================
2023-05-21 17:40:58,508:INFO:Initializing create_model()
2023-05-21 17:40:58,508:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc32cfc3070>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc316108370>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:40:58,508:INFO:Checking exceptions
2023-05-21 17:40:58,508:INFO:Importing libraries
2023-05-21 17:40:58,508:INFO:Copying training dataset
2023-05-21 17:40:58,547:INFO:Defining folds
2023-05-21 17:40:58,548:INFO:Declaring metric variables
2023-05-21 17:40:58,548:INFO:Importing untrained model
2023-05-21 17:40:58,550:INFO:Ridge Classifier Imported successfully
2023-05-21 17:40:58,551:INFO:Starting cross validation
2023-05-21 17:40:58,559:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 17:41:00,405:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:41:00,412:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:41:00,427:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:41:00,493:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:41:00,505:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:41:00,530:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:41:00,538:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:41:00,635:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:41:00,638:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:41:00,661:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:41:00,832:INFO:Calculating mean and std
2023-05-21 17:41:00,834:INFO:Creating metrics dataframe
2023-05-21 17:41:00,901:INFO:Uploading results into container
2023-05-21 17:41:00,903:INFO:Uploading model into container now
2023-05-21 17:41:00,905:INFO:_master_model_container: 4
2023-05-21 17:41:00,906:INFO:_display_container: 2
2023-05-21 17:41:00,908:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-05-21 17:41:00,908:INFO:create_model() successfully completed......................................
2023-05-21 17:41:01,031:INFO:SubProcess create_model() end ==================================
2023-05-21 17:41:01,032:INFO:Creating metrics dataframe
2023-05-21 17:41:01,055:INFO:Initializing Random Forest Classifier
2023-05-21 17:41:01,056:INFO:Total runtime is 0.5524710257848103 minutes
2023-05-21 17:41:01,056:INFO:SubProcess create_model() called ==================================
2023-05-21 17:41:01,057:INFO:Initializing create_model()
2023-05-21 17:41:01,057:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc32cfc3070>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc316108370>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:41:01,057:INFO:Checking exceptions
2023-05-21 17:41:01,058:INFO:Importing libraries
2023-05-21 17:41:01,058:INFO:Copying training dataset
2023-05-21 17:41:01,096:INFO:Defining folds
2023-05-21 17:41:01,096:INFO:Declaring metric variables
2023-05-21 17:41:01,097:INFO:Importing untrained model
2023-05-21 17:41:01,099:INFO:Random Forest Classifier Imported successfully
2023-05-21 17:41:01,100:INFO:Starting cross validation
2023-05-21 17:41:01,108:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 17:41:37,222:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 17:41:37,290:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 17:41:37,392:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 17:41:37,566:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 17:41:37,596:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 17:41:37,628:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 17:41:37,646:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 17:41:37,650:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 17:41:37,805:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 17:41:38,540:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 17:41:38,677:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 17:41:38,678:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 17:41:38,770:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 17:41:38,776:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 17:41:38,792:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 17:41:38,886:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 17:41:38,916:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 17:41:39,309:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 17:41:40,416:INFO:Calculating mean and std
2023-05-21 17:41:40,419:INFO:Creating metrics dataframe
2023-05-21 17:41:40,501:INFO:Uploading results into container
2023-05-21 17:41:40,503:INFO:Uploading model into container now
2023-05-21 17:41:40,505:INFO:_master_model_container: 5
2023-05-21 17:41:40,505:INFO:_display_container: 2
2023-05-21 17:41:40,507:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-05-21 17:41:40,508:INFO:create_model() successfully completed......................................
2023-05-21 17:41:40,620:INFO:SubProcess create_model() end ==================================
2023-05-21 17:41:40,620:INFO:Creating metrics dataframe
2023-05-21 17:41:40,644:INFO:Initializing Linear Discriminant Analysis
2023-05-21 17:41:40,645:INFO:Total runtime is 1.2122856855392454 minutes
2023-05-21 17:41:40,645:INFO:SubProcess create_model() called ==================================
2023-05-21 17:41:40,646:INFO:Initializing create_model()
2023-05-21 17:41:40,646:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc32cfc3070>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc316108370>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:41:40,646:INFO:Checking exceptions
2023-05-21 17:41:40,646:INFO:Importing libraries
2023-05-21 17:41:40,647:INFO:Copying training dataset
2023-05-21 17:41:40,685:INFO:Defining folds
2023-05-21 17:41:40,685:INFO:Declaring metric variables
2023-05-21 17:41:40,686:INFO:Importing untrained model
2023-05-21 17:41:40,687:INFO:Linear Discriminant Analysis Imported successfully
2023-05-21 17:41:40,688:INFO:Starting cross validation
2023-05-21 17:41:40,696:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 17:41:45,944:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 17:41:46,421:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 17:41:46,975:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 17:41:47,959:INFO:Calculating mean and std
2023-05-21 17:41:47,962:INFO:Creating metrics dataframe
2023-05-21 17:41:48,050:INFO:Uploading results into container
2023-05-21 17:41:48,052:INFO:Uploading model into container now
2023-05-21 17:41:48,054:INFO:_master_model_container: 6
2023-05-21 17:41:48,054:INFO:_display_container: 2
2023-05-21 17:41:48,055:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-21 17:41:48,056:INFO:create_model() successfully completed......................................
2023-05-21 17:41:48,296:INFO:SubProcess create_model() end ==================================
2023-05-21 17:41:48,297:INFO:Creating metrics dataframe
2023-05-21 17:41:48,321:INFO:Initializing Extra Trees Classifier
2023-05-21 17:41:48,321:INFO:Total runtime is 1.3402267813682553 minutes
2023-05-21 17:41:48,322:INFO:SubProcess create_model() called ==================================
2023-05-21 17:41:48,322:INFO:Initializing create_model()
2023-05-21 17:41:48,323:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc32cfc3070>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc316108370>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:41:48,323:INFO:Checking exceptions
2023-05-21 17:41:48,323:INFO:Importing libraries
2023-05-21 17:41:48,323:INFO:Copying training dataset
2023-05-21 17:41:48,368:INFO:Defining folds
2023-05-21 17:41:48,368:INFO:Declaring metric variables
2023-05-21 17:41:48,369:INFO:Importing untrained model
2023-05-21 17:41:48,372:INFO:Extra Trees Classifier Imported successfully
2023-05-21 17:41:48,373:INFO:Starting cross validation
2023-05-21 17:41:48,382:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 17:42:31,843:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 17:42:31,854:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 17:42:31,890:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 17:42:31,893:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 17:42:31,903:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 17:42:31,907:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 17:42:31,968:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 17:42:31,981:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 17:42:32,007:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 17:42:33,097:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 17:42:33,104:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 17:42:33,105:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 17:42:33,110:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 17:42:33,127:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 17:42:33,204:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 17:42:33,220:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 17:42:33,233:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 17:42:33,405:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 17:42:34,531:INFO:Calculating mean and std
2023-05-21 17:42:34,533:INFO:Creating metrics dataframe
2023-05-21 17:42:34,624:INFO:Uploading results into container
2023-05-21 17:42:34,626:INFO:Uploading model into container now
2023-05-21 17:42:34,628:INFO:_master_model_container: 7
2023-05-21 17:42:34,628:INFO:_display_container: 2
2023-05-21 17:42:34,631:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-05-21 17:42:34,631:INFO:create_model() successfully completed......................................
2023-05-21 17:42:34,741:INFO:SubProcess create_model() end ==================================
2023-05-21 17:42:34,741:INFO:Creating metrics dataframe
2023-05-21 17:42:34,764:INFO:Initializing Light Gradient Boosting Machine
2023-05-21 17:42:34,765:INFO:Total runtime is 2.1142852266629535 minutes
2023-05-21 17:42:34,765:INFO:SubProcess create_model() called ==================================
2023-05-21 17:42:34,766:INFO:Initializing create_model()
2023-05-21 17:42:34,766:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc32cfc3070>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc316108370>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:42:34,766:INFO:Checking exceptions
2023-05-21 17:42:34,766:INFO:Importing libraries
2023-05-21 17:42:34,766:INFO:Copying training dataset
2023-05-21 17:42:34,805:INFO:Defining folds
2023-05-21 17:42:34,806:INFO:Declaring metric variables
2023-05-21 17:42:34,806:INFO:Importing untrained model
2023-05-21 17:42:34,809:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 17:42:34,810:INFO:Starting cross validation
2023-05-21 17:42:34,817:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 17:42:38,910:INFO:Calculating mean and std
2023-05-21 17:42:38,913:INFO:Creating metrics dataframe
2023-05-21 17:42:39,009:INFO:Uploading results into container
2023-05-21 17:42:39,011:INFO:Uploading model into container now
2023-05-21 17:42:39,013:INFO:_master_model_container: 8
2023-05-21 17:42:39,013:INFO:_display_container: 2
2023-05-21 17:42:39,016:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 17:42:39,016:INFO:create_model() successfully completed......................................
2023-05-21 17:42:39,126:INFO:SubProcess create_model() end ==================================
2023-05-21 17:42:39,126:INFO:Creating metrics dataframe
2023-05-21 17:42:39,159:INFO:Initializing create_model()
2023-05-21 17:42:39,159:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc32cfc3070>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:42:39,159:INFO:Checking exceptions
2023-05-21 17:42:39,162:INFO:Importing libraries
2023-05-21 17:42:39,162:INFO:Copying training dataset
2023-05-21 17:42:39,200:INFO:Defining folds
2023-05-21 17:42:39,200:INFO:Declaring metric variables
2023-05-21 17:42:39,201:INFO:Importing untrained model
2023-05-21 17:42:39,201:INFO:Declaring custom model
2023-05-21 17:42:39,206:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 17:42:39,213:INFO:Cross validation set to False
2023-05-21 17:42:39,214:INFO:Fitting Model
2023-05-21 17:42:40,787:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 17:42:40,787:INFO:create_model() successfully completed......................................
2023-05-21 17:42:40,897:INFO:Creating Dashboard logs
2023-05-21 17:42:40,898:INFO:Model: Light Gradient Boosting Machine
2023-05-21 17:42:41,062:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-21 17:42:42,173:INFO:Initializing predict_model()
2023-05-21 17:42:42,174:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc32cfc3070>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fc316280a60>)
2023-05-21 17:42:42,174:INFO:Checking exceptions
2023-05-21 17:42:42,174:INFO:Preloading libraries
2023-05-21 17:42:42,841:INFO:SubProcess plot_model() called ==================================
2023-05-21 17:42:42,844:INFO:Initializing plot_model()
2023-05-21 17:42:42,844:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp9hxsnjqx, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc32cfc3070>, system=False)
2023-05-21 17:42:42,845:INFO:Checking exceptions
2023-05-21 17:42:42,860:INFO:Preloading libraries
2023-05-21 17:42:42,866:INFO:Copying training dataset
2023-05-21 17:42:42,866:INFO:Plot type: auc
2023-05-21 17:42:44,733:INFO:Fitting Model
2023-05-21 17:42:44,745:INFO:Scoring test/hold-out set
2023-05-21 17:42:45,066:INFO:Saving '/tmp/tmp9hxsnjqx/AUC.png'
2023-05-21 17:42:46,292:INFO:Visual Rendered Successfully
2023-05-21 17:42:46,425:INFO:plot_model() successfully completed......................................
2023-05-21 17:42:46,429:INFO:Initializing plot_model()
2023-05-21 17:42:46,430:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp9hxsnjqx, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc32cfc3070>, system=False)
2023-05-21 17:42:46,430:INFO:Checking exceptions
2023-05-21 17:42:46,448:INFO:Preloading libraries
2023-05-21 17:42:46,455:INFO:Copying training dataset
2023-05-21 17:42:46,455:INFO:Plot type: confusion_matrix
2023-05-21 17:42:47,029:INFO:Fitting Model
2023-05-21 17:42:47,033:INFO:Scoring test/hold-out set
2023-05-21 17:42:47,243:INFO:Saving '/tmp/tmp9hxsnjqx/Confusion Matrix.png'
2023-05-21 17:42:47,744:INFO:Visual Rendered Successfully
2023-05-21 17:42:47,939:INFO:plot_model() successfully completed......................................
2023-05-21 17:42:47,944:INFO:Initializing plot_model()
2023-05-21 17:42:47,944:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp9hxsnjqx, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc32cfc3070>, system=False)
2023-05-21 17:42:47,944:INFO:Checking exceptions
2023-05-21 17:42:47,961:INFO:Preloading libraries
2023-05-21 17:42:47,968:INFO:Copying training dataset
2023-05-21 17:42:47,968:INFO:Plot type: feature
2023-05-21 17:42:47,971:WARNING:No coef_ found. Trying feature_importances_
2023-05-21 17:42:48,290:INFO:Saving '/tmp/tmp9hxsnjqx/Feature Importance.png'
2023-05-21 17:42:49,010:INFO:Visual Rendered Successfully
2023-05-21 17:42:49,139:INFO:plot_model() successfully completed......................................
2023-05-21 17:42:49,141:INFO:SubProcess plot_model() end ==================================
2023-05-21 17:42:49,156:WARNING:/home/feuer/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-05-21 17:42:49,622:INFO:Creating Dashboard logs
2023-05-21 17:42:49,624:INFO:Model: Random Forest Classifier
2023-05-21 17:42:49,746:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 17:42:50,854:INFO:Creating Dashboard logs
2023-05-21 17:42:50,856:INFO:Model: Extra Trees Classifier
2023-05-21 17:42:51,069:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 17:42:52,215:INFO:Creating Dashboard logs
2023-05-21 17:42:52,216:INFO:Model: Decision Tree Classifier
2023-05-21 17:42:52,372:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2023-05-21 17:42:53,512:INFO:Creating Dashboard logs
2023-05-21 17:42:53,513:INFO:Model: Logistic Regression
2023-05-21 17:42:53,630:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-05-21 17:42:54,796:INFO:Creating Dashboard logs
2023-05-21 17:42:54,797:INFO:Model: Linear Discriminant Analysis
2023-05-21 17:42:54,994:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-05-21 17:42:56,641:INFO:Creating Dashboard logs
2023-05-21 17:42:56,642:INFO:Model: Naive Bayes
2023-05-21 17:42:56,821:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-05-21 17:42:58,369:INFO:Creating Dashboard logs
2023-05-21 17:42:58,371:INFO:Model: Ridge Classifier
2023-05-21 17:42:58,512:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2023-05-21 17:42:59,605:INFO:_master_model_container: 8
2023-05-21 17:42:59,605:INFO:_display_container: 2
2023-05-21 17:42:59,608:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 17:42:59,609:INFO:compare_models() successfully completed......................................
2023-05-21 17:43:33,034:INFO:PyCaret ClassificationExperiment
2023-05-21 17:43:33,034:INFO:Logging name: OnlyImportantFeatures
2023-05-21 17:43:33,034:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-21 17:43:33,034:INFO:version 3.0.0
2023-05-21 17:43:33,035:INFO:Initializing setup()
2023-05-21 17:43:33,035:INFO:self.USI: 09be
2023-05-21 17:43:33,035:INFO:self._variable_keys: {'y', 'seed', 'n_jobs_param', 'logging_param', 'target_param', 'html_param', 'y_train', '_available_plots', 'exp_name_log', '_ml_usecase', 'data', 'fold_generator', 'USI', 'is_multiclass', 'X', 'X_test', 'gpu_n_jobs_param', 'fold_shuffle_param', 'pipeline', 'X_train', 'exp_id', 'idx', 'fold_groups_param', 'log_plots_param', 'y_test', 'gpu_param', 'fix_imbalance', 'memory'}
2023-05-21 17:43:33,035:INFO:Checking environment
2023-05-21 17:43:33,035:INFO:python_version: 3.10.10
2023-05-21 17:43:33,035:INFO:python_build: ('main', 'Mar  5 2023 22:26:53')
2023-05-21 17:43:33,036:INFO:machine: x86_64
2023-05-21 17:43:33,036:INFO:platform: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 17:43:33,036:INFO:Memory: svmem(total=16717086720, available=3735580672, percent=77.7, used=10998456320, free=2695286784, active=10006720512, inactive=2552606720, buffers=16060416, cached=3007283200, shared=1564123136, slab=429891584)
2023-05-21 17:43:33,038:INFO:Physical Core: 6
2023-05-21 17:43:33,038:INFO:Logical Core: 12
2023-05-21 17:43:33,038:INFO:Checking libraries
2023-05-21 17:43:33,038:INFO:System:
2023-05-21 17:43:33,039:INFO:    python: 3.10.10 (main, Mar  5 2023, 22:26:53) [GCC 12.2.1 20230201]
2023-05-21 17:43:33,039:INFO:executable: /usr/bin/python3.10
2023-05-21 17:43:33,039:INFO:   machine: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 17:43:33,039:INFO:PyCaret required dependencies:
2023-05-21 17:43:33,040:INFO:                 pip: 23.0.1
2023-05-21 17:43:33,040:INFO:          setuptools: 67.6.1
2023-05-21 17:43:33,040:INFO:             pycaret: 3.0.0
2023-05-21 17:43:33,040:INFO:             IPython: 8.12.0
2023-05-21 17:43:33,040:INFO:          ipywidgets: 7.7.5
2023-05-21 17:43:33,040:INFO:                tqdm: 4.64.1
2023-05-21 17:43:33,041:INFO:               numpy: 1.23.0
2023-05-21 17:43:33,041:INFO:              pandas: 1.5.3
2023-05-21 17:43:33,041:INFO:              jinja2: 3.1.2
2023-05-21 17:43:33,041:INFO:               scipy: 1.9.3
2023-05-21 17:43:33,041:INFO:              joblib: 1.2.0
2023-05-21 17:43:33,042:INFO:             sklearn: 1.2.2
2023-05-21 17:43:33,042:INFO:                pyod: 1.0.9
2023-05-21 17:43:33,042:INFO:            imblearn: 0.10.1
2023-05-21 17:43:33,042:INFO:   category_encoders: 2.6.0
2023-05-21 17:43:33,042:INFO:            lightgbm: 3.3.5
2023-05-21 17:43:33,042:INFO:               numba: 0.57.0
2023-05-21 17:43:33,042:INFO:            requests: 2.28.2
2023-05-21 17:43:33,043:INFO:          matplotlib: 3.6.3
2023-05-21 17:43:33,043:INFO:          scikitplot: 0.3.7
2023-05-21 17:43:33,043:INFO:         yellowbrick: 1.5
2023-05-21 17:43:33,043:INFO:              plotly: 5.14.1
2023-05-21 17:43:33,043:INFO:             kaleido: 0.2.1
2023-05-21 17:43:33,044:INFO:         statsmodels: 0.13.5
2023-05-21 17:43:33,044:INFO:              sktime: 0.18.0
2023-05-21 17:43:33,044:INFO:               tbats: 1.1.3
2023-05-21 17:43:33,044:INFO:            pmdarima: 2.0.3
2023-05-21 17:43:33,044:INFO:              psutil: 5.9.4
2023-05-21 17:43:33,044:INFO:PyCaret optional dependencies:
2023-05-21 17:43:33,045:INFO:                shap: 0.41.0
2023-05-21 17:43:33,045:INFO:           interpret: 0.3.2
2023-05-21 17:43:33,045:INFO:                umap: 0.5.3
2023-05-21 17:43:33,045:INFO:    pandas_profiling: 3.6.6
2023-05-21 17:43:33,046:INFO:  explainerdashboard: 0.4.2.2
2023-05-21 17:43:33,046:INFO:             autoviz: 0.1.603
2023-05-21 17:43:33,046:INFO:           fairlearn: 0.7.0
2023-05-21 17:43:33,046:INFO:             xgboost: 1.7.5
2023-05-21 17:43:33,046:INFO:            catboost: Not installed
2023-05-21 17:43:33,046:INFO:              kmodes: Not installed
2023-05-21 17:43:33,047:INFO:             mlxtend: Not installed
2023-05-21 17:43:33,047:INFO:       statsforecast: Not installed
2023-05-21 17:43:33,047:INFO:        tune_sklearn: Not installed
2023-05-21 17:43:33,047:INFO:                 ray: Not installed
2023-05-21 17:43:33,047:INFO:            hyperopt: Not installed
2023-05-21 17:43:33,047:INFO:              optuna: 3.1.1
2023-05-21 17:43:33,048:INFO:               skopt: Not installed
2023-05-21 17:43:33,048:INFO:              mlflow: 2.3.1
2023-05-21 17:43:33,048:INFO:              gradio: Not installed
2023-05-21 17:43:33,048:INFO:             fastapi: Not installed
2023-05-21 17:43:33,048:INFO:             uvicorn: Not installed
2023-05-21 17:43:33,049:INFO:              m2cgen: Not installed
2023-05-21 17:43:33,049:INFO:           evidently: Not installed
2023-05-21 17:43:33,049:INFO:               fugue: Not installed
2023-05-21 17:43:33,049:INFO:           streamlit: Not installed
2023-05-21 17:43:33,049:INFO:             prophet: Not installed
2023-05-21 17:43:33,049:INFO:None
2023-05-21 17:43:33,050:INFO:Set up data.
2023-05-21 17:43:33,280:INFO:Set up train/test split.
2023-05-21 17:43:33,280:INFO:Set up data.
2023-05-21 17:43:33,351:INFO:Set up index.
2023-05-21 17:43:33,351:INFO:Set up folding strategy.
2023-05-21 17:43:33,351:INFO:Assigning column types.
2023-05-21 17:43:33,369:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-21 17:43:33,420:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 17:43:33,421:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 17:43:33,454:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 17:43:33,457:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 17:43:33,508:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 17:43:33,510:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 17:43:33,542:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 17:43:33,545:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 17:43:33,546:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-21 17:43:33,598:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 17:43:33,631:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 17:43:33,634:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 17:43:33,687:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 17:43:33,719:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 17:43:33,723:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 17:43:33,724:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-21 17:43:33,808:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 17:43:33,811:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 17:43:33,896:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 17:43:33,899:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 17:43:33,902:INFO:Preparing preprocessing pipeline...
2023-05-21 17:43:33,906:INFO:Set up simple imputation.
2023-05-21 17:43:33,926:INFO:Set up encoding of categorical features.
2023-05-21 17:43:34,265:INFO:Finished creating preprocessing pipeline.
2023-05-21 17:43:34,307:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 17:43:34,308:INFO:Creating final display dataframe.
2023-05-21 17:43:35,908:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     42
1                        Target      app_complete_flag
2                   Target type                 Binary
3           Original data shape            (238964, 7)
4        Transformed data shape           (238964, 39)
5   Transformed train set shape           (191171, 39)
6    Transformed test set shape            (47793, 39)
7              Numeric features                      3
8          Categorical features                      3
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13     Maximum one-hot encoding                     25
14              Encoding method                   None
15               Fold Generator        StratifiedKFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                  False
19               Log Experiment           MlflowLogger
20              Experiment Name  OnlyImportantFeatures
21                          USI                   09be
2023-05-21 17:43:36,019:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 17:43:36,022:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 17:43:36,113:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 17:43:36,119:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 17:43:36,122:INFO:Logging experiment in loggers
2023-05-21 17:43:37,077:INFO:SubProcess save_model() called ==================================
2023-05-21 17:43:37,180:INFO:Initializing save_model()
2023-05-21 17:43:37,181:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/tmp/tmpbr0adp76/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-21 17:43:37,181:INFO:Adding model into prep_pipe
2023-05-21 17:43:37,189:WARNING:Only Model saved as it was a pipeline.
2023-05-21 17:43:37,245:INFO:/tmp/tmpbr0adp76/Transformation Pipeline.pkl saved in current working directory
2023-05-21 17:43:37,288:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 17:43:37,288:INFO:save_model() successfully completed......................................
2023-05-21 17:43:37,479:INFO:SubProcess save_model() end ==================================
2023-05-21 17:43:38,141:INFO:setup() successfully completed in 3.18s...............
2023-05-21 17:43:48,612:INFO:Initializing compare_models()
2023-05-21 17:43:48,612:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc316092290>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fc316092290>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'])
2023-05-21 17:43:48,613:INFO:Checking exceptions
2023-05-21 17:43:48,650:INFO:Preparing display monitor
2023-05-21 17:43:48,669:INFO:Initializing Logistic Regression
2023-05-21 17:43:48,669:INFO:Total runtime is 7.708867390950521e-06 minutes
2023-05-21 17:43:48,670:INFO:SubProcess create_model() called ==================================
2023-05-21 17:43:48,671:INFO:Initializing create_model()
2023-05-21 17:43:48,672:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc316092290>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc318b08fa0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:43:48,672:INFO:Checking exceptions
2023-05-21 17:43:48,672:INFO:Importing libraries
2023-05-21 17:43:48,673:INFO:Copying training dataset
2023-05-21 17:43:48,718:INFO:Defining folds
2023-05-21 17:43:48,719:INFO:Declaring metric variables
2023-05-21 17:43:48,719:INFO:Importing untrained model
2023-05-21 17:43:48,721:INFO:Logistic Regression Imported successfully
2023-05-21 17:43:48,722:INFO:Starting cross validation
2023-05-21 17:43:48,730:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 17:43:50,422:INFO:Calculating mean and std
2023-05-21 17:43:50,423:INFO:Creating metrics dataframe
2023-05-21 17:43:50,486:INFO:Uploading results into container
2023-05-21 17:43:50,490:INFO:Uploading model into container now
2023-05-21 17:43:50,492:INFO:_master_model_container: 1
2023-05-21 17:43:50,493:INFO:_display_container: 2
2023-05-21 17:43:50,497:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-21 17:43:50,497:INFO:create_model() successfully completed......................................
2023-05-21 17:43:50,612:INFO:SubProcess create_model() end ==================================
2023-05-21 17:43:50,612:INFO:Creating metrics dataframe
2023-05-21 17:43:50,633:INFO:Initializing Naive Bayes
2023-05-21 17:43:50,633:INFO:Total runtime is 0.03273315827051799 minutes
2023-05-21 17:43:50,633:INFO:SubProcess create_model() called ==================================
2023-05-21 17:43:50,634:INFO:Initializing create_model()
2023-05-21 17:43:50,634:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc316092290>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc318b08fa0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:43:50,634:INFO:Checking exceptions
2023-05-21 17:43:50,634:INFO:Importing libraries
2023-05-21 17:43:50,635:INFO:Copying training dataset
2023-05-21 17:43:50,676:INFO:Defining folds
2023-05-21 17:43:50,676:INFO:Declaring metric variables
2023-05-21 17:43:50,677:INFO:Importing untrained model
2023-05-21 17:43:50,678:INFO:Naive Bayes Imported successfully
2023-05-21 17:43:50,679:INFO:Starting cross validation
2023-05-21 17:43:50,687:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 17:43:51,964:INFO:Calculating mean and std
2023-05-21 17:43:51,966:INFO:Creating metrics dataframe
2023-05-21 17:43:52,064:INFO:Uploading results into container
2023-05-21 17:43:52,066:INFO:Uploading model into container now
2023-05-21 17:43:52,068:INFO:_master_model_container: 2
2023-05-21 17:43:52,068:INFO:_display_container: 2
2023-05-21 17:43:52,069:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-21 17:43:52,069:INFO:create_model() successfully completed......................................
2023-05-21 17:43:52,191:INFO:SubProcess create_model() end ==================================
2023-05-21 17:43:52,191:INFO:Creating metrics dataframe
2023-05-21 17:43:52,215:INFO:Initializing Decision Tree Classifier
2023-05-21 17:43:52,215:INFO:Total runtime is 0.05909922122955323 minutes
2023-05-21 17:43:52,215:INFO:SubProcess create_model() called ==================================
2023-05-21 17:43:52,216:INFO:Initializing create_model()
2023-05-21 17:43:52,216:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc316092290>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc318b08fa0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:43:52,217:INFO:Checking exceptions
2023-05-21 17:43:52,217:INFO:Importing libraries
2023-05-21 17:43:52,217:INFO:Copying training dataset
2023-05-21 17:43:52,255:INFO:Defining folds
2023-05-21 17:43:52,255:INFO:Declaring metric variables
2023-05-21 17:43:52,256:INFO:Importing untrained model
2023-05-21 17:43:52,258:INFO:Decision Tree Classifier Imported successfully
2023-05-21 17:43:52,259:INFO:Starting cross validation
2023-05-21 17:43:52,267:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 17:43:53,530:INFO:Calculating mean and std
2023-05-21 17:43:53,533:INFO:Creating metrics dataframe
2023-05-21 17:43:53,631:INFO:Uploading results into container
2023-05-21 17:43:53,633:INFO:Uploading model into container now
2023-05-21 17:43:53,635:INFO:_master_model_container: 3
2023-05-21 17:43:53,635:INFO:_display_container: 2
2023-05-21 17:43:53,637:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-05-21 17:43:53,638:INFO:create_model() successfully completed......................................
2023-05-21 17:43:53,755:INFO:SubProcess create_model() end ==================================
2023-05-21 17:43:53,755:INFO:Creating metrics dataframe
2023-05-21 17:43:53,778:INFO:Initializing Ridge Classifier
2023-05-21 17:43:53,778:INFO:Total runtime is 0.08514954249064129 minutes
2023-05-21 17:43:53,778:INFO:SubProcess create_model() called ==================================
2023-05-21 17:43:53,779:INFO:Initializing create_model()
2023-05-21 17:43:53,779:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc316092290>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc318b08fa0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:43:53,779:INFO:Checking exceptions
2023-05-21 17:43:53,780:INFO:Importing libraries
2023-05-21 17:43:53,780:INFO:Copying training dataset
2023-05-21 17:43:53,818:INFO:Defining folds
2023-05-21 17:43:53,818:INFO:Declaring metric variables
2023-05-21 17:43:53,819:INFO:Importing untrained model
2023-05-21 17:43:53,820:INFO:Ridge Classifier Imported successfully
2023-05-21 17:43:53,821:INFO:Starting cross validation
2023-05-21 17:43:53,829:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 17:43:54,416:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:43:54,496:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:43:54,534:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:43:54,559:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:43:54,587:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:43:54,602:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:43:54,624:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:43:54,683:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:43:54,701:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:43:54,860:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:43:54,998:INFO:Calculating mean and std
2023-05-21 17:43:55,001:INFO:Creating metrics dataframe
2023-05-21 17:43:55,101:INFO:Uploading results into container
2023-05-21 17:43:55,103:INFO:Uploading model into container now
2023-05-21 17:43:55,104:INFO:_master_model_container: 4
2023-05-21 17:43:55,105:INFO:_display_container: 2
2023-05-21 17:43:55,106:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-05-21 17:43:55,106:INFO:create_model() successfully completed......................................
2023-05-21 17:43:55,239:INFO:SubProcess create_model() end ==================================
2023-05-21 17:43:55,239:INFO:Creating metrics dataframe
2023-05-21 17:43:55,268:INFO:Initializing Random Forest Classifier
2023-05-21 17:43:55,268:INFO:Total runtime is 0.10998788674672445 minutes
2023-05-21 17:43:55,269:INFO:SubProcess create_model() called ==================================
2023-05-21 17:43:55,270:INFO:Initializing create_model()
2023-05-21 17:43:55,270:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc316092290>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc318b08fa0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:43:55,270:INFO:Checking exceptions
2023-05-21 17:43:55,270:INFO:Importing libraries
2023-05-21 17:43:55,270:INFO:Copying training dataset
2023-05-21 17:43:55,314:INFO:Defining folds
2023-05-21 17:43:55,315:INFO:Declaring metric variables
2023-05-21 17:43:55,315:INFO:Importing untrained model
2023-05-21 17:43:55,317:INFO:Random Forest Classifier Imported successfully
2023-05-21 17:43:55,318:INFO:Starting cross validation
2023-05-21 17:43:55,326:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 17:43:58,282:INFO:Calculating mean and std
2023-05-21 17:43:58,285:INFO:Creating metrics dataframe
2023-05-21 17:43:58,392:INFO:Uploading results into container
2023-05-21 17:43:58,394:INFO:Uploading model into container now
2023-05-21 17:43:58,396:INFO:_master_model_container: 5
2023-05-21 17:43:58,396:INFO:_display_container: 2
2023-05-21 17:43:58,399:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-05-21 17:43:58,399:INFO:create_model() successfully completed......................................
2023-05-21 17:43:58,528:INFO:SubProcess create_model() end ==================================
2023-05-21 17:43:58,528:INFO:Creating metrics dataframe
2023-05-21 17:43:58,555:INFO:Initializing Linear Discriminant Analysis
2023-05-21 17:43:58,555:INFO:Total runtime is 0.1647782603899638 minutes
2023-05-21 17:43:58,556:INFO:SubProcess create_model() called ==================================
2023-05-21 17:43:58,557:INFO:Initializing create_model()
2023-05-21 17:43:58,558:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc316092290>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc318b08fa0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:43:58,558:INFO:Checking exceptions
2023-05-21 17:43:58,558:INFO:Importing libraries
2023-05-21 17:43:58,558:INFO:Copying training dataset
2023-05-21 17:43:58,598:INFO:Defining folds
2023-05-21 17:43:58,598:INFO:Declaring metric variables
2023-05-21 17:43:58,599:INFO:Importing untrained model
2023-05-21 17:43:58,600:INFO:Linear Discriminant Analysis Imported successfully
2023-05-21 17:43:58,601:INFO:Starting cross validation
2023-05-21 17:43:58,609:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 17:44:00,031:INFO:Calculating mean and std
2023-05-21 17:44:00,033:INFO:Creating metrics dataframe
2023-05-21 17:44:00,132:INFO:Uploading results into container
2023-05-21 17:44:00,134:INFO:Uploading model into container now
2023-05-21 17:44:00,135:INFO:_master_model_container: 6
2023-05-21 17:44:00,135:INFO:_display_container: 2
2023-05-21 17:44:00,137:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-21 17:44:00,137:INFO:create_model() successfully completed......................................
2023-05-21 17:44:00,259:INFO:SubProcess create_model() end ==================================
2023-05-21 17:44:00,259:INFO:Creating metrics dataframe
2023-05-21 17:44:00,281:INFO:Initializing Extra Trees Classifier
2023-05-21 17:44:00,282:INFO:Total runtime is 0.1935475746790568 minutes
2023-05-21 17:44:00,282:INFO:SubProcess create_model() called ==================================
2023-05-21 17:44:00,283:INFO:Initializing create_model()
2023-05-21 17:44:00,283:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc316092290>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc318b08fa0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:44:00,284:INFO:Checking exceptions
2023-05-21 17:44:00,284:INFO:Importing libraries
2023-05-21 17:44:00,284:INFO:Copying training dataset
2023-05-21 17:44:00,327:INFO:Defining folds
2023-05-21 17:44:00,327:INFO:Declaring metric variables
2023-05-21 17:44:00,328:INFO:Importing untrained model
2023-05-21 17:44:00,330:INFO:Extra Trees Classifier Imported successfully
2023-05-21 17:44:00,331:INFO:Starting cross validation
2023-05-21 17:44:00,339:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 17:44:03,171:INFO:Calculating mean and std
2023-05-21 17:44:03,174:INFO:Creating metrics dataframe
2023-05-21 17:44:03,273:INFO:Uploading results into container
2023-05-21 17:44:03,275:INFO:Uploading model into container now
2023-05-21 17:44:03,276:INFO:_master_model_container: 7
2023-05-21 17:44:03,277:INFO:_display_container: 2
2023-05-21 17:44:03,279:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-05-21 17:44:03,279:INFO:create_model() successfully completed......................................
2023-05-21 17:44:03,404:INFO:SubProcess create_model() end ==================================
2023-05-21 17:44:03,404:INFO:Creating metrics dataframe
2023-05-21 17:44:03,427:INFO:Initializing Light Gradient Boosting Machine
2023-05-21 17:44:03,427:INFO:Total runtime is 0.24597286383310954 minutes
2023-05-21 17:44:03,428:INFO:SubProcess create_model() called ==================================
2023-05-21 17:44:03,428:INFO:Initializing create_model()
2023-05-21 17:44:03,429:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc316092290>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc318b08fa0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:44:03,429:INFO:Checking exceptions
2023-05-21 17:44:03,429:INFO:Importing libraries
2023-05-21 17:44:03,429:INFO:Copying training dataset
2023-05-21 17:44:03,468:INFO:Defining folds
2023-05-21 17:44:03,469:INFO:Declaring metric variables
2023-05-21 17:44:03,469:INFO:Importing untrained model
2023-05-21 17:44:03,472:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 17:44:03,473:INFO:Starting cross validation
2023-05-21 17:44:03,481:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 17:44:06,992:INFO:Calculating mean and std
2023-05-21 17:44:06,995:INFO:Creating metrics dataframe
2023-05-21 17:44:07,095:INFO:Uploading results into container
2023-05-21 17:44:07,098:INFO:Uploading model into container now
2023-05-21 17:44:07,099:INFO:_master_model_container: 8
2023-05-21 17:44:07,099:INFO:_display_container: 2
2023-05-21 17:44:07,102:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 17:44:07,102:INFO:create_model() successfully completed......................................
2023-05-21 17:44:07,227:INFO:SubProcess create_model() end ==================================
2023-05-21 17:44:07,227:INFO:Creating metrics dataframe
2023-05-21 17:44:07,260:INFO:Initializing create_model()
2023-05-21 17:44:07,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc316092290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:44:07,261:INFO:Checking exceptions
2023-05-21 17:44:07,264:INFO:Importing libraries
2023-05-21 17:44:07,264:INFO:Copying training dataset
2023-05-21 17:44:07,302:INFO:Defining folds
2023-05-21 17:44:07,302:INFO:Declaring metric variables
2023-05-21 17:44:07,303:INFO:Importing untrained model
2023-05-21 17:44:07,303:INFO:Declaring custom model
2023-05-21 17:44:07,308:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 17:44:07,316:INFO:Cross validation set to False
2023-05-21 17:44:07,316:INFO:Fitting Model
2023-05-21 17:44:07,799:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 17:44:07,799:INFO:create_model() successfully completed......................................
2023-05-21 17:44:07,917:INFO:Creating Dashboard logs
2023-05-21 17:44:07,919:INFO:Model: Light Gradient Boosting Machine
2023-05-21 17:44:08,095:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-21 17:44:09,054:INFO:Initializing predict_model()
2023-05-21 17:44:09,054:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc316092290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fc315249e10>)
2023-05-21 17:44:09,054:INFO:Checking exceptions
2023-05-21 17:44:09,055:INFO:Preloading libraries
2023-05-21 17:44:09,681:INFO:SubProcess plot_model() called ==================================
2023-05-21 17:44:09,684:INFO:Initializing plot_model()
2023-05-21 17:44:09,684:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp_vf37_9l, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc316092290>, system=False)
2023-05-21 17:44:09,685:INFO:Checking exceptions
2023-05-21 17:44:09,698:INFO:Preloading libraries
2023-05-21 17:44:09,702:INFO:Copying training dataset
2023-05-21 17:44:09,703:INFO:Plot type: auc
2023-05-21 17:44:10,204:INFO:Fitting Model
2023-05-21 17:44:10,211:INFO:Scoring test/hold-out set
2023-05-21 17:44:10,452:INFO:Saving '/tmp/tmp_vf37_9l/AUC.png'
2023-05-21 17:44:11,293:INFO:Visual Rendered Successfully
2023-05-21 17:44:11,435:INFO:plot_model() successfully completed......................................
2023-05-21 17:44:11,440:INFO:Initializing plot_model()
2023-05-21 17:44:11,440:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp_vf37_9l, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc316092290>, system=False)
2023-05-21 17:44:11,441:INFO:Checking exceptions
2023-05-21 17:44:11,460:INFO:Preloading libraries
2023-05-21 17:44:11,465:INFO:Copying training dataset
2023-05-21 17:44:11,466:INFO:Plot type: confusion_matrix
2023-05-21 17:44:12,029:INFO:Fitting Model
2023-05-21 17:44:12,033:INFO:Scoring test/hold-out set
2023-05-21 17:44:12,256:INFO:Saving '/tmp/tmp_vf37_9l/Confusion Matrix.png'
2023-05-21 17:44:12,663:INFO:Visual Rendered Successfully
2023-05-21 17:44:12,837:INFO:plot_model() successfully completed......................................
2023-05-21 17:44:12,843:INFO:Initializing plot_model()
2023-05-21 17:44:12,843:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp_vf37_9l, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc316092290>, system=False)
2023-05-21 17:44:12,844:INFO:Checking exceptions
2023-05-21 17:44:12,879:INFO:Preloading libraries
2023-05-21 17:44:12,903:INFO:Copying training dataset
2023-05-21 17:44:12,903:INFO:Plot type: feature
2023-05-21 17:44:12,913:WARNING:No coef_ found. Trying feature_importances_
2023-05-21 17:44:13,246:INFO:Saving '/tmp/tmp_vf37_9l/Feature Importance.png'
2023-05-21 17:44:13,938:INFO:Visual Rendered Successfully
2023-05-21 17:44:14,069:INFO:plot_model() successfully completed......................................
2023-05-21 17:44:14,070:INFO:SubProcess plot_model() end ==================================
2023-05-21 17:44:14,455:INFO:Creating Dashboard logs
2023-05-21 17:44:14,456:INFO:Model: Random Forest Classifier
2023-05-21 17:44:14,577:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 17:44:15,741:INFO:Creating Dashboard logs
2023-05-21 17:44:15,743:INFO:Model: Extra Trees Classifier
2023-05-21 17:44:15,866:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 17:44:17,109:INFO:Creating Dashboard logs
2023-05-21 17:44:17,110:INFO:Model: Decision Tree Classifier
2023-05-21 17:44:17,224:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2023-05-21 17:44:18,680:INFO:Creating Dashboard logs
2023-05-21 17:44:18,683:INFO:Model: Logistic Regression
2023-05-21 17:44:18,911:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-05-21 17:44:20,848:INFO:Creating Dashboard logs
2023-05-21 17:44:20,850:INFO:Model: Linear Discriminant Analysis
2023-05-21 17:44:21,034:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-05-21 17:44:22,881:INFO:Creating Dashboard logs
2023-05-21 17:44:22,882:INFO:Model: Naive Bayes
2023-05-21 17:44:23,125:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-05-21 17:44:24,700:INFO:Creating Dashboard logs
2023-05-21 17:44:24,701:INFO:Model: Ridge Classifier
2023-05-21 17:44:24,848:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2023-05-21 17:44:26,417:INFO:_master_model_container: 8
2023-05-21 17:44:26,417:INFO:_display_container: 2
2023-05-21 17:44:26,422:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 17:44:26,422:INFO:compare_models() successfully completed......................................
2023-05-21 17:47:58,034:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 17:47:58,034:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 17:47:58,034:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 17:47:58,034:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 17:48:00,456:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-21 17:55:27,487:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 17:55:27,488:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 17:55:27,488:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 17:55:27,488:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 17:55:28,349:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-21 17:56:01,714:INFO:PyCaret ClassificationExperiment
2023-05-21 17:56:01,714:INFO:Logging name: Lead_Scoring_Training_Pipeline
2023-05-21 17:56:01,714:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-21 17:56:01,714:INFO:version 3.0.0
2023-05-21 17:56:01,714:INFO:Initializing setup()
2023-05-21 17:56:01,714:INFO:self.USI: 10b1
2023-05-21 17:56:01,715:INFO:self._variable_keys: {'logging_param', 'X_train', 'fold_shuffle_param', '_ml_usecase', '_available_plots', 'fold_generator', 'X_test', 'memory', 'n_jobs_param', 'log_plots_param', 'y', 'seed', 'fold_groups_param', 'pipeline', 'target_param', 'y_train', 'exp_id', 'gpu_param', 'gpu_n_jobs_param', 'y_test', 'is_multiclass', 'fix_imbalance', 'USI', 'X', 'exp_name_log', 'data', 'html_param', 'idx'}
2023-05-21 17:56:01,715:INFO:Checking environment
2023-05-21 17:56:01,715:INFO:python_version: 3.10.10
2023-05-21 17:56:01,715:INFO:python_build: ('main', 'Mar  5 2023 22:26:53')
2023-05-21 17:56:01,715:INFO:machine: x86_64
2023-05-21 17:56:01,717:INFO:platform: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 17:56:01,717:INFO:Memory: svmem(total=16717086720, available=8211038208, percent=50.9, used=6013849600, free=6751457280, active=5374050304, inactive=3260256256, buffers=31842304, cached=3919937536, shared=2073272320, slab=425033728)
2023-05-21 17:56:01,720:INFO:Physical Core: 6
2023-05-21 17:56:01,720:INFO:Logical Core: 12
2023-05-21 17:56:01,720:INFO:Checking libraries
2023-05-21 17:56:01,720:INFO:System:
2023-05-21 17:56:01,720:INFO:    python: 3.10.10 (main, Mar  5 2023, 22:26:53) [GCC 12.2.1 20230201]
2023-05-21 17:56:01,721:INFO:executable: /usr/bin/python3.10
2023-05-21 17:56:01,721:INFO:   machine: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 17:56:01,721:INFO:PyCaret required dependencies:
2023-05-21 17:56:01,721:INFO:                 pip: 23.0.1
2023-05-21 17:56:01,722:INFO:          setuptools: 67.6.1
2023-05-21 17:56:01,722:INFO:             pycaret: 3.0.0
2023-05-21 17:56:01,722:INFO:             IPython: 8.12.0
2023-05-21 17:56:01,722:INFO:          ipywidgets: 7.7.5
2023-05-21 17:56:01,722:INFO:                tqdm: 4.64.1
2023-05-21 17:56:01,722:INFO:               numpy: 1.23.0
2023-05-21 17:56:01,722:INFO:              pandas: 1.5.3
2023-05-21 17:56:01,723:INFO:              jinja2: 3.1.2
2023-05-21 17:56:01,723:INFO:               scipy: 1.9.3
2023-05-21 17:56:01,723:INFO:              joblib: 1.2.0
2023-05-21 17:56:01,723:INFO:             sklearn: 1.2.2
2023-05-21 17:56:01,723:INFO:                pyod: 1.0.9
2023-05-21 17:56:01,723:INFO:            imblearn: 0.10.1
2023-05-21 17:56:01,724:INFO:   category_encoders: 2.6.0
2023-05-21 17:56:01,724:INFO:            lightgbm: 3.3.5
2023-05-21 17:56:01,724:INFO:               numba: 0.57.0
2023-05-21 17:56:01,724:INFO:            requests: 2.28.2
2023-05-21 17:56:01,724:INFO:          matplotlib: 3.6.3
2023-05-21 17:56:01,724:INFO:          scikitplot: 0.3.7
2023-05-21 17:56:01,724:INFO:         yellowbrick: 1.5
2023-05-21 17:56:01,725:INFO:              plotly: 5.14.1
2023-05-21 17:56:01,725:INFO:             kaleido: 0.2.1
2023-05-21 17:56:01,725:INFO:         statsmodels: 0.13.5
2023-05-21 17:56:01,725:INFO:              sktime: 0.18.0
2023-05-21 17:56:01,725:INFO:               tbats: 1.1.3
2023-05-21 17:56:01,726:INFO:            pmdarima: 2.0.3
2023-05-21 17:56:01,726:INFO:              psutil: 5.9.4
2023-05-21 17:56:01,726:INFO:PyCaret optional dependencies:
2023-05-21 17:56:01,766:INFO:                shap: 0.41.0
2023-05-21 17:56:01,766:INFO:           interpret: 0.3.2
2023-05-21 17:56:01,766:INFO:                umap: 0.5.3
2023-05-21 17:56:01,766:INFO:    pandas_profiling: 3.6.6
2023-05-21 17:56:01,766:INFO:  explainerdashboard: 0.4.2.2
2023-05-21 17:56:01,767:INFO:             autoviz: 0.1.603
2023-05-21 17:56:01,767:INFO:           fairlearn: 0.7.0
2023-05-21 17:56:01,767:INFO:             xgboost: 1.7.5
2023-05-21 17:56:01,767:INFO:            catboost: Not installed
2023-05-21 17:56:01,767:INFO:              kmodes: Not installed
2023-05-21 17:56:01,767:INFO:             mlxtend: Not installed
2023-05-21 17:56:01,768:INFO:       statsforecast: Not installed
2023-05-21 17:56:01,768:INFO:        tune_sklearn: Not installed
2023-05-21 17:56:01,768:INFO:                 ray: Not installed
2023-05-21 17:56:01,768:INFO:            hyperopt: Not installed
2023-05-21 17:56:01,768:INFO:              optuna: 3.1.1
2023-05-21 17:56:01,768:INFO:               skopt: Not installed
2023-05-21 17:56:01,769:INFO:              mlflow: 2.3.1
2023-05-21 17:56:01,769:INFO:              gradio: Not installed
2023-05-21 17:56:01,769:INFO:             fastapi: Not installed
2023-05-21 17:56:01,769:INFO:             uvicorn: Not installed
2023-05-21 17:56:01,769:INFO:              m2cgen: Not installed
2023-05-21 17:56:01,769:INFO:           evidently: Not installed
2023-05-21 17:56:01,770:INFO:               fugue: Not installed
2023-05-21 17:56:01,770:INFO:           streamlit: Not installed
2023-05-21 17:56:01,770:INFO:             prophet: Not installed
2023-05-21 17:56:01,770:INFO:None
2023-05-21 17:56:01,770:INFO:Set up data.
2023-05-21 17:56:01,996:INFO:Set up train/test split.
2023-05-21 17:56:01,996:INFO:Set up data.
2023-05-21 17:56:02,067:INFO:Set up index.
2023-05-21 17:56:02,067:INFO:Set up folding strategy.
2023-05-21 17:56:02,068:INFO:Assigning column types.
2023-05-21 17:56:02,085:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-21 17:56:02,135:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 17:56:02,146:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 17:56:02,220:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 17:56:02,368:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 17:56:02,425:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 17:56:02,426:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 17:56:02,457:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 17:56:02,460:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 17:56:02,461:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-21 17:56:02,511:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 17:56:02,548:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 17:56:02,552:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 17:56:02,602:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 17:56:02,635:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 17:56:02,638:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 17:56:02,639:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-21 17:56:02,729:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 17:56:02,732:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 17:56:02,815:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 17:56:02,818:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 17:56:02,823:INFO:Preparing preprocessing pipeline...
2023-05-21 17:56:02,827:INFO:Set up simple imputation.
2023-05-21 17:56:02,847:INFO:Set up encoding of categorical features.
2023-05-21 17:56:03,210:INFO:Finished creating preprocessing pipeline.
2023-05-21 17:56:03,267:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 17:56:03,267:INFO:Creating final display dataframe.
2023-05-21 17:56:03,787:INFO:Setup _display_container:                     Description                           Value
0                    Session id                              42
1                        Target               app_complete_flag
2                   Target type                          Binary
3           Original data shape                     (238964, 7)
4        Transformed data shape                    (238964, 39)
5   Transformed train set shape                    (191171, 39)
6    Transformed test set shape                     (47793, 39)
7              Numeric features                               3
8          Categorical features                               3
9                    Preprocess                            True
10              Imputation type                          simple
11           Numeric imputation                            mean
12       Categorical imputation                            mode
13     Maximum one-hot encoding                              25
14              Encoding method                            None
15               Fold Generator                 StratifiedKFold
16                  Fold Number                              10
17                     CPU Jobs                              -1
18                      Use GPU                           False
19               Log Experiment                    MlflowLogger
20              Experiment Name  Lead_Scoring_Training_Pipeline
21                          USI                            10b1
2023-05-21 17:56:03,893:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 17:56:03,897:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 17:56:03,978:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 17:56:03,981:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 17:56:03,983:INFO:Logging experiment in loggers
2023-05-21 17:56:04,664:INFO:SubProcess save_model() called ==================================
2023-05-21 17:56:04,781:INFO:Initializing save_model()
2023-05-21 17:56:04,782:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/tmp/tmpbdnygshp/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-21 17:56:04,782:INFO:Adding model into prep_pipe
2023-05-21 17:56:04,789:WARNING:Only Model saved as it was a pipeline.
2023-05-21 17:56:04,832:INFO:/tmp/tmpbdnygshp/Transformation Pipeline.pkl saved in current working directory
2023-05-21 17:56:04,872:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped', 'city_tier',
                                             'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 T...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-05-21 17:56:04,872:INFO:save_model() successfully completed......................................
2023-05-21 17:56:05,028:INFO:SubProcess save_model() end ==================================
2023-05-21 17:56:05,654:INFO:setup() successfully completed in 2.36s...............
2023-05-21 17:56:12,204:INFO:Initializing compare_models()
2023-05-21 17:56:12,205:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f094799ed40>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f094799ed40>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'])
2023-05-21 17:56:12,205:INFO:Checking exceptions
2023-05-21 17:56:12,236:INFO:Preparing display monitor
2023-05-21 17:56:12,248:INFO:Initializing Logistic Regression
2023-05-21 17:56:12,249:INFO:Total runtime is 4.585584004720052e-06 minutes
2023-05-21 17:56:12,249:INFO:SubProcess create_model() called ==================================
2023-05-21 17:56:12,250:INFO:Initializing create_model()
2023-05-21 17:56:12,250:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f094799ed40>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f09327a4f10>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:56:12,250:INFO:Checking exceptions
2023-05-21 17:56:12,250:INFO:Importing libraries
2023-05-21 17:56:12,250:INFO:Copying training dataset
2023-05-21 17:56:12,295:INFO:Defining folds
2023-05-21 17:56:12,295:INFO:Declaring metric variables
2023-05-21 17:56:12,296:INFO:Importing untrained model
2023-05-21 17:56:12,298:INFO:Logistic Regression Imported successfully
2023-05-21 17:56:12,299:INFO:Starting cross validation
2023-05-21 17:56:12,308:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 17:56:19,956:INFO:Calculating mean and std
2023-05-21 17:56:19,958:INFO:Creating metrics dataframe
2023-05-21 17:56:20,057:INFO:Uploading results into container
2023-05-21 17:56:20,059:INFO:Uploading model into container now
2023-05-21 17:56:20,061:INFO:_master_model_container: 1
2023-05-21 17:56:20,061:INFO:_display_container: 2
2023-05-21 17:56:20,063:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-21 17:56:20,063:INFO:create_model() successfully completed......................................
2023-05-21 17:56:20,184:INFO:SubProcess create_model() end ==================================
2023-05-21 17:56:20,184:INFO:Creating metrics dataframe
2023-05-21 17:56:20,206:INFO:Initializing Naive Bayes
2023-05-21 17:56:20,206:INFO:Total runtime is 0.13262385527292886 minutes
2023-05-21 17:56:20,207:INFO:SubProcess create_model() called ==================================
2023-05-21 17:56:20,207:INFO:Initializing create_model()
2023-05-21 17:56:20,208:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f094799ed40>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f09327a4f10>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:56:20,208:INFO:Checking exceptions
2023-05-21 17:56:20,208:INFO:Importing libraries
2023-05-21 17:56:20,208:INFO:Copying training dataset
2023-05-21 17:56:20,250:INFO:Defining folds
2023-05-21 17:56:20,251:INFO:Declaring metric variables
2023-05-21 17:56:20,251:INFO:Importing untrained model
2023-05-21 17:56:20,252:INFO:Naive Bayes Imported successfully
2023-05-21 17:56:20,253:INFO:Starting cross validation
2023-05-21 17:56:20,261:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 17:56:23,945:INFO:Calculating mean and std
2023-05-21 17:56:23,948:INFO:Creating metrics dataframe
2023-05-21 17:56:24,048:INFO:Uploading results into container
2023-05-21 17:56:24,050:INFO:Uploading model into container now
2023-05-21 17:56:24,051:INFO:_master_model_container: 2
2023-05-21 17:56:24,052:INFO:_display_container: 2
2023-05-21 17:56:24,052:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-21 17:56:24,052:INFO:create_model() successfully completed......................................
2023-05-21 17:56:24,163:INFO:SubProcess create_model() end ==================================
2023-05-21 17:56:24,163:INFO:Creating metrics dataframe
2023-05-21 17:56:24,186:INFO:Initializing Decision Tree Classifier
2023-05-21 17:56:24,186:INFO:Total runtime is 0.19896598656972247 minutes
2023-05-21 17:56:24,187:INFO:SubProcess create_model() called ==================================
2023-05-21 17:56:24,188:INFO:Initializing create_model()
2023-05-21 17:56:24,188:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f094799ed40>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f09327a4f10>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:56:24,188:INFO:Checking exceptions
2023-05-21 17:56:24,188:INFO:Importing libraries
2023-05-21 17:56:24,188:INFO:Copying training dataset
2023-05-21 17:56:24,233:INFO:Defining folds
2023-05-21 17:56:24,233:INFO:Declaring metric variables
2023-05-21 17:56:24,234:INFO:Importing untrained model
2023-05-21 17:56:24,236:INFO:Decision Tree Classifier Imported successfully
2023-05-21 17:56:24,237:INFO:Starting cross validation
2023-05-21 17:56:24,244:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 17:56:25,549:INFO:Calculating mean and std
2023-05-21 17:56:25,551:INFO:Creating metrics dataframe
2023-05-21 17:56:25,632:INFO:Uploading results into container
2023-05-21 17:56:25,634:INFO:Uploading model into container now
2023-05-21 17:56:25,636:INFO:_master_model_container: 3
2023-05-21 17:56:25,636:INFO:_display_container: 2
2023-05-21 17:56:25,638:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-05-21 17:56:25,638:INFO:create_model() successfully completed......................................
2023-05-21 17:56:25,766:INFO:SubProcess create_model() end ==================================
2023-05-21 17:56:25,767:INFO:Creating metrics dataframe
2023-05-21 17:56:25,790:INFO:Initializing Ridge Classifier
2023-05-21 17:56:25,791:INFO:Total runtime is 0.2257047176361084 minutes
2023-05-21 17:56:25,791:INFO:SubProcess create_model() called ==================================
2023-05-21 17:56:25,792:INFO:Initializing create_model()
2023-05-21 17:56:25,792:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f094799ed40>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f09327a4f10>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:56:25,792:INFO:Checking exceptions
2023-05-21 17:56:25,792:INFO:Importing libraries
2023-05-21 17:56:25,793:INFO:Copying training dataset
2023-05-21 17:56:25,834:INFO:Defining folds
2023-05-21 17:56:25,834:INFO:Declaring metric variables
2023-05-21 17:56:25,835:INFO:Importing untrained model
2023-05-21 17:56:25,837:INFO:Ridge Classifier Imported successfully
2023-05-21 17:56:25,838:INFO:Starting cross validation
2023-05-21 17:56:25,846:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 17:56:26,457:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:56:26,458:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:56:26,524:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:56:26,591:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:56:26,609:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:56:26,630:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:56:26,632:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:56:26,642:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:56:26,686:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:56:26,704:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 17:56:27,026:INFO:Calculating mean and std
2023-05-21 17:56:27,029:INFO:Creating metrics dataframe
2023-05-21 17:56:27,126:INFO:Uploading results into container
2023-05-21 17:56:27,128:INFO:Uploading model into container now
2023-05-21 17:56:27,130:INFO:_master_model_container: 4
2023-05-21 17:56:27,130:INFO:_display_container: 2
2023-05-21 17:56:27,132:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-05-21 17:56:27,132:INFO:create_model() successfully completed......................................
2023-05-21 17:56:27,241:INFO:SubProcess create_model() end ==================================
2023-05-21 17:56:27,242:INFO:Creating metrics dataframe
2023-05-21 17:56:27,264:INFO:Initializing Random Forest Classifier
2023-05-21 17:56:27,264:INFO:Total runtime is 0.2502675414085388 minutes
2023-05-21 17:56:27,265:INFO:SubProcess create_model() called ==================================
2023-05-21 17:56:27,266:INFO:Initializing create_model()
2023-05-21 17:56:27,266:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f094799ed40>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f09327a4f10>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:56:27,266:INFO:Checking exceptions
2023-05-21 17:56:27,266:INFO:Importing libraries
2023-05-21 17:56:27,266:INFO:Copying training dataset
2023-05-21 17:56:27,303:INFO:Defining folds
2023-05-21 17:56:27,303:INFO:Declaring metric variables
2023-05-21 17:56:27,304:INFO:Importing untrained model
2023-05-21 17:56:27,306:INFO:Random Forest Classifier Imported successfully
2023-05-21 17:56:27,307:INFO:Starting cross validation
2023-05-21 17:56:27,315:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 17:56:30,119:INFO:Calculating mean and std
2023-05-21 17:56:30,122:INFO:Creating metrics dataframe
2023-05-21 17:56:30,220:INFO:Uploading results into container
2023-05-21 17:56:30,224:INFO:Uploading model into container now
2023-05-21 17:56:30,226:INFO:_master_model_container: 5
2023-05-21 17:56:30,226:INFO:_display_container: 2
2023-05-21 17:56:30,228:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-05-21 17:56:30,229:INFO:create_model() successfully completed......................................
2023-05-21 17:56:30,339:INFO:SubProcess create_model() end ==================================
2023-05-21 17:56:30,339:INFO:Creating metrics dataframe
2023-05-21 17:56:30,361:INFO:Initializing Linear Discriminant Analysis
2023-05-21 17:56:30,362:INFO:Total runtime is 0.3018889307975769 minutes
2023-05-21 17:56:30,362:INFO:SubProcess create_model() called ==================================
2023-05-21 17:56:30,363:INFO:Initializing create_model()
2023-05-21 17:56:30,363:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f094799ed40>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f09327a4f10>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:56:30,363:INFO:Checking exceptions
2023-05-21 17:56:30,363:INFO:Importing libraries
2023-05-21 17:56:30,364:INFO:Copying training dataset
2023-05-21 17:56:30,401:INFO:Defining folds
2023-05-21 17:56:30,401:INFO:Declaring metric variables
2023-05-21 17:56:30,402:INFO:Importing untrained model
2023-05-21 17:56:30,403:INFO:Linear Discriminant Analysis Imported successfully
2023-05-21 17:56:30,404:INFO:Starting cross validation
2023-05-21 17:56:30,412:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 17:56:31,671:INFO:Calculating mean and std
2023-05-21 17:56:31,673:INFO:Creating metrics dataframe
2023-05-21 17:56:31,770:INFO:Uploading results into container
2023-05-21 17:56:31,772:INFO:Uploading model into container now
2023-05-21 17:56:31,774:INFO:_master_model_container: 6
2023-05-21 17:56:31,774:INFO:_display_container: 2
2023-05-21 17:56:31,775:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-21 17:56:31,775:INFO:create_model() successfully completed......................................
2023-05-21 17:56:31,885:INFO:SubProcess create_model() end ==================================
2023-05-21 17:56:31,886:INFO:Creating metrics dataframe
2023-05-21 17:56:31,908:INFO:Initializing Extra Trees Classifier
2023-05-21 17:56:31,908:INFO:Total runtime is 0.3276671131451925 minutes
2023-05-21 17:56:31,909:INFO:SubProcess create_model() called ==================================
2023-05-21 17:56:31,910:INFO:Initializing create_model()
2023-05-21 17:56:31,910:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f094799ed40>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f09327a4f10>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:56:31,910:INFO:Checking exceptions
2023-05-21 17:56:31,910:INFO:Importing libraries
2023-05-21 17:56:31,910:INFO:Copying training dataset
2023-05-21 17:56:31,947:INFO:Defining folds
2023-05-21 17:56:31,947:INFO:Declaring metric variables
2023-05-21 17:56:31,948:INFO:Importing untrained model
2023-05-21 17:56:31,950:INFO:Extra Trees Classifier Imported successfully
2023-05-21 17:56:31,951:INFO:Starting cross validation
2023-05-21 17:56:31,959:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 17:56:34,867:INFO:Calculating mean and std
2023-05-21 17:56:34,869:INFO:Creating metrics dataframe
2023-05-21 17:56:34,967:INFO:Uploading results into container
2023-05-21 17:56:34,969:INFO:Uploading model into container now
2023-05-21 17:56:34,970:INFO:_master_model_container: 7
2023-05-21 17:56:34,970:INFO:_display_container: 2
2023-05-21 17:56:34,973:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-05-21 17:56:34,973:INFO:create_model() successfully completed......................................
2023-05-21 17:56:35,083:INFO:SubProcess create_model() end ==================================
2023-05-21 17:56:35,083:INFO:Creating metrics dataframe
2023-05-21 17:56:35,106:INFO:Initializing Light Gradient Boosting Machine
2023-05-21 17:56:35,106:INFO:Total runtime is 0.3809588114420573 minutes
2023-05-21 17:56:35,106:INFO:SubProcess create_model() called ==================================
2023-05-21 17:56:35,107:INFO:Initializing create_model()
2023-05-21 17:56:35,107:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f094799ed40>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f09327a4f10>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:56:35,107:INFO:Checking exceptions
2023-05-21 17:56:35,108:INFO:Importing libraries
2023-05-21 17:56:35,108:INFO:Copying training dataset
2023-05-21 17:56:35,145:INFO:Defining folds
2023-05-21 17:56:35,145:INFO:Declaring metric variables
2023-05-21 17:56:35,145:INFO:Importing untrained model
2023-05-21 17:56:35,148:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 17:56:35,149:INFO:Starting cross validation
2023-05-21 17:56:35,156:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 17:56:36,726:INFO:Calculating mean and std
2023-05-21 17:56:36,728:INFO:Creating metrics dataframe
2023-05-21 17:56:36,788:INFO:Uploading results into container
2023-05-21 17:56:36,791:INFO:Uploading model into container now
2023-05-21 17:56:36,794:INFO:_master_model_container: 8
2023-05-21 17:56:36,794:INFO:_display_container: 2
2023-05-21 17:56:36,800:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 17:56:36,800:INFO:create_model() successfully completed......................................
2023-05-21 17:56:36,912:INFO:SubProcess create_model() end ==================================
2023-05-21 17:56:36,913:INFO:Creating metrics dataframe
2023-05-21 17:56:36,946:INFO:Initializing create_model()
2023-05-21 17:56:36,946:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f094799ed40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-21 17:56:36,946:INFO:Checking exceptions
2023-05-21 17:56:36,949:INFO:Importing libraries
2023-05-21 17:56:36,949:INFO:Copying training dataset
2023-05-21 17:56:36,986:INFO:Defining folds
2023-05-21 17:56:36,986:INFO:Declaring metric variables
2023-05-21 17:56:36,987:INFO:Importing untrained model
2023-05-21 17:56:36,987:INFO:Declaring custom model
2023-05-21 17:56:36,992:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 17:56:36,999:INFO:Cross validation set to False
2023-05-21 17:56:37,000:INFO:Fitting Model
2023-05-21 17:56:37,476:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 17:56:37,477:INFO:create_model() successfully completed......................................
2023-05-21 17:56:37,588:INFO:Creating Dashboard logs
2023-05-21 17:56:37,589:INFO:Model: Light Gradient Boosting Machine
2023-05-21 17:56:37,717:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-21 17:56:38,463:INFO:Initializing predict_model()
2023-05-21 17:56:38,463:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f094799ed40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7f093438caf0>)
2023-05-21 17:56:38,464:INFO:Checking exceptions
2023-05-21 17:56:38,464:INFO:Preloading libraries
2023-05-21 17:56:39,094:INFO:SubProcess plot_model() called ==================================
2023-05-21 17:56:39,097:INFO:Initializing plot_model()
2023-05-21 17:56:39,097:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpj6dufoxg, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f094799ed40>, system=False)
2023-05-21 17:56:39,097:INFO:Checking exceptions
2023-05-21 17:56:39,110:INFO:Preloading libraries
2023-05-21 17:56:39,115:INFO:Copying training dataset
2023-05-21 17:56:39,115:INFO:Plot type: auc
2023-05-21 17:56:39,657:INFO:Fitting Model
2023-05-21 17:56:39,664:INFO:Scoring test/hold-out set
2023-05-21 17:56:39,989:INFO:Saving '/tmp/tmpj6dufoxg/AUC.png'
2023-05-21 17:56:40,992:INFO:Visual Rendered Successfully
2023-05-21 17:56:41,114:INFO:plot_model() successfully completed......................................
2023-05-21 17:56:41,118:INFO:Initializing plot_model()
2023-05-21 17:56:41,119:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpj6dufoxg, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f094799ed40>, system=False)
2023-05-21 17:56:41,119:INFO:Checking exceptions
2023-05-21 17:56:41,136:INFO:Preloading libraries
2023-05-21 17:56:41,142:INFO:Copying training dataset
2023-05-21 17:56:41,143:INFO:Plot type: confusion_matrix
2023-05-21 17:56:41,726:INFO:Fitting Model
2023-05-21 17:56:41,729:INFO:Scoring test/hold-out set
2023-05-21 17:56:42,076:INFO:Saving '/tmp/tmpj6dufoxg/Confusion Matrix.png'
2023-05-21 17:56:42,565:INFO:Visual Rendered Successfully
2023-05-21 17:56:42,690:INFO:plot_model() successfully completed......................................
2023-05-21 17:56:42,693:INFO:Initializing plot_model()
2023-05-21 17:56:42,693:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpj6dufoxg, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f094799ed40>, system=False)
2023-05-21 17:56:42,694:INFO:Checking exceptions
2023-05-21 17:56:42,707:INFO:Preloading libraries
2023-05-21 17:56:42,715:INFO:Copying training dataset
2023-05-21 17:56:42,715:INFO:Plot type: feature
2023-05-21 17:56:42,718:WARNING:No coef_ found. Trying feature_importances_
2023-05-21 17:56:43,028:INFO:Saving '/tmp/tmpj6dufoxg/Feature Importance.png'
2023-05-21 17:56:43,826:INFO:Visual Rendered Successfully
2023-05-21 17:56:44,005:INFO:plot_model() successfully completed......................................
2023-05-21 17:56:44,006:INFO:SubProcess plot_model() end ==================================
2023-05-21 17:56:44,013:WARNING:/home/feuer/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-05-21 17:56:44,420:INFO:Creating Dashboard logs
2023-05-21 17:56:44,422:INFO:Model: Random Forest Classifier
2023-05-21 17:56:44,561:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 17:56:45,679:INFO:Creating Dashboard logs
2023-05-21 17:56:45,681:INFO:Model: Extra Trees Classifier
2023-05-21 17:56:45,801:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 17:56:46,937:INFO:Creating Dashboard logs
2023-05-21 17:56:46,938:INFO:Model: Decision Tree Classifier
2023-05-21 17:56:47,050:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2023-05-21 17:56:48,221:INFO:Creating Dashboard logs
2023-05-21 17:56:48,223:INFO:Model: Logistic Regression
2023-05-21 17:56:48,343:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-05-21 17:56:49,337:INFO:Creating Dashboard logs
2023-05-21 17:56:49,338:INFO:Model: Linear Discriminant Analysis
2023-05-21 17:56:49,459:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-05-21 17:56:50,498:INFO:Creating Dashboard logs
2023-05-21 17:56:50,499:INFO:Model: Naive Bayes
2023-05-21 17:56:50,617:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-05-21 17:56:51,743:INFO:Creating Dashboard logs
2023-05-21 17:56:51,744:INFO:Model: Ridge Classifier
2023-05-21 17:56:51,860:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2023-05-21 17:56:53,078:INFO:_master_model_container: 8
2023-05-21 17:56:53,078:INFO:_display_container: 2
2023-05-21 17:56:53,082:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 17:56:53,082:INFO:compare_models() successfully completed......................................
2023-05-21 17:59:31,655:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 17:59:31,655:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 17:59:31,656:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 17:59:31,656:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 17:59:32,546:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-21 18:06:21,134:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 18:06:21,134:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 18:06:21,135:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 18:06:21,135:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 18:06:21,990:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-21 18:18:14,390:WARNING:<ipython-input-32-a343299b24ba>:1: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.
  encoded_df2 = pd.concat(encoded_df, placeholder_df)

2023-05-21 18:20:31,933:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 18:20:31,934:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 18:20:31,934:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 18:20:31,934:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 18:20:32,811:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-21 18:21:26,964:INFO:PyCaret ClassificationExperiment
2023-05-21 18:21:26,964:INFO:Logging name: Lead_Scoring_Training_Pipeline
2023-05-21 18:21:26,964:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-21 18:21:26,965:INFO:version 3.0.0
2023-05-21 18:21:26,965:INFO:Initializing setup()
2023-05-21 18:21:26,965:INFO:self.USI: b252
2023-05-21 18:21:26,965:INFO:self._variable_keys: {'_ml_usecase', '_available_plots', 'exp_id', 'pipeline', 'data', 'fold_shuffle_param', 'n_jobs_param', 'y', 'X', 'gpu_n_jobs_param', 'exp_name_log', 'log_plots_param', 'fold_generator', 'fold_groups_param', 'USI', 'html_param', 'fix_imbalance', 'y_train', 'is_multiclass', 'memory', 'y_test', 'idx', 'logging_param', 'X_train', 'gpu_param', 'seed', 'X_test', 'target_param'}
2023-05-21 18:21:26,965:INFO:Checking environment
2023-05-21 18:21:26,965:INFO:python_version: 3.10.10
2023-05-21 18:21:26,966:INFO:python_build: ('main', 'Mar  5 2023 22:26:53')
2023-05-21 18:21:26,966:INFO:machine: x86_64
2023-05-21 18:21:26,968:INFO:platform: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 18:21:26,968:INFO:Memory: svmem(total=16717086720, available=6507024384, percent=61.1, used=7644073984, free=4699234304, active=6857535488, inactive=3785494528, buffers=56791040, cached=4316987392, shared=2147053568, slab=438456320)
2023-05-21 18:21:26,971:INFO:Physical Core: 6
2023-05-21 18:21:26,971:INFO:Logical Core: 12
2023-05-21 18:21:26,971:INFO:Checking libraries
2023-05-21 18:21:26,972:INFO:System:
2023-05-21 18:21:26,972:INFO:    python: 3.10.10 (main, Mar  5 2023, 22:26:53) [GCC 12.2.1 20230201]
2023-05-21 18:21:26,972:INFO:executable: /usr/bin/python3.10
2023-05-21 18:21:26,972:INFO:   machine: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 18:21:26,972:INFO:PyCaret required dependencies:
2023-05-21 18:21:26,973:INFO:                 pip: 23.0.1
2023-05-21 18:21:26,973:INFO:          setuptools: 67.6.1
2023-05-21 18:21:26,973:INFO:             pycaret: 3.0.0
2023-05-21 18:21:26,973:INFO:             IPython: 8.12.0
2023-05-21 18:21:26,973:INFO:          ipywidgets: 7.7.5
2023-05-21 18:21:26,973:INFO:                tqdm: 4.64.1
2023-05-21 18:21:26,974:INFO:               numpy: 1.23.0
2023-05-21 18:21:26,974:INFO:              pandas: 1.5.3
2023-05-21 18:21:26,974:INFO:              jinja2: 3.1.2
2023-05-21 18:21:26,974:INFO:               scipy: 1.9.3
2023-05-21 18:21:26,974:INFO:              joblib: 1.2.0
2023-05-21 18:21:26,974:INFO:             sklearn: 1.2.2
2023-05-21 18:21:26,974:INFO:                pyod: 1.0.9
2023-05-21 18:21:26,975:INFO:            imblearn: 0.10.1
2023-05-21 18:21:26,975:INFO:   category_encoders: 2.6.0
2023-05-21 18:21:26,975:INFO:            lightgbm: 3.3.5
2023-05-21 18:21:26,975:INFO:               numba: 0.57.0
2023-05-21 18:21:26,975:INFO:            requests: 2.28.2
2023-05-21 18:21:26,975:INFO:          matplotlib: 3.6.3
2023-05-21 18:21:26,975:INFO:          scikitplot: 0.3.7
2023-05-21 18:21:26,976:INFO:         yellowbrick: 1.5
2023-05-21 18:21:26,976:INFO:              plotly: 5.14.1
2023-05-21 18:21:26,976:INFO:             kaleido: 0.2.1
2023-05-21 18:21:26,976:INFO:         statsmodels: 0.13.5
2023-05-21 18:21:26,976:INFO:              sktime: 0.18.0
2023-05-21 18:21:26,976:INFO:               tbats: 1.1.3
2023-05-21 18:21:26,976:INFO:            pmdarima: 2.0.3
2023-05-21 18:21:26,977:INFO:              psutil: 5.9.4
2023-05-21 18:21:26,977:INFO:PyCaret optional dependencies:
2023-05-21 18:21:27,016:INFO:                shap: 0.41.0
2023-05-21 18:21:27,016:INFO:           interpret: 0.3.2
2023-05-21 18:21:27,017:INFO:                umap: 0.5.3
2023-05-21 18:21:27,017:INFO:    pandas_profiling: 3.6.6
2023-05-21 18:21:27,017:INFO:  explainerdashboard: 0.4.2.2
2023-05-21 18:21:27,017:INFO:             autoviz: 0.1.603
2023-05-21 18:21:27,017:INFO:           fairlearn: 0.7.0
2023-05-21 18:21:27,017:INFO:             xgboost: 1.7.5
2023-05-21 18:21:27,018:INFO:            catboost: Not installed
2023-05-21 18:21:27,018:INFO:              kmodes: Not installed
2023-05-21 18:21:27,018:INFO:             mlxtend: Not installed
2023-05-21 18:21:27,018:INFO:       statsforecast: Not installed
2023-05-21 18:21:27,018:INFO:        tune_sklearn: Not installed
2023-05-21 18:21:27,018:INFO:                 ray: Not installed
2023-05-21 18:21:27,019:INFO:            hyperopt: Not installed
2023-05-21 18:21:27,019:INFO:              optuna: 3.1.1
2023-05-21 18:21:27,019:INFO:               skopt: Not installed
2023-05-21 18:21:27,019:INFO:              mlflow: 2.3.1
2023-05-21 18:21:27,019:INFO:              gradio: Not installed
2023-05-21 18:21:27,019:INFO:             fastapi: Not installed
2023-05-21 18:21:27,020:INFO:             uvicorn: Not installed
2023-05-21 18:21:27,020:INFO:              m2cgen: Not installed
2023-05-21 18:21:27,020:INFO:           evidently: Not installed
2023-05-21 18:21:27,020:INFO:               fugue: Not installed
2023-05-21 18:21:27,020:INFO:           streamlit: Not installed
2023-05-21 18:21:27,020:INFO:             prophet: Not installed
2023-05-21 18:21:27,021:INFO:None
2023-05-21 18:21:27,021:INFO:Set up data.
2023-05-21 18:21:27,150:INFO:Set up train/test split.
2023-05-21 18:21:27,150:INFO:Set up data.
2023-05-21 18:21:27,239:INFO:Set up index.
2023-05-21 18:21:27,239:INFO:Set up folding strategy.
2023-05-21 18:21:27,240:INFO:Assigning column types.
2023-05-21 18:21:27,287:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-21 18:21:27,338:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 18:21:27,341:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 18:21:27,380:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 18:21:27,450:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 18:21:27,501:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 18:21:27,502:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 18:21:27,534:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 18:21:27,538:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 18:21:27,538:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-21 18:21:27,589:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 18:21:27,623:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 18:21:27,627:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 18:21:27,684:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 18:21:27,719:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 18:21:27,722:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 18:21:27,723:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-21 18:21:27,810:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 18:21:27,814:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 18:21:27,899:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 18:21:27,903:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 18:21:27,908:INFO:Preparing preprocessing pipeline...
2023-05-21 18:21:27,917:INFO:Set up simple imputation.
2023-05-21 18:21:27,924:INFO:Set up column name cleaning.
2023-05-21 18:21:28,194:INFO:Finished creating preprocessing pipeline.
2023-05-21 18:21:28,234:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped',
                                             'referred_lead', 'city_tier_1.0',
                                             'city_tier_2.0', 'city_tier_3.0',
                                             'first_platform_c_Level0',
                                             'first_platform_c_Level1',
                                             'first_platform_c_Level2',
                                             'first_platform_c_Level3',
                                             'first_platform_c_Level7',
                                             'first_platform_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-21 18:21:28,234:INFO:Creating final display dataframe.
2023-05-21 18:21:29,705:INFO:Setup _display_container:                     Description                           Value
0                    Session id                              42
1                        Target               app_complete_flag
2                   Target type                          Binary
3           Original data shape                    (238964, 41)
4        Transformed data shape                    (238964, 41)
5   Transformed train set shape                    (191171, 41)
6    Transformed test set shape                     (47793, 41)
7              Numeric features                              40
8                    Preprocess                            True
9               Imputation type                          simple
10           Numeric imputation                            mean
11       Categorical imputation                            mode
12               Fold Generator                 StratifiedKFold
13                  Fold Number                              10
14                     CPU Jobs                              -1
15                      Use GPU                           False
16               Log Experiment                    MlflowLogger
17              Experiment Name  Lead_Scoring_Training_Pipeline
18                          USI                            b252
2023-05-21 18:21:29,818:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 18:21:29,821:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 18:21:29,904:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 18:21:29,907:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 18:21:29,909:INFO:Logging experiment in loggers
2023-05-21 18:21:30,674:INFO:SubProcess save_model() called ==================================
2023-05-21 18:21:30,780:INFO:Initializing save_model()
2023-05-21 18:21:30,780:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped',
                                             'referred_lead', 'city_tier_1.0',
                                             'city_tier_2.0', 'city_tier_3.0',
                                             'first_platform_c_Level0',
                                             'first_platform_c_Level1',
                                             'first_platform_c_Level2',
                                             'first_platform_c_Level3',
                                             'first_platform_c_Level7',
                                             'first_platform_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=/tmp/tmpeinyie0l/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped',
                                             'referred_lead', 'city_tier_1.0',
                                             'city_tier_2.0', 'city_tier_3.0',
                                             'first_platform_c_Level0',
                                             'first_platform_c_Level1',
                                             'first_platform_c_Level2',
                                             'first_platform_c_Level3',
                                             'first_platform_c_Level7',
                                             'first_platform_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-21 18:21:30,780:INFO:Adding model into prep_pipe
2023-05-21 18:21:30,787:WARNING:Only Model saved as it was a pipeline.
2023-05-21 18:21:30,807:INFO:/tmp/tmpeinyie0l/Transformation Pipeline.pkl saved in current working directory
2023-05-21 18:21:30,843:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped',
                                             'referred_lead', 'city_tier_1.0',
                                             'city_tier_2.0', 'city_tier_3.0',
                                             'first_platform_c_Level0',
                                             'first_platform_c_Level1',
                                             'first_platform_c_Level2',
                                             'first_platform_c_Level3',
                                             'first_platform_c_Level7',
                                             'first_platform_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-21 18:21:30,843:INFO:save_model() successfully completed......................................
2023-05-21 18:21:31,012:INFO:SubProcess save_model() end ==================================
2023-05-21 18:21:32,617:INFO:setup() successfully completed in 3.0s...............
2023-05-21 18:21:43,886:INFO:Initializing compare_models()
2023-05-21 18:21:43,886:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fca88bfed70>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fca88bfed70>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'])
2023-05-21 18:21:43,887:INFO:Checking exceptions
2023-05-21 18:21:43,962:INFO:Preparing display monitor
2023-05-21 18:21:43,975:INFO:Initializing Logistic Regression
2023-05-21 18:21:43,975:INFO:Total runtime is 5.404154459635417e-06 minutes
2023-05-21 18:21:43,975:INFO:SubProcess create_model() called ==================================
2023-05-21 18:21:43,976:INFO:Initializing create_model()
2023-05-21 18:21:43,976:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fca88bfed70>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fca75f676d0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:21:43,976:INFO:Checking exceptions
2023-05-21 18:21:43,976:INFO:Importing libraries
2023-05-21 18:21:43,977:INFO:Copying training dataset
2023-05-21 18:21:44,042:INFO:Defining folds
2023-05-21 18:21:44,042:INFO:Declaring metric variables
2023-05-21 18:21:44,043:INFO:Importing untrained model
2023-05-21 18:21:44,045:INFO:Logistic Regression Imported successfully
2023-05-21 18:21:44,046:INFO:Starting cross validation
2023-05-21 18:21:44,053:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 18:22:00,864:INFO:Calculating mean and std
2023-05-21 18:22:00,867:INFO:Creating metrics dataframe
2023-05-21 18:22:00,972:INFO:Uploading results into container
2023-05-21 18:22:00,974:INFO:Uploading model into container now
2023-05-21 18:22:00,975:INFO:_master_model_container: 1
2023-05-21 18:22:00,976:INFO:_display_container: 2
2023-05-21 18:22:00,978:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-21 18:22:00,978:INFO:create_model() successfully completed......................................
2023-05-21 18:22:01,109:INFO:SubProcess create_model() end ==================================
2023-05-21 18:22:01,109:INFO:Creating metrics dataframe
2023-05-21 18:22:01,134:INFO:Initializing Naive Bayes
2023-05-21 18:22:01,134:INFO:Total runtime is 0.2859957257906596 minutes
2023-05-21 18:22:01,135:INFO:SubProcess create_model() called ==================================
2023-05-21 18:22:01,136:INFO:Initializing create_model()
2023-05-21 18:22:01,136:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fca88bfed70>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fca75f676d0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:22:01,136:INFO:Checking exceptions
2023-05-21 18:22:01,136:INFO:Importing libraries
2023-05-21 18:22:01,136:INFO:Copying training dataset
2023-05-21 18:22:01,205:INFO:Defining folds
2023-05-21 18:22:01,205:INFO:Declaring metric variables
2023-05-21 18:22:01,206:INFO:Importing untrained model
2023-05-21 18:22:01,207:INFO:Naive Bayes Imported successfully
2023-05-21 18:22:01,208:INFO:Starting cross validation
2023-05-21 18:22:01,216:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 18:22:04,971:INFO:Calculating mean and std
2023-05-21 18:22:04,973:INFO:Creating metrics dataframe
2023-05-21 18:22:05,039:INFO:Uploading results into container
2023-05-21 18:22:05,041:INFO:Uploading model into container now
2023-05-21 18:22:05,043:INFO:_master_model_container: 2
2023-05-21 18:22:05,043:INFO:_display_container: 2
2023-05-21 18:22:05,043:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-21 18:22:05,043:INFO:create_model() successfully completed......................................
2023-05-21 18:22:05,158:INFO:SubProcess create_model() end ==================================
2023-05-21 18:22:05,158:INFO:Creating metrics dataframe
2023-05-21 18:22:05,181:INFO:Initializing Decision Tree Classifier
2023-05-21 18:22:05,181:INFO:Total runtime is 0.35344452460606895 minutes
2023-05-21 18:22:05,182:INFO:SubProcess create_model() called ==================================
2023-05-21 18:22:05,182:INFO:Initializing create_model()
2023-05-21 18:22:05,183:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fca88bfed70>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fca75f676d0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:22:05,183:INFO:Checking exceptions
2023-05-21 18:22:05,183:INFO:Importing libraries
2023-05-21 18:22:05,183:INFO:Copying training dataset
2023-05-21 18:22:05,247:INFO:Defining folds
2023-05-21 18:22:05,247:INFO:Declaring metric variables
2023-05-21 18:22:05,248:INFO:Importing untrained model
2023-05-21 18:22:05,249:INFO:Decision Tree Classifier Imported successfully
2023-05-21 18:22:05,250:INFO:Starting cross validation
2023-05-21 18:22:05,258:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 18:22:07,984:INFO:Calculating mean and std
2023-05-21 18:22:07,986:INFO:Creating metrics dataframe
2023-05-21 18:22:08,095:INFO:Uploading results into container
2023-05-21 18:22:08,097:INFO:Uploading model into container now
2023-05-21 18:22:08,099:INFO:_master_model_container: 3
2023-05-21 18:22:08,099:INFO:_display_container: 2
2023-05-21 18:22:08,101:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-05-21 18:22:08,101:INFO:create_model() successfully completed......................................
2023-05-21 18:22:08,222:INFO:SubProcess create_model() end ==================================
2023-05-21 18:22:08,222:INFO:Creating metrics dataframe
2023-05-21 18:22:08,247:INFO:Initializing Ridge Classifier
2023-05-21 18:22:08,247:INFO:Total runtime is 0.4045401255289714 minutes
2023-05-21 18:22:08,248:INFO:SubProcess create_model() called ==================================
2023-05-21 18:22:08,249:INFO:Initializing create_model()
2023-05-21 18:22:08,249:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fca88bfed70>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fca75f676d0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:22:08,249:INFO:Checking exceptions
2023-05-21 18:22:08,250:INFO:Importing libraries
2023-05-21 18:22:08,250:INFO:Copying training dataset
2023-05-21 18:22:08,321:INFO:Defining folds
2023-05-21 18:22:08,322:INFO:Declaring metric variables
2023-05-21 18:22:08,323:INFO:Importing untrained model
2023-05-21 18:22:08,326:INFO:Ridge Classifier Imported successfully
2023-05-21 18:22:08,327:INFO:Starting cross validation
2023-05-21 18:22:08,334:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 18:22:09,425:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:22:09,450:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:22:09,458:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:22:09,493:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:22:09,514:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:22:09,548:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:22:09,551:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:22:09,581:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:22:09,693:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:22:09,718:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:22:10,052:INFO:Calculating mean and std
2023-05-21 18:22:10,054:INFO:Creating metrics dataframe
2023-05-21 18:22:10,129:INFO:Uploading results into container
2023-05-21 18:22:10,131:INFO:Uploading model into container now
2023-05-21 18:22:10,132:INFO:_master_model_container: 4
2023-05-21 18:22:10,133:INFO:_display_container: 2
2023-05-21 18:22:10,134:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-05-21 18:22:10,134:INFO:create_model() successfully completed......................................
2023-05-21 18:22:10,250:INFO:SubProcess create_model() end ==================================
2023-05-21 18:22:10,250:INFO:Creating metrics dataframe
2023-05-21 18:22:10,276:INFO:Initializing Random Forest Classifier
2023-05-21 18:22:10,276:INFO:Total runtime is 0.4383652210235596 minutes
2023-05-21 18:22:10,277:INFO:SubProcess create_model() called ==================================
2023-05-21 18:22:10,278:INFO:Initializing create_model()
2023-05-21 18:22:10,278:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fca88bfed70>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fca75f676d0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:22:10,278:INFO:Checking exceptions
2023-05-21 18:22:10,278:INFO:Importing libraries
2023-05-21 18:22:10,278:INFO:Copying training dataset
2023-05-21 18:22:10,343:INFO:Defining folds
2023-05-21 18:22:10,344:INFO:Declaring metric variables
2023-05-21 18:22:10,344:INFO:Importing untrained model
2023-05-21 18:22:10,347:INFO:Random Forest Classifier Imported successfully
2023-05-21 18:22:10,348:INFO:Starting cross validation
2023-05-21 18:22:10,355:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 18:22:47,330:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 18:22:47,411:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 18:22:47,607:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 18:22:47,690:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 18:22:47,764:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 18:22:47,834:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 18:22:48,044:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 18:22:48,132:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 18:22:48,134:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 18:22:49,726:INFO:Calculating mean and std
2023-05-21 18:22:49,727:INFO:Creating metrics dataframe
2023-05-21 18:22:49,806:INFO:Uploading results into container
2023-05-21 18:22:49,808:INFO:Uploading model into container now
2023-05-21 18:22:49,809:INFO:_master_model_container: 5
2023-05-21 18:22:49,810:INFO:_display_container: 2
2023-05-21 18:22:49,812:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-05-21 18:22:49,812:INFO:create_model() successfully completed......................................
2023-05-21 18:22:49,943:INFO:SubProcess create_model() end ==================================
2023-05-21 18:22:49,943:INFO:Creating metrics dataframe
2023-05-21 18:22:49,966:INFO:Initializing Linear Discriminant Analysis
2023-05-21 18:22:49,966:INFO:Total runtime is 1.0998655835787456 minutes
2023-05-21 18:22:49,967:INFO:SubProcess create_model() called ==================================
2023-05-21 18:22:49,968:INFO:Initializing create_model()
2023-05-21 18:22:49,968:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fca88bfed70>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fca75f676d0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:22:49,968:INFO:Checking exceptions
2023-05-21 18:22:49,968:INFO:Importing libraries
2023-05-21 18:22:49,968:INFO:Copying training dataset
2023-05-21 18:22:50,033:INFO:Defining folds
2023-05-21 18:22:50,033:INFO:Declaring metric variables
2023-05-21 18:22:50,034:INFO:Importing untrained model
2023-05-21 18:22:50,036:INFO:Linear Discriminant Analysis Imported successfully
2023-05-21 18:22:50,037:INFO:Starting cross validation
2023-05-21 18:22:50,044:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 18:22:56,188:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 18:22:56,321:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 18:22:57,094:INFO:Calculating mean and std
2023-05-21 18:22:57,096:INFO:Creating metrics dataframe
2023-05-21 18:22:57,189:INFO:Uploading results into container
2023-05-21 18:22:57,191:INFO:Uploading model into container now
2023-05-21 18:22:57,192:INFO:_master_model_container: 6
2023-05-21 18:22:57,192:INFO:_display_container: 2
2023-05-21 18:22:57,194:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-21 18:22:57,194:INFO:create_model() successfully completed......................................
2023-05-21 18:22:57,314:INFO:SubProcess create_model() end ==================================
2023-05-21 18:22:57,314:INFO:Creating metrics dataframe
2023-05-21 18:22:57,337:INFO:Initializing Extra Trees Classifier
2023-05-21 18:22:57,337:INFO:Total runtime is 1.2227167288462322 minutes
2023-05-21 18:22:57,338:INFO:SubProcess create_model() called ==================================
2023-05-21 18:22:57,339:INFO:Initializing create_model()
2023-05-21 18:22:57,339:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fca88bfed70>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fca75f676d0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:22:57,339:INFO:Checking exceptions
2023-05-21 18:22:57,339:INFO:Importing libraries
2023-05-21 18:22:57,339:INFO:Copying training dataset
2023-05-21 18:22:57,408:INFO:Defining folds
2023-05-21 18:22:57,408:INFO:Declaring metric variables
2023-05-21 18:22:57,409:INFO:Importing untrained model
2023-05-21 18:22:57,411:INFO:Extra Trees Classifier Imported successfully
2023-05-21 18:22:57,412:INFO:Starting cross validation
2023-05-21 18:22:57,420:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 18:23:42,161:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 18:23:42,334:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 18:23:42,348:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 18:23:42,414:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 18:23:42,449:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 18:23:42,464:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 18:23:42,520:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 18:23:42,527:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 18:23:44,398:INFO:Calculating mean and std
2023-05-21 18:23:44,400:INFO:Creating metrics dataframe
2023-05-21 18:23:44,485:INFO:Uploading results into container
2023-05-21 18:23:44,487:INFO:Uploading model into container now
2023-05-21 18:23:44,488:INFO:_master_model_container: 7
2023-05-21 18:23:44,488:INFO:_display_container: 2
2023-05-21 18:23:44,491:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-05-21 18:23:44,491:INFO:create_model() successfully completed......................................
2023-05-21 18:23:44,606:INFO:SubProcess create_model() end ==================================
2023-05-21 18:23:44,606:INFO:Creating metrics dataframe
2023-05-21 18:23:44,629:INFO:Initializing Light Gradient Boosting Machine
2023-05-21 18:23:44,629:INFO:Total runtime is 2.0109163761138915 minutes
2023-05-21 18:23:44,630:INFO:SubProcess create_model() called ==================================
2023-05-21 18:23:44,631:INFO:Initializing create_model()
2023-05-21 18:23:44,631:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fca88bfed70>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fca75f676d0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:23:44,631:INFO:Checking exceptions
2023-05-21 18:23:44,631:INFO:Importing libraries
2023-05-21 18:23:44,631:INFO:Copying training dataset
2023-05-21 18:23:44,696:INFO:Defining folds
2023-05-21 18:23:44,696:INFO:Declaring metric variables
2023-05-21 18:23:44,697:INFO:Importing untrained model
2023-05-21 18:23:44,699:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 18:23:44,700:INFO:Starting cross validation
2023-05-21 18:23:44,707:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 18:23:49,046:INFO:Calculating mean and std
2023-05-21 18:23:49,048:INFO:Creating metrics dataframe
2023-05-21 18:23:49,140:INFO:Uploading results into container
2023-05-21 18:23:49,142:INFO:Uploading model into container now
2023-05-21 18:23:49,144:INFO:_master_model_container: 8
2023-05-21 18:23:49,144:INFO:_display_container: 2
2023-05-21 18:23:49,147:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 18:23:49,147:INFO:create_model() successfully completed......................................
2023-05-21 18:23:49,278:INFO:SubProcess create_model() end ==================================
2023-05-21 18:23:49,278:INFO:Creating metrics dataframe
2023-05-21 18:23:49,314:INFO:Initializing create_model()
2023-05-21 18:23:49,315:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fca88bfed70>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:23:49,315:INFO:Checking exceptions
2023-05-21 18:23:49,318:INFO:Importing libraries
2023-05-21 18:23:49,318:INFO:Copying training dataset
2023-05-21 18:23:49,386:INFO:Defining folds
2023-05-21 18:23:49,386:INFO:Declaring metric variables
2023-05-21 18:23:49,387:INFO:Importing untrained model
2023-05-21 18:23:49,387:INFO:Declaring custom model
2023-05-21 18:23:49,393:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 18:23:49,401:INFO:Cross validation set to False
2023-05-21 18:23:49,401:INFO:Fitting Model
2023-05-21 18:23:50,391:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 18:23:50,391:INFO:create_model() successfully completed......................................
2023-05-21 18:23:50,508:INFO:Creating Dashboard logs
2023-05-21 18:23:50,510:INFO:Model: Light Gradient Boosting Machine
2023-05-21 18:23:50,731:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-21 18:23:51,679:INFO:Initializing predict_model()
2023-05-21 18:23:51,680:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fca88bfed70>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fca72638700>)
2023-05-21 18:23:51,680:INFO:Checking exceptions
2023-05-21 18:23:51,680:INFO:Preloading libraries
2023-05-21 18:23:52,274:INFO:SubProcess plot_model() called ==================================
2023-05-21 18:23:52,277:INFO:Initializing plot_model()
2023-05-21 18:23:52,277:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpl3jzwul7, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fca88bfed70>, system=False)
2023-05-21 18:23:52,278:INFO:Checking exceptions
2023-05-21 18:23:52,300:INFO:Preloading libraries
2023-05-21 18:23:52,305:INFO:Copying training dataset
2023-05-21 18:23:52,305:INFO:Plot type: auc
2023-05-21 18:23:53,346:INFO:Fitting Model
2023-05-21 18:23:53,358:INFO:Scoring test/hold-out set
2023-05-21 18:23:53,671:INFO:Saving '/tmp/tmpl3jzwul7/AUC.png'
2023-05-21 18:23:55,006:INFO:Visual Rendered Successfully
2023-05-21 18:23:55,139:INFO:plot_model() successfully completed......................................
2023-05-21 18:23:55,143:INFO:Initializing plot_model()
2023-05-21 18:23:55,144:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpl3jzwul7, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fca88bfed70>, system=False)
2023-05-21 18:23:55,144:INFO:Checking exceptions
2023-05-21 18:23:55,169:INFO:Preloading libraries
2023-05-21 18:23:55,176:INFO:Copying training dataset
2023-05-21 18:23:55,176:INFO:Plot type: confusion_matrix
2023-05-21 18:23:55,623:INFO:Fitting Model
2023-05-21 18:23:55,626:INFO:Scoring test/hold-out set
2023-05-21 18:23:55,848:INFO:Saving '/tmp/tmpl3jzwul7/Confusion Matrix.png'
2023-05-21 18:23:56,373:INFO:Visual Rendered Successfully
2023-05-21 18:23:56,571:INFO:plot_model() successfully completed......................................
2023-05-21 18:23:56,584:INFO:Initializing plot_model()
2023-05-21 18:23:56,584:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpl3jzwul7, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fca88bfed70>, system=False)
2023-05-21 18:23:56,584:INFO:Checking exceptions
2023-05-21 18:23:56,619:INFO:Preloading libraries
2023-05-21 18:23:56,627:INFO:Copying training dataset
2023-05-21 18:23:56,628:INFO:Plot type: feature
2023-05-21 18:23:56,631:WARNING:No coef_ found. Trying feature_importances_
2023-05-21 18:23:56,984:INFO:Saving '/tmp/tmpl3jzwul7/Feature Importance.png'
2023-05-21 18:23:57,675:INFO:Visual Rendered Successfully
2023-05-21 18:23:57,796:INFO:plot_model() successfully completed......................................
2023-05-21 18:23:57,797:INFO:SubProcess plot_model() end ==================================
2023-05-21 18:23:57,849:WARNING:/home/feuer/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-05-21 18:23:58,800:INFO:Creating Dashboard logs
2023-05-21 18:23:58,801:INFO:Model: Random Forest Classifier
2023-05-21 18:23:59,060:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 18:24:00,727:INFO:Creating Dashboard logs
2023-05-21 18:24:00,729:INFO:Model: Extra Trees Classifier
2023-05-21 18:24:00,859:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 18:24:01,950:INFO:Creating Dashboard logs
2023-05-21 18:24:01,951:INFO:Model: Decision Tree Classifier
2023-05-21 18:24:02,093:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2023-05-21 18:24:03,166:INFO:Creating Dashboard logs
2023-05-21 18:24:03,168:INFO:Model: Logistic Regression
2023-05-21 18:24:03,300:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-05-21 18:24:04,484:INFO:Creating Dashboard logs
2023-05-21 18:24:04,485:INFO:Model: Linear Discriminant Analysis
2023-05-21 18:24:04,634:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-05-21 18:24:06,522:INFO:Creating Dashboard logs
2023-05-21 18:24:06,523:INFO:Model: Naive Bayes
2023-05-21 18:24:06,646:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-05-21 18:24:07,729:INFO:Creating Dashboard logs
2023-05-21 18:24:07,730:INFO:Model: Ridge Classifier
2023-05-21 18:24:07,858:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2023-05-21 18:24:09,022:INFO:_master_model_container: 8
2023-05-21 18:24:09,022:INFO:_display_container: 2
2023-05-21 18:24:09,025:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 18:24:09,025:INFO:compare_models() successfully completed......................................
2023-05-21 18:29:15,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 18:29:15,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 18:29:15,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 18:29:15,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 18:29:17,919:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-21 18:29:22,208:INFO:PyCaret ClassificationExperiment
2023-05-21 18:29:22,208:INFO:Logging name: Lead_Scoring_Training_Pipeline
2023-05-21 18:29:22,208:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-21 18:29:22,208:INFO:version 3.0.0
2023-05-21 18:29:22,208:INFO:Initializing setup()
2023-05-21 18:29:22,208:INFO:self.USI: 1316
2023-05-21 18:29:22,208:INFO:self._variable_keys: {'html_param', 'memory', 'gpu_param', 'is_multiclass', 'n_jobs_param', 'y', 'data', 'gpu_n_jobs_param', 'exp_id', 'X_train', 'target_param', 'fold_generator', 'y_train', 'log_plots_param', '_ml_usecase', 'X_test', 'logging_param', 'X', 'exp_name_log', 'fix_imbalance', 'idx', 'y_test', 'fold_shuffle_param', '_available_plots', 'USI', 'fold_groups_param', 'pipeline', 'seed'}
2023-05-21 18:29:22,208:INFO:Checking environment
2023-05-21 18:29:22,208:INFO:python_version: 3.10.10
2023-05-21 18:29:22,208:INFO:python_build: ('main', 'Mar  5 2023 22:26:53')
2023-05-21 18:29:22,208:INFO:machine: x86_64
2023-05-21 18:29:22,210:INFO:platform: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 18:29:22,210:INFO:Memory: svmem(total=16717086720, available=7591788544, percent=54.6, used=7869808640, free=6572601344, active=2325381120, inactive=5548756992, buffers=25440256, cached=2249236480, shared=912015360, slab=480821248)
2023-05-21 18:29:22,211:INFO:Physical Core: 6
2023-05-21 18:29:22,211:INFO:Logical Core: 12
2023-05-21 18:29:22,211:INFO:Checking libraries
2023-05-21 18:29:22,211:INFO:System:
2023-05-21 18:29:22,211:INFO:    python: 3.10.10 (main, Mar  5 2023, 22:26:53) [GCC 12.2.1 20230201]
2023-05-21 18:29:22,211:INFO:executable: /usr/bin/python3.10
2023-05-21 18:29:22,211:INFO:   machine: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 18:29:22,211:INFO:PyCaret required dependencies:
2023-05-21 18:29:22,211:INFO:                 pip: 23.0.1
2023-05-21 18:29:22,212:INFO:          setuptools: 67.6.1
2023-05-21 18:29:22,212:INFO:             pycaret: 3.0.0
2023-05-21 18:29:22,212:INFO:             IPython: 8.12.0
2023-05-21 18:29:22,212:INFO:          ipywidgets: 7.7.5
2023-05-21 18:29:22,212:INFO:                tqdm: 4.64.1
2023-05-21 18:29:22,212:INFO:               numpy: 1.23.0
2023-05-21 18:29:22,212:INFO:              pandas: 1.5.3
2023-05-21 18:29:22,212:INFO:              jinja2: 3.1.2
2023-05-21 18:29:22,212:INFO:               scipy: 1.9.3
2023-05-21 18:29:22,212:INFO:              joblib: 1.2.0
2023-05-21 18:29:22,212:INFO:             sklearn: 1.2.2
2023-05-21 18:29:22,212:INFO:                pyod: 1.0.9
2023-05-21 18:29:22,212:INFO:            imblearn: 0.10.1
2023-05-21 18:29:22,212:INFO:   category_encoders: 2.6.0
2023-05-21 18:29:22,212:INFO:            lightgbm: 3.3.5
2023-05-21 18:29:22,212:INFO:               numba: 0.57.0
2023-05-21 18:29:22,212:INFO:            requests: 2.28.2
2023-05-21 18:29:22,212:INFO:          matplotlib: 3.6.3
2023-05-21 18:29:22,212:INFO:          scikitplot: 0.3.7
2023-05-21 18:29:22,212:INFO:         yellowbrick: 1.5
2023-05-21 18:29:22,212:INFO:              plotly: 5.14.1
2023-05-21 18:29:22,213:INFO:             kaleido: 0.2.1
2023-05-21 18:29:22,213:INFO:         statsmodels: 0.13.5
2023-05-21 18:29:22,213:INFO:              sktime: 0.18.0
2023-05-21 18:29:22,213:INFO:               tbats: 1.1.3
2023-05-21 18:29:22,213:INFO:            pmdarima: 2.0.3
2023-05-21 18:29:22,213:INFO:              psutil: 5.9.4
2023-05-21 18:29:22,213:INFO:PyCaret optional dependencies:
2023-05-21 18:29:22,222:INFO:                shap: 0.41.0
2023-05-21 18:29:22,222:INFO:           interpret: 0.3.2
2023-05-21 18:29:22,223:INFO:                umap: 0.5.3
2023-05-21 18:29:22,223:INFO:    pandas_profiling: 3.6.6
2023-05-21 18:29:22,223:INFO:  explainerdashboard: 0.4.2.2
2023-05-21 18:29:22,223:INFO:             autoviz: 0.1.603
2023-05-21 18:29:22,223:INFO:           fairlearn: 0.7.0
2023-05-21 18:29:22,223:INFO:             xgboost: 1.7.5
2023-05-21 18:29:22,223:INFO:            catboost: Not installed
2023-05-21 18:29:22,223:INFO:              kmodes: Not installed
2023-05-21 18:29:22,223:INFO:             mlxtend: Not installed
2023-05-21 18:29:22,223:INFO:       statsforecast: Not installed
2023-05-21 18:29:22,223:INFO:        tune_sklearn: Not installed
2023-05-21 18:29:22,223:INFO:                 ray: Not installed
2023-05-21 18:29:22,223:INFO:            hyperopt: Not installed
2023-05-21 18:29:22,223:INFO:              optuna: 3.1.1
2023-05-21 18:29:22,223:INFO:               skopt: Not installed
2023-05-21 18:29:22,223:INFO:              mlflow: 2.3.1
2023-05-21 18:29:22,223:INFO:              gradio: Not installed
2023-05-21 18:29:22,223:INFO:             fastapi: Not installed
2023-05-21 18:29:22,223:INFO:             uvicorn: Not installed
2023-05-21 18:29:22,223:INFO:              m2cgen: Not installed
2023-05-21 18:29:22,224:INFO:           evidently: Not installed
2023-05-21 18:29:22,224:INFO:               fugue: Not installed
2023-05-21 18:29:22,224:INFO:           streamlit: Not installed
2023-05-21 18:29:22,224:INFO:             prophet: Not installed
2023-05-21 18:29:22,224:INFO:None
2023-05-21 18:29:22,224:INFO:Set up data.
2023-05-21 18:29:22,327:INFO:Set up train/test split.
2023-05-21 18:29:22,327:INFO:Set up data.
2023-05-21 18:29:22,356:INFO:Set up index.
2023-05-21 18:29:22,356:INFO:Set up folding strategy.
2023-05-21 18:29:22,356:INFO:Assigning column types.
2023-05-21 18:29:22,391:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-21 18:29:22,434:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 18:29:22,446:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 18:29:22,524:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 18:29:22,618:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 18:29:22,662:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 18:29:22,662:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 18:29:22,690:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 18:29:22,692:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 18:29:22,692:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-21 18:29:22,737:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 18:29:22,764:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 18:29:22,766:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 18:29:22,810:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 18:29:22,837:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 18:29:22,840:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 18:29:22,840:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-21 18:29:22,912:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 18:29:22,915:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 18:29:22,985:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 18:29:22,988:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 18:29:22,989:INFO:Preparing preprocessing pipeline...
2023-05-21 18:29:22,994:INFO:Set up simple imputation.
2023-05-21 18:29:23,000:INFO:Set up column name cleaning.
2023-05-21 18:29:23,140:INFO:Finished creating preprocessing pipeline.
2023-05-21 18:29:23,149:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped',
                                             'referred_lead', 'city_tier_1.0',
                                             'city_tier_2.0', 'city_tier_3.0',
                                             'first_platform_c_Level0',
                                             'first_platform_c_Level1',
                                             'first_platform_c_Level2',
                                             'first_platform_c_Level3',
                                             'first_platform_c_Level7',
                                             'first_platform_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-21 18:29:23,149:INFO:Creating final display dataframe.
2023-05-21 18:29:23,367:INFO:Setup _display_container:                     Description                           Value
0                    Session id                              42
1                        Target               app_complete_flag
2                   Target type                          Binary
3           Original data shape                    (238964, 41)
4        Transformed data shape                    (238964, 41)
5   Transformed train set shape                    (191171, 41)
6    Transformed test set shape                     (47793, 41)
7              Numeric features                              40
8                    Preprocess                            True
9               Imputation type                          simple
10           Numeric imputation                            mean
11       Categorical imputation                            mode
12               Fold Generator                 StratifiedKFold
13                  Fold Number                              10
14                     CPU Jobs                              -1
15                      Use GPU                           False
16               Log Experiment                    MlflowLogger
17              Experiment Name  Lead_Scoring_Training_Pipeline
18                          USI                            1316
2023-05-21 18:29:23,442:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 18:29:23,445:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 18:29:23,516:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 18:29:23,518:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 18:29:23,519:INFO:Logging experiment in loggers
2023-05-21 18:29:24,080:INFO:SubProcess save_model() called ==================================
2023-05-21 18:29:24,094:INFO:Initializing save_model()
2023-05-21 18:29:24,094:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped',
                                             'referred_lead', 'city_tier_1.0',
                                             'city_tier_2.0', 'city_tier_3.0',
                                             'first_platform_c_Level0',
                                             'first_platform_c_Level1',
                                             'first_platform_c_Level2',
                                             'first_platform_c_Level3',
                                             'first_platform_c_Level7',
                                             'first_platform_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=/tmp/tmpw0b_f4n2/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped',
                                             'referred_lead', 'city_tier_1.0',
                                             'city_tier_2.0', 'city_tier_3.0',
                                             'first_platform_c_Level0',
                                             'first_platform_c_Level1',
                                             'first_platform_c_Level2',
                                             'first_platform_c_Level3',
                                             'first_platform_c_Level7',
                                             'first_platform_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-21 18:29:24,094:INFO:Adding model into prep_pipe
2023-05-21 18:29:24,095:WARNING:Only Model saved as it was a pipeline.
2023-05-21 18:29:24,099:INFO:/tmp/tmpw0b_f4n2/Transformation Pipeline.pkl saved in current working directory
2023-05-21 18:29:24,106:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped',
                                             'referred_lead', 'city_tier_1.0',
                                             'city_tier_2.0', 'city_tier_3.0',
                                             'first_platform_c_Level0',
                                             'first_platform_c_Level1',
                                             'first_platform_c_Level2',
                                             'first_platform_c_Level3',
                                             'first_platform_c_Level7',
                                             'first_platform_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-21 18:29:24,106:INFO:save_model() successfully completed......................................
2023-05-21 18:29:24,223:INFO:SubProcess save_model() end ==================================
2023-05-21 18:29:25,493:INFO:setup() successfully completed in 1.34s...............
2023-05-21 18:29:25,493:INFO:Initializing compare_models()
2023-05-21 18:29:25,493:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc2403c9bd0>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fc2403c9bd0>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'])
2023-05-21 18:29:25,493:INFO:Checking exceptions
2023-05-21 18:29:25,523:INFO:Preparing display monitor
2023-05-21 18:29:25,526:INFO:Initializing Logistic Regression
2023-05-21 18:29:25,526:INFO:Total runtime is 1.243750254313151e-06 minutes
2023-05-21 18:29:25,526:INFO:SubProcess create_model() called ==================================
2023-05-21 18:29:25,527:INFO:Initializing create_model()
2023-05-21 18:29:25,527:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc2403c9bd0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1faf16a70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:29:25,527:INFO:Checking exceptions
2023-05-21 18:29:25,527:INFO:Importing libraries
2023-05-21 18:29:25,527:INFO:Copying training dataset
2023-05-21 18:29:25,580:INFO:Defining folds
2023-05-21 18:29:25,580:INFO:Declaring metric variables
2023-05-21 18:29:25,580:INFO:Importing untrained model
2023-05-21 18:29:25,580:INFO:Logistic Regression Imported successfully
2023-05-21 18:29:25,580:INFO:Starting cross validation
2023-05-21 18:29:25,581:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 18:29:28,266:INFO:Calculating mean and std
2023-05-21 18:29:28,267:INFO:Creating metrics dataframe
2023-05-21 18:29:28,299:INFO:Uploading results into container
2023-05-21 18:29:28,300:INFO:Uploading model into container now
2023-05-21 18:29:28,300:INFO:_master_model_container: 1
2023-05-21 18:29:28,300:INFO:_display_container: 2
2023-05-21 18:29:28,301:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-21 18:29:28,301:INFO:create_model() successfully completed......................................
2023-05-21 18:29:28,413:INFO:SubProcess create_model() end ==================================
2023-05-21 18:29:28,413:INFO:Creating metrics dataframe
2023-05-21 18:29:28,417:INFO:Initializing Naive Bayes
2023-05-21 18:29:28,417:INFO:Total runtime is 0.04817366202672323 minutes
2023-05-21 18:29:28,417:INFO:SubProcess create_model() called ==================================
2023-05-21 18:29:28,417:INFO:Initializing create_model()
2023-05-21 18:29:28,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc2403c9bd0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1faf16a70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:29:28,417:INFO:Checking exceptions
2023-05-21 18:29:28,417:INFO:Importing libraries
2023-05-21 18:29:28,417:INFO:Copying training dataset
2023-05-21 18:29:28,471:INFO:Defining folds
2023-05-21 18:29:28,471:INFO:Declaring metric variables
2023-05-21 18:29:28,471:INFO:Importing untrained model
2023-05-21 18:29:28,471:INFO:Naive Bayes Imported successfully
2023-05-21 18:29:28,471:INFO:Starting cross validation
2023-05-21 18:29:28,472:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 18:29:30,161:INFO:Calculating mean and std
2023-05-21 18:29:30,161:INFO:Creating metrics dataframe
2023-05-21 18:29:30,193:INFO:Uploading results into container
2023-05-21 18:29:30,194:INFO:Uploading model into container now
2023-05-21 18:29:30,194:INFO:_master_model_container: 2
2023-05-21 18:29:30,194:INFO:_display_container: 2
2023-05-21 18:29:30,194:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-21 18:29:30,194:INFO:create_model() successfully completed......................................
2023-05-21 18:29:30,294:INFO:SubProcess create_model() end ==================================
2023-05-21 18:29:30,294:INFO:Creating metrics dataframe
2023-05-21 18:29:30,298:INFO:Initializing Decision Tree Classifier
2023-05-21 18:29:30,298:INFO:Total runtime is 0.07953580220540366 minutes
2023-05-21 18:29:30,299:INFO:SubProcess create_model() called ==================================
2023-05-21 18:29:30,299:INFO:Initializing create_model()
2023-05-21 18:29:30,299:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc2403c9bd0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1faf16a70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:29:30,299:INFO:Checking exceptions
2023-05-21 18:29:30,299:INFO:Importing libraries
2023-05-21 18:29:30,299:INFO:Copying training dataset
2023-05-21 18:29:30,350:INFO:Defining folds
2023-05-21 18:29:30,351:INFO:Declaring metric variables
2023-05-21 18:29:30,351:INFO:Importing untrained model
2023-05-21 18:29:30,351:INFO:Decision Tree Classifier Imported successfully
2023-05-21 18:29:30,351:INFO:Starting cross validation
2023-05-21 18:29:30,352:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 18:29:31,050:INFO:Calculating mean and std
2023-05-21 18:29:31,051:INFO:Creating metrics dataframe
2023-05-21 18:29:31,082:INFO:Uploading results into container
2023-05-21 18:29:31,083:INFO:Uploading model into container now
2023-05-21 18:29:31,083:INFO:_master_model_container: 3
2023-05-21 18:29:31,083:INFO:_display_container: 2
2023-05-21 18:29:31,084:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-05-21 18:29:31,084:INFO:create_model() successfully completed......................................
2023-05-21 18:29:31,190:INFO:SubProcess create_model() end ==================================
2023-05-21 18:29:31,190:INFO:Creating metrics dataframe
2023-05-21 18:29:31,194:INFO:Initializing Ridge Classifier
2023-05-21 18:29:31,194:INFO:Total runtime is 0.0944612741470337 minutes
2023-05-21 18:29:31,194:INFO:SubProcess create_model() called ==================================
2023-05-21 18:29:31,194:INFO:Initializing create_model()
2023-05-21 18:29:31,194:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc2403c9bd0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1faf16a70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:29:31,194:INFO:Checking exceptions
2023-05-21 18:29:31,194:INFO:Importing libraries
2023-05-21 18:29:31,195:INFO:Copying training dataset
2023-05-21 18:29:31,248:INFO:Defining folds
2023-05-21 18:29:31,248:INFO:Declaring metric variables
2023-05-21 18:29:31,248:INFO:Importing untrained model
2023-05-21 18:29:31,249:INFO:Ridge Classifier Imported successfully
2023-05-21 18:29:31,249:INFO:Starting cross validation
2023-05-21 18:29:31,249:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 18:29:31,541:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:29:31,615:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:29:31,638:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:29:31,638:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:29:31,650:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:29:31,664:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:29:31,682:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:29:31,683:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:29:31,689:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:29:31,691:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:29:31,893:INFO:Calculating mean and std
2023-05-21 18:29:31,894:INFO:Creating metrics dataframe
2023-05-21 18:29:31,910:INFO:Uploading results into container
2023-05-21 18:29:31,910:INFO:Uploading model into container now
2023-05-21 18:29:31,911:INFO:_master_model_container: 4
2023-05-21 18:29:31,911:INFO:_display_container: 2
2023-05-21 18:29:31,911:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-05-21 18:29:31,911:INFO:create_model() successfully completed......................................
2023-05-21 18:29:32,002:INFO:SubProcess create_model() end ==================================
2023-05-21 18:29:32,002:INFO:Creating metrics dataframe
2023-05-21 18:29:32,006:INFO:Initializing Random Forest Classifier
2023-05-21 18:29:32,007:INFO:Total runtime is 0.1080038626988729 minutes
2023-05-21 18:29:32,007:INFO:SubProcess create_model() called ==================================
2023-05-21 18:29:32,007:INFO:Initializing create_model()
2023-05-21 18:29:32,007:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc2403c9bd0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1faf16a70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:29:32,007:INFO:Checking exceptions
2023-05-21 18:29:32,007:INFO:Importing libraries
2023-05-21 18:29:32,007:INFO:Copying training dataset
2023-05-21 18:29:32,059:INFO:Defining folds
2023-05-21 18:29:32,059:INFO:Declaring metric variables
2023-05-21 18:29:32,059:INFO:Importing untrained model
2023-05-21 18:29:32,059:INFO:Random Forest Classifier Imported successfully
2023-05-21 18:29:32,060:INFO:Starting cross validation
2023-05-21 18:29:32,060:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 18:29:33,715:INFO:Calculating mean and std
2023-05-21 18:29:33,716:INFO:Creating metrics dataframe
2023-05-21 18:29:33,748:INFO:Uploading results into container
2023-05-21 18:29:33,748:INFO:Uploading model into container now
2023-05-21 18:29:33,749:INFO:_master_model_container: 5
2023-05-21 18:29:33,749:INFO:_display_container: 2
2023-05-21 18:29:33,750:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-05-21 18:29:33,750:INFO:create_model() successfully completed......................................
2023-05-21 18:29:33,860:INFO:SubProcess create_model() end ==================================
2023-05-21 18:29:33,860:INFO:Creating metrics dataframe
2023-05-21 18:29:33,865:INFO:Initializing Linear Discriminant Analysis
2023-05-21 18:29:33,865:INFO:Total runtime is 0.13897511959075928 minutes
2023-05-21 18:29:33,865:INFO:SubProcess create_model() called ==================================
2023-05-21 18:29:33,865:INFO:Initializing create_model()
2023-05-21 18:29:33,865:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc2403c9bd0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1faf16a70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:29:33,865:INFO:Checking exceptions
2023-05-21 18:29:33,865:INFO:Importing libraries
2023-05-21 18:29:33,865:INFO:Copying training dataset
2023-05-21 18:29:33,923:INFO:Defining folds
2023-05-21 18:29:33,924:INFO:Declaring metric variables
2023-05-21 18:29:33,924:INFO:Importing untrained model
2023-05-21 18:29:33,924:INFO:Linear Discriminant Analysis Imported successfully
2023-05-21 18:29:33,924:INFO:Starting cross validation
2023-05-21 18:29:33,925:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 18:29:34,647:INFO:Calculating mean and std
2023-05-21 18:29:34,648:INFO:Creating metrics dataframe
2023-05-21 18:29:34,666:INFO:Uploading results into container
2023-05-21 18:29:34,666:INFO:Uploading model into container now
2023-05-21 18:29:34,667:INFO:_master_model_container: 6
2023-05-21 18:29:34,667:INFO:_display_container: 2
2023-05-21 18:29:34,667:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-21 18:29:34,667:INFO:create_model() successfully completed......................................
2023-05-21 18:29:34,771:INFO:SubProcess create_model() end ==================================
2023-05-21 18:29:34,771:INFO:Creating metrics dataframe
2023-05-21 18:29:34,775:INFO:Initializing Extra Trees Classifier
2023-05-21 18:29:34,775:INFO:Total runtime is 0.1541483481725057 minutes
2023-05-21 18:29:34,775:INFO:SubProcess create_model() called ==================================
2023-05-21 18:29:34,776:INFO:Initializing create_model()
2023-05-21 18:29:34,776:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc2403c9bd0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1faf16a70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:29:34,776:INFO:Checking exceptions
2023-05-21 18:29:34,776:INFO:Importing libraries
2023-05-21 18:29:34,776:INFO:Copying training dataset
2023-05-21 18:29:34,840:INFO:Defining folds
2023-05-21 18:29:34,840:INFO:Declaring metric variables
2023-05-21 18:29:34,840:INFO:Importing untrained model
2023-05-21 18:29:34,841:INFO:Extra Trees Classifier Imported successfully
2023-05-21 18:29:34,841:INFO:Starting cross validation
2023-05-21 18:29:34,842:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 18:29:36,526:INFO:Calculating mean and std
2023-05-21 18:29:36,526:INFO:Creating metrics dataframe
2023-05-21 18:29:36,559:INFO:Uploading results into container
2023-05-21 18:29:36,560:INFO:Uploading model into container now
2023-05-21 18:29:36,560:INFO:_master_model_container: 7
2023-05-21 18:29:36,560:INFO:_display_container: 2
2023-05-21 18:29:36,561:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-05-21 18:29:36,561:INFO:create_model() successfully completed......................................
2023-05-21 18:29:36,665:INFO:SubProcess create_model() end ==================================
2023-05-21 18:29:36,665:INFO:Creating metrics dataframe
2023-05-21 18:29:36,669:INFO:Initializing Light Gradient Boosting Machine
2023-05-21 18:29:36,669:INFO:Total runtime is 0.18570974667867024 minutes
2023-05-21 18:29:36,669:INFO:SubProcess create_model() called ==================================
2023-05-21 18:29:36,669:INFO:Initializing create_model()
2023-05-21 18:29:36,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc2403c9bd0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1faf16a70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:29:36,669:INFO:Checking exceptions
2023-05-21 18:29:36,669:INFO:Importing libraries
2023-05-21 18:29:36,669:INFO:Copying training dataset
2023-05-21 18:29:36,728:INFO:Defining folds
2023-05-21 18:29:36,728:INFO:Declaring metric variables
2023-05-21 18:29:36,728:INFO:Importing untrained model
2023-05-21 18:29:36,729:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 18:29:36,729:INFO:Starting cross validation
2023-05-21 18:29:36,730:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 18:29:37,637:INFO:Calculating mean and std
2023-05-21 18:29:37,638:INFO:Creating metrics dataframe
2023-05-21 18:29:37,654:INFO:Uploading results into container
2023-05-21 18:29:37,655:INFO:Uploading model into container now
2023-05-21 18:29:37,655:INFO:_master_model_container: 8
2023-05-21 18:29:37,655:INFO:_display_container: 2
2023-05-21 18:29:37,655:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 18:29:37,655:INFO:create_model() successfully completed......................................
2023-05-21 18:29:37,751:INFO:SubProcess create_model() end ==================================
2023-05-21 18:29:37,751:INFO:Creating metrics dataframe
2023-05-21 18:29:37,757:INFO:Initializing create_model()
2023-05-21 18:29:37,757:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc2403c9bd0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:29:37,757:INFO:Checking exceptions
2023-05-21 18:29:37,757:INFO:Importing libraries
2023-05-21 18:29:37,757:INFO:Copying training dataset
2023-05-21 18:29:37,814:INFO:Defining folds
2023-05-21 18:29:37,814:INFO:Declaring metric variables
2023-05-21 18:29:37,814:INFO:Importing untrained model
2023-05-21 18:29:37,814:INFO:Declaring custom model
2023-05-21 18:29:37,815:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 18:29:37,815:INFO:Cross validation set to False
2023-05-21 18:29:37,815:INFO:Fitting Model
2023-05-21 18:29:37,965:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 18:29:37,965:INFO:create_model() successfully completed......................................
2023-05-21 18:29:38,059:INFO:Creating Dashboard logs
2023-05-21 18:29:38,060:INFO:Model: Light Gradient Boosting Machine
2023-05-21 18:29:38,147:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-21 18:29:38,702:INFO:Initializing predict_model()
2023-05-21 18:29:38,702:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc2403c9bd0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fc1fb26ce50>)
2023-05-21 18:29:38,702:INFO:Checking exceptions
2023-05-21 18:29:38,702:INFO:Preloading libraries
2023-05-21 18:29:39,095:INFO:SubProcess plot_model() called ==================================
2023-05-21 18:29:39,096:INFO:Initializing plot_model()
2023-05-21 18:29:39,096:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpzzd8farl, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc2403c9bd0>, system=False)
2023-05-21 18:29:39,096:INFO:Checking exceptions
2023-05-21 18:29:39,118:INFO:Preloading libraries
2023-05-21 18:29:39,122:INFO:Copying training dataset
2023-05-21 18:29:39,122:INFO:Plot type: auc
2023-05-21 18:29:39,381:INFO:Fitting Model
2023-05-21 18:29:39,386:INFO:Scoring test/hold-out set
2023-05-21 18:29:39,537:INFO:Saving '/tmp/tmpzzd8farl/AUC.png'
2023-05-21 18:29:39,757:INFO:Visual Rendered Successfully
2023-05-21 18:29:39,851:INFO:plot_model() successfully completed......................................
2023-05-21 18:29:39,852:INFO:Initializing plot_model()
2023-05-21 18:29:39,852:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpzzd8farl, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc2403c9bd0>, system=False)
2023-05-21 18:29:39,852:INFO:Checking exceptions
2023-05-21 18:29:39,871:INFO:Preloading libraries
2023-05-21 18:29:39,875:INFO:Copying training dataset
2023-05-21 18:29:39,875:INFO:Plot type: confusion_matrix
2023-05-21 18:29:40,069:INFO:Fitting Model
2023-05-21 18:29:40,072:INFO:Scoring test/hold-out set
2023-05-21 18:29:40,191:INFO:Saving '/tmp/tmpzzd8farl/Confusion Matrix.png'
2023-05-21 18:29:40,289:INFO:Visual Rendered Successfully
2023-05-21 18:29:40,395:INFO:plot_model() successfully completed......................................
2023-05-21 18:29:40,396:INFO:Initializing plot_model()
2023-05-21 18:29:40,396:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpzzd8farl, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc2403c9bd0>, system=False)
2023-05-21 18:29:40,396:INFO:Checking exceptions
2023-05-21 18:29:40,417:INFO:Preloading libraries
2023-05-21 18:29:40,421:INFO:Copying training dataset
2023-05-21 18:29:40,421:INFO:Plot type: feature
2023-05-21 18:29:40,421:WARNING:No coef_ found. Trying feature_importances_
2023-05-21 18:29:40,516:INFO:Saving '/tmp/tmpzzd8farl/Feature Importance.png'
2023-05-21 18:29:40,652:INFO:Visual Rendered Successfully
2023-05-21 18:29:40,747:INFO:plot_model() successfully completed......................................
2023-05-21 18:29:40,747:INFO:SubProcess plot_model() end ==================================
2023-05-21 18:29:40,770:WARNING:/home/feuer/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-05-21 18:29:41,126:INFO:Creating Dashboard logs
2023-05-21 18:29:41,127:INFO:Model: Random Forest Classifier
2023-05-21 18:29:41,202:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 18:29:42,023:INFO:Creating Dashboard logs
2023-05-21 18:29:42,023:INFO:Model: Extra Trees Classifier
2023-05-21 18:29:42,135:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 18:29:43,153:INFO:Creating Dashboard logs
2023-05-21 18:29:43,153:INFO:Model: Decision Tree Classifier
2023-05-21 18:29:43,218:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2023-05-21 18:29:43,998:INFO:Creating Dashboard logs
2023-05-21 18:29:43,999:INFO:Model: Logistic Regression
2023-05-21 18:29:44,080:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-05-21 18:29:44,873:INFO:Creating Dashboard logs
2023-05-21 18:29:44,874:INFO:Model: Linear Discriminant Analysis
2023-05-21 18:29:44,974:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-05-21 18:29:45,781:INFO:Creating Dashboard logs
2023-05-21 18:29:45,782:INFO:Model: Naive Bayes
2023-05-21 18:29:45,851:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-05-21 18:29:46,657:INFO:Creating Dashboard logs
2023-05-21 18:29:46,657:INFO:Model: Ridge Classifier
2023-05-21 18:29:46,735:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2023-05-21 18:29:47,534:INFO:_master_model_container: 8
2023-05-21 18:29:47,534:INFO:_display_container: 2
2023-05-21 18:29:47,534:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 18:29:47,534:INFO:compare_models() successfully completed......................................
2023-05-21 18:30:50,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 18:30:50,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 18:30:50,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 18:30:50,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 18:30:51,400:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-21 18:30:54,410:INFO:PyCaret ClassificationExperiment
2023-05-21 18:30:54,410:INFO:Logging name: Lead_Scoring_Training_Pipeline
2023-05-21 18:30:54,410:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-21 18:30:54,410:INFO:version 3.0.0
2023-05-21 18:30:54,410:INFO:Initializing setup()
2023-05-21 18:30:54,410:INFO:self.USI: 8afd
2023-05-21 18:30:54,410:INFO:self._variable_keys: {'fold_shuffle_param', 'fix_imbalance', 'exp_name_log', 'fold_groups_param', '_available_plots', 'exp_id', 'X', 'html_param', 'X_test', 'log_plots_param', 'n_jobs_param', 'seed', 'fold_generator', 'y', 'is_multiclass', 'USI', 'idx', 'gpu_n_jobs_param', 'memory', 'y_train', '_ml_usecase', 'target_param', 'pipeline', 'data', 'X_train', 'logging_param', 'y_test', 'gpu_param'}
2023-05-21 18:30:54,410:INFO:Checking environment
2023-05-21 18:30:54,411:INFO:python_version: 3.10.10
2023-05-21 18:30:54,411:INFO:python_build: ('main', 'Mar  5 2023 22:26:53')
2023-05-21 18:30:54,411:INFO:machine: x86_64
2023-05-21 18:30:54,411:INFO:platform: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 18:30:54,412:INFO:Memory: svmem(total=16717086720, available=7387828224, percent=55.8, used=7842185216, free=6316515328, active=2400169984, inactive=5811167232, buffers=36507648, cached=2521878528, shared=1143644160, slab=480960512)
2023-05-21 18:30:54,412:INFO:Physical Core: 6
2023-05-21 18:30:54,412:INFO:Logical Core: 12
2023-05-21 18:30:54,412:INFO:Checking libraries
2023-05-21 18:30:54,413:INFO:System:
2023-05-21 18:30:54,413:INFO:    python: 3.10.10 (main, Mar  5 2023, 22:26:53) [GCC 12.2.1 20230201]
2023-05-21 18:30:54,413:INFO:executable: /usr/bin/python3.10
2023-05-21 18:30:54,413:INFO:   machine: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 18:30:54,413:INFO:PyCaret required dependencies:
2023-05-21 18:30:54,413:INFO:                 pip: 23.0.1
2023-05-21 18:30:54,413:INFO:          setuptools: 67.6.1
2023-05-21 18:30:54,413:INFO:             pycaret: 3.0.0
2023-05-21 18:30:54,413:INFO:             IPython: 8.12.0
2023-05-21 18:30:54,413:INFO:          ipywidgets: 7.7.5
2023-05-21 18:30:54,413:INFO:                tqdm: 4.64.1
2023-05-21 18:30:54,413:INFO:               numpy: 1.23.0
2023-05-21 18:30:54,413:INFO:              pandas: 1.5.3
2023-05-21 18:30:54,413:INFO:              jinja2: 3.1.2
2023-05-21 18:30:54,413:INFO:               scipy: 1.9.3
2023-05-21 18:30:54,413:INFO:              joblib: 1.2.0
2023-05-21 18:30:54,413:INFO:             sklearn: 1.2.2
2023-05-21 18:30:54,413:INFO:                pyod: 1.0.9
2023-05-21 18:30:54,413:INFO:            imblearn: 0.10.1
2023-05-21 18:30:54,413:INFO:   category_encoders: 2.6.0
2023-05-21 18:30:54,413:INFO:            lightgbm: 3.3.5
2023-05-21 18:30:54,413:INFO:               numba: 0.57.0
2023-05-21 18:30:54,413:INFO:            requests: 2.28.2
2023-05-21 18:30:54,413:INFO:          matplotlib: 3.6.3
2023-05-21 18:30:54,413:INFO:          scikitplot: 0.3.7
2023-05-21 18:30:54,414:INFO:         yellowbrick: 1.5
2023-05-21 18:30:54,414:INFO:              plotly: 5.14.1
2023-05-21 18:30:54,414:INFO:             kaleido: 0.2.1
2023-05-21 18:30:54,414:INFO:         statsmodels: 0.13.5
2023-05-21 18:30:54,414:INFO:              sktime: 0.18.0
2023-05-21 18:30:54,414:INFO:               tbats: 1.1.3
2023-05-21 18:30:54,414:INFO:            pmdarima: 2.0.3
2023-05-21 18:30:54,414:INFO:              psutil: 5.9.4
2023-05-21 18:30:54,414:INFO:PyCaret optional dependencies:
2023-05-21 18:30:54,425:INFO:                shap: 0.41.0
2023-05-21 18:30:54,425:INFO:           interpret: 0.3.2
2023-05-21 18:30:54,425:INFO:                umap: 0.5.3
2023-05-21 18:30:54,425:INFO:    pandas_profiling: 3.6.6
2023-05-21 18:30:54,425:INFO:  explainerdashboard: 0.4.2.2
2023-05-21 18:30:54,425:INFO:             autoviz: 0.1.603
2023-05-21 18:30:54,425:INFO:           fairlearn: 0.7.0
2023-05-21 18:30:54,425:INFO:             xgboost: 1.7.5
2023-05-21 18:30:54,425:INFO:            catboost: Not installed
2023-05-21 18:30:54,426:INFO:              kmodes: Not installed
2023-05-21 18:30:54,426:INFO:             mlxtend: Not installed
2023-05-21 18:30:54,426:INFO:       statsforecast: Not installed
2023-05-21 18:30:54,426:INFO:        tune_sklearn: Not installed
2023-05-21 18:30:54,426:INFO:                 ray: Not installed
2023-05-21 18:30:54,426:INFO:            hyperopt: Not installed
2023-05-21 18:30:54,426:INFO:              optuna: 3.1.1
2023-05-21 18:30:54,426:INFO:               skopt: Not installed
2023-05-21 18:30:54,426:INFO:              mlflow: 2.3.1
2023-05-21 18:30:54,426:INFO:              gradio: Not installed
2023-05-21 18:30:54,426:INFO:             fastapi: Not installed
2023-05-21 18:30:54,426:INFO:             uvicorn: Not installed
2023-05-21 18:30:54,426:INFO:              m2cgen: Not installed
2023-05-21 18:30:54,426:INFO:           evidently: Not installed
2023-05-21 18:30:54,426:INFO:               fugue: Not installed
2023-05-21 18:30:54,426:INFO:           streamlit: Not installed
2023-05-21 18:30:54,426:INFO:             prophet: Not installed
2023-05-21 18:30:54,426:INFO:None
2023-05-21 18:30:54,426:INFO:Set up data.
2023-05-21 18:30:54,520:INFO:Set up train/test split.
2023-05-21 18:30:54,520:INFO:Set up data.
2023-05-21 18:30:54,555:INFO:Set up index.
2023-05-21 18:30:54,555:INFO:Set up folding strategy.
2023-05-21 18:30:54,555:INFO:Assigning column types.
2023-05-21 18:30:54,596:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-21 18:30:54,645:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 18:30:54,647:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 18:30:54,679:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 18:30:54,698:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 18:30:54,743:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 18:30:54,743:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 18:30:54,771:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 18:30:54,774:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 18:30:54,774:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-21 18:30:54,824:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 18:30:54,858:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 18:30:54,861:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 18:30:54,915:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 18:30:54,944:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 18:30:54,947:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 18:30:54,947:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-21 18:30:55,022:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 18:30:55,025:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 18:30:55,106:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 18:30:55,109:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 18:30:55,110:INFO:Preparing preprocessing pipeline...
2023-05-21 18:30:55,116:INFO:Set up simple imputation.
2023-05-21 18:30:55,121:INFO:Set up column name cleaning.
2023-05-21 18:30:55,261:INFO:Finished creating preprocessing pipeline.
2023-05-21 18:30:55,266:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped',
                                             'referred_lead', 'city_tier_1.0',
                                             'city_tier_2.0', 'city_tier_3.0',
                                             'first_platform_c_Level0',
                                             'first_platform_c_Level1',
                                             'first_platform_c_Level2',
                                             'first_platform_c_Level3',
                                             'first_platform_c_Level7',
                                             'first_platform_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-21 18:30:55,266:INFO:Creating final display dataframe.
2023-05-21 18:30:55,457:INFO:Setup _display_container:                     Description                           Value
0                    Session id                              42
1                        Target               app_complete_flag
2                   Target type                          Binary
3           Original data shape                    (238964, 41)
4        Transformed data shape                    (238964, 41)
5   Transformed train set shape                    (191171, 41)
6    Transformed test set shape                     (47793, 41)
7              Numeric features                              40
8                    Preprocess                            True
9               Imputation type                          simple
10           Numeric imputation                            mean
11       Categorical imputation                            mode
12               Fold Generator                 StratifiedKFold
13                  Fold Number                              10
14                     CPU Jobs                              -1
15                      Use GPU                           False
16               Log Experiment                    MlflowLogger
17              Experiment Name  Lead_Scoring_Training_Pipeline
18                          USI                            8afd
2023-05-21 18:30:55,531:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 18:30:55,534:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 18:30:55,606:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 18:30:55,609:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 18:30:55,609:INFO:Logging experiment in loggers
2023-05-21 18:30:56,084:INFO:SubProcess save_model() called ==================================
2023-05-21 18:30:56,095:INFO:Initializing save_model()
2023-05-21 18:30:56,095:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped',
                                             'referred_lead', 'city_tier_1.0',
                                             'city_tier_2.0', 'city_tier_3.0',
                                             'first_platform_c_Level0',
                                             'first_platform_c_Level1',
                                             'first_platform_c_Level2',
                                             'first_platform_c_Level3',
                                             'first_platform_c_Level7',
                                             'first_platform_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=/tmp/tmp2att8w7x/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped',
                                             'referred_lead', 'city_tier_1.0',
                                             'city_tier_2.0', 'city_tier_3.0',
                                             'first_platform_c_Level0',
                                             'first_platform_c_Level1',
                                             'first_platform_c_Level2',
                                             'first_platform_c_Level3',
                                             'first_platform_c_Level7',
                                             'first_platform_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-21 18:30:56,095:INFO:Adding model into prep_pipe
2023-05-21 18:30:56,096:WARNING:Only Model saved as it was a pipeline.
2023-05-21 18:30:56,099:INFO:/tmp/tmp2att8w7x/Transformation Pipeline.pkl saved in current working directory
2023-05-21 18:30:56,103:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped',
                                             'referred_lead', 'city_tier_1.0',
                                             'city_tier_2.0', 'city_tier_3.0',
                                             'first_platform_c_Level0',
                                             'first_platform_c_Level1',
                                             'first_platform_c_Level2',
                                             'first_platform_c_Level3',
                                             'first_platform_c_Level7',
                                             'first_platform_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-21 18:30:56,104:INFO:save_model() successfully completed......................................
2023-05-21 18:30:56,221:INFO:SubProcess save_model() end ==================================
2023-05-21 18:30:57,547:INFO:setup() successfully completed in 1.22s...............
2023-05-21 18:30:57,547:INFO:Initializing compare_models()
2023-05-21 18:30:57,547:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3a6cdc9bd0>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f3a6cdc9bd0>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'])
2023-05-21 18:30:57,547:INFO:Checking exceptions
2023-05-21 18:30:57,577:INFO:Preparing display monitor
2023-05-21 18:30:57,580:INFO:Initializing Logistic Regression
2023-05-21 18:30:57,581:INFO:Total runtime is 1.2556711832682292e-06 minutes
2023-05-21 18:30:57,581:INFO:SubProcess create_model() called ==================================
2023-05-21 18:30:57,581:INFO:Initializing create_model()
2023-05-21 18:30:57,581:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3a6cdc9bd0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3a278cea70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:30:57,581:INFO:Checking exceptions
2023-05-21 18:30:57,581:INFO:Importing libraries
2023-05-21 18:30:57,581:INFO:Copying training dataset
2023-05-21 18:30:57,641:INFO:Defining folds
2023-05-21 18:30:57,641:INFO:Declaring metric variables
2023-05-21 18:30:57,641:INFO:Importing untrained model
2023-05-21 18:30:57,641:INFO:Logistic Regression Imported successfully
2023-05-21 18:30:57,642:INFO:Starting cross validation
2023-05-21 18:30:57,642:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 18:31:00,282:INFO:Calculating mean and std
2023-05-21 18:31:00,283:INFO:Creating metrics dataframe
2023-05-21 18:31:00,315:INFO:Uploading results into container
2023-05-21 18:31:00,316:INFO:Uploading model into container now
2023-05-21 18:31:00,316:INFO:_master_model_container: 1
2023-05-21 18:31:00,316:INFO:_display_container: 2
2023-05-21 18:31:00,317:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-21 18:31:00,317:INFO:create_model() successfully completed......................................
2023-05-21 18:31:00,430:INFO:SubProcess create_model() end ==================================
2023-05-21 18:31:00,431:INFO:Creating metrics dataframe
2023-05-21 18:31:00,434:INFO:Initializing Naive Bayes
2023-05-21 18:31:00,434:INFO:Total runtime is 0.04756349722544352 minutes
2023-05-21 18:31:00,434:INFO:SubProcess create_model() called ==================================
2023-05-21 18:31:00,435:INFO:Initializing create_model()
2023-05-21 18:31:00,435:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3a6cdc9bd0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3a278cea70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:31:00,435:INFO:Checking exceptions
2023-05-21 18:31:00,435:INFO:Importing libraries
2023-05-21 18:31:00,435:INFO:Copying training dataset
2023-05-21 18:31:00,488:INFO:Defining folds
2023-05-21 18:31:00,489:INFO:Declaring metric variables
2023-05-21 18:31:00,489:INFO:Importing untrained model
2023-05-21 18:31:00,489:INFO:Naive Bayes Imported successfully
2023-05-21 18:31:00,489:INFO:Starting cross validation
2023-05-21 18:31:00,490:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 18:31:02,177:INFO:Calculating mean and std
2023-05-21 18:31:02,178:INFO:Creating metrics dataframe
2023-05-21 18:31:02,194:INFO:Uploading results into container
2023-05-21 18:31:02,195:INFO:Uploading model into container now
2023-05-21 18:31:02,195:INFO:_master_model_container: 2
2023-05-21 18:31:02,195:INFO:_display_container: 2
2023-05-21 18:31:02,195:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-21 18:31:02,195:INFO:create_model() successfully completed......................................
2023-05-21 18:31:02,300:INFO:SubProcess create_model() end ==================================
2023-05-21 18:31:02,301:INFO:Creating metrics dataframe
2023-05-21 18:31:02,305:INFO:Initializing Decision Tree Classifier
2023-05-21 18:31:02,305:INFO:Total runtime is 0.07873635689417521 minutes
2023-05-21 18:31:02,305:INFO:SubProcess create_model() called ==================================
2023-05-21 18:31:02,305:INFO:Initializing create_model()
2023-05-21 18:31:02,305:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3a6cdc9bd0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3a278cea70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:31:02,305:INFO:Checking exceptions
2023-05-21 18:31:02,305:INFO:Importing libraries
2023-05-21 18:31:02,305:INFO:Copying training dataset
2023-05-21 18:31:02,358:INFO:Defining folds
2023-05-21 18:31:02,358:INFO:Declaring metric variables
2023-05-21 18:31:02,358:INFO:Importing untrained model
2023-05-21 18:31:02,358:INFO:Decision Tree Classifier Imported successfully
2023-05-21 18:31:02,359:INFO:Starting cross validation
2023-05-21 18:31:02,359:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 18:31:03,034:INFO:Calculating mean and std
2023-05-21 18:31:03,035:INFO:Creating metrics dataframe
2023-05-21 18:31:03,058:INFO:Uploading results into container
2023-05-21 18:31:03,059:INFO:Uploading model into container now
2023-05-21 18:31:03,059:INFO:_master_model_container: 3
2023-05-21 18:31:03,059:INFO:_display_container: 2
2023-05-21 18:31:03,059:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-05-21 18:31:03,059:INFO:create_model() successfully completed......................................
2023-05-21 18:31:03,154:INFO:SubProcess create_model() end ==================================
2023-05-21 18:31:03,154:INFO:Creating metrics dataframe
2023-05-21 18:31:03,158:INFO:Initializing Ridge Classifier
2023-05-21 18:31:03,158:INFO:Total runtime is 0.09296239217122396 minutes
2023-05-21 18:31:03,158:INFO:SubProcess create_model() called ==================================
2023-05-21 18:31:03,159:INFO:Initializing create_model()
2023-05-21 18:31:03,159:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3a6cdc9bd0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3a278cea70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:31:03,159:INFO:Checking exceptions
2023-05-21 18:31:03,159:INFO:Importing libraries
2023-05-21 18:31:03,159:INFO:Copying training dataset
2023-05-21 18:31:03,221:INFO:Defining folds
2023-05-21 18:31:03,221:INFO:Declaring metric variables
2023-05-21 18:31:03,221:INFO:Importing untrained model
2023-05-21 18:31:03,221:INFO:Ridge Classifier Imported successfully
2023-05-21 18:31:03,221:INFO:Starting cross validation
2023-05-21 18:31:03,222:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 18:31:03,546:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:31:03,555:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:31:03,590:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:31:03,597:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:31:03,600:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:31:03,607:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:31:03,611:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:31:03,612:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:31:03,631:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:31:03,644:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 18:31:03,834:INFO:Calculating mean and std
2023-05-21 18:31:03,835:INFO:Creating metrics dataframe
2023-05-21 18:31:03,865:INFO:Uploading results into container
2023-05-21 18:31:03,865:INFO:Uploading model into container now
2023-05-21 18:31:03,866:INFO:_master_model_container: 4
2023-05-21 18:31:03,866:INFO:_display_container: 2
2023-05-21 18:31:03,866:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-05-21 18:31:03,866:INFO:create_model() successfully completed......................................
2023-05-21 18:31:03,967:INFO:SubProcess create_model() end ==================================
2023-05-21 18:31:03,967:INFO:Creating metrics dataframe
2023-05-21 18:31:03,971:INFO:Initializing Random Forest Classifier
2023-05-21 18:31:03,971:INFO:Total runtime is 0.10651700496673584 minutes
2023-05-21 18:31:03,972:INFO:SubProcess create_model() called ==================================
2023-05-21 18:31:03,972:INFO:Initializing create_model()
2023-05-21 18:31:03,972:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3a6cdc9bd0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3a278cea70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:31:03,972:INFO:Checking exceptions
2023-05-21 18:31:03,972:INFO:Importing libraries
2023-05-21 18:31:03,972:INFO:Copying training dataset
2023-05-21 18:31:04,023:INFO:Defining folds
2023-05-21 18:31:04,023:INFO:Declaring metric variables
2023-05-21 18:31:04,023:INFO:Importing untrained model
2023-05-21 18:31:04,023:INFO:Random Forest Classifier Imported successfully
2023-05-21 18:31:04,023:INFO:Starting cross validation
2023-05-21 18:31:04,024:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 18:31:05,548:INFO:Calculating mean and std
2023-05-21 18:31:05,549:INFO:Creating metrics dataframe
2023-05-21 18:31:05,572:INFO:Uploading results into container
2023-05-21 18:31:05,573:INFO:Uploading model into container now
2023-05-21 18:31:05,573:INFO:_master_model_container: 5
2023-05-21 18:31:05,573:INFO:_display_container: 2
2023-05-21 18:31:05,574:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-05-21 18:31:05,574:INFO:create_model() successfully completed......................................
2023-05-21 18:31:05,674:INFO:SubProcess create_model() end ==================================
2023-05-21 18:31:05,675:INFO:Creating metrics dataframe
2023-05-21 18:31:05,679:INFO:Initializing Linear Discriminant Analysis
2023-05-21 18:31:05,679:INFO:Total runtime is 0.1349712649981181 minutes
2023-05-21 18:31:05,679:INFO:SubProcess create_model() called ==================================
2023-05-21 18:31:05,679:INFO:Initializing create_model()
2023-05-21 18:31:05,679:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3a6cdc9bd0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3a278cea70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:31:05,679:INFO:Checking exceptions
2023-05-21 18:31:05,679:INFO:Importing libraries
2023-05-21 18:31:05,679:INFO:Copying training dataset
2023-05-21 18:31:05,732:INFO:Defining folds
2023-05-21 18:31:05,732:INFO:Declaring metric variables
2023-05-21 18:31:05,732:INFO:Importing untrained model
2023-05-21 18:31:05,732:INFO:Linear Discriminant Analysis Imported successfully
2023-05-21 18:31:05,733:INFO:Starting cross validation
2023-05-21 18:31:05,733:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 18:31:06,432:INFO:Calculating mean and std
2023-05-21 18:31:06,432:INFO:Creating metrics dataframe
2023-05-21 18:31:06,449:INFO:Uploading results into container
2023-05-21 18:31:06,449:INFO:Uploading model into container now
2023-05-21 18:31:06,450:INFO:_master_model_container: 6
2023-05-21 18:31:06,450:INFO:_display_container: 2
2023-05-21 18:31:06,450:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-21 18:31:06,450:INFO:create_model() successfully completed......................................
2023-05-21 18:31:06,548:INFO:SubProcess create_model() end ==================================
2023-05-21 18:31:06,548:INFO:Creating metrics dataframe
2023-05-21 18:31:06,553:INFO:Initializing Extra Trees Classifier
2023-05-21 18:31:06,553:INFO:Total runtime is 0.14953901370366415 minutes
2023-05-21 18:31:06,553:INFO:SubProcess create_model() called ==================================
2023-05-21 18:31:06,553:INFO:Initializing create_model()
2023-05-21 18:31:06,553:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3a6cdc9bd0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3a278cea70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:31:06,553:INFO:Checking exceptions
2023-05-21 18:31:06,553:INFO:Importing libraries
2023-05-21 18:31:06,553:INFO:Copying training dataset
2023-05-21 18:31:06,605:INFO:Defining folds
2023-05-21 18:31:06,605:INFO:Declaring metric variables
2023-05-21 18:31:06,605:INFO:Importing untrained model
2023-05-21 18:31:06,606:INFO:Extra Trees Classifier Imported successfully
2023-05-21 18:31:06,606:INFO:Starting cross validation
2023-05-21 18:31:06,606:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 18:31:08,311:INFO:Calculating mean and std
2023-05-21 18:31:08,312:INFO:Creating metrics dataframe
2023-05-21 18:31:08,342:INFO:Uploading results into container
2023-05-21 18:31:08,343:INFO:Uploading model into container now
2023-05-21 18:31:08,343:INFO:_master_model_container: 7
2023-05-21 18:31:08,343:INFO:_display_container: 2
2023-05-21 18:31:08,344:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-05-21 18:31:08,344:INFO:create_model() successfully completed......................................
2023-05-21 18:31:08,449:INFO:SubProcess create_model() end ==================================
2023-05-21 18:31:08,449:INFO:Creating metrics dataframe
2023-05-21 18:31:08,454:INFO:Initializing Light Gradient Boosting Machine
2023-05-21 18:31:08,454:INFO:Total runtime is 0.1812194307645162 minutes
2023-05-21 18:31:08,454:INFO:SubProcess create_model() called ==================================
2023-05-21 18:31:08,454:INFO:Initializing create_model()
2023-05-21 18:31:08,454:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3a6cdc9bd0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3a278cea70>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:31:08,454:INFO:Checking exceptions
2023-05-21 18:31:08,454:INFO:Importing libraries
2023-05-21 18:31:08,454:INFO:Copying training dataset
2023-05-21 18:31:08,515:INFO:Defining folds
2023-05-21 18:31:08,515:INFO:Declaring metric variables
2023-05-21 18:31:08,515:INFO:Importing untrained model
2023-05-21 18:31:08,516:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 18:31:08,516:INFO:Starting cross validation
2023-05-21 18:31:08,517:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 18:31:09,409:INFO:Calculating mean and std
2023-05-21 18:31:09,410:INFO:Creating metrics dataframe
2023-05-21 18:31:09,426:INFO:Uploading results into container
2023-05-21 18:31:09,426:INFO:Uploading model into container now
2023-05-21 18:31:09,427:INFO:_master_model_container: 8
2023-05-21 18:31:09,427:INFO:_display_container: 2
2023-05-21 18:31:09,427:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 18:31:09,427:INFO:create_model() successfully completed......................................
2023-05-21 18:31:09,528:INFO:SubProcess create_model() end ==================================
2023-05-21 18:31:09,528:INFO:Creating metrics dataframe
2023-05-21 18:31:09,533:INFO:Initializing create_model()
2023-05-21 18:31:09,533:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3a6cdc9bd0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-21 18:31:09,533:INFO:Checking exceptions
2023-05-21 18:31:09,534:INFO:Importing libraries
2023-05-21 18:31:09,534:INFO:Copying training dataset
2023-05-21 18:31:09,585:INFO:Defining folds
2023-05-21 18:31:09,585:INFO:Declaring metric variables
2023-05-21 18:31:09,586:INFO:Importing untrained model
2023-05-21 18:31:09,586:INFO:Declaring custom model
2023-05-21 18:31:09,586:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 18:31:09,587:INFO:Cross validation set to False
2023-05-21 18:31:09,587:INFO:Fitting Model
2023-05-21 18:31:09,730:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 18:31:09,730:INFO:create_model() successfully completed......................................
2023-05-21 18:31:09,824:INFO:Creating Dashboard logs
2023-05-21 18:31:09,824:INFO:Model: Light Gradient Boosting Machine
2023-05-21 18:31:09,905:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-21 18:31:10,391:INFO:Initializing predict_model()
2023-05-21 18:31:10,391:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3a6cdc9bd0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7f3a22f08e50>)
2023-05-21 18:31:10,391:INFO:Checking exceptions
2023-05-21 18:31:10,391:INFO:Preloading libraries
2023-05-21 18:31:10,761:INFO:SubProcess plot_model() called ==================================
2023-05-21 18:31:10,761:INFO:Initializing plot_model()
2023-05-21 18:31:10,761:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp7nhlkf1b, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3a6cdc9bd0>, system=False)
2023-05-21 18:31:10,761:INFO:Checking exceptions
2023-05-21 18:31:10,783:INFO:Preloading libraries
2023-05-21 18:31:10,786:INFO:Copying training dataset
2023-05-21 18:31:10,786:INFO:Plot type: auc
2023-05-21 18:31:11,022:INFO:Fitting Model
2023-05-21 18:31:11,027:INFO:Scoring test/hold-out set
2023-05-21 18:31:11,169:INFO:Saving '/tmp/tmp7nhlkf1b/AUC.png'
2023-05-21 18:31:11,378:INFO:Visual Rendered Successfully
2023-05-21 18:31:11,471:INFO:plot_model() successfully completed......................................
2023-05-21 18:31:11,472:INFO:Initializing plot_model()
2023-05-21 18:31:11,472:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp7nhlkf1b, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3a6cdc9bd0>, system=False)
2023-05-21 18:31:11,472:INFO:Checking exceptions
2023-05-21 18:31:11,492:INFO:Preloading libraries
2023-05-21 18:31:11,496:INFO:Copying training dataset
2023-05-21 18:31:11,496:INFO:Plot type: confusion_matrix
2023-05-21 18:31:11,675:INFO:Fitting Model
2023-05-21 18:31:11,677:INFO:Scoring test/hold-out set
2023-05-21 18:31:11,792:INFO:Saving '/tmp/tmp7nhlkf1b/Confusion Matrix.png'
2023-05-21 18:31:11,881:INFO:Visual Rendered Successfully
2023-05-21 18:31:11,975:INFO:plot_model() successfully completed......................................
2023-05-21 18:31:11,976:INFO:Initializing plot_model()
2023-05-21 18:31:11,977:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp7nhlkf1b, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3a6cdc9bd0>, system=False)
2023-05-21 18:31:11,977:INFO:Checking exceptions
2023-05-21 18:31:11,995:INFO:Preloading libraries
2023-05-21 18:31:11,999:INFO:Copying training dataset
2023-05-21 18:31:11,999:INFO:Plot type: feature
2023-05-21 18:31:12,000:WARNING:No coef_ found. Trying feature_importances_
2023-05-21 18:31:12,081:INFO:Saving '/tmp/tmp7nhlkf1b/Feature Importance.png'
2023-05-21 18:31:12,205:INFO:Visual Rendered Successfully
2023-05-21 18:31:12,299:INFO:plot_model() successfully completed......................................
2023-05-21 18:31:12,300:INFO:SubProcess plot_model() end ==================================
2023-05-21 18:31:12,301:WARNING:/home/feuer/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-05-21 18:31:12,556:INFO:Creating Dashboard logs
2023-05-21 18:31:12,556:INFO:Model: Random Forest Classifier
2023-05-21 18:31:12,669:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 18:31:13,552:INFO:Creating Dashboard logs
2023-05-21 18:31:13,552:INFO:Model: Extra Trees Classifier
2023-05-21 18:31:13,657:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 18:31:14,573:INFO:Creating Dashboard logs
2023-05-21 18:31:14,573:INFO:Model: Decision Tree Classifier
2023-05-21 18:31:14,678:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2023-05-21 18:31:15,498:INFO:Creating Dashboard logs
2023-05-21 18:31:15,499:INFO:Model: Logistic Regression
2023-05-21 18:31:15,591:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-05-21 18:31:16,478:INFO:Creating Dashboard logs
2023-05-21 18:31:16,478:INFO:Model: Linear Discriminant Analysis
2023-05-21 18:31:16,566:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-05-21 18:31:17,408:INFO:Creating Dashboard logs
2023-05-21 18:31:17,408:INFO:Model: Naive Bayes
2023-05-21 18:31:17,483:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-05-21 18:31:18,263:INFO:Creating Dashboard logs
2023-05-21 18:31:18,264:INFO:Model: Ridge Classifier
2023-05-21 18:31:18,346:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2023-05-21 18:31:19,105:INFO:_master_model_container: 8
2023-05-21 18:31:19,105:INFO:_display_container: 2
2023-05-21 18:31:19,105:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 18:31:19,105:INFO:compare_models() successfully completed......................................
2023-05-21 19:00:58,698:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 19:00:58,698:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 19:00:58,699:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 19:00:58,699:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 19:00:59,735:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-21 19:01:16,439:INFO:PyCaret ClassificationExperiment
2023-05-21 19:01:16,440:INFO:Logging name: Lead_Scoring_Training_Pipeline
2023-05-21 19:01:16,440:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-21 19:01:16,440:INFO:version 3.0.0
2023-05-21 19:01:16,440:INFO:Initializing setup()
2023-05-21 19:01:16,440:INFO:self.USI: 967b
2023-05-21 19:01:16,440:INFO:self._variable_keys: {'html_param', 'fold_generator', 'gpu_param', 'y_test', 'exp_name_log', 'fold_groups_param', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'X_train', 'seed', 'target_param', 'logging_param', 'y', 'idx', 'X_test', 'exp_id', 'memory', 'USI', '_available_plots', 'log_plots_param', 'X', 'is_multiclass', 'data', 'y_train', 'fold_shuffle_param', 'fix_imbalance', 'pipeline'}
2023-05-21 19:01:16,440:INFO:Checking environment
2023-05-21 19:01:16,440:INFO:python_version: 3.10.10
2023-05-21 19:01:16,440:INFO:python_build: ('main', 'Mar  5 2023 22:26:53')
2023-05-21 19:01:16,440:INFO:machine: x86_64
2023-05-21 19:01:16,442:INFO:platform: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 19:01:16,442:INFO:Memory: svmem(total=16717086720, available=5800218624, percent=65.3, used=9291526144, free=4422823936, active=4365303808, inactive=5687312384, buffers=52330496, cached=2950406144, shared=1281904640, slab=487649280)
2023-05-21 19:01:16,444:INFO:Physical Core: 6
2023-05-21 19:01:16,444:INFO:Logical Core: 12
2023-05-21 19:01:16,444:INFO:Checking libraries
2023-05-21 19:01:16,444:INFO:System:
2023-05-21 19:01:16,444:INFO:    python: 3.10.10 (main, Mar  5 2023, 22:26:53) [GCC 12.2.1 20230201]
2023-05-21 19:01:16,445:INFO:executable: /usr/bin/python3.10
2023-05-21 19:01:16,445:INFO:   machine: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 19:01:16,445:INFO:PyCaret required dependencies:
2023-05-21 19:01:16,445:INFO:                 pip: 23.0.1
2023-05-21 19:01:16,445:INFO:          setuptools: 67.6.1
2023-05-21 19:01:16,445:INFO:             pycaret: 3.0.0
2023-05-21 19:01:16,445:INFO:             IPython: 8.12.0
2023-05-21 19:01:16,445:INFO:          ipywidgets: 7.7.5
2023-05-21 19:01:16,445:INFO:                tqdm: 4.64.1
2023-05-21 19:01:16,445:INFO:               numpy: 1.23.0
2023-05-21 19:01:16,446:INFO:              pandas: 1.5.3
2023-05-21 19:01:16,446:INFO:              jinja2: 3.1.2
2023-05-21 19:01:16,446:INFO:               scipy: 1.9.3
2023-05-21 19:01:16,446:INFO:              joblib: 1.2.0
2023-05-21 19:01:16,446:INFO:             sklearn: 1.2.2
2023-05-21 19:01:16,446:INFO:                pyod: 1.0.9
2023-05-21 19:01:16,446:INFO:            imblearn: 0.10.1
2023-05-21 19:01:16,446:INFO:   category_encoders: 2.6.0
2023-05-21 19:01:16,446:INFO:            lightgbm: 3.3.5
2023-05-21 19:01:16,446:INFO:               numba: 0.57.0
2023-05-21 19:01:16,446:INFO:            requests: 2.28.2
2023-05-21 19:01:16,446:INFO:          matplotlib: 3.6.3
2023-05-21 19:01:16,447:INFO:          scikitplot: 0.3.7
2023-05-21 19:01:16,447:INFO:         yellowbrick: 1.5
2023-05-21 19:01:16,447:INFO:              plotly: 5.14.1
2023-05-21 19:01:16,447:INFO:             kaleido: 0.2.1
2023-05-21 19:01:16,447:INFO:         statsmodels: 0.13.5
2023-05-21 19:01:16,447:INFO:              sktime: 0.18.0
2023-05-21 19:01:16,447:INFO:               tbats: 1.1.3
2023-05-21 19:01:16,447:INFO:            pmdarima: 2.0.3
2023-05-21 19:01:16,447:INFO:              psutil: 5.9.4
2023-05-21 19:01:16,447:INFO:PyCaret optional dependencies:
2023-05-21 19:01:16,481:INFO:                shap: 0.41.0
2023-05-21 19:01:16,481:INFO:           interpret: 0.3.2
2023-05-21 19:01:16,481:INFO:                umap: 0.5.3
2023-05-21 19:01:16,481:INFO:    pandas_profiling: 3.6.6
2023-05-21 19:01:16,481:INFO:  explainerdashboard: 0.4.2.2
2023-05-21 19:01:16,481:INFO:             autoviz: 0.1.603
2023-05-21 19:01:16,482:INFO:           fairlearn: 0.7.0
2023-05-21 19:01:16,482:INFO:             xgboost: 1.7.5
2023-05-21 19:01:16,482:INFO:            catboost: Not installed
2023-05-21 19:01:16,482:INFO:              kmodes: Not installed
2023-05-21 19:01:16,482:INFO:             mlxtend: Not installed
2023-05-21 19:01:16,482:INFO:       statsforecast: Not installed
2023-05-21 19:01:16,482:INFO:        tune_sklearn: Not installed
2023-05-21 19:01:16,482:INFO:                 ray: Not installed
2023-05-21 19:01:16,482:INFO:            hyperopt: Not installed
2023-05-21 19:01:16,482:INFO:              optuna: 3.1.1
2023-05-21 19:01:16,482:INFO:               skopt: Not installed
2023-05-21 19:01:16,483:INFO:              mlflow: 2.3.1
2023-05-21 19:01:16,483:INFO:              gradio: Not installed
2023-05-21 19:01:16,483:INFO:             fastapi: Not installed
2023-05-21 19:01:16,483:INFO:             uvicorn: Not installed
2023-05-21 19:01:16,483:INFO:              m2cgen: Not installed
2023-05-21 19:01:16,483:INFO:           evidently: Not installed
2023-05-21 19:01:16,483:INFO:               fugue: Not installed
2023-05-21 19:01:16,483:INFO:           streamlit: Not installed
2023-05-21 19:01:16,483:INFO:             prophet: Not installed
2023-05-21 19:01:16,483:INFO:None
2023-05-21 19:01:16,483:INFO:Set up data.
2023-05-21 19:01:16,582:INFO:Set up train/test split.
2023-05-21 19:01:16,582:INFO:Set up data.
2023-05-21 19:01:16,641:INFO:Set up index.
2023-05-21 19:01:16,641:INFO:Set up folding strategy.
2023-05-21 19:01:16,642:INFO:Assigning column types.
2023-05-21 19:01:16,682:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-21 19:01:16,734:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 19:01:16,736:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 19:01:16,775:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 19:01:16,823:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 19:01:16,875:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 19:01:16,876:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 19:01:16,909:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 19:01:16,912:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 19:01:16,912:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-21 19:01:16,965:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 19:01:16,996:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 19:01:16,999:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 19:01:17,050:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 19:01:17,081:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 19:01:17,084:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 19:01:17,085:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-21 19:01:17,170:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 19:01:17,173:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 19:01:17,255:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 19:01:17,258:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 19:01:17,261:INFO:Preparing preprocessing pipeline...
2023-05-21 19:01:17,268:INFO:Set up simple imputation.
2023-05-21 19:01:17,275:INFO:Set up column name cleaning.
2023-05-21 19:01:17,488:INFO:Finished creating preprocessing pipeline.
2023-05-21 19:01:17,513:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped',
                                             'referred_lead', 'city_tier_1.0',
                                             'city_tier_2.0', 'city_tier_3.0',
                                             'first_platform_c_Level0',
                                             'first_platform_c_Level1',
                                             'first_platform_c_Level2',
                                             'first_platform_c_Level3',
                                             'first_platform_c_Level7',
                                             'first_platform_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-21 19:01:17,513:INFO:Creating final display dataframe.
2023-05-21 19:01:17,850:INFO:Setup _display_container:                     Description                           Value
0                    Session id                              42
1                        Target               app_complete_flag
2                   Target type                          Binary
3           Original data shape                    (238964, 41)
4        Transformed data shape                    (238964, 41)
5   Transformed train set shape                    (191171, 41)
6    Transformed test set shape                     (47793, 41)
7              Numeric features                              40
8                    Preprocess                            True
9               Imputation type                          simple
10           Numeric imputation                            mean
11       Categorical imputation                            mode
12               Fold Generator                 StratifiedKFold
13                  Fold Number                              10
14                     CPU Jobs                              -1
15                      Use GPU                           False
16               Log Experiment                    MlflowLogger
17              Experiment Name  Lead_Scoring_Training_Pipeline
18                          USI                            967b
2023-05-21 19:01:17,947:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 19:01:17,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 19:01:18,032:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 19:01:18,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 19:01:18,036:INFO:Logging experiment in loggers
2023-05-21 19:01:18,690:INFO:SubProcess save_model() called ==================================
2023-05-21 19:01:18,771:INFO:Initializing save_model()
2023-05-21 19:01:18,771:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped',
                                             'referred_lead', 'city_tier_1.0',
                                             'city_tier_2.0', 'city_tier_3.0',
                                             'first_platform_c_Level0',
                                             'first_platform_c_Level1',
                                             'first_platform_c_Level2',
                                             'first_platform_c_Level3',
                                             'first_platform_c_Level7',
                                             'first_platform_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=/tmp/tmp4hpd40gi/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped',
                                             'referred_lead', 'city_tier_1.0',
                                             'city_tier_2.0', 'city_tier_3.0',
                                             'first_platform_c_Level0',
                                             'first_platform_c_Level1',
                                             'first_platform_c_Level2',
                                             'first_platform_c_Level3',
                                             'first_platform_c_Level7',
                                             'first_platform_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-21 19:01:18,771:INFO:Adding model into prep_pipe
2023-05-21 19:01:18,775:WARNING:Only Model saved as it was a pipeline.
2023-05-21 19:01:18,785:INFO:/tmp/tmp4hpd40gi/Transformation Pipeline.pkl saved in current working directory
2023-05-21 19:01:18,807:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped',
                                             'referred_lead', 'city_tier_1.0',
                                             'city_tier_2.0', 'city_tier_3.0',
                                             'first_platform_c_Level0',
                                             'first_platform_c_Level1',
                                             'first_platform_c_Level2',
                                             'first_platform_c_Level3',
                                             'first_platform_c_Level7',
                                             'first_platform_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-21 19:01:18,807:INFO:save_model() successfully completed......................................
2023-05-21 19:01:18,973:INFO:SubProcess save_model() end ==================================
2023-05-21 19:01:20,277:INFO:setup() successfully completed in 1.7s...............
2023-05-21 19:01:20,277:INFO:Initializing compare_models()
2023-05-21 19:01:20,278:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3d229f4340>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f3d229f4340>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'])
2023-05-21 19:01:20,278:INFO:Checking exceptions
2023-05-21 19:01:20,313:INFO:Preparing display monitor
2023-05-21 19:01:20,321:INFO:Initializing Logistic Regression
2023-05-21 19:01:20,321:INFO:Total runtime is 3.401438395182292e-06 minutes
2023-05-21 19:01:20,321:INFO:SubProcess create_model() called ==================================
2023-05-21 19:01:20,322:INFO:Initializing create_model()
2023-05-21 19:01:20,322:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3d229f4340>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d0fb5dff0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 19:01:20,322:INFO:Checking exceptions
2023-05-21 19:01:20,322:INFO:Importing libraries
2023-05-21 19:01:20,322:INFO:Copying training dataset
2023-05-21 19:01:20,384:INFO:Defining folds
2023-05-21 19:01:20,385:INFO:Declaring metric variables
2023-05-21 19:01:20,385:INFO:Importing untrained model
2023-05-21 19:01:20,386:INFO:Logistic Regression Imported successfully
2023-05-21 19:01:20,387:INFO:Starting cross validation
2023-05-21 19:01:20,391:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 19:01:27,899:INFO:Calculating mean and std
2023-05-21 19:01:27,901:INFO:Creating metrics dataframe
2023-05-21 19:01:28,008:INFO:Uploading results into container
2023-05-21 19:01:28,009:INFO:Uploading model into container now
2023-05-21 19:01:28,010:INFO:_master_model_container: 1
2023-05-21 19:01:28,010:INFO:_display_container: 2
2023-05-21 19:01:28,012:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-21 19:01:28,012:INFO:create_model() successfully completed......................................
2023-05-21 19:01:28,131:INFO:SubProcess create_model() end ==================================
2023-05-21 19:01:28,131:INFO:Creating metrics dataframe
2023-05-21 19:01:28,143:INFO:Initializing Naive Bayes
2023-05-21 19:01:28,143:INFO:Total runtime is 0.13036989370981852 minutes
2023-05-21 19:01:28,143:INFO:SubProcess create_model() called ==================================
2023-05-21 19:01:28,144:INFO:Initializing create_model()
2023-05-21 19:01:28,144:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3d229f4340>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d0fb5dff0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 19:01:28,144:INFO:Checking exceptions
2023-05-21 19:01:28,144:INFO:Importing libraries
2023-05-21 19:01:28,144:INFO:Copying training dataset
2023-05-21 19:01:28,207:INFO:Defining folds
2023-05-21 19:01:28,207:INFO:Declaring metric variables
2023-05-21 19:01:28,208:INFO:Importing untrained model
2023-05-21 19:01:28,208:INFO:Naive Bayes Imported successfully
2023-05-21 19:01:28,209:INFO:Starting cross validation
2023-05-21 19:01:28,213:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 19:01:32,241:INFO:Calculating mean and std
2023-05-21 19:01:32,242:INFO:Creating metrics dataframe
2023-05-21 19:01:32,360:INFO:Uploading results into container
2023-05-21 19:01:32,362:INFO:Uploading model into container now
2023-05-21 19:01:32,364:INFO:_master_model_container: 2
2023-05-21 19:01:32,364:INFO:_display_container: 2
2023-05-21 19:01:32,364:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-21 19:01:32,364:INFO:create_model() successfully completed......................................
2023-05-21 19:01:32,493:INFO:SubProcess create_model() end ==================================
2023-05-21 19:01:32,493:INFO:Creating metrics dataframe
2023-05-21 19:01:32,506:INFO:Initializing Decision Tree Classifier
2023-05-21 19:01:32,506:INFO:Total runtime is 0.2030969262123108 minutes
2023-05-21 19:01:32,507:INFO:SubProcess create_model() called ==================================
2023-05-21 19:01:32,507:INFO:Initializing create_model()
2023-05-21 19:01:32,507:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3d229f4340>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d0fb5dff0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 19:01:32,507:INFO:Checking exceptions
2023-05-21 19:01:32,507:INFO:Importing libraries
2023-05-21 19:01:32,507:INFO:Copying training dataset
2023-05-21 19:01:32,580:INFO:Defining folds
2023-05-21 19:01:32,580:INFO:Declaring metric variables
2023-05-21 19:01:32,581:INFO:Importing untrained model
2023-05-21 19:01:32,583:INFO:Decision Tree Classifier Imported successfully
2023-05-21 19:01:32,584:INFO:Starting cross validation
2023-05-21 19:01:32,590:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 19:01:34,027:INFO:Calculating mean and std
2023-05-21 19:01:34,029:INFO:Creating metrics dataframe
2023-05-21 19:01:34,137:INFO:Uploading results into container
2023-05-21 19:01:34,138:INFO:Uploading model into container now
2023-05-21 19:01:34,139:INFO:_master_model_container: 3
2023-05-21 19:01:34,139:INFO:_display_container: 2
2023-05-21 19:01:34,140:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-05-21 19:01:34,140:INFO:create_model() successfully completed......................................
2023-05-21 19:01:34,262:INFO:SubProcess create_model() end ==================================
2023-05-21 19:01:34,262:INFO:Creating metrics dataframe
2023-05-21 19:01:34,276:INFO:Initializing Ridge Classifier
2023-05-21 19:01:34,277:INFO:Total runtime is 0.2326014796892802 minutes
2023-05-21 19:01:34,277:INFO:SubProcess create_model() called ==================================
2023-05-21 19:01:34,277:INFO:Initializing create_model()
2023-05-21 19:01:34,278:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3d229f4340>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d0fb5dff0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 19:01:34,278:INFO:Checking exceptions
2023-05-21 19:01:34,278:INFO:Importing libraries
2023-05-21 19:01:34,278:INFO:Copying training dataset
2023-05-21 19:01:34,346:INFO:Defining folds
2023-05-21 19:01:34,346:INFO:Declaring metric variables
2023-05-21 19:01:34,346:INFO:Importing untrained model
2023-05-21 19:01:34,347:INFO:Ridge Classifier Imported successfully
2023-05-21 19:01:34,348:INFO:Starting cross validation
2023-05-21 19:01:34,353:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 19:01:34,852:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 19:01:34,857:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 19:01:34,857:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 19:01:34,879:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 19:01:34,908:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 19:01:34,917:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 19:01:34,936:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 19:01:34,942:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 19:01:35,002:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 19:01:35,273:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 19:01:35,689:INFO:Calculating mean and std
2023-05-21 19:01:35,691:INFO:Creating metrics dataframe
2023-05-21 19:01:35,805:INFO:Uploading results into container
2023-05-21 19:01:35,806:INFO:Uploading model into container now
2023-05-21 19:01:35,807:INFO:_master_model_container: 4
2023-05-21 19:01:35,807:INFO:_display_container: 2
2023-05-21 19:01:35,808:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-05-21 19:01:35,808:INFO:create_model() successfully completed......................................
2023-05-21 19:01:35,926:INFO:SubProcess create_model() end ==================================
2023-05-21 19:01:35,926:INFO:Creating metrics dataframe
2023-05-21 19:01:35,943:INFO:Initializing Random Forest Classifier
2023-05-21 19:01:35,943:INFO:Total runtime is 0.2603784958521525 minutes
2023-05-21 19:01:35,944:INFO:SubProcess create_model() called ==================================
2023-05-21 19:01:35,944:INFO:Initializing create_model()
2023-05-21 19:01:35,944:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3d229f4340>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d0fb5dff0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 19:01:35,944:INFO:Checking exceptions
2023-05-21 19:01:35,944:INFO:Importing libraries
2023-05-21 19:01:35,944:INFO:Copying training dataset
2023-05-21 19:01:36,005:INFO:Defining folds
2023-05-21 19:01:36,005:INFO:Declaring metric variables
2023-05-21 19:01:36,005:INFO:Importing untrained model
2023-05-21 19:01:36,007:INFO:Random Forest Classifier Imported successfully
2023-05-21 19:01:36,007:INFO:Starting cross validation
2023-05-21 19:01:36,011:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 19:01:38,991:INFO:Calculating mean and std
2023-05-21 19:01:38,993:INFO:Creating metrics dataframe
2023-05-21 19:01:39,115:INFO:Uploading results into container
2023-05-21 19:01:39,116:INFO:Uploading model into container now
2023-05-21 19:01:39,117:INFO:_master_model_container: 5
2023-05-21 19:01:39,117:INFO:_display_container: 2
2023-05-21 19:01:39,119:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-05-21 19:01:39,119:INFO:create_model() successfully completed......................................
2023-05-21 19:01:39,243:INFO:SubProcess create_model() end ==================================
2023-05-21 19:01:39,243:INFO:Creating metrics dataframe
2023-05-21 19:01:39,262:INFO:Initializing Linear Discriminant Analysis
2023-05-21 19:01:39,262:INFO:Total runtime is 0.31569364468256633 minutes
2023-05-21 19:01:39,263:INFO:SubProcess create_model() called ==================================
2023-05-21 19:01:39,263:INFO:Initializing create_model()
2023-05-21 19:01:39,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3d229f4340>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d0fb5dff0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 19:01:39,263:INFO:Checking exceptions
2023-05-21 19:01:39,264:INFO:Importing libraries
2023-05-21 19:01:39,264:INFO:Copying training dataset
2023-05-21 19:01:39,334:INFO:Defining folds
2023-05-21 19:01:39,335:INFO:Declaring metric variables
2023-05-21 19:01:39,335:INFO:Importing untrained model
2023-05-21 19:01:39,336:INFO:Linear Discriminant Analysis Imported successfully
2023-05-21 19:01:39,336:INFO:Starting cross validation
2023-05-21 19:01:39,340:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 19:01:40,641:INFO:Calculating mean and std
2023-05-21 19:01:40,642:INFO:Creating metrics dataframe
2023-05-21 19:01:40,709:INFO:Uploading results into container
2023-05-21 19:01:40,710:INFO:Uploading model into container now
2023-05-21 19:01:40,711:INFO:_master_model_container: 6
2023-05-21 19:01:40,711:INFO:_display_container: 2
2023-05-21 19:01:40,712:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-21 19:01:40,712:INFO:create_model() successfully completed......................................
2023-05-21 19:01:40,835:INFO:SubProcess create_model() end ==================================
2023-05-21 19:01:40,835:INFO:Creating metrics dataframe
2023-05-21 19:01:40,850:INFO:Initializing Extra Trees Classifier
2023-05-21 19:01:40,850:INFO:Total runtime is 0.34215974013010664 minutes
2023-05-21 19:01:40,850:INFO:SubProcess create_model() called ==================================
2023-05-21 19:01:40,851:INFO:Initializing create_model()
2023-05-21 19:01:40,851:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3d229f4340>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d0fb5dff0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 19:01:40,851:INFO:Checking exceptions
2023-05-21 19:01:40,851:INFO:Importing libraries
2023-05-21 19:01:40,851:INFO:Copying training dataset
2023-05-21 19:01:40,909:INFO:Defining folds
2023-05-21 19:01:40,909:INFO:Declaring metric variables
2023-05-21 19:01:40,910:INFO:Importing untrained model
2023-05-21 19:01:40,911:INFO:Extra Trees Classifier Imported successfully
2023-05-21 19:01:40,912:INFO:Starting cross validation
2023-05-21 19:01:40,916:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 19:01:43,734:INFO:Calculating mean and std
2023-05-21 19:01:43,736:INFO:Creating metrics dataframe
2023-05-21 19:01:43,820:INFO:Uploading results into container
2023-05-21 19:01:43,821:INFO:Uploading model into container now
2023-05-21 19:01:43,822:INFO:_master_model_container: 7
2023-05-21 19:01:43,822:INFO:_display_container: 2
2023-05-21 19:01:43,823:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-05-21 19:01:43,824:INFO:create_model() successfully completed......................................
2023-05-21 19:01:43,933:INFO:SubProcess create_model() end ==================================
2023-05-21 19:01:43,934:INFO:Creating metrics dataframe
2023-05-21 19:01:43,947:INFO:Initializing Light Gradient Boosting Machine
2023-05-21 19:01:43,947:INFO:Total runtime is 0.39377414385477705 minutes
2023-05-21 19:01:43,947:INFO:SubProcess create_model() called ==================================
2023-05-21 19:01:43,948:INFO:Initializing create_model()
2023-05-21 19:01:43,948:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3d229f4340>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d0fb5dff0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 19:01:43,948:INFO:Checking exceptions
2023-05-21 19:01:43,948:INFO:Importing libraries
2023-05-21 19:01:43,948:INFO:Copying training dataset
2023-05-21 19:01:44,005:INFO:Defining folds
2023-05-21 19:01:44,005:INFO:Declaring metric variables
2023-05-21 19:01:44,006:INFO:Importing untrained model
2023-05-21 19:01:44,007:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 19:01:44,008:INFO:Starting cross validation
2023-05-21 19:01:44,012:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 19:01:45,597:INFO:Calculating mean and std
2023-05-21 19:01:45,599:INFO:Creating metrics dataframe
2023-05-21 19:01:45,674:INFO:Uploading results into container
2023-05-21 19:01:45,675:INFO:Uploading model into container now
2023-05-21 19:01:45,676:INFO:_master_model_container: 8
2023-05-21 19:01:45,676:INFO:_display_container: 2
2023-05-21 19:01:45,678:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 19:01:45,678:INFO:create_model() successfully completed......................................
2023-05-21 19:01:45,793:INFO:SubProcess create_model() end ==================================
2023-05-21 19:01:45,794:INFO:Creating metrics dataframe
2023-05-21 19:01:45,814:INFO:Initializing create_model()
2023-05-21 19:01:45,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3d229f4340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-21 19:01:45,814:INFO:Checking exceptions
2023-05-21 19:01:45,816:INFO:Importing libraries
2023-05-21 19:01:45,816:INFO:Copying training dataset
2023-05-21 19:01:45,875:INFO:Defining folds
2023-05-21 19:01:45,875:INFO:Declaring metric variables
2023-05-21 19:01:45,876:INFO:Importing untrained model
2023-05-21 19:01:45,876:INFO:Declaring custom model
2023-05-21 19:01:45,879:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 19:01:45,882:INFO:Cross validation set to False
2023-05-21 19:01:45,883:INFO:Fitting Model
2023-05-21 19:01:46,141:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 19:01:46,141:INFO:create_model() successfully completed......................................
2023-05-21 19:01:46,252:INFO:Creating Dashboard logs
2023-05-21 19:01:46,253:INFO:Model: Light Gradient Boosting Machine
2023-05-21 19:01:46,359:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-21 19:01:47,020:INFO:Initializing predict_model()
2023-05-21 19:01:47,021:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3d229f4340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7f3d0fa28940>)
2023-05-21 19:01:47,021:INFO:Checking exceptions
2023-05-21 19:01:47,021:INFO:Preloading libraries
2023-05-21 19:01:47,507:INFO:SubProcess plot_model() called ==================================
2023-05-21 19:01:47,509:INFO:Initializing plot_model()
2023-05-21 19:01:47,509:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpyz28zlz8, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3d229f4340>, system=False)
2023-05-21 19:01:47,509:INFO:Checking exceptions
2023-05-21 19:01:47,529:INFO:Preloading libraries
2023-05-21 19:01:47,534:INFO:Copying training dataset
2023-05-21 19:01:47,534:INFO:Plot type: auc
2023-05-21 19:01:47,850:INFO:Fitting Model
2023-05-21 19:01:47,856:INFO:Scoring test/hold-out set
2023-05-21 19:01:48,086:INFO:Saving '/tmp/tmpyz28zlz8/AUC.png'
2023-05-21 19:01:48,639:INFO:Visual Rendered Successfully
2023-05-21 19:01:48,759:INFO:plot_model() successfully completed......................................
2023-05-21 19:01:48,762:INFO:Initializing plot_model()
2023-05-21 19:01:48,762:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpyz28zlz8, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3d229f4340>, system=False)
2023-05-21 19:01:48,762:INFO:Checking exceptions
2023-05-21 19:01:48,783:INFO:Preloading libraries
2023-05-21 19:01:48,791:INFO:Copying training dataset
2023-05-21 19:01:48,791:INFO:Plot type: confusion_matrix
2023-05-21 19:01:49,109:INFO:Fitting Model
2023-05-21 19:01:49,112:INFO:Scoring test/hold-out set
2023-05-21 19:01:49,273:INFO:Saving '/tmp/tmpyz28zlz8/Confusion Matrix.png'
2023-05-21 19:01:49,577:INFO:Visual Rendered Successfully
2023-05-21 19:01:49,698:INFO:plot_model() successfully completed......................................
2023-05-21 19:01:49,701:INFO:Initializing plot_model()
2023-05-21 19:01:49,702:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpyz28zlz8, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3d229f4340>, system=False)
2023-05-21 19:01:49,702:INFO:Checking exceptions
2023-05-21 19:01:49,728:INFO:Preloading libraries
2023-05-21 19:01:49,735:INFO:Copying training dataset
2023-05-21 19:01:49,735:INFO:Plot type: feature
2023-05-21 19:01:49,738:WARNING:No coef_ found. Trying feature_importances_
2023-05-21 19:01:49,962:INFO:Saving '/tmp/tmpyz28zlz8/Feature Importance.png'
2023-05-21 19:01:50,337:INFO:Visual Rendered Successfully
2023-05-21 19:01:50,469:INFO:plot_model() successfully completed......................................
2023-05-21 19:01:50,470:INFO:SubProcess plot_model() end ==================================
2023-05-21 19:01:50,476:WARNING:/home/feuer/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-05-21 19:01:50,855:INFO:Creating Dashboard logs
2023-05-21 19:01:50,856:INFO:Model: Random Forest Classifier
2023-05-21 19:01:50,979:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 19:01:52,027:INFO:Creating Dashboard logs
2023-05-21 19:01:52,029:INFO:Model: Extra Trees Classifier
2023-05-21 19:01:52,122:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 19:01:53,286:INFO:Creating Dashboard logs
2023-05-21 19:01:53,287:INFO:Model: Decision Tree Classifier
2023-05-21 19:01:53,388:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2023-05-21 19:01:54,458:INFO:Creating Dashboard logs
2023-05-21 19:01:54,459:INFO:Model: Logistic Regression
2023-05-21 19:01:54,566:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-05-21 19:01:55,577:INFO:Creating Dashboard logs
2023-05-21 19:01:55,578:INFO:Model: Linear Discriminant Analysis
2023-05-21 19:01:55,662:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-05-21 19:01:56,695:INFO:Creating Dashboard logs
2023-05-21 19:01:56,695:INFO:Model: Naive Bayes
2023-05-21 19:01:56,822:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-05-21 19:01:57,883:INFO:Creating Dashboard logs
2023-05-21 19:01:57,884:INFO:Model: Ridge Classifier
2023-05-21 19:01:58,028:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2023-05-21 19:01:59,073:INFO:_master_model_container: 8
2023-05-21 19:01:59,073:INFO:_display_container: 2
2023-05-21 19:01:59,074:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 19:01:59,075:INFO:compare_models() successfully completed......................................
2023-05-21 19:02:37,452:INFO:Initializing tune_model()
2023-05-21 19:02:37,453:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=50, custom_grid={'learning_rate': [0.005, 0.01, 0.05, 0.1], 'n_estimators': [8, 16, 24, 32], 'num_leaves': [6, 8, 12, 16], 'boosting_type': ['gbdt', 'dart'], 'objective': ['binary'], 'max_bin': [255, 510], 'random_state': [500], 'colsample_bytree': [0.64, 0.65, 0.66], 'subsample': [0.7, 0.75], 'reg_alpha': [1, 1.2], 'reg_lambda': [1, 1.2, 1.4]}, optimize=AUC, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3d229f4340>)
2023-05-21 19:02:37,453:INFO:Checking exceptions
2023-05-21 19:02:37,453:INFO:Soft dependency imported: optuna: 3.1.1
2023-05-21 19:02:38,570:INFO:Copying training dataset
2023-05-21 19:02:38,613:INFO:Checking base model
2023-05-21 19:02:38,613:INFO:Base model : Light Gradient Boosting Machine
2023-05-21 19:02:38,616:INFO:Declaring metric variables
2023-05-21 19:02:38,616:INFO:Defining Hyperparameters
2023-05-21 19:02:38,746:INFO:custom_grid: {'actual_estimator__learning_rate': CategoricalDistribution(values=[0.005, 0.01, 0.05, 0.1]), 'actual_estimator__n_estimators': CategoricalDistribution(values=[8, 16, 24, 32]), 'actual_estimator__num_leaves': CategoricalDistribution(values=[6, 8, 12, 16]), 'actual_estimator__boosting_type': CategoricalDistribution(values=['gbdt', 'dart']), 'actual_estimator__objective': CategoricalDistribution(values=['binary']), 'actual_estimator__max_bin': CategoricalDistribution(values=[255, 510]), 'actual_estimator__random_state': CategoricalDistribution(values=[500]), 'actual_estimator__colsample_bytree': CategoricalDistribution(values=[0.64, 0.65, 0.66]), 'actual_estimator__subsample': CategoricalDistribution(values=[0.7, 0.75]), 'actual_estimator__reg_alpha': CategoricalDistribution(values=[1, 1.2]), 'actual_estimator__reg_lambda': CategoricalDistribution(values=[1, 1.2, 1.4])}
2023-05-21 19:02:38,747:INFO:Tuning with n_jobs=-1
2023-05-21 19:02:38,748:WARNING:/home/feuer/.local/lib/python3.10/site-packages/optuna/samplers/_tpe/sampler.py:282: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-21 19:02:38,748:WARNING:/home/feuer/.local/lib/python3.10/site-packages/optuna/samplers/_tpe/sampler.py:301: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-21 19:02:38,749:INFO:Initializing optuna.integration.OptunaSearchCV
2023-05-21 19:02:38,757:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:2445: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-05-21 19:02:41,496:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-21 19:02:41,586:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-21 19:02:41,649:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-21 19:02:41,701:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-21 19:02:41,837:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-21 19:02:42,135:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-21 19:02:42,199:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-21 19:02:42,216:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-21 19:02:42,262:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-21 19:02:42,408:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-21 19:02:42,818:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-21 19:02:45,429:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:02:45,587:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:02:45,769:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-21 19:02:45,932:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-21 19:02:46,132:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-21 19:02:46,138:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:02:46,169:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-21 19:02:46,930:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-05-21 19:02:47,017:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:02:47,397:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:02:48,995:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:02:49,018:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:02:49,061:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:02:49,102:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:02:49,108:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:02:49,122:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:02:50,104:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:02:50,922:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:02:51,166:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:02:51,968:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:02:52,053:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:02:52,103:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-21 19:02:52,119:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-21 19:02:52,136:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:02:52,502:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-21 19:02:52,546:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:02:52,552:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:02:53,618:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-21 19:02:53,867:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:02:54,109:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-21 19:02:54,298:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-21 19:02:55,208:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:02:55,255:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:02:55,310:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-21 19:02:55,547:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:02:58,092:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:02:59,731:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:02:59,759:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-21 19:02:59,795:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:00,356:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:00,375:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:00,570:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:00,806:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-05-21 19:03:02,544:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:02,596:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:03,035:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:03,122:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-05-21 19:03:03,401:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:03,655:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:03,999:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:04,206:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:04,451:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:06,670:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:07,105:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:07,167:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:07,806:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:07,925:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:08,089:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:08,504:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-21 19:03:09,072:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:09,190:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:10,086:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:10,399:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:10,416:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:10,450:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:12,867:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:13,167:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:13,234:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:16,210:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-21 19:03:16,276:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-21 19:03:16,459:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:16,603:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:18,832:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:19,093:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-21 19:03:19,161:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-21 19:03:19,400:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-21 19:03:20,415:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:23,659:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:23,880:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:23,971:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:23,999:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:24,036:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:25,062:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:25,090:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:25,092:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:25,217:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:27,127:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-21 19:03:27,336:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:27,922:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-21 19:03:27,982:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-21 19:03:29,851:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:29,877:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:31,723:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:31,875:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:31,883:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:33,968:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:34,168:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:34,314:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:34,525:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:35,517:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:43,997:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:45,283:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:45,318:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:46,106:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:46,276:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:49,416:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:49,535:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:49,543:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:51,373:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:51,459:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:51,538:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:54,639:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:55,194:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:55,347:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:55,665:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:55,869:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:56,593:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:56,733:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:57,811:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:57,814:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:03:58,011:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:03:58,039:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:04:03,269:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:04:03,443:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:04:07,393:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:04:08,136:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:04:11,573:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:04:11,902:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:04:11,906:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:04:23,562:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:04:23,922:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:04:23,957:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:04:25,282:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:04:25,547:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:04:25,622:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:04:26,502:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:04:36,367:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:04:36,368:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:04:36,841:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:04:37,020:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:04:41,498:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:04:41,603:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:04:41,620:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:04:43,297:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:04:45,208:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:04:45,566:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:04:45,604:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:04:45,671:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:04:46,800:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:04:46,890:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:04:48,557:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:04:49,717:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:04:49,772:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:04:49,838:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:04:55,866:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:04:56,515:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:04:56,537:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:04:56,568:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:05:01,664:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:05:02,008:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:05:02,133:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:05:03,076:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:05:03,272:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:05:06,203:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:05:09,698:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:05:12,523:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:05:12,698:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:05:12,905:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:05:12,913:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:05:13,905:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:05:13,937:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:05:15,306:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:05:15,308:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:05:15,310:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:05:16,349:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:05:16,407:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:05:34,428:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:05:40,227:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:05:40,427:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:05:44,883:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:05:45,066:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:05:45,215:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:05:45,447:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:05:48,710:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-21 19:05:48,737:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-21 19:05:48,740:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-21 19:05:50,847:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:05:51,721:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:05:51,721:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:05:51,802:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:05:51,989:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:05:52,046:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:05:53,149:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:05:53,471:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:05:53,712:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:05:53,997:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:05:54,084:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:05:54,093:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:05:57,956:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:06:10,714:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:06:10,745:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:06:11,684:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:06:11,711:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:06:30,535:INFO:best_params: {'actual_estimator__learning_rate': 0.1, 'actual_estimator__n_estimators': 32, 'actual_estimator__num_leaves': 16, 'actual_estimator__boosting_type': 'gbdt', 'actual_estimator__objective': 'binary', 'actual_estimator__max_bin': 510, 'actual_estimator__random_state': 500, 'actual_estimator__colsample_bytree': 0.64, 'actual_estimator__subsample': 0.75, 'actual_estimator__reg_alpha': 1, 'actual_estimator__reg_lambda': 1.2}
2023-05-21 19:06:30,536:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-05-21 19:06:30,537:WARNING:Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 2674, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-05-21 19:06:30,537:INFO:Hyperparameter search completed
2023-05-21 19:06:30,537:INFO:SubProcess create_model() called ==================================
2023-05-21 19:06:30,545:INFO:Initializing create_model()
2023-05-21 19:06:30,545:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3d229f4340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d7c90be20>, model_only=True, return_train_score=False, kwargs={'learning_rate': 0.1, 'n_estimators': 32, 'num_leaves': 16, 'boosting_type': 'gbdt', 'objective': 'binary', 'max_bin': 510, 'random_state': 500, 'colsample_bytree': 0.64, 'subsample': 0.75, 'reg_alpha': 1, 'reg_lambda': 1.2})
2023-05-21 19:06:30,546:INFO:Checking exceptions
2023-05-21 19:06:30,546:INFO:Importing libraries
2023-05-21 19:06:30,546:INFO:Copying training dataset
2023-05-21 19:06:30,641:INFO:Defining folds
2023-05-21 19:06:30,641:INFO:Declaring metric variables
2023-05-21 19:06:30,642:INFO:Importing untrained model
2023-05-21 19:06:30,642:INFO:Declaring custom model
2023-05-21 19:06:30,647:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 19:06:30,648:INFO:Starting cross validation
2023-05-21 19:06:30,656:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 19:06:32,883:INFO:Calculating mean and std
2023-05-21 19:06:32,884:INFO:Creating metrics dataframe
2023-05-21 19:06:32,902:INFO:Finalizing model
2023-05-21 19:06:34,326:INFO:Uploading results into container
2023-05-21 19:06:34,329:INFO:Uploading model into container now
2023-05-21 19:06:34,330:INFO:_master_model_container: 9
2023-05-21 19:06:34,330:INFO:_display_container: 3
2023-05-21 19:06:34,333:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.64,
               importance_type='split', learning_rate=0.1, max_bin=510,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=32, n_jobs=-1, num_leaves=16,
               objective='binary', random_state=500, reg_alpha=1,
               reg_lambda=1.2, silent='warn', subsample=0.75,
               subsample_for_bin=200000, subsample_freq=0)
2023-05-21 19:06:34,333:INFO:create_model() successfully completed......................................
2023-05-21 19:06:34,461:INFO:SubProcess create_model() end ==================================
2023-05-21 19:06:34,461:INFO:choose_better activated
2023-05-21 19:06:34,462:INFO:SubProcess create_model() called ==================================
2023-05-21 19:06:34,466:INFO:Initializing create_model()
2023-05-21 19:06:34,466:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3d229f4340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-21 19:06:34,466:INFO:Checking exceptions
2023-05-21 19:06:34,469:INFO:Importing libraries
2023-05-21 19:06:34,469:INFO:Copying training dataset
2023-05-21 19:06:34,533:INFO:Defining folds
2023-05-21 19:06:34,533:INFO:Declaring metric variables
2023-05-21 19:06:34,534:INFO:Importing untrained model
2023-05-21 19:06:34,534:INFO:Declaring custom model
2023-05-21 19:06:34,539:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 19:06:34,540:INFO:Starting cross validation
2023-05-21 19:06:34,547:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 19:06:38,270:INFO:Calculating mean and std
2023-05-21 19:06:38,272:INFO:Creating metrics dataframe
2023-05-21 19:06:38,286:INFO:Finalizing model
2023-05-21 19:06:39,738:INFO:Uploading results into container
2023-05-21 19:06:39,740:INFO:Uploading model into container now
2023-05-21 19:06:39,741:INFO:_master_model_container: 10
2023-05-21 19:06:39,741:INFO:_display_container: 4
2023-05-21 19:06:39,744:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 19:06:39,745:INFO:create_model() successfully completed......................................
2023-05-21 19:06:39,874:INFO:SubProcess create_model() end ==================================
2023-05-21 19:06:39,879:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.8201
2023-05-21 19:06:39,883:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.64,
               importance_type='split', learning_rate=0.1, max_bin=510,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=32, n_jobs=-1, num_leaves=16,
               objective='binary', random_state=500, reg_alpha=1,
               reg_lambda=1.2, silent='warn', subsample=0.75,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.8147
2023-05-21 19:06:39,885:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2023-05-21 19:06:39,886:INFO:choose_better completed
2023-05-21 19:06:39,886:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-05-21 19:06:39,886:INFO:Creating Dashboard logs
2023-05-21 19:06:39,888:INFO:Model: Light Gradient Boosting Machine
2023-05-21 19:06:40,058:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-21 19:06:41,127:INFO:Initializing predict_model()
2023-05-21 19:06:41,127:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3d229f4340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7f3cd4ea3010>)
2023-05-21 19:06:41,127:INFO:Checking exceptions
2023-05-21 19:06:41,128:INFO:Preloading libraries
2023-05-21 19:07:06,780:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 19:07:06,780:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 19:07:06,780:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 19:07:06,781:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-21 19:07:09,752:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-21 19:07:18,885:INFO:PyCaret ClassificationExperiment
2023-05-21 19:07:18,885:INFO:Logging name: Lead_Scoring_Training_Pipeline
2023-05-21 19:07:18,885:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-21 19:07:18,885:INFO:version 3.0.0
2023-05-21 19:07:18,885:INFO:Initializing setup()
2023-05-21 19:07:18,885:INFO:self.USI: 23f0
2023-05-21 19:07:18,885:INFO:self._variable_keys: {'seed', 'html_param', 'target_param', 'fold_generator', 'exp_name_log', 'X_test', 'log_plots_param', 'X_train', 'fix_imbalance', 'X', 'data', 'gpu_param', 'y_test', 'USI', 'y_train', 'exp_id', 'n_jobs_param', '_available_plots', 'fold_groups_param', 'memory', 'logging_param', 'y', 'idx', '_ml_usecase', 'is_multiclass', 'pipeline', 'fold_shuffle_param', 'gpu_n_jobs_param'}
2023-05-21 19:07:18,885:INFO:Checking environment
2023-05-21 19:07:18,885:INFO:python_version: 3.10.10
2023-05-21 19:07:18,885:INFO:python_build: ('main', 'Mar  5 2023 22:26:53')
2023-05-21 19:07:18,885:INFO:machine: x86_64
2023-05-21 19:07:18,887:INFO:platform: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 19:07:18,887:INFO:Memory: svmem(total=16717086720, available=5078401024, percent=69.6, used=8661995520, free=4236009472, active=4338999296, inactive=5504749568, buffers=15831040, cached=3803250688, shared=2612289536, slab=509210624)
2023-05-21 19:07:18,889:INFO:Physical Core: 6
2023-05-21 19:07:18,890:INFO:Logical Core: 12
2023-05-21 19:07:18,890:INFO:Checking libraries
2023-05-21 19:07:18,890:INFO:System:
2023-05-21 19:07:18,890:INFO:    python: 3.10.10 (main, Mar  5 2023, 22:26:53) [GCC 12.2.1 20230201]
2023-05-21 19:07:18,890:INFO:executable: /usr/bin/python3.10
2023-05-21 19:07:18,890:INFO:   machine: Linux-6.1.26-1-MANJARO-x86_64-with-glibc2.37
2023-05-21 19:07:18,890:INFO:PyCaret required dependencies:
2023-05-21 19:07:18,890:INFO:                 pip: 23.0.1
2023-05-21 19:07:18,890:INFO:          setuptools: 67.6.1
2023-05-21 19:07:18,891:INFO:             pycaret: 3.0.0
2023-05-21 19:07:18,891:INFO:             IPython: 8.12.0
2023-05-21 19:07:18,891:INFO:          ipywidgets: 7.7.5
2023-05-21 19:07:18,891:INFO:                tqdm: 4.64.1
2023-05-21 19:07:18,891:INFO:               numpy: 1.23.0
2023-05-21 19:07:18,891:INFO:              pandas: 1.5.3
2023-05-21 19:07:18,891:INFO:              jinja2: 3.1.2
2023-05-21 19:07:18,891:INFO:               scipy: 1.9.3
2023-05-21 19:07:18,891:INFO:              joblib: 1.2.0
2023-05-21 19:07:18,891:INFO:             sklearn: 1.2.2
2023-05-21 19:07:18,891:INFO:                pyod: 1.0.9
2023-05-21 19:07:18,891:INFO:            imblearn: 0.10.1
2023-05-21 19:07:18,891:INFO:   category_encoders: 2.6.0
2023-05-21 19:07:18,892:INFO:            lightgbm: 3.3.5
2023-05-21 19:07:18,892:INFO:               numba: 0.57.0
2023-05-21 19:07:18,892:INFO:            requests: 2.28.2
2023-05-21 19:07:18,892:INFO:          matplotlib: 3.6.3
2023-05-21 19:07:18,892:INFO:          scikitplot: 0.3.7
2023-05-21 19:07:18,892:INFO:         yellowbrick: 1.5
2023-05-21 19:07:18,892:INFO:              plotly: 5.14.1
2023-05-21 19:07:18,892:INFO:             kaleido: 0.2.1
2023-05-21 19:07:18,892:INFO:         statsmodels: 0.13.5
2023-05-21 19:07:18,892:INFO:              sktime: 0.18.0
2023-05-21 19:07:18,892:INFO:               tbats: 1.1.3
2023-05-21 19:07:18,892:INFO:            pmdarima: 2.0.3
2023-05-21 19:07:18,892:INFO:              psutil: 5.9.4
2023-05-21 19:07:18,893:INFO:PyCaret optional dependencies:
2023-05-21 19:07:18,921:INFO:                shap: 0.41.0
2023-05-21 19:07:18,921:INFO:           interpret: 0.3.2
2023-05-21 19:07:18,921:INFO:                umap: 0.5.3
2023-05-21 19:07:18,922:INFO:    pandas_profiling: 3.6.6
2023-05-21 19:07:18,922:INFO:  explainerdashboard: 0.4.2.2
2023-05-21 19:07:18,922:INFO:             autoviz: 0.1.603
2023-05-21 19:07:18,922:INFO:           fairlearn: 0.7.0
2023-05-21 19:07:18,922:INFO:             xgboost: 1.7.5
2023-05-21 19:07:18,922:INFO:            catboost: Not installed
2023-05-21 19:07:18,922:INFO:              kmodes: Not installed
2023-05-21 19:07:18,922:INFO:             mlxtend: Not installed
2023-05-21 19:07:18,922:INFO:       statsforecast: Not installed
2023-05-21 19:07:18,922:INFO:        tune_sklearn: Not installed
2023-05-21 19:07:18,922:INFO:                 ray: Not installed
2023-05-21 19:07:18,922:INFO:            hyperopt: Not installed
2023-05-21 19:07:18,923:INFO:              optuna: 3.1.1
2023-05-21 19:07:18,923:INFO:               skopt: Not installed
2023-05-21 19:07:18,923:INFO:              mlflow: 2.3.1
2023-05-21 19:07:18,923:INFO:              gradio: Not installed
2023-05-21 19:07:18,923:INFO:             fastapi: Not installed
2023-05-21 19:07:18,923:INFO:             uvicorn: Not installed
2023-05-21 19:07:18,923:INFO:              m2cgen: Not installed
2023-05-21 19:07:18,923:INFO:           evidently: Not installed
2023-05-21 19:07:18,923:INFO:               fugue: Not installed
2023-05-21 19:07:18,923:INFO:           streamlit: Not installed
2023-05-21 19:07:18,923:INFO:             prophet: Not installed
2023-05-21 19:07:18,923:INFO:None
2023-05-21 19:07:18,923:INFO:Set up data.
2023-05-21 19:07:19,022:INFO:Set up train/test split.
2023-05-21 19:07:19,022:INFO:Set up data.
2023-05-21 19:07:19,082:INFO:Set up index.
2023-05-21 19:07:19,082:INFO:Set up folding strategy.
2023-05-21 19:07:19,082:INFO:Assigning column types.
2023-05-21 19:07:19,124:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-21 19:07:19,175:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 19:07:19,189:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 19:07:19,251:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 19:07:19,358:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 19:07:19,408:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-21 19:07:19,409:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 19:07:19,440:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 19:07:19,443:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 19:07:19,444:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-21 19:07:19,494:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 19:07:19,524:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 19:07:19,528:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 19:07:19,578:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-21 19:07:19,610:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 19:07:19,613:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 19:07:19,614:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-21 19:07:19,695:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 19:07:19,698:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 19:07:19,780:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 19:07:19,783:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 19:07:19,786:INFO:Preparing preprocessing pipeline...
2023-05-21 19:07:19,793:INFO:Set up simple imputation.
2023-05-21 19:07:19,801:INFO:Set up column name cleaning.
2023-05-21 19:07:19,999:INFO:Finished creating preprocessing pipeline.
2023-05-21 19:07:20,029:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped',
                                             'referred_lead', 'city_tier_1.0',
                                             'city_tier_2.0', 'city_tier_3.0',
                                             'first_platform_c_Level0',
                                             'first_platform_c_Level1',
                                             'first_platform_c_Level2',
                                             'first_platform_c_Level3',
                                             'first_platform_c_Level7',
                                             'first_platform_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-21 19:07:20,029:INFO:Creating final display dataframe.
2023-05-21 19:07:20,399:INFO:Setup _display_container:                     Description                           Value
0                    Session id                              42
1                        Target               app_complete_flag
2                   Target type                          Binary
3           Original data shape                    (238964, 41)
4        Transformed data shape                    (238964, 41)
5   Transformed train set shape                    (191171, 41)
6    Transformed test set shape                     (47793, 41)
7              Numeric features                              40
8                    Preprocess                            True
9               Imputation type                          simple
10           Numeric imputation                            mean
11       Categorical imputation                            mode
12               Fold Generator                 StratifiedKFold
13                  Fold Number                              10
14                     CPU Jobs                              -1
15                      Use GPU                           False
16               Log Experiment                    MlflowLogger
17              Experiment Name  Lead_Scoring_Training_Pipeline
18                          USI                            23f0
2023-05-21 19:07:20,497:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 19:07:20,500:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 19:07:20,582:INFO:Soft dependency imported: xgboost: 1.7.5
2023-05-21 19:07:20,585:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-21 19:07:20,589:INFO:Logging experiment in loggers
2023-05-21 19:07:21,222:INFO:SubProcess save_model() called ==================================
2023-05-21 19:07:21,310:INFO:Initializing save_model()
2023-05-21 19:07:21,310:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped',
                                             'referred_lead', 'city_tier_1.0',
                                             'city_tier_2.0', 'city_tier_3.0',
                                             'first_platform_c_Level0',
                                             'first_platform_c_Level1',
                                             'first_platform_c_Level2',
                                             'first_platform_c_Level3',
                                             'first_platform_c_Level7',
                                             'first_platform_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=/tmp/tmpqcp2rk_0/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped',
                                             'referred_lead', 'city_tier_1.0',
                                             'city_tier_2.0', 'city_tier_3.0',
                                             'first_platform_c_Level0',
                                             'first_platform_c_Level1',
                                             'first_platform_c_Level2',
                                             'first_platform_c_Level3',
                                             'first_platform_c_Level7',
                                             'first_platform_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-21 19:07:21,310:INFO:Adding model into prep_pipe
2023-05-21 19:07:21,314:WARNING:Only Model saved as it was a pipeline.
2023-05-21 19:07:21,325:INFO:/tmp/tmpqcp2rk_0/Transformation Pipeline.pkl saved in current working directory
2023-05-21 19:07:21,347:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_dropped',
                                             'referred_lead', 'city_tier_1.0',
                                             'city_tier_2.0', 'city_tier_3.0',
                                             'first_platform_c_Level0',
                                             'first_platform_c_Level1',
                                             'first_platform_c_Level2',
                                             'first_platform_c_Level3',
                                             'first_platform_c_Level7',
                                             'first_platform_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-21 19:07:21,347:INFO:save_model() successfully completed......................................
2023-05-21 19:07:21,618:INFO:SubProcess save_model() end ==================================
2023-05-21 19:07:22,956:INFO:setup() successfully completed in 1.89s...............
2023-05-21 19:07:22,956:INFO:Initializing compare_models()
2023-05-21 19:07:22,956:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7adf96c370>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f7adf96c370>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada', 'xgboost'])
2023-05-21 19:07:22,956:INFO:Checking exceptions
2023-05-21 19:07:22,993:INFO:Preparing display monitor
2023-05-21 19:07:23,001:INFO:Initializing Logistic Regression
2023-05-21 19:07:23,001:INFO:Total runtime is 4.116694132486979e-06 minutes
2023-05-21 19:07:23,002:INFO:SubProcess create_model() called ==================================
2023-05-21 19:07:23,002:INFO:Initializing create_model()
2023-05-21 19:07:23,002:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7adf96c370>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7acc4733a0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 19:07:23,002:INFO:Checking exceptions
2023-05-21 19:07:23,002:INFO:Importing libraries
2023-05-21 19:07:23,003:INFO:Copying training dataset
2023-05-21 19:07:23,062:INFO:Defining folds
2023-05-21 19:07:23,063:INFO:Declaring metric variables
2023-05-21 19:07:23,063:INFO:Importing untrained model
2023-05-21 19:07:23,064:INFO:Logistic Regression Imported successfully
2023-05-21 19:07:23,065:INFO:Starting cross validation
2023-05-21 19:07:23,069:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 19:07:31,111:INFO:Calculating mean and std
2023-05-21 19:07:31,114:INFO:Creating metrics dataframe
2023-05-21 19:07:31,301:INFO:Uploading results into container
2023-05-21 19:07:31,303:INFO:Uploading model into container now
2023-05-21 19:07:31,304:INFO:_master_model_container: 1
2023-05-21 19:07:31,304:INFO:_display_container: 2
2023-05-21 19:07:31,305:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-21 19:07:31,306:INFO:create_model() successfully completed......................................
2023-05-21 19:07:31,424:INFO:SubProcess create_model() end ==================================
2023-05-21 19:07:31,424:INFO:Creating metrics dataframe
2023-05-21 19:07:31,436:INFO:Initializing Naive Bayes
2023-05-21 19:07:31,436:INFO:Total runtime is 0.1405890464782715 minutes
2023-05-21 19:07:31,437:INFO:SubProcess create_model() called ==================================
2023-05-21 19:07:31,437:INFO:Initializing create_model()
2023-05-21 19:07:31,437:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7adf96c370>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7acc4733a0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 19:07:31,437:INFO:Checking exceptions
2023-05-21 19:07:31,437:INFO:Importing libraries
2023-05-21 19:07:31,437:INFO:Copying training dataset
2023-05-21 19:07:31,500:INFO:Defining folds
2023-05-21 19:07:31,500:INFO:Declaring metric variables
2023-05-21 19:07:31,500:INFO:Importing untrained model
2023-05-21 19:07:31,501:INFO:Naive Bayes Imported successfully
2023-05-21 19:07:31,502:INFO:Starting cross validation
2023-05-21 19:07:31,506:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 19:07:35,263:INFO:Calculating mean and std
2023-05-21 19:07:35,265:INFO:Creating metrics dataframe
2023-05-21 19:07:35,529:INFO:Uploading results into container
2023-05-21 19:07:35,531:INFO:Uploading model into container now
2023-05-21 19:07:35,532:INFO:_master_model_container: 2
2023-05-21 19:07:35,532:INFO:_display_container: 2
2023-05-21 19:07:35,532:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-21 19:07:35,532:INFO:create_model() successfully completed......................................
2023-05-21 19:07:35,640:INFO:SubProcess create_model() end ==================================
2023-05-21 19:07:35,640:INFO:Creating metrics dataframe
2023-05-21 19:07:35,654:INFO:Initializing Decision Tree Classifier
2023-05-21 19:07:35,654:INFO:Total runtime is 0.21087859869003298 minutes
2023-05-21 19:07:35,654:INFO:SubProcess create_model() called ==================================
2023-05-21 19:07:35,654:INFO:Initializing create_model()
2023-05-21 19:07:35,654:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7adf96c370>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7acc4733a0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 19:07:35,655:INFO:Checking exceptions
2023-05-21 19:07:35,655:INFO:Importing libraries
2023-05-21 19:07:35,655:INFO:Copying training dataset
2023-05-21 19:07:35,712:INFO:Defining folds
2023-05-21 19:07:35,712:INFO:Declaring metric variables
2023-05-21 19:07:35,713:INFO:Importing untrained model
2023-05-21 19:07:35,714:INFO:Decision Tree Classifier Imported successfully
2023-05-21 19:07:35,715:INFO:Starting cross validation
2023-05-21 19:07:35,718:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 19:07:37,767:INFO:Calculating mean and std
2023-05-21 19:07:37,769:INFO:Creating metrics dataframe
2023-05-21 19:07:38,051:INFO:Uploading results into container
2023-05-21 19:07:38,052:INFO:Uploading model into container now
2023-05-21 19:07:38,053:INFO:_master_model_container: 3
2023-05-21 19:07:38,053:INFO:_display_container: 2
2023-05-21 19:07:38,055:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-05-21 19:07:38,055:INFO:create_model() successfully completed......................................
2023-05-21 19:07:38,164:INFO:SubProcess create_model() end ==================================
2023-05-21 19:07:38,165:INFO:Creating metrics dataframe
2023-05-21 19:07:38,178:INFO:Initializing Ridge Classifier
2023-05-21 19:07:38,178:INFO:Total runtime is 0.25294989347457886 minutes
2023-05-21 19:07:38,178:INFO:SubProcess create_model() called ==================================
2023-05-21 19:07:38,179:INFO:Initializing create_model()
2023-05-21 19:07:38,179:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7adf96c370>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7acc4733a0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 19:07:38,179:INFO:Checking exceptions
2023-05-21 19:07:38,179:INFO:Importing libraries
2023-05-21 19:07:38,179:INFO:Copying training dataset
2023-05-21 19:07:38,237:INFO:Defining folds
2023-05-21 19:07:38,238:INFO:Declaring metric variables
2023-05-21 19:07:38,238:INFO:Importing untrained model
2023-05-21 19:07:38,239:INFO:Ridge Classifier Imported successfully
2023-05-21 19:07:38,240:INFO:Starting cross validation
2023-05-21 19:07:38,243:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 19:07:38,673:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 19:07:38,706:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 19:07:38,713:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 19:07:38,722:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 19:07:38,759:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 19:07:38,799:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 19:07:38,812:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 19:07:38,817:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 19:07:38,820:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 19:07:38,830:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/feuer/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-21 19:07:40,289:INFO:Calculating mean and std
2023-05-21 19:07:40,292:INFO:Creating metrics dataframe
2023-05-21 19:07:40,543:INFO:Uploading results into container
2023-05-21 19:07:40,544:INFO:Uploading model into container now
2023-05-21 19:07:40,545:INFO:_master_model_container: 4
2023-05-21 19:07:40,545:INFO:_display_container: 2
2023-05-21 19:07:40,546:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-05-21 19:07:40,546:INFO:create_model() successfully completed......................................
2023-05-21 19:07:40,657:INFO:SubProcess create_model() end ==================================
2023-05-21 19:07:40,657:INFO:Creating metrics dataframe
2023-05-21 19:07:40,670:INFO:Initializing Random Forest Classifier
2023-05-21 19:07:40,670:INFO:Total runtime is 0.29448867241541543 minutes
2023-05-21 19:07:40,671:INFO:SubProcess create_model() called ==================================
2023-05-21 19:07:40,671:INFO:Initializing create_model()
2023-05-21 19:07:40,671:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7adf96c370>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7acc4733a0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 19:07:40,671:INFO:Checking exceptions
2023-05-21 19:07:40,671:INFO:Importing libraries
2023-05-21 19:07:40,671:INFO:Copying training dataset
2023-05-21 19:07:40,730:INFO:Defining folds
2023-05-21 19:07:40,730:INFO:Declaring metric variables
2023-05-21 19:07:40,730:INFO:Importing untrained model
2023-05-21 19:07:40,731:INFO:Random Forest Classifier Imported successfully
2023-05-21 19:07:40,732:INFO:Starting cross validation
2023-05-21 19:07:40,736:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 19:07:44,514:INFO:Calculating mean and std
2023-05-21 19:07:44,516:INFO:Creating metrics dataframe
2023-05-21 19:07:44,773:INFO:Uploading results into container
2023-05-21 19:07:44,775:INFO:Uploading model into container now
2023-05-21 19:07:44,775:INFO:_master_model_container: 5
2023-05-21 19:07:44,776:INFO:_display_container: 2
2023-05-21 19:07:44,777:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-05-21 19:07:44,777:INFO:create_model() successfully completed......................................
2023-05-21 19:07:44,888:INFO:SubProcess create_model() end ==================================
2023-05-21 19:07:44,888:INFO:Creating metrics dataframe
2023-05-21 19:07:44,901:INFO:Initializing Linear Discriminant Analysis
2023-05-21 19:07:44,901:INFO:Total runtime is 0.3650071104367574 minutes
2023-05-21 19:07:44,902:INFO:SubProcess create_model() called ==================================
2023-05-21 19:07:44,902:INFO:Initializing create_model()
2023-05-21 19:07:44,902:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7adf96c370>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7acc4733a0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 19:07:44,902:INFO:Checking exceptions
2023-05-21 19:07:44,902:INFO:Importing libraries
2023-05-21 19:07:44,902:INFO:Copying training dataset
2023-05-21 19:07:44,961:INFO:Defining folds
2023-05-21 19:07:44,961:INFO:Declaring metric variables
2023-05-21 19:07:44,961:INFO:Importing untrained model
2023-05-21 19:07:44,962:INFO:Linear Discriminant Analysis Imported successfully
2023-05-21 19:07:44,963:INFO:Starting cross validation
2023-05-21 19:07:44,966:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 19:07:47,104:INFO:Calculating mean and std
2023-05-21 19:07:47,105:INFO:Creating metrics dataframe
2023-05-21 19:07:47,333:INFO:Uploading results into container
2023-05-21 19:07:47,334:INFO:Uploading model into container now
2023-05-21 19:07:47,335:INFO:_master_model_container: 6
2023-05-21 19:07:47,335:INFO:_display_container: 2
2023-05-21 19:07:47,336:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-21 19:07:47,336:INFO:create_model() successfully completed......................................
2023-05-21 19:07:47,449:INFO:SubProcess create_model() end ==================================
2023-05-21 19:07:47,449:INFO:Creating metrics dataframe
2023-05-21 19:07:47,462:INFO:Initializing Extra Trees Classifier
2023-05-21 19:07:47,462:INFO:Total runtime is 0.40768903493881226 minutes
2023-05-21 19:07:47,463:INFO:SubProcess create_model() called ==================================
2023-05-21 19:07:47,463:INFO:Initializing create_model()
2023-05-21 19:07:47,463:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7adf96c370>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7acc4733a0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 19:07:47,463:INFO:Checking exceptions
2023-05-21 19:07:47,463:INFO:Importing libraries
2023-05-21 19:07:47,463:INFO:Copying training dataset
2023-05-21 19:07:47,521:INFO:Defining folds
2023-05-21 19:07:47,521:INFO:Declaring metric variables
2023-05-21 19:07:47,522:INFO:Importing untrained model
2023-05-21 19:07:47,523:INFO:Extra Trees Classifier Imported successfully
2023-05-21 19:07:47,523:INFO:Starting cross validation
2023-05-21 19:07:47,527:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 19:07:51,117:INFO:Calculating mean and std
2023-05-21 19:07:51,119:INFO:Creating metrics dataframe
2023-05-21 19:07:51,385:INFO:Uploading results into container
2023-05-21 19:07:51,386:INFO:Uploading model into container now
2023-05-21 19:07:51,387:INFO:_master_model_container: 7
2023-05-21 19:07:51,387:INFO:_display_container: 2
2023-05-21 19:07:51,389:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-05-21 19:07:51,389:INFO:create_model() successfully completed......................................
2023-05-21 19:07:51,497:INFO:SubProcess create_model() end ==================================
2023-05-21 19:07:51,498:INFO:Creating metrics dataframe
2023-05-21 19:07:51,511:INFO:Initializing Light Gradient Boosting Machine
2023-05-21 19:07:51,511:INFO:Total runtime is 0.4751704772313436 minutes
2023-05-21 19:07:51,511:INFO:SubProcess create_model() called ==================================
2023-05-21 19:07:51,512:INFO:Initializing create_model()
2023-05-21 19:07:51,512:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7adf96c370>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7acc4733a0>, model_only=True, return_train_score=False, kwargs={})
2023-05-21 19:07:51,512:INFO:Checking exceptions
2023-05-21 19:07:51,512:INFO:Importing libraries
2023-05-21 19:07:51,512:INFO:Copying training dataset
2023-05-21 19:07:51,570:INFO:Defining folds
2023-05-21 19:07:51,570:INFO:Declaring metric variables
2023-05-21 19:07:51,571:INFO:Importing untrained model
2023-05-21 19:07:51,572:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 19:07:51,573:INFO:Starting cross validation
2023-05-21 19:07:51,576:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 19:07:54,060:INFO:Calculating mean and std
2023-05-21 19:07:54,062:INFO:Creating metrics dataframe
2023-05-21 19:07:54,336:INFO:Uploading results into container
2023-05-21 19:07:54,337:INFO:Uploading model into container now
2023-05-21 19:07:54,338:INFO:_master_model_container: 8
2023-05-21 19:07:54,338:INFO:_display_container: 2
2023-05-21 19:07:54,340:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 19:07:54,340:INFO:create_model() successfully completed......................................
2023-05-21 19:07:54,451:INFO:SubProcess create_model() end ==================================
2023-05-21 19:07:54,452:INFO:Creating metrics dataframe
2023-05-21 19:07:54,471:INFO:Initializing create_model()
2023-05-21 19:07:54,471:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7adf96c370>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-21 19:07:54,471:INFO:Checking exceptions
2023-05-21 19:07:54,472:INFO:Importing libraries
2023-05-21 19:07:54,473:INFO:Copying training dataset
2023-05-21 19:07:54,530:INFO:Defining folds
2023-05-21 19:07:54,531:INFO:Declaring metric variables
2023-05-21 19:07:54,531:INFO:Importing untrained model
2023-05-21 19:07:54,531:INFO:Declaring custom model
2023-05-21 19:07:54,534:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 19:07:54,538:INFO:Cross validation set to False
2023-05-21 19:07:54,538:INFO:Fitting Model
2023-05-21 19:07:54,843:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 19:07:54,843:INFO:create_model() successfully completed......................................
2023-05-21 19:07:54,957:INFO:Creating Dashboard logs
2023-05-21 19:07:54,958:INFO:Model: Light Gradient Boosting Machine
2023-05-21 19:07:55,079:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-21 19:07:55,850:INFO:Initializing predict_model()
2023-05-21 19:07:55,850:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7adf96c370>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7f7ac6af4820>)
2023-05-21 19:07:55,850:INFO:Checking exceptions
2023-05-21 19:07:55,850:INFO:Preloading libraries
2023-05-21 19:07:56,351:INFO:SubProcess plot_model() called ==================================
2023-05-21 19:07:56,353:INFO:Initializing plot_model()
2023-05-21 19:07:56,353:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpub4yu8gg, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7adf96c370>, system=False)
2023-05-21 19:07:56,353:INFO:Checking exceptions
2023-05-21 19:07:56,374:INFO:Preloading libraries
2023-05-21 19:07:56,378:INFO:Copying training dataset
2023-05-21 19:07:56,378:INFO:Plot type: auc
2023-05-21 19:07:57,007:INFO:Fitting Model
2023-05-21 19:07:57,013:INFO:Scoring test/hold-out set
2023-05-21 19:07:57,233:INFO:Saving '/tmp/tmpub4yu8gg/AUC.png'
2023-05-21 19:07:57,898:INFO:Visual Rendered Successfully
2023-05-21 19:07:58,031:INFO:plot_model() successfully completed......................................
2023-05-21 19:07:58,033:INFO:Initializing plot_model()
2023-05-21 19:07:58,033:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpub4yu8gg, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7adf96c370>, system=False)
2023-05-21 19:07:58,033:INFO:Checking exceptions
2023-05-21 19:07:58,057:INFO:Preloading libraries
2023-05-21 19:07:58,065:INFO:Copying training dataset
2023-05-21 19:07:58,066:INFO:Plot type: confusion_matrix
2023-05-21 19:07:58,388:INFO:Fitting Model
2023-05-21 19:07:58,393:INFO:Scoring test/hold-out set
2023-05-21 19:07:58,602:INFO:Saving '/tmp/tmpub4yu8gg/Confusion Matrix.png'
2023-05-21 19:07:58,895:INFO:Visual Rendered Successfully
2023-05-21 19:07:59,019:INFO:plot_model() successfully completed......................................
2023-05-21 19:07:59,021:INFO:Initializing plot_model()
2023-05-21 19:07:59,021:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpub4yu8gg, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7adf96c370>, system=False)
2023-05-21 19:07:59,022:INFO:Checking exceptions
2023-05-21 19:07:59,045:INFO:Preloading libraries
2023-05-21 19:07:59,054:INFO:Copying training dataset
2023-05-21 19:07:59,054:INFO:Plot type: feature
2023-05-21 19:07:59,056:WARNING:No coef_ found. Trying feature_importances_
2023-05-21 19:07:59,314:INFO:Saving '/tmp/tmpub4yu8gg/Feature Importance.png'
2023-05-21 19:07:59,703:INFO:Visual Rendered Successfully
2023-05-21 19:07:59,826:INFO:plot_model() successfully completed......................................
2023-05-21 19:07:59,827:INFO:SubProcess plot_model() end ==================================
2023-05-21 19:07:59,831:WARNING:/home/feuer/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-05-21 19:08:00,492:INFO:Creating Dashboard logs
2023-05-21 19:08:00,493:INFO:Model: Random Forest Classifier
2023-05-21 19:08:00,586:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 19:08:01,826:INFO:Creating Dashboard logs
2023-05-21 19:08:01,827:INFO:Model: Extra Trees Classifier
2023-05-21 19:08:01,938:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-05-21 19:08:03,016:INFO:Creating Dashboard logs
2023-05-21 19:08:03,017:INFO:Model: Decision Tree Classifier
2023-05-21 19:08:03,118:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2023-05-21 19:08:04,314:INFO:Creating Dashboard logs
2023-05-21 19:08:04,314:INFO:Model: Logistic Regression
2023-05-21 19:08:04,430:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-05-21 19:08:05,601:INFO:Creating Dashboard logs
2023-05-21 19:08:05,602:INFO:Model: Linear Discriminant Analysis
2023-05-21 19:08:05,704:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-05-21 19:08:07,059:INFO:Creating Dashboard logs
2023-05-21 19:08:07,059:INFO:Model: Naive Bayes
2023-05-21 19:08:07,205:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-05-21 19:08:08,269:INFO:Creating Dashboard logs
2023-05-21 19:08:08,270:INFO:Model: Ridge Classifier
2023-05-21 19:08:08,509:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2023-05-21 19:08:09,951:INFO:_master_model_container: 8
2023-05-21 19:08:09,951:INFO:_display_container: 2
2023-05-21 19:08:09,953:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 19:08:09,953:INFO:compare_models() successfully completed......................................
2023-05-21 19:08:18,941:INFO:Initializing tune_model()
2023-05-21 19:08:18,942:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=50, custom_grid={'learning_rate': [0.005, 0.01, 0.05, 0.1], 'n_estimators': [8, 16, 24, 32], 'num_leaves': [6, 8, 12, 16], 'boosting_type': ['gbdt', 'dart'], 'objective': ['binary'], 'max_bin': [255, 510], 'random_state': [500], 'colsample_bytree': [0.64, 0.65, 0.66], 'subsample': [0.7, 0.75], 'reg_alpha': [1, 1.2], 'reg_lambda': [1, 1.2, 1.4]}, optimize=AUC, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7adf96c370>)
2023-05-21 19:08:18,942:INFO:Checking exceptions
2023-05-21 19:08:18,942:INFO:Soft dependency imported: optuna: 3.1.1
2023-05-21 19:08:19,817:INFO:Copying training dataset
2023-05-21 19:08:19,857:INFO:Checking base model
2023-05-21 19:08:19,858:INFO:Base model : Light Gradient Boosting Machine
2023-05-21 19:08:19,859:INFO:Declaring metric variables
2023-05-21 19:08:19,859:INFO:Defining Hyperparameters
2023-05-21 19:08:19,992:INFO:custom_grid: {'actual_estimator__learning_rate': CategoricalDistribution(values=[0.005, 0.01, 0.05, 0.1]), 'actual_estimator__n_estimators': CategoricalDistribution(values=[8, 16, 24, 32]), 'actual_estimator__num_leaves': CategoricalDistribution(values=[6, 8, 12, 16]), 'actual_estimator__boosting_type': CategoricalDistribution(values=['gbdt', 'dart']), 'actual_estimator__objective': CategoricalDistribution(values=['binary']), 'actual_estimator__max_bin': CategoricalDistribution(values=[255, 510]), 'actual_estimator__random_state': CategoricalDistribution(values=[500]), 'actual_estimator__colsample_bytree': CategoricalDistribution(values=[0.64, 0.65, 0.66]), 'actual_estimator__subsample': CategoricalDistribution(values=[0.7, 0.75]), 'actual_estimator__reg_alpha': CategoricalDistribution(values=[1, 1.2]), 'actual_estimator__reg_lambda': CategoricalDistribution(values=[1, 1.2, 1.4])}
2023-05-21 19:08:19,992:INFO:Tuning with n_jobs=-1
2023-05-21 19:08:19,993:WARNING:/home/feuer/.local/lib/python3.10/site-packages/optuna/samplers/_tpe/sampler.py:282: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-21 19:08:19,993:WARNING:/home/feuer/.local/lib/python3.10/site-packages/optuna/samplers/_tpe/sampler.py:301: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-21 19:08:19,994:INFO:Initializing optuna.integration.OptunaSearchCV
2023-05-21 19:08:19,999:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:2445: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-05-21 19:08:24,143:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:24,443:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:24,507:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:25,432:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:25,502:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:26,047:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:26,573:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:27,222:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:27,527:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:27,709:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:27,933:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:28,030:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:28,047:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:28,262:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-05-21 19:08:29,045:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:29,137:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:29,551:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:30,417:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:30,465:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:31,071:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.46s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:31,497:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:31,497:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:31,683:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:31,688:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:31,750:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:34,543:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:35,495:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:35,612:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:35,809:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:36,359:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:37,373:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:37,481:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:37,578:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:37,804:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:37,841:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:37,869:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:37,912:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:39,096:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:39,330:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:40,352:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:40,482:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.46s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:40,909:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:41,022:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:41,174:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:41,479:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:41,826:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:41,844:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:41,864:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:41,963:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:44,979:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:45,620:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:45,822:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:45,980:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:47,605:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:47,625:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:47,995:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:48,059:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:48,102:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:48,116:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:48,189:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:48,265:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:49,588:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:49,968:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:50,980:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 2.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:51,190:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:51,207:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 2.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:51,257:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-05-21 19:08:51,296:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:51,536:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:51,628:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:52,350:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:56,614:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:56,625:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:57,669:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:57,833:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:57,840:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:58,229:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:58,259:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:59,062:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:59,308:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:08:59,402:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:08:59,420:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:00,423:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:00,517:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:00,606:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:01,184:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:01,442:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:01,521:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:06,401:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:07,731:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:07,853:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:07,875:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:08,343:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:08,445:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:08,485:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:08,769:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:09,301:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:09,302:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:09,308:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:09,901:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:10,449:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:11,422:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.46s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:11,725:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-05-21 19:09:11,796:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 1.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-05-21 19:09:11,830:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-05-21 19:09:11,859:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:12,801:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:13,120:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:13,342:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:13,446:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:13,669:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:13,767:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:14,232:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:14,301:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:14,302:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:31,357:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:31,535:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:32,272:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:32,392:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:32,615:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:32,672:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:33,928:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:34,167:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:34,831:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:35,274:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:35,477:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:36,413:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:36,620:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:36,778:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:38,615:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:39,193:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:39,271:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:39,297:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:39,763:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:40,767:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:41,764:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:41,843:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:42,048:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:44,248:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:45,720:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:45,730:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:47,467:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:47,906:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:47,918:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:47,929:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:47,933:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:48,944:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:48,995:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:49,034:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:50,445:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:51,000:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:51,151:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:51,256:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:51,284:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:54,102:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:54,182:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:54,872:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:09:58,806:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:59,551:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:59,562:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:59,596:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:09:59,617:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:10:01,002:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:10:01,135:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:10:01,147:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:10:01,297:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:10:01,306:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:10:07,535:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:10:07,659:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:10:07,798:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:10:08,901:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:10:09,106:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:10:28,220:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:10:32,817:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:10:33,173:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:10:33,358:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:10:33,521:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:10:38,740:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:10:38,746:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:10:39,157:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:10:39,158:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:10:50,741:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:10:58,563:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:10:58,661:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:10:58,662:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:10:59,658:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:10:59,666:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:10:59,702:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:11:00,771:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:11:25,809:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:11:28,274:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:11:29,320:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:11:31,897:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:11:40,935:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:11:40,983:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:11:44,040:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-21 19:11:45,023:WARNING:/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:319: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-21 19:12:18,179:INFO:best_params: {'actual_estimator__learning_rate': 0.1, 'actual_estimator__n_estimators': 32, 'actual_estimator__num_leaves': 16, 'actual_estimator__boosting_type': 'gbdt', 'actual_estimator__objective': 'binary', 'actual_estimator__max_bin': 510, 'actual_estimator__random_state': 500, 'actual_estimator__colsample_bytree': 0.66, 'actual_estimator__subsample': 0.75, 'actual_estimator__reg_alpha': 1.2, 'actual_estimator__reg_lambda': 1}
2023-05-21 19:12:18,179:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-05-21 19:12:18,180:WARNING:Traceback (most recent call last):
  File "/home/feuer/.local/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 2674, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-05-21 19:12:18,180:INFO:Hyperparameter search completed
2023-05-21 19:12:18,180:INFO:SubProcess create_model() called ==================================
2023-05-21 19:12:18,182:INFO:Initializing create_model()
2023-05-21 19:12:18,182:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7adf96c370>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7acc704a30>, model_only=True, return_train_score=False, kwargs={'learning_rate': 0.1, 'n_estimators': 32, 'num_leaves': 16, 'boosting_type': 'gbdt', 'objective': 'binary', 'max_bin': 510, 'random_state': 500, 'colsample_bytree': 0.66, 'subsample': 0.75, 'reg_alpha': 1.2, 'reg_lambda': 1})
2023-05-21 19:12:18,182:INFO:Checking exceptions
2023-05-21 19:12:18,182:INFO:Importing libraries
2023-05-21 19:12:18,182:INFO:Copying training dataset
2023-05-21 19:12:18,241:INFO:Defining folds
2023-05-21 19:12:18,241:INFO:Declaring metric variables
2023-05-21 19:12:18,242:INFO:Importing untrained model
2023-05-21 19:12:18,242:INFO:Declaring custom model
2023-05-21 19:12:18,245:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 19:12:18,245:INFO:Starting cross validation
2023-05-21 19:12:18,250:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 19:12:19,897:INFO:Calculating mean and std
2023-05-21 19:12:19,899:INFO:Creating metrics dataframe
2023-05-21 19:12:19,921:INFO:Finalizing model
2023-05-21 19:12:21,442:INFO:Uploading results into container
2023-05-21 19:12:21,449:INFO:Uploading model into container now
2023-05-21 19:12:21,450:INFO:_master_model_container: 9
2023-05-21 19:12:21,450:INFO:_display_container: 3
2023-05-21 19:12:21,452:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.66,
               importance_type='split', learning_rate=0.1, max_bin=510,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=32, n_jobs=-1, num_leaves=16,
               objective='binary', random_state=500, reg_alpha=1.2,
               reg_lambda=1, silent='warn', subsample=0.75,
               subsample_for_bin=200000, subsample_freq=0)
2023-05-21 19:12:21,452:INFO:create_model() successfully completed......................................
2023-05-21 19:12:21,588:INFO:SubProcess create_model() end ==================================
2023-05-21 19:12:21,588:INFO:choose_better activated
2023-05-21 19:12:21,589:INFO:SubProcess create_model() called ==================================
2023-05-21 19:12:21,591:INFO:Initializing create_model()
2023-05-21 19:12:21,591:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7adf96c370>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-21 19:12:21,591:INFO:Checking exceptions
2023-05-21 19:12:21,593:INFO:Importing libraries
2023-05-21 19:12:21,593:INFO:Copying training dataset
2023-05-21 19:12:21,663:INFO:Defining folds
2023-05-21 19:12:21,663:INFO:Declaring metric variables
2023-05-21 19:12:21,663:INFO:Importing untrained model
2023-05-21 19:12:21,663:INFO:Declaring custom model
2023-05-21 19:12:21,667:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-21 19:12:21,667:INFO:Starting cross validation
2023-05-21 19:12:21,672:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-05-21 19:12:23,716:INFO:Calculating mean and std
2023-05-21 19:12:23,718:INFO:Creating metrics dataframe
2023-05-21 19:12:23,726:INFO:Finalizing model
2023-05-21 19:12:24,252:INFO:Uploading results into container
2023-05-21 19:12:24,253:INFO:Uploading model into container now
2023-05-21 19:12:24,255:INFO:_master_model_container: 10
2023-05-21 19:12:24,255:INFO:_display_container: 4
2023-05-21 19:12:24,257:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 19:12:24,257:INFO:create_model() successfully completed......................................
2023-05-21 19:12:24,404:INFO:SubProcess create_model() end ==================================
2023-05-21 19:12:24,407:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.8201
2023-05-21 19:12:24,420:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.66,
               importance_type='split', learning_rate=0.1, max_bin=510,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=32, n_jobs=-1, num_leaves=16,
               objective='binary', random_state=500, reg_alpha=1.2,
               reg_lambda=1, silent='warn', subsample=0.75,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.8147
2023-05-21 19:12:24,422:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2023-05-21 19:12:24,422:INFO:choose_better completed
2023-05-21 19:12:24,422:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-05-21 19:12:24,423:INFO:Creating Dashboard logs
2023-05-21 19:12:24,424:INFO:Model: Light Gradient Boosting Machine
2023-05-21 19:12:24,623:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-05-21 19:12:25,469:INFO:Initializing predict_model()
2023-05-21 19:12:25,470:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7adf96c370>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7f7a9aa6de10>)
2023-05-21 19:12:25,470:INFO:Checking exceptions
2023-05-21 19:12:25,470:INFO:Preloading libraries
2023-05-21 19:12:26,019:INFO:SubProcess plot_model() called ==================================
2023-05-21 19:12:26,021:INFO:Initializing plot_model()
2023-05-21 19:12:26,021:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp5uks7n9u, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7adf96c370>, system=False)
2023-05-21 19:12:26,021:INFO:Checking exceptions
2023-05-21 19:12:26,043:INFO:Preloading libraries
2023-05-21 19:12:26,049:INFO:Copying training dataset
2023-05-21 19:12:26,049:INFO:Plot type: auc
2023-05-21 19:12:26,485:INFO:Fitting Model
2023-05-21 19:12:26,492:INFO:Scoring test/hold-out set
2023-05-21 19:12:26,676:INFO:Saving '/tmp/tmp5uks7n9u/AUC.png'
2023-05-21 19:12:27,192:INFO:Visual Rendered Successfully
2023-05-21 19:12:27,326:INFO:plot_model() successfully completed......................................
2023-05-21 19:12:27,329:INFO:Initializing plot_model()
2023-05-21 19:12:27,329:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp5uks7n9u, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7adf96c370>, system=False)
2023-05-21 19:12:27,329:INFO:Checking exceptions
2023-05-21 19:12:27,353:INFO:Preloading libraries
2023-05-21 19:12:27,361:INFO:Copying training dataset
2023-05-21 19:12:27,361:INFO:Plot type: confusion_matrix
2023-05-21 19:12:27,636:INFO:Fitting Model
2023-05-21 19:12:27,641:INFO:Scoring test/hold-out set
2023-05-21 19:12:27,813:INFO:Saving '/tmp/tmp5uks7n9u/Confusion Matrix.png'
2023-05-21 19:12:28,050:INFO:Visual Rendered Successfully
2023-05-21 19:12:28,188:INFO:plot_model() successfully completed......................................
2023-05-21 19:12:28,190:INFO:Initializing plot_model()
2023-05-21 19:12:28,191:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp5uks7n9u, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7adf96c370>, system=False)
2023-05-21 19:12:28,191:INFO:Checking exceptions
2023-05-21 19:12:28,217:INFO:Preloading libraries
2023-05-21 19:12:28,224:INFO:Copying training dataset
2023-05-21 19:12:28,224:INFO:Plot type: feature
2023-05-21 19:12:28,227:WARNING:No coef_ found. Trying feature_importances_
2023-05-21 19:12:28,402:INFO:Saving '/tmp/tmp5uks7n9u/Feature Importance.png'
2023-05-21 19:12:28,790:INFO:Visual Rendered Successfully
2023-05-21 19:12:28,933:INFO:plot_model() successfully completed......................................
2023-05-21 19:12:28,934:INFO:SubProcess plot_model() end ==================================
2023-05-21 19:12:29,478:INFO:_master_model_container: 10
2023-05-21 19:12:29,478:INFO:_display_container: 3
2023-05-21 19:12:29,480:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-21 19:12:29,480:INFO:tune_model() successfully completed......................................
